{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f295a39db00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdate\n",
    "%matplotlib inline \n",
    "\n",
    "# 加载数据\n",
    "path = \"./dataSets/train-test.csv\"\n",
    "# skipfooter=3\n",
    "dataset = pd.read_csv(path, usecols=[1])\n",
    "dataset = np.array(dataset)\n",
    "plt.plot(dataset)\n",
    "plt.show()\n",
    "\n",
    "# normalize the dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataSet = scaler.fit_transform(dataset)\n",
    "\n",
    "# split into train and test sets; 80% 是训练数据，其余是测试数据\n",
    "train_size = int(len(dataSet) * 0.8)\n",
    "test_size = len(dataSet) - train_size\n",
    "train, test = dataSet[0:train_size], dataSet[train_size:len(dataSet)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据格式转化(t,t+1)\n",
    "def convert_data(data, time_step=1):\n",
    "    data_X,data_Y = [],[]  \n",
    "    for i in range(len(data) - time_step - 1):\n",
    "        x = data[i: (i + time_step)]  \n",
    "        y = data[i+1:i + time_step+1]      \n",
    "        data_X.append(x.tolist())\n",
    "        data_Y.append(y.tolist()) \n",
    "    return data_X, data_Y\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)\n",
    "\n",
    "# use this function to prepare the train and test datasets for modeling\n",
    "#time_step=5\n",
    "time_step = 5     #时间步\n",
    "train_x, train_y = convert_data(train, time_step)\n",
    "test_x, test_y = convert_data(test, time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#———————————————————形成训练集—————————————————————\n",
    "#设置常量\n",
    "hidden_unit = 5       #hidden layer units 记忆和储存过去状态的节点个数\n",
    "batch_size = 4    #每一批次训练多少个样例\n",
    "input_size = 1      #输入层维度\n",
    "output_size = 1     #输出层维度\n",
    "lr = 0.0001       #学习率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow运行版本：1.3.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "print(\"tensorflow运行版本：\" + tf.__version__)\n",
    "\n",
    "# LSTM 的 X 需要有这样的结构： [samples, time steps, features]，所以做一下变换\n",
    "with tf.name_scope('inputs'):\n",
    "    X = tf.placeholder(tf.float32, [None,time_step,input_size])    #每批次输入网络的tensor\n",
    "    Y = tf.placeholder(tf.float32, [None,time_step,output_size])   #每批次tensor对应的标签\n",
    "# 输入层、输出层权重、偏置\n",
    "with tf.name_scope('layer'):\n",
    "        with tf.name_scope('weights'):\n",
    "            weights={\n",
    "                     'in':tf.Variable(tf.random_normal([input_size,hidden_unit])),\n",
    "                     'out':tf.Variable(tf.random_normal([hidden_unit,1]))\n",
    "                     }\n",
    "        with tf.name_scope('biases'):\n",
    "            biases={\n",
    "                    'in':tf.Variable(tf.constant(0.1,shape=[hidden_unit,])),\n",
    "                    'out':tf.Variable(tf.constant(0.1,shape=[1,]))\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm(batch):  #参数：输入网络批次数目\n",
    "\n",
    "  \n",
    "    w_in = weights['in']\n",
    "    b_in = biases['in']\n",
    "    input = tf.reshape(X,[-1,input_size])  #需要将tensor转成2维进行计算，计算后的结果作为隐藏层的输入\n",
    "    with tf.variable_scope(tf.get_variable_scope()) as scope:\n",
    "        \n",
    "        lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(hidden_unit) #10个节点\n",
    "        input_lstm = tf.matmul(input, w_in) + b_in\n",
    "        input_lstm = tf.reshape(input_lstm, [-1, time_step, hidden_unit])  #将tensor转成3维，作为lstm cell的输入      \n",
    "        print(input_lstm)\n",
    "        init_state = lstm_cell.zero_state(batch,dtype = tf.float32)\n",
    "        # output_rnn是记录lstm每个隐状态输出节点的结果，final_states是最后一个cell的结果，数据格式为tuple\n",
    "        output_rnn, final_states = tf.nn.dynamic_rnn(\n",
    "            lstm_cell, \n",
    "            input_lstm, \n",
    "            initial_state = init_state, \n",
    "            dtype = tf.float32) \n",
    "        \n",
    "        output = tf.reshape(output_rnn, [-1, hidden_unit]) #  作为输出层的输入\n",
    "        w_out = weights['out']\n",
    "        b_out = biases['out']\n",
    "        #matmul做矩阵乘法\n",
    "        pred = tf.matmul(output, w_out) + b_out\n",
    "        return pred, final_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "def train_lstm():   \n",
    "    global batch_size\n",
    "    iteration = 1\n",
    "    epochs = 10000\n",
    "    log_dir = './predict_logs'\n",
    "    with tf.variable_scope(\"rnn\"):\n",
    "        pred, _ = lstm(batch_size)\n",
    "    # 损失函数\n",
    "    loss = tf.reduce_mean(tf.square(tf.reshape(pred,[-1])-tf.reshape(Y, [-1])))\n",
    "    #tf.summary.scalar('loss_function', loss)\n",
    "    train_op = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "    saver = tf.train.Saver(tf.global_variables())\n",
    "    with tf.Session() as sess:\n",
    "        keep_prob = tf.placeholder(tf.float32)\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        # summaries合并\n",
    "        #merged = tf.summary.merge_all()    \n",
    "        # 写到指定的磁盘路径中\n",
    "        #train_writer = tf.summary.FileWriter(log_dir + '/train', sess.graph)\n",
    "        # 重复训练5000次\n",
    "        for e in range(epochs):\n",
    "            step=0\n",
    "            start = 0\n",
    "            end = start + batch_size\n",
    "            while(end < len(train_x)):\n",
    "                x = train_x[start:end]\n",
    "                y = train_y[start:end]\n",
    "                _,loss_ = sess.run([train_op, loss], feed_dict = {X: x, Y:y, keep_prob : 0.3})\n",
    "                start += batch_size\n",
    "                end = start + batch_size\n",
    "                # 每10步保存一次参数\n",
    "                if step% 10 == 0:                    \n",
    "                    print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                    \"Iteration: {:d}\".format(iteration),\n",
    "                    \"Train loss: {:6f}\".format(loss_))\n",
    "                    #train_writer.add_summary(summary, e);\n",
    "\n",
    "                train_loss.append(loss_)\n",
    "                iteration += 1  \n",
    "                step += 1\n",
    "        saver.save(sess, \"checkpoints-lstm/predict.ckpt\")\n",
    "        #绘训练过程指标图\n",
    "        t = np.arange(iteration - 1)\n",
    "        plt.figure(figsize = (9,6))\n",
    "        plt.plot(t, np.array(train_loss),  'r-')\n",
    "        plt.xlabel(\"iteration\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend(['train'], loc='upper right')\n",
    "        plt.show()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"rnn_1/rnn/rnn/Reshape:0\", shape=(?, 5, 5), dtype=float32)\n",
      "Epoch: 0/10000 Iteration: 1 Train loss: 0.148118\n",
      "Epoch: 1/10000 Iteration: 8 Train loss: 0.142498\n",
      "Epoch: 2/10000 Iteration: 15 Train loss: 0.137152\n",
      "Epoch: 3/10000 Iteration: 22 Train loss: 0.131953\n",
      "Epoch: 4/10000 Iteration: 29 Train loss: 0.126902\n",
      "Epoch: 5/10000 Iteration: 36 Train loss: 0.122004\n",
      "Epoch: 6/10000 Iteration: 43 Train loss: 0.117260\n",
      "Epoch: 7/10000 Iteration: 50 Train loss: 0.112671\n",
      "Epoch: 8/10000 Iteration: 57 Train loss: 0.108236\n",
      "Epoch: 9/10000 Iteration: 64 Train loss: 0.103952\n",
      "Epoch: 10/10000 Iteration: 71 Train loss: 0.099818\n",
      "Epoch: 11/10000 Iteration: 78 Train loss: 0.095831\n",
      "Epoch: 12/10000 Iteration: 85 Train loss: 0.091987\n",
      "Epoch: 13/10000 Iteration: 92 Train loss: 0.088285\n",
      "Epoch: 14/10000 Iteration: 99 Train loss: 0.084720\n",
      "Epoch: 15/10000 Iteration: 106 Train loss: 0.081289\n",
      "Epoch: 16/10000 Iteration: 113 Train loss: 0.077990\n",
      "Epoch: 17/10000 Iteration: 120 Train loss: 0.074820\n",
      "Epoch: 18/10000 Iteration: 127 Train loss: 0.071774\n",
      "Epoch: 19/10000 Iteration: 134 Train loss: 0.068851\n",
      "Epoch: 20/10000 Iteration: 141 Train loss: 0.066046\n",
      "Epoch: 21/10000 Iteration: 148 Train loss: 0.063357\n",
      "Epoch: 22/10000 Iteration: 155 Train loss: 0.060781\n",
      "Epoch: 23/10000 Iteration: 162 Train loss: 0.058314\n",
      "Epoch: 24/10000 Iteration: 169 Train loss: 0.055953\n",
      "Epoch: 25/10000 Iteration: 176 Train loss: 0.053696\n",
      "Epoch: 26/10000 Iteration: 183 Train loss: 0.051539\n",
      "Epoch: 27/10000 Iteration: 190 Train loss: 0.049479\n",
      "Epoch: 28/10000 Iteration: 197 Train loss: 0.047514\n",
      "Epoch: 29/10000 Iteration: 204 Train loss: 0.045640\n",
      "Epoch: 30/10000 Iteration: 211 Train loss: 0.043854\n",
      "Epoch: 31/10000 Iteration: 218 Train loss: 0.042154\n",
      "Epoch: 32/10000 Iteration: 225 Train loss: 0.040536\n",
      "Epoch: 33/10000 Iteration: 232 Train loss: 0.038998\n",
      "Epoch: 34/10000 Iteration: 239 Train loss: 0.037538\n",
      "Epoch: 35/10000 Iteration: 246 Train loss: 0.036151\n",
      "Epoch: 36/10000 Iteration: 253 Train loss: 0.034836\n",
      "Epoch: 37/10000 Iteration: 260 Train loss: 0.033590\n",
      "Epoch: 38/10000 Iteration: 267 Train loss: 0.032410\n",
      "Epoch: 39/10000 Iteration: 274 Train loss: 0.031294\n",
      "Epoch: 40/10000 Iteration: 281 Train loss: 0.030239\n",
      "Epoch: 41/10000 Iteration: 288 Train loss: 0.029242\n",
      "Epoch: 42/10000 Iteration: 295 Train loss: 0.028302\n",
      "Epoch: 43/10000 Iteration: 302 Train loss: 0.027416\n",
      "Epoch: 44/10000 Iteration: 309 Train loss: 0.026581\n",
      "Epoch: 45/10000 Iteration: 316 Train loss: 0.025795\n",
      "Epoch: 46/10000 Iteration: 323 Train loss: 0.025056\n",
      "Epoch: 47/10000 Iteration: 330 Train loss: 0.024362\n",
      "Epoch: 48/10000 Iteration: 337 Train loss: 0.023710\n",
      "Epoch: 49/10000 Iteration: 344 Train loss: 0.023099\n",
      "Epoch: 50/10000 Iteration: 351 Train loss: 0.022527\n",
      "Epoch: 51/10000 Iteration: 358 Train loss: 0.021991\n",
      "Epoch: 52/10000 Iteration: 365 Train loss: 0.021490\n",
      "Epoch: 53/10000 Iteration: 372 Train loss: 0.021022\n",
      "Epoch: 54/10000 Iteration: 379 Train loss: 0.020585\n",
      "Epoch: 55/10000 Iteration: 386 Train loss: 0.020178\n",
      "Epoch: 56/10000 Iteration: 393 Train loss: 0.019798\n",
      "Epoch: 57/10000 Iteration: 400 Train loss: 0.019445\n",
      "Epoch: 58/10000 Iteration: 407 Train loss: 0.019116\n",
      "Epoch: 59/10000 Iteration: 414 Train loss: 0.018811\n",
      "Epoch: 60/10000 Iteration: 421 Train loss: 0.018527\n",
      "Epoch: 61/10000 Iteration: 428 Train loss: 0.018264\n",
      "Epoch: 62/10000 Iteration: 435 Train loss: 0.018020\n",
      "Epoch: 63/10000 Iteration: 442 Train loss: 0.017794\n",
      "Epoch: 64/10000 Iteration: 449 Train loss: 0.017585\n",
      "Epoch: 65/10000 Iteration: 456 Train loss: 0.017392\n",
      "Epoch: 66/10000 Iteration: 463 Train loss: 0.017213\n",
      "Epoch: 67/10000 Iteration: 470 Train loss: 0.017048\n",
      "Epoch: 68/10000 Iteration: 477 Train loss: 0.016895\n",
      "Epoch: 69/10000 Iteration: 484 Train loss: 0.016754\n",
      "Epoch: 70/10000 Iteration: 491 Train loss: 0.016624\n",
      "Epoch: 71/10000 Iteration: 498 Train loss: 0.016505\n",
      "Epoch: 72/10000 Iteration: 505 Train loss: 0.016394\n",
      "Epoch: 73/10000 Iteration: 512 Train loss: 0.016292\n",
      "Epoch: 74/10000 Iteration: 519 Train loss: 0.016198\n",
      "Epoch: 75/10000 Iteration: 526 Train loss: 0.016112\n",
      "Epoch: 76/10000 Iteration: 533 Train loss: 0.016032\n",
      "Epoch: 77/10000 Iteration: 540 Train loss: 0.015958\n",
      "Epoch: 78/10000 Iteration: 547 Train loss: 0.015889\n",
      "Epoch: 79/10000 Iteration: 554 Train loss: 0.015826\n",
      "Epoch: 80/10000 Iteration: 561 Train loss: 0.015768\n",
      "Epoch: 81/10000 Iteration: 568 Train loss: 0.015714\n",
      "Epoch: 82/10000 Iteration: 575 Train loss: 0.015663\n",
      "Epoch: 83/10000 Iteration: 582 Train loss: 0.015616\n",
      "Epoch: 84/10000 Iteration: 589 Train loss: 0.015573\n",
      "Epoch: 85/10000 Iteration: 596 Train loss: 0.015532\n",
      "Epoch: 86/10000 Iteration: 603 Train loss: 0.015493\n",
      "Epoch: 87/10000 Iteration: 610 Train loss: 0.015457\n",
      "Epoch: 88/10000 Iteration: 617 Train loss: 0.015423\n",
      "Epoch: 89/10000 Iteration: 624 Train loss: 0.015391\n",
      "Epoch: 90/10000 Iteration: 631 Train loss: 0.015360\n",
      "Epoch: 91/10000 Iteration: 638 Train loss: 0.015330\n",
      "Epoch: 92/10000 Iteration: 645 Train loss: 0.015302\n",
      "Epoch: 93/10000 Iteration: 652 Train loss: 0.015274\n",
      "Epoch: 94/10000 Iteration: 659 Train loss: 0.015248\n",
      "Epoch: 95/10000 Iteration: 666 Train loss: 0.015222\n",
      "Epoch: 96/10000 Iteration: 673 Train loss: 0.015197\n",
      "Epoch: 97/10000 Iteration: 680 Train loss: 0.015172\n",
      "Epoch: 98/10000 Iteration: 687 Train loss: 0.015148\n",
      "Epoch: 99/10000 Iteration: 694 Train loss: 0.015124\n",
      "Epoch: 100/10000 Iteration: 701 Train loss: 0.015100\n",
      "Epoch: 101/10000 Iteration: 708 Train loss: 0.015076\n",
      "Epoch: 102/10000 Iteration: 715 Train loss: 0.015052\n",
      "Epoch: 103/10000 Iteration: 722 Train loss: 0.015029\n",
      "Epoch: 104/10000 Iteration: 729 Train loss: 0.015005\n",
      "Epoch: 105/10000 Iteration: 736 Train loss: 0.014981\n",
      "Epoch: 106/10000 Iteration: 743 Train loss: 0.014957\n",
      "Epoch: 107/10000 Iteration: 750 Train loss: 0.014933\n",
      "Epoch: 108/10000 Iteration: 757 Train loss: 0.014908\n",
      "Epoch: 109/10000 Iteration: 764 Train loss: 0.014883\n",
      "Epoch: 110/10000 Iteration: 771 Train loss: 0.014858\n",
      "Epoch: 111/10000 Iteration: 778 Train loss: 0.014833\n",
      "Epoch: 112/10000 Iteration: 785 Train loss: 0.014807\n",
      "Epoch: 113/10000 Iteration: 792 Train loss: 0.014781\n",
      "Epoch: 114/10000 Iteration: 799 Train loss: 0.014755\n",
      "Epoch: 115/10000 Iteration: 806 Train loss: 0.014728\n",
      "Epoch: 116/10000 Iteration: 813 Train loss: 0.014701\n",
      "Epoch: 117/10000 Iteration: 820 Train loss: 0.014673\n",
      "Epoch: 118/10000 Iteration: 827 Train loss: 0.014645\n",
      "Epoch: 119/10000 Iteration: 834 Train loss: 0.014617\n",
      "Epoch: 120/10000 Iteration: 841 Train loss: 0.014588\n",
      "Epoch: 121/10000 Iteration: 848 Train loss: 0.014559\n",
      "Epoch: 122/10000 Iteration: 855 Train loss: 0.014530\n",
      "Epoch: 123/10000 Iteration: 862 Train loss: 0.014500\n",
      "Epoch: 124/10000 Iteration: 869 Train loss: 0.014470\n",
      "Epoch: 125/10000 Iteration: 876 Train loss: 0.014439\n",
      "Epoch: 126/10000 Iteration: 883 Train loss: 0.014408\n",
      "Epoch: 127/10000 Iteration: 890 Train loss: 0.014377\n",
      "Epoch: 128/10000 Iteration: 897 Train loss: 0.014346\n",
      "Epoch: 129/10000 Iteration: 904 Train loss: 0.014314\n",
      "Epoch: 130/10000 Iteration: 911 Train loss: 0.014282\n",
      "Epoch: 131/10000 Iteration: 918 Train loss: 0.014249\n",
      "Epoch: 132/10000 Iteration: 925 Train loss: 0.014216\n",
      "Epoch: 133/10000 Iteration: 932 Train loss: 0.014183\n",
      "Epoch: 134/10000 Iteration: 939 Train loss: 0.014150\n",
      "Epoch: 135/10000 Iteration: 946 Train loss: 0.014116\n",
      "Epoch: 136/10000 Iteration: 953 Train loss: 0.014082\n",
      "Epoch: 137/10000 Iteration: 960 Train loss: 0.014048\n",
      "Epoch: 138/10000 Iteration: 967 Train loss: 0.014014\n",
      "Epoch: 139/10000 Iteration: 974 Train loss: 0.013979\n",
      "Epoch: 140/10000 Iteration: 981 Train loss: 0.013944\n",
      "Epoch: 141/10000 Iteration: 988 Train loss: 0.013909\n",
      "Epoch: 142/10000 Iteration: 995 Train loss: 0.013874\n",
      "Epoch: 143/10000 Iteration: 1002 Train loss: 0.013838\n",
      "Epoch: 144/10000 Iteration: 1009 Train loss: 0.013803\n",
      "Epoch: 145/10000 Iteration: 1016 Train loss: 0.013767\n",
      "Epoch: 146/10000 Iteration: 1023 Train loss: 0.013731\n",
      "Epoch: 147/10000 Iteration: 1030 Train loss: 0.013694\n",
      "Epoch: 148/10000 Iteration: 1037 Train loss: 0.013658\n",
      "Epoch: 149/10000 Iteration: 1044 Train loss: 0.013622\n",
      "Epoch: 150/10000 Iteration: 1051 Train loss: 0.013585\n",
      "Epoch: 151/10000 Iteration: 1058 Train loss: 0.013548\n",
      "Epoch: 152/10000 Iteration: 1065 Train loss: 0.013511\n",
      "Epoch: 153/10000 Iteration: 1072 Train loss: 0.013474\n",
      "Epoch: 154/10000 Iteration: 1079 Train loss: 0.013437\n",
      "Epoch: 155/10000 Iteration: 1086 Train loss: 0.013400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 156/10000 Iteration: 1093 Train loss: 0.013363\n",
      "Epoch: 157/10000 Iteration: 1100 Train loss: 0.013325\n",
      "Epoch: 158/10000 Iteration: 1107 Train loss: 0.013288\n",
      "Epoch: 159/10000 Iteration: 1114 Train loss: 0.013251\n",
      "Epoch: 160/10000 Iteration: 1121 Train loss: 0.013213\n",
      "Epoch: 161/10000 Iteration: 1128 Train loss: 0.013175\n",
      "Epoch: 162/10000 Iteration: 1135 Train loss: 0.013138\n",
      "Epoch: 163/10000 Iteration: 1142 Train loss: 0.013100\n",
      "Epoch: 164/10000 Iteration: 1149 Train loss: 0.013062\n",
      "Epoch: 165/10000 Iteration: 1156 Train loss: 0.013024\n",
      "Epoch: 166/10000 Iteration: 1163 Train loss: 0.012987\n",
      "Epoch: 167/10000 Iteration: 1170 Train loss: 0.012949\n",
      "Epoch: 168/10000 Iteration: 1177 Train loss: 0.012911\n",
      "Epoch: 169/10000 Iteration: 1184 Train loss: 0.012873\n",
      "Epoch: 170/10000 Iteration: 1191 Train loss: 0.012835\n",
      "Epoch: 171/10000 Iteration: 1198 Train loss: 0.012797\n",
      "Epoch: 172/10000 Iteration: 1205 Train loss: 0.012760\n",
      "Epoch: 173/10000 Iteration: 1212 Train loss: 0.012722\n",
      "Epoch: 174/10000 Iteration: 1219 Train loss: 0.012684\n",
      "Epoch: 175/10000 Iteration: 1226 Train loss: 0.012646\n",
      "Epoch: 176/10000 Iteration: 1233 Train loss: 0.012608\n",
      "Epoch: 177/10000 Iteration: 1240 Train loss: 0.012570\n",
      "Epoch: 178/10000 Iteration: 1247 Train loss: 0.012533\n",
      "Epoch: 179/10000 Iteration: 1254 Train loss: 0.012495\n",
      "Epoch: 180/10000 Iteration: 1261 Train loss: 0.012457\n",
      "Epoch: 181/10000 Iteration: 1268 Train loss: 0.012419\n",
      "Epoch: 182/10000 Iteration: 1275 Train loss: 0.012382\n",
      "Epoch: 183/10000 Iteration: 1282 Train loss: 0.012344\n",
      "Epoch: 184/10000 Iteration: 1289 Train loss: 0.012307\n",
      "Epoch: 185/10000 Iteration: 1296 Train loss: 0.012269\n",
      "Epoch: 186/10000 Iteration: 1303 Train loss: 0.012232\n",
      "Epoch: 187/10000 Iteration: 1310 Train loss: 0.012194\n",
      "Epoch: 188/10000 Iteration: 1317 Train loss: 0.012157\n",
      "Epoch: 189/10000 Iteration: 1324 Train loss: 0.012120\n",
      "Epoch: 190/10000 Iteration: 1331 Train loss: 0.012082\n",
      "Epoch: 191/10000 Iteration: 1338 Train loss: 0.012045\n",
      "Epoch: 192/10000 Iteration: 1345 Train loss: 0.012008\n",
      "Epoch: 193/10000 Iteration: 1352 Train loss: 0.011971\n",
      "Epoch: 194/10000 Iteration: 1359 Train loss: 0.011934\n",
      "Epoch: 195/10000 Iteration: 1366 Train loss: 0.011897\n",
      "Epoch: 196/10000 Iteration: 1373 Train loss: 0.011860\n",
      "Epoch: 197/10000 Iteration: 1380 Train loss: 0.011823\n",
      "Epoch: 198/10000 Iteration: 1387 Train loss: 0.011786\n",
      "Epoch: 199/10000 Iteration: 1394 Train loss: 0.011750\n",
      "Epoch: 200/10000 Iteration: 1401 Train loss: 0.011713\n",
      "Epoch: 201/10000 Iteration: 1408 Train loss: 0.011677\n",
      "Epoch: 202/10000 Iteration: 1415 Train loss: 0.011640\n",
      "Epoch: 203/10000 Iteration: 1422 Train loss: 0.011604\n",
      "Epoch: 204/10000 Iteration: 1429 Train loss: 0.011568\n",
      "Epoch: 205/10000 Iteration: 1436 Train loss: 0.011531\n",
      "Epoch: 206/10000 Iteration: 1443 Train loss: 0.011495\n",
      "Epoch: 207/10000 Iteration: 1450 Train loss: 0.011459\n",
      "Epoch: 208/10000 Iteration: 1457 Train loss: 0.011423\n",
      "Epoch: 209/10000 Iteration: 1464 Train loss: 0.011387\n",
      "Epoch: 210/10000 Iteration: 1471 Train loss: 0.011352\n",
      "Epoch: 211/10000 Iteration: 1478 Train loss: 0.011316\n",
      "Epoch: 212/10000 Iteration: 1485 Train loss: 0.011280\n",
      "Epoch: 213/10000 Iteration: 1492 Train loss: 0.011245\n",
      "Epoch: 214/10000 Iteration: 1499 Train loss: 0.011209\n",
      "Epoch: 215/10000 Iteration: 1506 Train loss: 0.011174\n",
      "Epoch: 216/10000 Iteration: 1513 Train loss: 0.011139\n",
      "Epoch: 217/10000 Iteration: 1520 Train loss: 0.011103\n",
      "Epoch: 218/10000 Iteration: 1527 Train loss: 0.011068\n",
      "Epoch: 219/10000 Iteration: 1534 Train loss: 0.011033\n",
      "Epoch: 220/10000 Iteration: 1541 Train loss: 0.010998\n",
      "Epoch: 221/10000 Iteration: 1548 Train loss: 0.010964\n",
      "Epoch: 222/10000 Iteration: 1555 Train loss: 0.010929\n",
      "Epoch: 223/10000 Iteration: 1562 Train loss: 0.010894\n",
      "Epoch: 224/10000 Iteration: 1569 Train loss: 0.010860\n",
      "Epoch: 225/10000 Iteration: 1576 Train loss: 0.010825\n",
      "Epoch: 226/10000 Iteration: 1583 Train loss: 0.010791\n",
      "Epoch: 227/10000 Iteration: 1590 Train loss: 0.010757\n",
      "Epoch: 228/10000 Iteration: 1597 Train loss: 0.010723\n",
      "Epoch: 229/10000 Iteration: 1604 Train loss: 0.010689\n",
      "Epoch: 230/10000 Iteration: 1611 Train loss: 0.010655\n",
      "Epoch: 231/10000 Iteration: 1618 Train loss: 0.010621\n",
      "Epoch: 232/10000 Iteration: 1625 Train loss: 0.010587\n",
      "Epoch: 233/10000 Iteration: 1632 Train loss: 0.010554\n",
      "Epoch: 234/10000 Iteration: 1639 Train loss: 0.010520\n",
      "Epoch: 235/10000 Iteration: 1646 Train loss: 0.010487\n",
      "Epoch: 236/10000 Iteration: 1653 Train loss: 0.010453\n",
      "Epoch: 237/10000 Iteration: 1660 Train loss: 0.010420\n",
      "Epoch: 238/10000 Iteration: 1667 Train loss: 0.010387\n",
      "Epoch: 239/10000 Iteration: 1674 Train loss: 0.010354\n",
      "Epoch: 240/10000 Iteration: 1681 Train loss: 0.010321\n",
      "Epoch: 241/10000 Iteration: 1688 Train loss: 0.010288\n",
      "Epoch: 242/10000 Iteration: 1695 Train loss: 0.010255\n",
      "Epoch: 243/10000 Iteration: 1702 Train loss: 0.010223\n",
      "Epoch: 244/10000 Iteration: 1709 Train loss: 0.010190\n",
      "Epoch: 245/10000 Iteration: 1716 Train loss: 0.010158\n",
      "Epoch: 246/10000 Iteration: 1723 Train loss: 0.010126\n",
      "Epoch: 247/10000 Iteration: 1730 Train loss: 0.010093\n",
      "Epoch: 248/10000 Iteration: 1737 Train loss: 0.010061\n",
      "Epoch: 249/10000 Iteration: 1744 Train loss: 0.010029\n",
      "Epoch: 250/10000 Iteration: 1751 Train loss: 0.009997\n",
      "Epoch: 251/10000 Iteration: 1758 Train loss: 0.009966\n",
      "Epoch: 252/10000 Iteration: 1765 Train loss: 0.009934\n",
      "Epoch: 253/10000 Iteration: 1772 Train loss: 0.009902\n",
      "Epoch: 254/10000 Iteration: 1779 Train loss: 0.009871\n",
      "Epoch: 255/10000 Iteration: 1786 Train loss: 0.009840\n",
      "Epoch: 256/10000 Iteration: 1793 Train loss: 0.009808\n",
      "Epoch: 257/10000 Iteration: 1800 Train loss: 0.009777\n",
      "Epoch: 258/10000 Iteration: 1807 Train loss: 0.009746\n",
      "Epoch: 259/10000 Iteration: 1814 Train loss: 0.009715\n",
      "Epoch: 260/10000 Iteration: 1821 Train loss: 0.009685\n",
      "Epoch: 261/10000 Iteration: 1828 Train loss: 0.009654\n",
      "Epoch: 262/10000 Iteration: 1835 Train loss: 0.009623\n",
      "Epoch: 263/10000 Iteration: 1842 Train loss: 0.009593\n",
      "Epoch: 264/10000 Iteration: 1849 Train loss: 0.009562\n",
      "Epoch: 265/10000 Iteration: 1856 Train loss: 0.009532\n",
      "Epoch: 266/10000 Iteration: 1863 Train loss: 0.009502\n",
      "Epoch: 267/10000 Iteration: 1870 Train loss: 0.009472\n",
      "Epoch: 268/10000 Iteration: 1877 Train loss: 0.009442\n",
      "Epoch: 269/10000 Iteration: 1884 Train loss: 0.009412\n",
      "Epoch: 270/10000 Iteration: 1891 Train loss: 0.009382\n",
      "Epoch: 271/10000 Iteration: 1898 Train loss: 0.009353\n",
      "Epoch: 272/10000 Iteration: 1905 Train loss: 0.009323\n",
      "Epoch: 273/10000 Iteration: 1912 Train loss: 0.009294\n",
      "Epoch: 274/10000 Iteration: 1919 Train loss: 0.009264\n",
      "Epoch: 275/10000 Iteration: 1926 Train loss: 0.009235\n",
      "Epoch: 276/10000 Iteration: 1933 Train loss: 0.009206\n",
      "Epoch: 277/10000 Iteration: 1940 Train loss: 0.009177\n",
      "Epoch: 278/10000 Iteration: 1947 Train loss: 0.009148\n",
      "Epoch: 279/10000 Iteration: 1954 Train loss: 0.009120\n",
      "Epoch: 280/10000 Iteration: 1961 Train loss: 0.009091\n",
      "Epoch: 281/10000 Iteration: 1968 Train loss: 0.009062\n",
      "Epoch: 282/10000 Iteration: 1975 Train loss: 0.009034\n",
      "Epoch: 283/10000 Iteration: 1982 Train loss: 0.009006\n",
      "Epoch: 284/10000 Iteration: 1989 Train loss: 0.008978\n",
      "Epoch: 285/10000 Iteration: 1996 Train loss: 0.008949\n",
      "Epoch: 286/10000 Iteration: 2003 Train loss: 0.008921\n",
      "Epoch: 287/10000 Iteration: 2010 Train loss: 0.008894\n",
      "Epoch: 288/10000 Iteration: 2017 Train loss: 0.008866\n",
      "Epoch: 289/10000 Iteration: 2024 Train loss: 0.008838\n",
      "Epoch: 290/10000 Iteration: 2031 Train loss: 0.008811\n",
      "Epoch: 291/10000 Iteration: 2038 Train loss: 0.008783\n",
      "Epoch: 292/10000 Iteration: 2045 Train loss: 0.008756\n",
      "Epoch: 293/10000 Iteration: 2052 Train loss: 0.008729\n",
      "Epoch: 294/10000 Iteration: 2059 Train loss: 0.008702\n",
      "Epoch: 295/10000 Iteration: 2066 Train loss: 0.008675\n",
      "Epoch: 296/10000 Iteration: 2073 Train loss: 0.008648\n",
      "Epoch: 297/10000 Iteration: 2080 Train loss: 0.008621\n",
      "Epoch: 298/10000 Iteration: 2087 Train loss: 0.008594\n",
      "Epoch: 299/10000 Iteration: 2094 Train loss: 0.008568\n",
      "Epoch: 300/10000 Iteration: 2101 Train loss: 0.008542\n",
      "Epoch: 301/10000 Iteration: 2108 Train loss: 0.008515\n",
      "Epoch: 302/10000 Iteration: 2115 Train loss: 0.008489\n",
      "Epoch: 303/10000 Iteration: 2122 Train loss: 0.008463\n",
      "Epoch: 304/10000 Iteration: 2129 Train loss: 0.008437\n",
      "Epoch: 305/10000 Iteration: 2136 Train loss: 0.008411\n",
      "Epoch: 306/10000 Iteration: 2143 Train loss: 0.008386\n",
      "Epoch: 307/10000 Iteration: 2150 Train loss: 0.008360\n",
      "Epoch: 308/10000 Iteration: 2157 Train loss: 0.008334\n",
      "Epoch: 309/10000 Iteration: 2164 Train loss: 0.008309\n",
      "Epoch: 310/10000 Iteration: 2171 Train loss: 0.008284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 311/10000 Iteration: 2178 Train loss: 0.008259\n",
      "Epoch: 312/10000 Iteration: 2185 Train loss: 0.008234\n",
      "Epoch: 313/10000 Iteration: 2192 Train loss: 0.008209\n",
      "Epoch: 314/10000 Iteration: 2199 Train loss: 0.008184\n",
      "Epoch: 315/10000 Iteration: 2206 Train loss: 0.008159\n",
      "Epoch: 316/10000 Iteration: 2213 Train loss: 0.008134\n",
      "Epoch: 317/10000 Iteration: 2220 Train loss: 0.008110\n",
      "Epoch: 318/10000 Iteration: 2227 Train loss: 0.008086\n",
      "Epoch: 319/10000 Iteration: 2234 Train loss: 0.008061\n",
      "Epoch: 320/10000 Iteration: 2241 Train loss: 0.008037\n",
      "Epoch: 321/10000 Iteration: 2248 Train loss: 0.008013\n",
      "Epoch: 322/10000 Iteration: 2255 Train loss: 0.007989\n",
      "Epoch: 323/10000 Iteration: 2262 Train loss: 0.007966\n",
      "Epoch: 324/10000 Iteration: 2269 Train loss: 0.007942\n",
      "Epoch: 325/10000 Iteration: 2276 Train loss: 0.007918\n",
      "Epoch: 326/10000 Iteration: 2283 Train loss: 0.007895\n",
      "Epoch: 327/10000 Iteration: 2290 Train loss: 0.007872\n",
      "Epoch: 328/10000 Iteration: 2297 Train loss: 0.007848\n",
      "Epoch: 329/10000 Iteration: 2304 Train loss: 0.007825\n",
      "Epoch: 330/10000 Iteration: 2311 Train loss: 0.007802\n",
      "Epoch: 331/10000 Iteration: 2318 Train loss: 0.007779\n",
      "Epoch: 332/10000 Iteration: 2325 Train loss: 0.007757\n",
      "Epoch: 333/10000 Iteration: 2332 Train loss: 0.007734\n",
      "Epoch: 334/10000 Iteration: 2339 Train loss: 0.007711\n",
      "Epoch: 335/10000 Iteration: 2346 Train loss: 0.007689\n",
      "Epoch: 336/10000 Iteration: 2353 Train loss: 0.007667\n",
      "Epoch: 337/10000 Iteration: 2360 Train loss: 0.007645\n",
      "Epoch: 338/10000 Iteration: 2367 Train loss: 0.007623\n",
      "Epoch: 339/10000 Iteration: 2374 Train loss: 0.007601\n",
      "Epoch: 340/10000 Iteration: 2381 Train loss: 0.007579\n",
      "Epoch: 341/10000 Iteration: 2388 Train loss: 0.007557\n",
      "Epoch: 342/10000 Iteration: 2395 Train loss: 0.007536\n",
      "Epoch: 343/10000 Iteration: 2402 Train loss: 0.007514\n",
      "Epoch: 344/10000 Iteration: 2409 Train loss: 0.007493\n",
      "Epoch: 345/10000 Iteration: 2416 Train loss: 0.007471\n",
      "Epoch: 346/10000 Iteration: 2423 Train loss: 0.007450\n",
      "Epoch: 347/10000 Iteration: 2430 Train loss: 0.007429\n",
      "Epoch: 348/10000 Iteration: 2437 Train loss: 0.007408\n",
      "Epoch: 349/10000 Iteration: 2444 Train loss: 0.007388\n",
      "Epoch: 350/10000 Iteration: 2451 Train loss: 0.007367\n",
      "Epoch: 351/10000 Iteration: 2458 Train loss: 0.007346\n",
      "Epoch: 352/10000 Iteration: 2465 Train loss: 0.007326\n",
      "Epoch: 353/10000 Iteration: 2472 Train loss: 0.007306\n",
      "Epoch: 354/10000 Iteration: 2479 Train loss: 0.007286\n",
      "Epoch: 355/10000 Iteration: 2486 Train loss: 0.007265\n",
      "Epoch: 356/10000 Iteration: 2493 Train loss: 0.007245\n",
      "Epoch: 357/10000 Iteration: 2500 Train loss: 0.007226\n",
      "Epoch: 358/10000 Iteration: 2507 Train loss: 0.007206\n",
      "Epoch: 359/10000 Iteration: 2514 Train loss: 0.007186\n",
      "Epoch: 360/10000 Iteration: 2521 Train loss: 0.007167\n",
      "Epoch: 361/10000 Iteration: 2528 Train loss: 0.007147\n",
      "Epoch: 362/10000 Iteration: 2535 Train loss: 0.007128\n",
      "Epoch: 363/10000 Iteration: 2542 Train loss: 0.007109\n",
      "Epoch: 364/10000 Iteration: 2549 Train loss: 0.007090\n",
      "Epoch: 365/10000 Iteration: 2556 Train loss: 0.007071\n",
      "Epoch: 366/10000 Iteration: 2563 Train loss: 0.007052\n",
      "Epoch: 367/10000 Iteration: 2570 Train loss: 0.007034\n",
      "Epoch: 368/10000 Iteration: 2577 Train loss: 0.007015\n",
      "Epoch: 369/10000 Iteration: 2584 Train loss: 0.006997\n",
      "Epoch: 370/10000 Iteration: 2591 Train loss: 0.006978\n",
      "Epoch: 371/10000 Iteration: 2598 Train loss: 0.006960\n",
      "Epoch: 372/10000 Iteration: 2605 Train loss: 0.006942\n",
      "Epoch: 373/10000 Iteration: 2612 Train loss: 0.006924\n",
      "Epoch: 374/10000 Iteration: 2619 Train loss: 0.006906\n",
      "Epoch: 375/10000 Iteration: 2626 Train loss: 0.006889\n",
      "Epoch: 376/10000 Iteration: 2633 Train loss: 0.006871\n",
      "Epoch: 377/10000 Iteration: 2640 Train loss: 0.006854\n",
      "Epoch: 378/10000 Iteration: 2647 Train loss: 0.006836\n",
      "Epoch: 379/10000 Iteration: 2654 Train loss: 0.006819\n",
      "Epoch: 380/10000 Iteration: 2661 Train loss: 0.006802\n",
      "Epoch: 381/10000 Iteration: 2668 Train loss: 0.006785\n",
      "Epoch: 382/10000 Iteration: 2675 Train loss: 0.006768\n",
      "Epoch: 383/10000 Iteration: 2682 Train loss: 0.006751\n",
      "Epoch: 384/10000 Iteration: 2689 Train loss: 0.006734\n",
      "Epoch: 385/10000 Iteration: 2696 Train loss: 0.006718\n",
      "Epoch: 386/10000 Iteration: 2703 Train loss: 0.006702\n",
      "Epoch: 387/10000 Iteration: 2710 Train loss: 0.006685\n",
      "Epoch: 388/10000 Iteration: 2717 Train loss: 0.006669\n",
      "Epoch: 389/10000 Iteration: 2724 Train loss: 0.006653\n",
      "Epoch: 390/10000 Iteration: 2731 Train loss: 0.006637\n",
      "Epoch: 391/10000 Iteration: 2738 Train loss: 0.006621\n",
      "Epoch: 392/10000 Iteration: 2745 Train loss: 0.006605\n",
      "Epoch: 393/10000 Iteration: 2752 Train loss: 0.006590\n",
      "Epoch: 394/10000 Iteration: 2759 Train loss: 0.006574\n",
      "Epoch: 395/10000 Iteration: 2766 Train loss: 0.006559\n",
      "Epoch: 396/10000 Iteration: 2773 Train loss: 0.006544\n",
      "Epoch: 397/10000 Iteration: 2780 Train loss: 0.006529\n",
      "Epoch: 398/10000 Iteration: 2787 Train loss: 0.006514\n",
      "Epoch: 399/10000 Iteration: 2794 Train loss: 0.006499\n",
      "Epoch: 400/10000 Iteration: 2801 Train loss: 0.006484\n",
      "Epoch: 401/10000 Iteration: 2808 Train loss: 0.006469\n",
      "Epoch: 402/10000 Iteration: 2815 Train loss: 0.006455\n",
      "Epoch: 403/10000 Iteration: 2822 Train loss: 0.006440\n",
      "Epoch: 404/10000 Iteration: 2829 Train loss: 0.006426\n",
      "Epoch: 405/10000 Iteration: 2836 Train loss: 0.006412\n",
      "Epoch: 406/10000 Iteration: 2843 Train loss: 0.006398\n",
      "Epoch: 407/10000 Iteration: 2850 Train loss: 0.006384\n",
      "Epoch: 408/10000 Iteration: 2857 Train loss: 0.006370\n",
      "Epoch: 409/10000 Iteration: 2864 Train loss: 0.006356\n",
      "Epoch: 410/10000 Iteration: 2871 Train loss: 0.006343\n",
      "Epoch: 411/10000 Iteration: 2878 Train loss: 0.006329\n",
      "Epoch: 412/10000 Iteration: 2885 Train loss: 0.006316\n",
      "Epoch: 413/10000 Iteration: 2892 Train loss: 0.006302\n",
      "Epoch: 414/10000 Iteration: 2899 Train loss: 0.006289\n",
      "Epoch: 415/10000 Iteration: 2906 Train loss: 0.006276\n",
      "Epoch: 416/10000 Iteration: 2913 Train loss: 0.006263\n",
      "Epoch: 417/10000 Iteration: 2920 Train loss: 0.006251\n",
      "Epoch: 418/10000 Iteration: 2927 Train loss: 0.006238\n",
      "Epoch: 419/10000 Iteration: 2934 Train loss: 0.006225\n",
      "Epoch: 420/10000 Iteration: 2941 Train loss: 0.006213\n",
      "Epoch: 421/10000 Iteration: 2948 Train loss: 0.006201\n",
      "Epoch: 422/10000 Iteration: 2955 Train loss: 0.006188\n",
      "Epoch: 423/10000 Iteration: 2962 Train loss: 0.006176\n",
      "Epoch: 424/10000 Iteration: 2969 Train loss: 0.006164\n",
      "Epoch: 425/10000 Iteration: 2976 Train loss: 0.006152\n",
      "Epoch: 426/10000 Iteration: 2983 Train loss: 0.006141\n",
      "Epoch: 427/10000 Iteration: 2990 Train loss: 0.006129\n",
      "Epoch: 428/10000 Iteration: 2997 Train loss: 0.006118\n",
      "Epoch: 429/10000 Iteration: 3004 Train loss: 0.006106\n",
      "Epoch: 430/10000 Iteration: 3011 Train loss: 0.006095\n",
      "Epoch: 431/10000 Iteration: 3018 Train loss: 0.006084\n",
      "Epoch: 432/10000 Iteration: 3025 Train loss: 0.006073\n",
      "Epoch: 433/10000 Iteration: 3032 Train loss: 0.006062\n",
      "Epoch: 434/10000 Iteration: 3039 Train loss: 0.006051\n",
      "Epoch: 435/10000 Iteration: 3046 Train loss: 0.006040\n",
      "Epoch: 436/10000 Iteration: 3053 Train loss: 0.006030\n",
      "Epoch: 437/10000 Iteration: 3060 Train loss: 0.006019\n",
      "Epoch: 438/10000 Iteration: 3067 Train loss: 0.006009\n",
      "Epoch: 439/10000 Iteration: 3074 Train loss: 0.005998\n",
      "Epoch: 440/10000 Iteration: 3081 Train loss: 0.005988\n",
      "Epoch: 441/10000 Iteration: 3088 Train loss: 0.005978\n",
      "Epoch: 442/10000 Iteration: 3095 Train loss: 0.005968\n",
      "Epoch: 443/10000 Iteration: 3102 Train loss: 0.005959\n",
      "Epoch: 444/10000 Iteration: 3109 Train loss: 0.005949\n",
      "Epoch: 445/10000 Iteration: 3116 Train loss: 0.005939\n",
      "Epoch: 446/10000 Iteration: 3123 Train loss: 0.005930\n",
      "Epoch: 447/10000 Iteration: 3130 Train loss: 0.005920\n",
      "Epoch: 448/10000 Iteration: 3137 Train loss: 0.005911\n",
      "Epoch: 449/10000 Iteration: 3144 Train loss: 0.005902\n",
      "Epoch: 450/10000 Iteration: 3151 Train loss: 0.005893\n",
      "Epoch: 451/10000 Iteration: 3158 Train loss: 0.005884\n",
      "Epoch: 452/10000 Iteration: 3165 Train loss: 0.005875\n",
      "Epoch: 453/10000 Iteration: 3172 Train loss: 0.005867\n",
      "Epoch: 454/10000 Iteration: 3179 Train loss: 0.005858\n",
      "Epoch: 455/10000 Iteration: 3186 Train loss: 0.005850\n",
      "Epoch: 456/10000 Iteration: 3193 Train loss: 0.005841\n",
      "Epoch: 457/10000 Iteration: 3200 Train loss: 0.005833\n",
      "Epoch: 458/10000 Iteration: 3207 Train loss: 0.005825\n",
      "Epoch: 459/10000 Iteration: 3214 Train loss: 0.005817\n",
      "Epoch: 460/10000 Iteration: 3221 Train loss: 0.005809\n",
      "Epoch: 461/10000 Iteration: 3228 Train loss: 0.005801\n",
      "Epoch: 462/10000 Iteration: 3235 Train loss: 0.005793\n",
      "Epoch: 463/10000 Iteration: 3242 Train loss: 0.005786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 464/10000 Iteration: 3249 Train loss: 0.005778\n",
      "Epoch: 465/10000 Iteration: 3256 Train loss: 0.005771\n",
      "Epoch: 466/10000 Iteration: 3263 Train loss: 0.005764\n",
      "Epoch: 467/10000 Iteration: 3270 Train loss: 0.005757\n",
      "Epoch: 468/10000 Iteration: 3277 Train loss: 0.005750\n",
      "Epoch: 469/10000 Iteration: 3284 Train loss: 0.005743\n",
      "Epoch: 470/10000 Iteration: 3291 Train loss: 0.005736\n",
      "Epoch: 471/10000 Iteration: 3298 Train loss: 0.005729\n",
      "Epoch: 472/10000 Iteration: 3305 Train loss: 0.005722\n",
      "Epoch: 473/10000 Iteration: 3312 Train loss: 0.005716\n",
      "Epoch: 474/10000 Iteration: 3319 Train loss: 0.005709\n",
      "Epoch: 475/10000 Iteration: 3326 Train loss: 0.005703\n",
      "Epoch: 476/10000 Iteration: 3333 Train loss: 0.005697\n",
      "Epoch: 477/10000 Iteration: 3340 Train loss: 0.005691\n",
      "Epoch: 478/10000 Iteration: 3347 Train loss: 0.005685\n",
      "Epoch: 479/10000 Iteration: 3354 Train loss: 0.005679\n",
      "Epoch: 480/10000 Iteration: 3361 Train loss: 0.005673\n",
      "Epoch: 481/10000 Iteration: 3368 Train loss: 0.005667\n",
      "Epoch: 482/10000 Iteration: 3375 Train loss: 0.005662\n",
      "Epoch: 483/10000 Iteration: 3382 Train loss: 0.005656\n",
      "Epoch: 484/10000 Iteration: 3389 Train loss: 0.005651\n",
      "Epoch: 485/10000 Iteration: 3396 Train loss: 0.005646\n",
      "Epoch: 486/10000 Iteration: 3403 Train loss: 0.005641\n",
      "Epoch: 487/10000 Iteration: 3410 Train loss: 0.005636\n",
      "Epoch: 488/10000 Iteration: 3417 Train loss: 0.005631\n",
      "Epoch: 489/10000 Iteration: 3424 Train loss: 0.005626\n",
      "Epoch: 490/10000 Iteration: 3431 Train loss: 0.005621\n",
      "Epoch: 491/10000 Iteration: 3438 Train loss: 0.005616\n",
      "Epoch: 492/10000 Iteration: 3445 Train loss: 0.005612\n",
      "Epoch: 493/10000 Iteration: 3452 Train loss: 0.005607\n",
      "Epoch: 494/10000 Iteration: 3459 Train loss: 0.005603\n",
      "Epoch: 495/10000 Iteration: 3466 Train loss: 0.005599\n",
      "Epoch: 496/10000 Iteration: 3473 Train loss: 0.005594\n",
      "Epoch: 497/10000 Iteration: 3480 Train loss: 0.005590\n",
      "Epoch: 498/10000 Iteration: 3487 Train loss: 0.005586\n",
      "Epoch: 499/10000 Iteration: 3494 Train loss: 0.005583\n",
      "Epoch: 500/10000 Iteration: 3501 Train loss: 0.005579\n",
      "Epoch: 501/10000 Iteration: 3508 Train loss: 0.005575\n",
      "Epoch: 502/10000 Iteration: 3515 Train loss: 0.005571\n",
      "Epoch: 503/10000 Iteration: 3522 Train loss: 0.005568\n",
      "Epoch: 504/10000 Iteration: 3529 Train loss: 0.005565\n",
      "Epoch: 505/10000 Iteration: 3536 Train loss: 0.005561\n",
      "Epoch: 506/10000 Iteration: 3543 Train loss: 0.005558\n",
      "Epoch: 507/10000 Iteration: 3550 Train loss: 0.005555\n",
      "Epoch: 508/10000 Iteration: 3557 Train loss: 0.005552\n",
      "Epoch: 509/10000 Iteration: 3564 Train loss: 0.005549\n",
      "Epoch: 510/10000 Iteration: 3571 Train loss: 0.005546\n",
      "Epoch: 511/10000 Iteration: 3578 Train loss: 0.005543\n",
      "Epoch: 512/10000 Iteration: 3585 Train loss: 0.005541\n",
      "Epoch: 513/10000 Iteration: 3592 Train loss: 0.005538\n",
      "Epoch: 514/10000 Iteration: 3599 Train loss: 0.005536\n",
      "Epoch: 515/10000 Iteration: 3606 Train loss: 0.005533\n",
      "Epoch: 516/10000 Iteration: 3613 Train loss: 0.005531\n",
      "Epoch: 517/10000 Iteration: 3620 Train loss: 0.005529\n",
      "Epoch: 518/10000 Iteration: 3627 Train loss: 0.005527\n",
      "Epoch: 519/10000 Iteration: 3634 Train loss: 0.005525\n",
      "Epoch: 520/10000 Iteration: 3641 Train loss: 0.005523\n",
      "Epoch: 521/10000 Iteration: 3648 Train loss: 0.005521\n",
      "Epoch: 522/10000 Iteration: 3655 Train loss: 0.005519\n",
      "Epoch: 523/10000 Iteration: 3662 Train loss: 0.005517\n",
      "Epoch: 524/10000 Iteration: 3669 Train loss: 0.005516\n",
      "Epoch: 525/10000 Iteration: 3676 Train loss: 0.005514\n",
      "Epoch: 526/10000 Iteration: 3683 Train loss: 0.005513\n",
      "Epoch: 527/10000 Iteration: 3690 Train loss: 0.005512\n",
      "Epoch: 528/10000 Iteration: 3697 Train loss: 0.005510\n",
      "Epoch: 529/10000 Iteration: 3704 Train loss: 0.005509\n",
      "Epoch: 530/10000 Iteration: 3711 Train loss: 0.005508\n",
      "Epoch: 531/10000 Iteration: 3718 Train loss: 0.005507\n",
      "Epoch: 532/10000 Iteration: 3725 Train loss: 0.005506\n",
      "Epoch: 533/10000 Iteration: 3732 Train loss: 0.005505\n",
      "Epoch: 534/10000 Iteration: 3739 Train loss: 0.005505\n",
      "Epoch: 535/10000 Iteration: 3746 Train loss: 0.005504\n",
      "Epoch: 536/10000 Iteration: 3753 Train loss: 0.005503\n",
      "Epoch: 537/10000 Iteration: 3760 Train loss: 0.005503\n",
      "Epoch: 538/10000 Iteration: 3767 Train loss: 0.005502\n",
      "Epoch: 539/10000 Iteration: 3774 Train loss: 0.005502\n",
      "Epoch: 540/10000 Iteration: 3781 Train loss: 0.005502\n",
      "Epoch: 541/10000 Iteration: 3788 Train loss: 0.005502\n",
      "Epoch: 542/10000 Iteration: 3795 Train loss: 0.005501\n",
      "Epoch: 543/10000 Iteration: 3802 Train loss: 0.005501\n",
      "Epoch: 544/10000 Iteration: 3809 Train loss: 0.005501\n",
      "Epoch: 545/10000 Iteration: 3816 Train loss: 0.005502\n",
      "Epoch: 546/10000 Iteration: 3823 Train loss: 0.005502\n",
      "Epoch: 547/10000 Iteration: 3830 Train loss: 0.005502\n",
      "Epoch: 548/10000 Iteration: 3837 Train loss: 0.005502\n",
      "Epoch: 549/10000 Iteration: 3844 Train loss: 0.005503\n",
      "Epoch: 550/10000 Iteration: 3851 Train loss: 0.005503\n",
      "Epoch: 551/10000 Iteration: 3858 Train loss: 0.005504\n",
      "Epoch: 552/10000 Iteration: 3865 Train loss: 0.005504\n",
      "Epoch: 553/10000 Iteration: 3872 Train loss: 0.005505\n",
      "Epoch: 554/10000 Iteration: 3879 Train loss: 0.005506\n",
      "Epoch: 555/10000 Iteration: 3886 Train loss: 0.005507\n",
      "Epoch: 556/10000 Iteration: 3893 Train loss: 0.005508\n",
      "Epoch: 557/10000 Iteration: 3900 Train loss: 0.005509\n",
      "Epoch: 558/10000 Iteration: 3907 Train loss: 0.005510\n",
      "Epoch: 559/10000 Iteration: 3914 Train loss: 0.005511\n",
      "Epoch: 560/10000 Iteration: 3921 Train loss: 0.005512\n",
      "Epoch: 561/10000 Iteration: 3928 Train loss: 0.005513\n",
      "Epoch: 562/10000 Iteration: 3935 Train loss: 0.005514\n",
      "Epoch: 563/10000 Iteration: 3942 Train loss: 0.005516\n",
      "Epoch: 564/10000 Iteration: 3949 Train loss: 0.005517\n",
      "Epoch: 565/10000 Iteration: 3956 Train loss: 0.005519\n",
      "Epoch: 566/10000 Iteration: 3963 Train loss: 0.005520\n",
      "Epoch: 567/10000 Iteration: 3970 Train loss: 0.005522\n",
      "Epoch: 568/10000 Iteration: 3977 Train loss: 0.005524\n",
      "Epoch: 569/10000 Iteration: 3984 Train loss: 0.005525\n",
      "Epoch: 570/10000 Iteration: 3991 Train loss: 0.005527\n",
      "Epoch: 571/10000 Iteration: 3998 Train loss: 0.005529\n",
      "Epoch: 572/10000 Iteration: 4005 Train loss: 0.005531\n",
      "Epoch: 573/10000 Iteration: 4012 Train loss: 0.005533\n",
      "Epoch: 574/10000 Iteration: 4019 Train loss: 0.005535\n",
      "Epoch: 575/10000 Iteration: 4026 Train loss: 0.005537\n",
      "Epoch: 576/10000 Iteration: 4033 Train loss: 0.005539\n",
      "Epoch: 577/10000 Iteration: 4040 Train loss: 0.005541\n",
      "Epoch: 578/10000 Iteration: 4047 Train loss: 0.005544\n",
      "Epoch: 579/10000 Iteration: 4054 Train loss: 0.005546\n",
      "Epoch: 580/10000 Iteration: 4061 Train loss: 0.005548\n",
      "Epoch: 581/10000 Iteration: 4068 Train loss: 0.005551\n",
      "Epoch: 582/10000 Iteration: 4075 Train loss: 0.005553\n",
      "Epoch: 583/10000 Iteration: 4082 Train loss: 0.005556\n",
      "Epoch: 584/10000 Iteration: 4089 Train loss: 0.005559\n",
      "Epoch: 585/10000 Iteration: 4096 Train loss: 0.005561\n",
      "Epoch: 586/10000 Iteration: 4103 Train loss: 0.005564\n",
      "Epoch: 587/10000 Iteration: 4110 Train loss: 0.005567\n",
      "Epoch: 588/10000 Iteration: 4117 Train loss: 0.005570\n",
      "Epoch: 589/10000 Iteration: 4124 Train loss: 0.005572\n",
      "Epoch: 590/10000 Iteration: 4131 Train loss: 0.005575\n",
      "Epoch: 591/10000 Iteration: 4138 Train loss: 0.005578\n",
      "Epoch: 592/10000 Iteration: 4145 Train loss: 0.005581\n",
      "Epoch: 593/10000 Iteration: 4152 Train loss: 0.005584\n",
      "Epoch: 594/10000 Iteration: 4159 Train loss: 0.005587\n",
      "Epoch: 595/10000 Iteration: 4166 Train loss: 0.005591\n",
      "Epoch: 596/10000 Iteration: 4173 Train loss: 0.005594\n",
      "Epoch: 597/10000 Iteration: 4180 Train loss: 0.005597\n",
      "Epoch: 598/10000 Iteration: 4187 Train loss: 0.005600\n",
      "Epoch: 599/10000 Iteration: 4194 Train loss: 0.005604\n",
      "Epoch: 600/10000 Iteration: 4201 Train loss: 0.005607\n",
      "Epoch: 601/10000 Iteration: 4208 Train loss: 0.005610\n",
      "Epoch: 602/10000 Iteration: 4215 Train loss: 0.005614\n",
      "Epoch: 603/10000 Iteration: 4222 Train loss: 0.005617\n",
      "Epoch: 604/10000 Iteration: 4229 Train loss: 0.005621\n",
      "Epoch: 605/10000 Iteration: 4236 Train loss: 0.005625\n",
      "Epoch: 606/10000 Iteration: 4243 Train loss: 0.005628\n",
      "Epoch: 607/10000 Iteration: 4250 Train loss: 0.005632\n",
      "Epoch: 608/10000 Iteration: 4257 Train loss: 0.005636\n",
      "Epoch: 609/10000 Iteration: 4264 Train loss: 0.005639\n",
      "Epoch: 610/10000 Iteration: 4271 Train loss: 0.005643\n",
      "Epoch: 611/10000 Iteration: 4278 Train loss: 0.005647\n",
      "Epoch: 612/10000 Iteration: 4285 Train loss: 0.005651\n",
      "Epoch: 613/10000 Iteration: 4292 Train loss: 0.005655\n",
      "Epoch: 614/10000 Iteration: 4299 Train loss: 0.005659\n",
      "Epoch: 615/10000 Iteration: 4306 Train loss: 0.005663\n",
      "Epoch: 616/10000 Iteration: 4313 Train loss: 0.005666\n",
      "Epoch: 617/10000 Iteration: 4320 Train loss: 0.005671\n",
      "Epoch: 618/10000 Iteration: 4327 Train loss: 0.005675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 619/10000 Iteration: 4334 Train loss: 0.005679\n",
      "Epoch: 620/10000 Iteration: 4341 Train loss: 0.005683\n",
      "Epoch: 621/10000 Iteration: 4348 Train loss: 0.005687\n",
      "Epoch: 622/10000 Iteration: 4355 Train loss: 0.005691\n",
      "Epoch: 623/10000 Iteration: 4362 Train loss: 0.005695\n",
      "Epoch: 624/10000 Iteration: 4369 Train loss: 0.005700\n",
      "Epoch: 625/10000 Iteration: 4376 Train loss: 0.005704\n",
      "Epoch: 626/10000 Iteration: 4383 Train loss: 0.005708\n",
      "Epoch: 627/10000 Iteration: 4390 Train loss: 0.005712\n",
      "Epoch: 628/10000 Iteration: 4397 Train loss: 0.005717\n",
      "Epoch: 629/10000 Iteration: 4404 Train loss: 0.005721\n",
      "Epoch: 630/10000 Iteration: 4411 Train loss: 0.005726\n",
      "Epoch: 631/10000 Iteration: 4418 Train loss: 0.005730\n",
      "Epoch: 632/10000 Iteration: 4425 Train loss: 0.005734\n",
      "Epoch: 633/10000 Iteration: 4432 Train loss: 0.005739\n",
      "Epoch: 634/10000 Iteration: 4439 Train loss: 0.005743\n",
      "Epoch: 635/10000 Iteration: 4446 Train loss: 0.005748\n",
      "Epoch: 636/10000 Iteration: 4453 Train loss: 0.005752\n",
      "Epoch: 637/10000 Iteration: 4460 Train loss: 0.005757\n",
      "Epoch: 638/10000 Iteration: 4467 Train loss: 0.005762\n",
      "Epoch: 639/10000 Iteration: 4474 Train loss: 0.005766\n",
      "Epoch: 640/10000 Iteration: 4481 Train loss: 0.005771\n",
      "Epoch: 641/10000 Iteration: 4488 Train loss: 0.005776\n",
      "Epoch: 642/10000 Iteration: 4495 Train loss: 0.005780\n",
      "Epoch: 643/10000 Iteration: 4502 Train loss: 0.005785\n",
      "Epoch: 644/10000 Iteration: 4509 Train loss: 0.005790\n",
      "Epoch: 645/10000 Iteration: 4516 Train loss: 0.005794\n",
      "Epoch: 646/10000 Iteration: 4523 Train loss: 0.005799\n",
      "Epoch: 647/10000 Iteration: 4530 Train loss: 0.005804\n",
      "Epoch: 648/10000 Iteration: 4537 Train loss: 0.005809\n",
      "Epoch: 649/10000 Iteration: 4544 Train loss: 0.005813\n",
      "Epoch: 650/10000 Iteration: 4551 Train loss: 0.005818\n",
      "Epoch: 651/10000 Iteration: 4558 Train loss: 0.005823\n",
      "Epoch: 652/10000 Iteration: 4565 Train loss: 0.005828\n",
      "Epoch: 653/10000 Iteration: 4572 Train loss: 0.005833\n",
      "Epoch: 654/10000 Iteration: 4579 Train loss: 0.005838\n",
      "Epoch: 655/10000 Iteration: 4586 Train loss: 0.005842\n",
      "Epoch: 656/10000 Iteration: 4593 Train loss: 0.005847\n",
      "Epoch: 657/10000 Iteration: 4600 Train loss: 0.005852\n",
      "Epoch: 658/10000 Iteration: 4607 Train loss: 0.005857\n",
      "Epoch: 659/10000 Iteration: 4614 Train loss: 0.005862\n",
      "Epoch: 660/10000 Iteration: 4621 Train loss: 0.005867\n",
      "Epoch: 661/10000 Iteration: 4628 Train loss: 0.005872\n",
      "Epoch: 662/10000 Iteration: 4635 Train loss: 0.005877\n",
      "Epoch: 663/10000 Iteration: 4642 Train loss: 0.005882\n",
      "Epoch: 664/10000 Iteration: 4649 Train loss: 0.005887\n",
      "Epoch: 665/10000 Iteration: 4656 Train loss: 0.005892\n",
      "Epoch: 666/10000 Iteration: 4663 Train loss: 0.005897\n",
      "Epoch: 667/10000 Iteration: 4670 Train loss: 0.005902\n",
      "Epoch: 668/10000 Iteration: 4677 Train loss: 0.005907\n",
      "Epoch: 669/10000 Iteration: 4684 Train loss: 0.005912\n",
      "Epoch: 670/10000 Iteration: 4691 Train loss: 0.005917\n",
      "Epoch: 671/10000 Iteration: 4698 Train loss: 0.005922\n",
      "Epoch: 672/10000 Iteration: 4705 Train loss: 0.005927\n",
      "Epoch: 673/10000 Iteration: 4712 Train loss: 0.005932\n",
      "Epoch: 674/10000 Iteration: 4719 Train loss: 0.005937\n",
      "Epoch: 675/10000 Iteration: 4726 Train loss: 0.005942\n",
      "Epoch: 676/10000 Iteration: 4733 Train loss: 0.005947\n",
      "Epoch: 677/10000 Iteration: 4740 Train loss: 0.005952\n",
      "Epoch: 678/10000 Iteration: 4747 Train loss: 0.005957\n",
      "Epoch: 679/10000 Iteration: 4754 Train loss: 0.005962\n",
      "Epoch: 680/10000 Iteration: 4761 Train loss: 0.005967\n",
      "Epoch: 681/10000 Iteration: 4768 Train loss: 0.005972\n",
      "Epoch: 682/10000 Iteration: 4775 Train loss: 0.005977\n",
      "Epoch: 683/10000 Iteration: 4782 Train loss: 0.005982\n",
      "Epoch: 684/10000 Iteration: 4789 Train loss: 0.005987\n",
      "Epoch: 685/10000 Iteration: 4796 Train loss: 0.005992\n",
      "Epoch: 686/10000 Iteration: 4803 Train loss: 0.005997\n",
      "Epoch: 687/10000 Iteration: 4810 Train loss: 0.006002\n",
      "Epoch: 688/10000 Iteration: 4817 Train loss: 0.006007\n",
      "Epoch: 689/10000 Iteration: 4824 Train loss: 0.006012\n",
      "Epoch: 690/10000 Iteration: 4831 Train loss: 0.006017\n",
      "Epoch: 691/10000 Iteration: 4838 Train loss: 0.006022\n",
      "Epoch: 692/10000 Iteration: 4845 Train loss: 0.006027\n",
      "Epoch: 693/10000 Iteration: 4852 Train loss: 0.006032\n",
      "Epoch: 694/10000 Iteration: 4859 Train loss: 0.006037\n",
      "Epoch: 695/10000 Iteration: 4866 Train loss: 0.006042\n",
      "Epoch: 696/10000 Iteration: 4873 Train loss: 0.006047\n",
      "Epoch: 697/10000 Iteration: 4880 Train loss: 0.006052\n",
      "Epoch: 698/10000 Iteration: 4887 Train loss: 0.006057\n",
      "Epoch: 699/10000 Iteration: 4894 Train loss: 0.006062\n",
      "Epoch: 700/10000 Iteration: 4901 Train loss: 0.006067\n",
      "Epoch: 701/10000 Iteration: 4908 Train loss: 0.006072\n",
      "Epoch: 702/10000 Iteration: 4915 Train loss: 0.006077\n",
      "Epoch: 703/10000 Iteration: 4922 Train loss: 0.006082\n",
      "Epoch: 704/10000 Iteration: 4929 Train loss: 0.006087\n",
      "Epoch: 705/10000 Iteration: 4936 Train loss: 0.006092\n",
      "Epoch: 706/10000 Iteration: 4943 Train loss: 0.006097\n",
      "Epoch: 707/10000 Iteration: 4950 Train loss: 0.006102\n",
      "Epoch: 708/10000 Iteration: 4957 Train loss: 0.006107\n",
      "Epoch: 709/10000 Iteration: 4964 Train loss: 0.006112\n",
      "Epoch: 710/10000 Iteration: 4971 Train loss: 0.006117\n",
      "Epoch: 711/10000 Iteration: 4978 Train loss: 0.006122\n",
      "Epoch: 712/10000 Iteration: 4985 Train loss: 0.006126\n",
      "Epoch: 713/10000 Iteration: 4992 Train loss: 0.006131\n",
      "Epoch: 714/10000 Iteration: 4999 Train loss: 0.006136\n",
      "Epoch: 715/10000 Iteration: 5006 Train loss: 0.006141\n",
      "Epoch: 716/10000 Iteration: 5013 Train loss: 0.006146\n",
      "Epoch: 717/10000 Iteration: 5020 Train loss: 0.006151\n",
      "Epoch: 718/10000 Iteration: 5027 Train loss: 0.006156\n",
      "Epoch: 719/10000 Iteration: 5034 Train loss: 0.006160\n",
      "Epoch: 720/10000 Iteration: 5041 Train loss: 0.006165\n",
      "Epoch: 721/10000 Iteration: 5048 Train loss: 0.006170\n",
      "Epoch: 722/10000 Iteration: 5055 Train loss: 0.006175\n",
      "Epoch: 723/10000 Iteration: 5062 Train loss: 0.006179\n",
      "Epoch: 724/10000 Iteration: 5069 Train loss: 0.006184\n",
      "Epoch: 725/10000 Iteration: 5076 Train loss: 0.006189\n",
      "Epoch: 726/10000 Iteration: 5083 Train loss: 0.006194\n",
      "Epoch: 727/10000 Iteration: 5090 Train loss: 0.006198\n",
      "Epoch: 728/10000 Iteration: 5097 Train loss: 0.006203\n",
      "Epoch: 729/10000 Iteration: 5104 Train loss: 0.006208\n",
      "Epoch: 730/10000 Iteration: 5111 Train loss: 0.006212\n",
      "Epoch: 731/10000 Iteration: 5118 Train loss: 0.006217\n",
      "Epoch: 732/10000 Iteration: 5125 Train loss: 0.006222\n",
      "Epoch: 733/10000 Iteration: 5132 Train loss: 0.006226\n",
      "Epoch: 734/10000 Iteration: 5139 Train loss: 0.006231\n",
      "Epoch: 735/10000 Iteration: 5146 Train loss: 0.006236\n",
      "Epoch: 736/10000 Iteration: 5153 Train loss: 0.006240\n",
      "Epoch: 737/10000 Iteration: 5160 Train loss: 0.006245\n",
      "Epoch: 738/10000 Iteration: 5167 Train loss: 0.006249\n",
      "Epoch: 739/10000 Iteration: 5174 Train loss: 0.006254\n",
      "Epoch: 740/10000 Iteration: 5181 Train loss: 0.006258\n",
      "Epoch: 741/10000 Iteration: 5188 Train loss: 0.006263\n",
      "Epoch: 742/10000 Iteration: 5195 Train loss: 0.006267\n",
      "Epoch: 743/10000 Iteration: 5202 Train loss: 0.006272\n",
      "Epoch: 744/10000 Iteration: 5209 Train loss: 0.006276\n",
      "Epoch: 745/10000 Iteration: 5216 Train loss: 0.006281\n",
      "Epoch: 746/10000 Iteration: 5223 Train loss: 0.006285\n",
      "Epoch: 747/10000 Iteration: 5230 Train loss: 0.006290\n",
      "Epoch: 748/10000 Iteration: 5237 Train loss: 0.006294\n",
      "Epoch: 749/10000 Iteration: 5244 Train loss: 0.006299\n",
      "Epoch: 750/10000 Iteration: 5251 Train loss: 0.006303\n",
      "Epoch: 751/10000 Iteration: 5258 Train loss: 0.006307\n",
      "Epoch: 752/10000 Iteration: 5265 Train loss: 0.006312\n",
      "Epoch: 753/10000 Iteration: 5272 Train loss: 0.006316\n",
      "Epoch: 754/10000 Iteration: 5279 Train loss: 0.006320\n",
      "Epoch: 755/10000 Iteration: 5286 Train loss: 0.006325\n",
      "Epoch: 756/10000 Iteration: 5293 Train loss: 0.006329\n",
      "Epoch: 757/10000 Iteration: 5300 Train loss: 0.006333\n",
      "Epoch: 758/10000 Iteration: 5307 Train loss: 0.006337\n",
      "Epoch: 759/10000 Iteration: 5314 Train loss: 0.006342\n",
      "Epoch: 760/10000 Iteration: 5321 Train loss: 0.006346\n",
      "Epoch: 761/10000 Iteration: 5328 Train loss: 0.006350\n",
      "Epoch: 762/10000 Iteration: 5335 Train loss: 0.006354\n",
      "Epoch: 763/10000 Iteration: 5342 Train loss: 0.006358\n",
      "Epoch: 764/10000 Iteration: 5349 Train loss: 0.006362\n",
      "Epoch: 765/10000 Iteration: 5356 Train loss: 0.006366\n",
      "Epoch: 766/10000 Iteration: 5363 Train loss: 0.006371\n",
      "Epoch: 767/10000 Iteration: 5370 Train loss: 0.006375\n",
      "Epoch: 768/10000 Iteration: 5377 Train loss: 0.006379\n",
      "Epoch: 769/10000 Iteration: 5384 Train loss: 0.006383\n",
      "Epoch: 770/10000 Iteration: 5391 Train loss: 0.006387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 771/10000 Iteration: 5398 Train loss: 0.006391\n",
      "Epoch: 772/10000 Iteration: 5405 Train loss: 0.006395\n",
      "Epoch: 773/10000 Iteration: 5412 Train loss: 0.006399\n",
      "Epoch: 774/10000 Iteration: 5419 Train loss: 0.006403\n",
      "Epoch: 775/10000 Iteration: 5426 Train loss: 0.006407\n",
      "Epoch: 776/10000 Iteration: 5433 Train loss: 0.006411\n",
      "Epoch: 777/10000 Iteration: 5440 Train loss: 0.006414\n",
      "Epoch: 778/10000 Iteration: 5447 Train loss: 0.006418\n",
      "Epoch: 779/10000 Iteration: 5454 Train loss: 0.006422\n",
      "Epoch: 780/10000 Iteration: 5461 Train loss: 0.006426\n",
      "Epoch: 781/10000 Iteration: 5468 Train loss: 0.006430\n",
      "Epoch: 782/10000 Iteration: 5475 Train loss: 0.006434\n",
      "Epoch: 783/10000 Iteration: 5482 Train loss: 0.006437\n",
      "Epoch: 784/10000 Iteration: 5489 Train loss: 0.006441\n",
      "Epoch: 785/10000 Iteration: 5496 Train loss: 0.006445\n",
      "Epoch: 786/10000 Iteration: 5503 Train loss: 0.006449\n",
      "Epoch: 787/10000 Iteration: 5510 Train loss: 0.006452\n",
      "Epoch: 788/10000 Iteration: 5517 Train loss: 0.006456\n",
      "Epoch: 789/10000 Iteration: 5524 Train loss: 0.006460\n",
      "Epoch: 790/10000 Iteration: 5531 Train loss: 0.006463\n",
      "Epoch: 791/10000 Iteration: 5538 Train loss: 0.006467\n",
      "Epoch: 792/10000 Iteration: 5545 Train loss: 0.006471\n",
      "Epoch: 793/10000 Iteration: 5552 Train loss: 0.006474\n",
      "Epoch: 794/10000 Iteration: 5559 Train loss: 0.006478\n",
      "Epoch: 795/10000 Iteration: 5566 Train loss: 0.006481\n",
      "Epoch: 796/10000 Iteration: 5573 Train loss: 0.006485\n",
      "Epoch: 797/10000 Iteration: 5580 Train loss: 0.006489\n",
      "Epoch: 798/10000 Iteration: 5587 Train loss: 0.006492\n",
      "Epoch: 799/10000 Iteration: 5594 Train loss: 0.006496\n",
      "Epoch: 800/10000 Iteration: 5601 Train loss: 0.006499\n",
      "Epoch: 801/10000 Iteration: 5608 Train loss: 0.006503\n",
      "Epoch: 802/10000 Iteration: 5615 Train loss: 0.006506\n",
      "Epoch: 803/10000 Iteration: 5622 Train loss: 0.006509\n",
      "Epoch: 804/10000 Iteration: 5629 Train loss: 0.006513\n",
      "Epoch: 805/10000 Iteration: 5636 Train loss: 0.006516\n",
      "Epoch: 806/10000 Iteration: 5643 Train loss: 0.006520\n",
      "Epoch: 807/10000 Iteration: 5650 Train loss: 0.006523\n",
      "Epoch: 808/10000 Iteration: 5657 Train loss: 0.006526\n",
      "Epoch: 809/10000 Iteration: 5664 Train loss: 0.006530\n",
      "Epoch: 810/10000 Iteration: 5671 Train loss: 0.006533\n",
      "Epoch: 811/10000 Iteration: 5678 Train loss: 0.006536\n",
      "Epoch: 812/10000 Iteration: 5685 Train loss: 0.006539\n",
      "Epoch: 813/10000 Iteration: 5692 Train loss: 0.006543\n",
      "Epoch: 814/10000 Iteration: 5699 Train loss: 0.006546\n",
      "Epoch: 815/10000 Iteration: 5706 Train loss: 0.006549\n",
      "Epoch: 816/10000 Iteration: 5713 Train loss: 0.006552\n",
      "Epoch: 817/10000 Iteration: 5720 Train loss: 0.006555\n",
      "Epoch: 818/10000 Iteration: 5727 Train loss: 0.006559\n",
      "Epoch: 819/10000 Iteration: 5734 Train loss: 0.006562\n",
      "Epoch: 820/10000 Iteration: 5741 Train loss: 0.006565\n",
      "Epoch: 821/10000 Iteration: 5748 Train loss: 0.006568\n",
      "Epoch: 822/10000 Iteration: 5755 Train loss: 0.006571\n",
      "Epoch: 823/10000 Iteration: 5762 Train loss: 0.006574\n",
      "Epoch: 824/10000 Iteration: 5769 Train loss: 0.006577\n",
      "Epoch: 825/10000 Iteration: 5776 Train loss: 0.006580\n",
      "Epoch: 826/10000 Iteration: 5783 Train loss: 0.006583\n",
      "Epoch: 827/10000 Iteration: 5790 Train loss: 0.006586\n",
      "Epoch: 828/10000 Iteration: 5797 Train loss: 0.006589\n",
      "Epoch: 829/10000 Iteration: 5804 Train loss: 0.006592\n",
      "Epoch: 830/10000 Iteration: 5811 Train loss: 0.006595\n",
      "Epoch: 831/10000 Iteration: 5818 Train loss: 0.006598\n",
      "Epoch: 832/10000 Iteration: 5825 Train loss: 0.006601\n",
      "Epoch: 833/10000 Iteration: 5832 Train loss: 0.006604\n",
      "Epoch: 834/10000 Iteration: 5839 Train loss: 0.006607\n",
      "Epoch: 835/10000 Iteration: 5846 Train loss: 0.006610\n",
      "Epoch: 836/10000 Iteration: 5853 Train loss: 0.006613\n",
      "Epoch: 837/10000 Iteration: 5860 Train loss: 0.006615\n",
      "Epoch: 838/10000 Iteration: 5867 Train loss: 0.006618\n",
      "Epoch: 839/10000 Iteration: 5874 Train loss: 0.006621\n",
      "Epoch: 840/10000 Iteration: 5881 Train loss: 0.006624\n",
      "Epoch: 841/10000 Iteration: 5888 Train loss: 0.006627\n",
      "Epoch: 842/10000 Iteration: 5895 Train loss: 0.006629\n",
      "Epoch: 843/10000 Iteration: 5902 Train loss: 0.006632\n",
      "Epoch: 844/10000 Iteration: 5909 Train loss: 0.006635\n",
      "Epoch: 845/10000 Iteration: 5916 Train loss: 0.006638\n",
      "Epoch: 846/10000 Iteration: 5923 Train loss: 0.006640\n",
      "Epoch: 847/10000 Iteration: 5930 Train loss: 0.006643\n",
      "Epoch: 848/10000 Iteration: 5937 Train loss: 0.006646\n",
      "Epoch: 849/10000 Iteration: 5944 Train loss: 0.006648\n",
      "Epoch: 850/10000 Iteration: 5951 Train loss: 0.006651\n",
      "Epoch: 851/10000 Iteration: 5958 Train loss: 0.006654\n",
      "Epoch: 852/10000 Iteration: 5965 Train loss: 0.006656\n",
      "Epoch: 853/10000 Iteration: 5972 Train loss: 0.006659\n",
      "Epoch: 854/10000 Iteration: 5979 Train loss: 0.006661\n",
      "Epoch: 855/10000 Iteration: 5986 Train loss: 0.006664\n",
      "Epoch: 856/10000 Iteration: 5993 Train loss: 0.006667\n",
      "Epoch: 857/10000 Iteration: 6000 Train loss: 0.006669\n",
      "Epoch: 858/10000 Iteration: 6007 Train loss: 0.006672\n",
      "Epoch: 859/10000 Iteration: 6014 Train loss: 0.006674\n",
      "Epoch: 860/10000 Iteration: 6021 Train loss: 0.006677\n",
      "Epoch: 861/10000 Iteration: 6028 Train loss: 0.006679\n",
      "Epoch: 862/10000 Iteration: 6035 Train loss: 0.006682\n",
      "Epoch: 863/10000 Iteration: 6042 Train loss: 0.006684\n",
      "Epoch: 864/10000 Iteration: 6049 Train loss: 0.006687\n",
      "Epoch: 865/10000 Iteration: 6056 Train loss: 0.006689\n",
      "Epoch: 866/10000 Iteration: 6063 Train loss: 0.006691\n",
      "Epoch: 867/10000 Iteration: 6070 Train loss: 0.006694\n",
      "Epoch: 868/10000 Iteration: 6077 Train loss: 0.006696\n",
      "Epoch: 869/10000 Iteration: 6084 Train loss: 0.006699\n",
      "Epoch: 870/10000 Iteration: 6091 Train loss: 0.006701\n",
      "Epoch: 871/10000 Iteration: 6098 Train loss: 0.006703\n",
      "Epoch: 872/10000 Iteration: 6105 Train loss: 0.006706\n",
      "Epoch: 873/10000 Iteration: 6112 Train loss: 0.006708\n",
      "Epoch: 874/10000 Iteration: 6119 Train loss: 0.006710\n",
      "Epoch: 875/10000 Iteration: 6126 Train loss: 0.006713\n",
      "Epoch: 876/10000 Iteration: 6133 Train loss: 0.006715\n",
      "Epoch: 877/10000 Iteration: 6140 Train loss: 0.006717\n",
      "Epoch: 878/10000 Iteration: 6147 Train loss: 0.006719\n",
      "Epoch: 879/10000 Iteration: 6154 Train loss: 0.006722\n",
      "Epoch: 880/10000 Iteration: 6161 Train loss: 0.006724\n",
      "Epoch: 881/10000 Iteration: 6168 Train loss: 0.006726\n",
      "Epoch: 882/10000 Iteration: 6175 Train loss: 0.006728\n",
      "Epoch: 883/10000 Iteration: 6182 Train loss: 0.006731\n",
      "Epoch: 884/10000 Iteration: 6189 Train loss: 0.006733\n",
      "Epoch: 885/10000 Iteration: 6196 Train loss: 0.006735\n",
      "Epoch: 886/10000 Iteration: 6203 Train loss: 0.006737\n",
      "Epoch: 887/10000 Iteration: 6210 Train loss: 0.006739\n",
      "Epoch: 888/10000 Iteration: 6217 Train loss: 0.006741\n",
      "Epoch: 889/10000 Iteration: 6224 Train loss: 0.006744\n",
      "Epoch: 890/10000 Iteration: 6231 Train loss: 0.006746\n",
      "Epoch: 891/10000 Iteration: 6238 Train loss: 0.006748\n",
      "Epoch: 892/10000 Iteration: 6245 Train loss: 0.006750\n",
      "Epoch: 893/10000 Iteration: 6252 Train loss: 0.006752\n",
      "Epoch: 894/10000 Iteration: 6259 Train loss: 0.006754\n",
      "Epoch: 895/10000 Iteration: 6266 Train loss: 0.006756\n",
      "Epoch: 896/10000 Iteration: 6273 Train loss: 0.006758\n",
      "Epoch: 897/10000 Iteration: 6280 Train loss: 0.006760\n",
      "Epoch: 898/10000 Iteration: 6287 Train loss: 0.006762\n",
      "Epoch: 899/10000 Iteration: 6294 Train loss: 0.006764\n",
      "Epoch: 900/10000 Iteration: 6301 Train loss: 0.006766\n",
      "Epoch: 901/10000 Iteration: 6308 Train loss: 0.006768\n",
      "Epoch: 902/10000 Iteration: 6315 Train loss: 0.006770\n",
      "Epoch: 903/10000 Iteration: 6322 Train loss: 0.006772\n",
      "Epoch: 904/10000 Iteration: 6329 Train loss: 0.006774\n",
      "Epoch: 905/10000 Iteration: 6336 Train loss: 0.006776\n",
      "Epoch: 906/10000 Iteration: 6343 Train loss: 0.006778\n",
      "Epoch: 907/10000 Iteration: 6350 Train loss: 0.006780\n",
      "Epoch: 908/10000 Iteration: 6357 Train loss: 0.006782\n",
      "Epoch: 909/10000 Iteration: 6364 Train loss: 0.006784\n",
      "Epoch: 910/10000 Iteration: 6371 Train loss: 0.006786\n",
      "Epoch: 911/10000 Iteration: 6378 Train loss: 0.006788\n",
      "Epoch: 912/10000 Iteration: 6385 Train loss: 0.006790\n",
      "Epoch: 913/10000 Iteration: 6392 Train loss: 0.006792\n",
      "Epoch: 914/10000 Iteration: 6399 Train loss: 0.006793\n",
      "Epoch: 915/10000 Iteration: 6406 Train loss: 0.006795\n",
      "Epoch: 916/10000 Iteration: 6413 Train loss: 0.006797\n",
      "Epoch: 917/10000 Iteration: 6420 Train loss: 0.006799\n",
      "Epoch: 918/10000 Iteration: 6427 Train loss: 0.006801\n",
      "Epoch: 919/10000 Iteration: 6434 Train loss: 0.006803\n",
      "Epoch: 920/10000 Iteration: 6441 Train loss: 0.006804\n",
      "Epoch: 921/10000 Iteration: 6448 Train loss: 0.006806\n",
      "Epoch: 922/10000 Iteration: 6455 Train loss: 0.006808\n",
      "Epoch: 923/10000 Iteration: 6462 Train loss: 0.006810\n",
      "Epoch: 924/10000 Iteration: 6469 Train loss: 0.006812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 925/10000 Iteration: 6476 Train loss: 0.006813\n",
      "Epoch: 926/10000 Iteration: 6483 Train loss: 0.006815\n",
      "Epoch: 927/10000 Iteration: 6490 Train loss: 0.006817\n",
      "Epoch: 928/10000 Iteration: 6497 Train loss: 0.006819\n",
      "Epoch: 929/10000 Iteration: 6504 Train loss: 0.006821\n",
      "Epoch: 930/10000 Iteration: 6511 Train loss: 0.006822\n",
      "Epoch: 931/10000 Iteration: 6518 Train loss: 0.006824\n",
      "Epoch: 932/10000 Iteration: 6525 Train loss: 0.006826\n",
      "Epoch: 933/10000 Iteration: 6532 Train loss: 0.006827\n",
      "Epoch: 934/10000 Iteration: 6539 Train loss: 0.006829\n",
      "Epoch: 935/10000 Iteration: 6546 Train loss: 0.006831\n",
      "Epoch: 936/10000 Iteration: 6553 Train loss: 0.006832\n",
      "Epoch: 937/10000 Iteration: 6560 Train loss: 0.006834\n",
      "Epoch: 938/10000 Iteration: 6567 Train loss: 0.006836\n",
      "Epoch: 939/10000 Iteration: 6574 Train loss: 0.006838\n",
      "Epoch: 940/10000 Iteration: 6581 Train loss: 0.006839\n",
      "Epoch: 941/10000 Iteration: 6588 Train loss: 0.006841\n",
      "Epoch: 942/10000 Iteration: 6595 Train loss: 0.006842\n",
      "Epoch: 943/10000 Iteration: 6602 Train loss: 0.006844\n",
      "Epoch: 944/10000 Iteration: 6609 Train loss: 0.006846\n",
      "Epoch: 945/10000 Iteration: 6616 Train loss: 0.006847\n",
      "Epoch: 946/10000 Iteration: 6623 Train loss: 0.006849\n",
      "Epoch: 947/10000 Iteration: 6630 Train loss: 0.006851\n",
      "Epoch: 948/10000 Iteration: 6637 Train loss: 0.006852\n",
      "Epoch: 949/10000 Iteration: 6644 Train loss: 0.006854\n",
      "Epoch: 950/10000 Iteration: 6651 Train loss: 0.006855\n",
      "Epoch: 951/10000 Iteration: 6658 Train loss: 0.006857\n",
      "Epoch: 952/10000 Iteration: 6665 Train loss: 0.006859\n",
      "Epoch: 953/10000 Iteration: 6672 Train loss: 0.006860\n",
      "Epoch: 954/10000 Iteration: 6679 Train loss: 0.006862\n",
      "Epoch: 955/10000 Iteration: 6686 Train loss: 0.006863\n",
      "Epoch: 956/10000 Iteration: 6693 Train loss: 0.006865\n",
      "Epoch: 957/10000 Iteration: 6700 Train loss: 0.006866\n",
      "Epoch: 958/10000 Iteration: 6707 Train loss: 0.006868\n",
      "Epoch: 959/10000 Iteration: 6714 Train loss: 0.006869\n",
      "Epoch: 960/10000 Iteration: 6721 Train loss: 0.006871\n",
      "Epoch: 961/10000 Iteration: 6728 Train loss: 0.006872\n",
      "Epoch: 962/10000 Iteration: 6735 Train loss: 0.006874\n",
      "Epoch: 963/10000 Iteration: 6742 Train loss: 0.006875\n",
      "Epoch: 964/10000 Iteration: 6749 Train loss: 0.006877\n",
      "Epoch: 965/10000 Iteration: 6756 Train loss: 0.006878\n",
      "Epoch: 966/10000 Iteration: 6763 Train loss: 0.006880\n",
      "Epoch: 967/10000 Iteration: 6770 Train loss: 0.006881\n",
      "Epoch: 968/10000 Iteration: 6777 Train loss: 0.006883\n",
      "Epoch: 969/10000 Iteration: 6784 Train loss: 0.006884\n",
      "Epoch: 970/10000 Iteration: 6791 Train loss: 0.006886\n",
      "Epoch: 971/10000 Iteration: 6798 Train loss: 0.006887\n",
      "Epoch: 972/10000 Iteration: 6805 Train loss: 0.006889\n",
      "Epoch: 973/10000 Iteration: 6812 Train loss: 0.006890\n",
      "Epoch: 974/10000 Iteration: 6819 Train loss: 0.006892\n",
      "Epoch: 975/10000 Iteration: 6826 Train loss: 0.006893\n",
      "Epoch: 976/10000 Iteration: 6833 Train loss: 0.006895\n",
      "Epoch: 977/10000 Iteration: 6840 Train loss: 0.006896\n",
      "Epoch: 978/10000 Iteration: 6847 Train loss: 0.006897\n",
      "Epoch: 979/10000 Iteration: 6854 Train loss: 0.006899\n",
      "Epoch: 980/10000 Iteration: 6861 Train loss: 0.006900\n",
      "Epoch: 981/10000 Iteration: 6868 Train loss: 0.006902\n",
      "Epoch: 982/10000 Iteration: 6875 Train loss: 0.006903\n",
      "Epoch: 983/10000 Iteration: 6882 Train loss: 0.006904\n",
      "Epoch: 984/10000 Iteration: 6889 Train loss: 0.006906\n",
      "Epoch: 985/10000 Iteration: 6896 Train loss: 0.006907\n",
      "Epoch: 986/10000 Iteration: 6903 Train loss: 0.006909\n",
      "Epoch: 987/10000 Iteration: 6910 Train loss: 0.006910\n",
      "Epoch: 988/10000 Iteration: 6917 Train loss: 0.006911\n",
      "Epoch: 989/10000 Iteration: 6924 Train loss: 0.006913\n",
      "Epoch: 990/10000 Iteration: 6931 Train loss: 0.006914\n",
      "Epoch: 991/10000 Iteration: 6938 Train loss: 0.006915\n",
      "Epoch: 992/10000 Iteration: 6945 Train loss: 0.006917\n",
      "Epoch: 993/10000 Iteration: 6952 Train loss: 0.006918\n",
      "Epoch: 994/10000 Iteration: 6959 Train loss: 0.006920\n",
      "Epoch: 995/10000 Iteration: 6966 Train loss: 0.006921\n",
      "Epoch: 996/10000 Iteration: 6973 Train loss: 0.006922\n",
      "Epoch: 997/10000 Iteration: 6980 Train loss: 0.006924\n",
      "Epoch: 998/10000 Iteration: 6987 Train loss: 0.006925\n",
      "Epoch: 999/10000 Iteration: 6994 Train loss: 0.006926\n",
      "Epoch: 1000/10000 Iteration: 7001 Train loss: 0.006927\n",
      "Epoch: 1001/10000 Iteration: 7008 Train loss: 0.006929\n",
      "Epoch: 1002/10000 Iteration: 7015 Train loss: 0.006930\n",
      "Epoch: 1003/10000 Iteration: 7022 Train loss: 0.006931\n",
      "Epoch: 1004/10000 Iteration: 7029 Train loss: 0.006933\n",
      "Epoch: 1005/10000 Iteration: 7036 Train loss: 0.006934\n",
      "Epoch: 1006/10000 Iteration: 7043 Train loss: 0.006935\n",
      "Epoch: 1007/10000 Iteration: 7050 Train loss: 0.006937\n",
      "Epoch: 1008/10000 Iteration: 7057 Train loss: 0.006938\n",
      "Epoch: 1009/10000 Iteration: 7064 Train loss: 0.006939\n",
      "Epoch: 1010/10000 Iteration: 7071 Train loss: 0.006940\n",
      "Epoch: 1011/10000 Iteration: 7078 Train loss: 0.006942\n",
      "Epoch: 1012/10000 Iteration: 7085 Train loss: 0.006943\n",
      "Epoch: 1013/10000 Iteration: 7092 Train loss: 0.006944\n",
      "Epoch: 1014/10000 Iteration: 7099 Train loss: 0.006946\n",
      "Epoch: 1015/10000 Iteration: 7106 Train loss: 0.006947\n",
      "Epoch: 1016/10000 Iteration: 7113 Train loss: 0.006948\n",
      "Epoch: 1017/10000 Iteration: 7120 Train loss: 0.006949\n",
      "Epoch: 1018/10000 Iteration: 7127 Train loss: 0.006951\n",
      "Epoch: 1019/10000 Iteration: 7134 Train loss: 0.006952\n",
      "Epoch: 1020/10000 Iteration: 7141 Train loss: 0.006953\n",
      "Epoch: 1021/10000 Iteration: 7148 Train loss: 0.006954\n",
      "Epoch: 1022/10000 Iteration: 7155 Train loss: 0.006956\n",
      "Epoch: 1023/10000 Iteration: 7162 Train loss: 0.006957\n",
      "Epoch: 1024/10000 Iteration: 7169 Train loss: 0.006958\n",
      "Epoch: 1025/10000 Iteration: 7176 Train loss: 0.006959\n",
      "Epoch: 1026/10000 Iteration: 7183 Train loss: 0.006960\n",
      "Epoch: 1027/10000 Iteration: 7190 Train loss: 0.006962\n",
      "Epoch: 1028/10000 Iteration: 7197 Train loss: 0.006963\n",
      "Epoch: 1029/10000 Iteration: 7204 Train loss: 0.006964\n",
      "Epoch: 1030/10000 Iteration: 7211 Train loss: 0.006965\n",
      "Epoch: 1031/10000 Iteration: 7218 Train loss: 0.006966\n",
      "Epoch: 1032/10000 Iteration: 7225 Train loss: 0.006968\n",
      "Epoch: 1033/10000 Iteration: 7232 Train loss: 0.006969\n",
      "Epoch: 1034/10000 Iteration: 7239 Train loss: 0.006970\n",
      "Epoch: 1035/10000 Iteration: 7246 Train loss: 0.006971\n",
      "Epoch: 1036/10000 Iteration: 7253 Train loss: 0.006972\n",
      "Epoch: 1037/10000 Iteration: 7260 Train loss: 0.006974\n",
      "Epoch: 1038/10000 Iteration: 7267 Train loss: 0.006975\n",
      "Epoch: 1039/10000 Iteration: 7274 Train loss: 0.006976\n",
      "Epoch: 1040/10000 Iteration: 7281 Train loss: 0.006977\n",
      "Epoch: 1041/10000 Iteration: 7288 Train loss: 0.006978\n",
      "Epoch: 1042/10000 Iteration: 7295 Train loss: 0.006979\n",
      "Epoch: 1043/10000 Iteration: 7302 Train loss: 0.006981\n",
      "Epoch: 1044/10000 Iteration: 7309 Train loss: 0.006982\n",
      "Epoch: 1045/10000 Iteration: 7316 Train loss: 0.006983\n",
      "Epoch: 1046/10000 Iteration: 7323 Train loss: 0.006984\n",
      "Epoch: 1047/10000 Iteration: 7330 Train loss: 0.006985\n",
      "Epoch: 1048/10000 Iteration: 7337 Train loss: 0.006986\n",
      "Epoch: 1049/10000 Iteration: 7344 Train loss: 0.006988\n",
      "Epoch: 1050/10000 Iteration: 7351 Train loss: 0.006989\n",
      "Epoch: 1051/10000 Iteration: 7358 Train loss: 0.006990\n",
      "Epoch: 1052/10000 Iteration: 7365 Train loss: 0.006991\n",
      "Epoch: 1053/10000 Iteration: 7372 Train loss: 0.006992\n",
      "Epoch: 1054/10000 Iteration: 7379 Train loss: 0.006993\n",
      "Epoch: 1055/10000 Iteration: 7386 Train loss: 0.006994\n",
      "Epoch: 1056/10000 Iteration: 7393 Train loss: 0.006995\n",
      "Epoch: 1057/10000 Iteration: 7400 Train loss: 0.006997\n",
      "Epoch: 1058/10000 Iteration: 7407 Train loss: 0.006998\n",
      "Epoch: 1059/10000 Iteration: 7414 Train loss: 0.006999\n",
      "Epoch: 1060/10000 Iteration: 7421 Train loss: 0.007000\n",
      "Epoch: 1061/10000 Iteration: 7428 Train loss: 0.007001\n",
      "Epoch: 1062/10000 Iteration: 7435 Train loss: 0.007002\n",
      "Epoch: 1063/10000 Iteration: 7442 Train loss: 0.007003\n",
      "Epoch: 1064/10000 Iteration: 7449 Train loss: 0.007004\n",
      "Epoch: 1065/10000 Iteration: 7456 Train loss: 0.007006\n",
      "Epoch: 1066/10000 Iteration: 7463 Train loss: 0.007007\n",
      "Epoch: 1067/10000 Iteration: 7470 Train loss: 0.007008\n",
      "Epoch: 1068/10000 Iteration: 7477 Train loss: 0.007009\n",
      "Epoch: 1069/10000 Iteration: 7484 Train loss: 0.007010\n",
      "Epoch: 1070/10000 Iteration: 7491 Train loss: 0.007011\n",
      "Epoch: 1071/10000 Iteration: 7498 Train loss: 0.007012\n",
      "Epoch: 1072/10000 Iteration: 7505 Train loss: 0.007013\n",
      "Epoch: 1073/10000 Iteration: 7512 Train loss: 0.007014\n",
      "Epoch: 1074/10000 Iteration: 7519 Train loss: 0.007015\n",
      "Epoch: 1075/10000 Iteration: 7526 Train loss: 0.007016\n",
      "Epoch: 1076/10000 Iteration: 7533 Train loss: 0.007018\n",
      "Epoch: 1077/10000 Iteration: 7540 Train loss: 0.007019\n",
      "Epoch: 1078/10000 Iteration: 7547 Train loss: 0.007020\n",
      "Epoch: 1079/10000 Iteration: 7554 Train loss: 0.007021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1080/10000 Iteration: 7561 Train loss: 0.007022\n",
      "Epoch: 1081/10000 Iteration: 7568 Train loss: 0.007023\n",
      "Epoch: 1082/10000 Iteration: 7575 Train loss: 0.007024\n",
      "Epoch: 1083/10000 Iteration: 7582 Train loss: 0.007025\n",
      "Epoch: 1084/10000 Iteration: 7589 Train loss: 0.007026\n",
      "Epoch: 1085/10000 Iteration: 7596 Train loss: 0.007027\n",
      "Epoch: 1086/10000 Iteration: 7603 Train loss: 0.007028\n",
      "Epoch: 1087/10000 Iteration: 7610 Train loss: 0.007029\n",
      "Epoch: 1088/10000 Iteration: 7617 Train loss: 0.007030\n",
      "Epoch: 1089/10000 Iteration: 7624 Train loss: 0.007031\n",
      "Epoch: 1090/10000 Iteration: 7631 Train loss: 0.007032\n",
      "Epoch: 1091/10000 Iteration: 7638 Train loss: 0.007033\n",
      "Epoch: 1092/10000 Iteration: 7645 Train loss: 0.007034\n",
      "Epoch: 1093/10000 Iteration: 7652 Train loss: 0.007035\n",
      "Epoch: 1094/10000 Iteration: 7659 Train loss: 0.007036\n",
      "Epoch: 1095/10000 Iteration: 7666 Train loss: 0.007038\n",
      "Epoch: 1096/10000 Iteration: 7673 Train loss: 0.007039\n",
      "Epoch: 1097/10000 Iteration: 7680 Train loss: 0.007040\n",
      "Epoch: 1098/10000 Iteration: 7687 Train loss: 0.007041\n",
      "Epoch: 1099/10000 Iteration: 7694 Train loss: 0.007042\n",
      "Epoch: 1100/10000 Iteration: 7701 Train loss: 0.007043\n",
      "Epoch: 1101/10000 Iteration: 7708 Train loss: 0.007044\n",
      "Epoch: 1102/10000 Iteration: 7715 Train loss: 0.007045\n",
      "Epoch: 1103/10000 Iteration: 7722 Train loss: 0.007046\n",
      "Epoch: 1104/10000 Iteration: 7729 Train loss: 0.007047\n",
      "Epoch: 1105/10000 Iteration: 7736 Train loss: 0.007048\n",
      "Epoch: 1106/10000 Iteration: 7743 Train loss: 0.007049\n",
      "Epoch: 1107/10000 Iteration: 7750 Train loss: 0.007050\n",
      "Epoch: 1108/10000 Iteration: 7757 Train loss: 0.007051\n",
      "Epoch: 1109/10000 Iteration: 7764 Train loss: 0.007052\n",
      "Epoch: 1110/10000 Iteration: 7771 Train loss: 0.007053\n",
      "Epoch: 1111/10000 Iteration: 7778 Train loss: 0.007054\n",
      "Epoch: 1112/10000 Iteration: 7785 Train loss: 0.007055\n",
      "Epoch: 1113/10000 Iteration: 7792 Train loss: 0.007056\n",
      "Epoch: 1114/10000 Iteration: 7799 Train loss: 0.007057\n",
      "Epoch: 1115/10000 Iteration: 7806 Train loss: 0.007058\n",
      "Epoch: 1116/10000 Iteration: 7813 Train loss: 0.007059\n",
      "Epoch: 1117/10000 Iteration: 7820 Train loss: 0.007060\n",
      "Epoch: 1118/10000 Iteration: 7827 Train loss: 0.007061\n",
      "Epoch: 1119/10000 Iteration: 7834 Train loss: 0.007062\n",
      "Epoch: 1120/10000 Iteration: 7841 Train loss: 0.007063\n",
      "Epoch: 1121/10000 Iteration: 7848 Train loss: 0.007064\n",
      "Epoch: 1122/10000 Iteration: 7855 Train loss: 0.007065\n",
      "Epoch: 1123/10000 Iteration: 7862 Train loss: 0.007066\n",
      "Epoch: 1124/10000 Iteration: 7869 Train loss: 0.007067\n",
      "Epoch: 1125/10000 Iteration: 7876 Train loss: 0.007068\n",
      "Epoch: 1126/10000 Iteration: 7883 Train loss: 0.007068\n",
      "Epoch: 1127/10000 Iteration: 7890 Train loss: 0.007069\n",
      "Epoch: 1128/10000 Iteration: 7897 Train loss: 0.007070\n",
      "Epoch: 1129/10000 Iteration: 7904 Train loss: 0.007071\n",
      "Epoch: 1130/10000 Iteration: 7911 Train loss: 0.007072\n",
      "Epoch: 1131/10000 Iteration: 7918 Train loss: 0.007073\n",
      "Epoch: 1132/10000 Iteration: 7925 Train loss: 0.007074\n",
      "Epoch: 1133/10000 Iteration: 7932 Train loss: 0.007075\n",
      "Epoch: 1134/10000 Iteration: 7939 Train loss: 0.007076\n",
      "Epoch: 1135/10000 Iteration: 7946 Train loss: 0.007077\n",
      "Epoch: 1136/10000 Iteration: 7953 Train loss: 0.007078\n",
      "Epoch: 1137/10000 Iteration: 7960 Train loss: 0.007079\n",
      "Epoch: 1138/10000 Iteration: 7967 Train loss: 0.007080\n",
      "Epoch: 1139/10000 Iteration: 7974 Train loss: 0.007081\n",
      "Epoch: 1140/10000 Iteration: 7981 Train loss: 0.007082\n",
      "Epoch: 1141/10000 Iteration: 7988 Train loss: 0.007083\n",
      "Epoch: 1142/10000 Iteration: 7995 Train loss: 0.007084\n",
      "Epoch: 1143/10000 Iteration: 8002 Train loss: 0.007085\n",
      "Epoch: 1144/10000 Iteration: 8009 Train loss: 0.007086\n",
      "Epoch: 1145/10000 Iteration: 8016 Train loss: 0.007086\n",
      "Epoch: 1146/10000 Iteration: 8023 Train loss: 0.007087\n",
      "Epoch: 1147/10000 Iteration: 8030 Train loss: 0.007088\n",
      "Epoch: 1148/10000 Iteration: 8037 Train loss: 0.007089\n",
      "Epoch: 1149/10000 Iteration: 8044 Train loss: 0.007090\n",
      "Epoch: 1150/10000 Iteration: 8051 Train loss: 0.007091\n",
      "Epoch: 1151/10000 Iteration: 8058 Train loss: 0.007092\n",
      "Epoch: 1152/10000 Iteration: 8065 Train loss: 0.007093\n",
      "Epoch: 1153/10000 Iteration: 8072 Train loss: 0.007094\n",
      "Epoch: 1154/10000 Iteration: 8079 Train loss: 0.007095\n",
      "Epoch: 1155/10000 Iteration: 8086 Train loss: 0.007096\n",
      "Epoch: 1156/10000 Iteration: 8093 Train loss: 0.007097\n",
      "Epoch: 1157/10000 Iteration: 8100 Train loss: 0.007098\n",
      "Epoch: 1158/10000 Iteration: 8107 Train loss: 0.007098\n",
      "Epoch: 1159/10000 Iteration: 8114 Train loss: 0.007099\n",
      "Epoch: 1160/10000 Iteration: 8121 Train loss: 0.007100\n",
      "Epoch: 1161/10000 Iteration: 8128 Train loss: 0.007101\n",
      "Epoch: 1162/10000 Iteration: 8135 Train loss: 0.007102\n",
      "Epoch: 1163/10000 Iteration: 8142 Train loss: 0.007103\n",
      "Epoch: 1164/10000 Iteration: 8149 Train loss: 0.007104\n",
      "Epoch: 1165/10000 Iteration: 8156 Train loss: 0.007105\n",
      "Epoch: 1166/10000 Iteration: 8163 Train loss: 0.007106\n",
      "Epoch: 1167/10000 Iteration: 8170 Train loss: 0.007107\n",
      "Epoch: 1168/10000 Iteration: 8177 Train loss: 0.007107\n",
      "Epoch: 1169/10000 Iteration: 8184 Train loss: 0.007108\n",
      "Epoch: 1170/10000 Iteration: 8191 Train loss: 0.007109\n",
      "Epoch: 1171/10000 Iteration: 8198 Train loss: 0.007110\n",
      "Epoch: 1172/10000 Iteration: 8205 Train loss: 0.007111\n",
      "Epoch: 1173/10000 Iteration: 8212 Train loss: 0.007112\n",
      "Epoch: 1174/10000 Iteration: 8219 Train loss: 0.007113\n",
      "Epoch: 1175/10000 Iteration: 8226 Train loss: 0.007114\n",
      "Epoch: 1176/10000 Iteration: 8233 Train loss: 0.007114\n",
      "Epoch: 1177/10000 Iteration: 8240 Train loss: 0.007115\n",
      "Epoch: 1178/10000 Iteration: 8247 Train loss: 0.007116\n",
      "Epoch: 1179/10000 Iteration: 8254 Train loss: 0.007117\n",
      "Epoch: 1180/10000 Iteration: 8261 Train loss: 0.007118\n",
      "Epoch: 1181/10000 Iteration: 8268 Train loss: 0.007119\n",
      "Epoch: 1182/10000 Iteration: 8275 Train loss: 0.007120\n",
      "Epoch: 1183/10000 Iteration: 8282 Train loss: 0.007121\n",
      "Epoch: 1184/10000 Iteration: 8289 Train loss: 0.007121\n",
      "Epoch: 1185/10000 Iteration: 8296 Train loss: 0.007122\n",
      "Epoch: 1186/10000 Iteration: 8303 Train loss: 0.007123\n",
      "Epoch: 1187/10000 Iteration: 8310 Train loss: 0.007124\n",
      "Epoch: 1188/10000 Iteration: 8317 Train loss: 0.007125\n",
      "Epoch: 1189/10000 Iteration: 8324 Train loss: 0.007126\n",
      "Epoch: 1190/10000 Iteration: 8331 Train loss: 0.007127\n",
      "Epoch: 1191/10000 Iteration: 8338 Train loss: 0.007127\n",
      "Epoch: 1192/10000 Iteration: 8345 Train loss: 0.007128\n",
      "Epoch: 1193/10000 Iteration: 8352 Train loss: 0.007129\n",
      "Epoch: 1194/10000 Iteration: 8359 Train loss: 0.007130\n",
      "Epoch: 1195/10000 Iteration: 8366 Train loss: 0.007131\n",
      "Epoch: 1196/10000 Iteration: 8373 Train loss: 0.007132\n",
      "Epoch: 1197/10000 Iteration: 8380 Train loss: 0.007132\n",
      "Epoch: 1198/10000 Iteration: 8387 Train loss: 0.007133\n",
      "Epoch: 1199/10000 Iteration: 8394 Train loss: 0.007134\n",
      "Epoch: 1200/10000 Iteration: 8401 Train loss: 0.007135\n",
      "Epoch: 1201/10000 Iteration: 8408 Train loss: 0.007136\n",
      "Epoch: 1202/10000 Iteration: 8415 Train loss: 0.007137\n",
      "Epoch: 1203/10000 Iteration: 8422 Train loss: 0.007137\n",
      "Epoch: 1204/10000 Iteration: 8429 Train loss: 0.007138\n",
      "Epoch: 1205/10000 Iteration: 8436 Train loss: 0.007139\n",
      "Epoch: 1206/10000 Iteration: 8443 Train loss: 0.007140\n",
      "Epoch: 1207/10000 Iteration: 8450 Train loss: 0.007141\n",
      "Epoch: 1208/10000 Iteration: 8457 Train loss: 0.007142\n",
      "Epoch: 1209/10000 Iteration: 8464 Train loss: 0.007142\n",
      "Epoch: 1210/10000 Iteration: 8471 Train loss: 0.007143\n",
      "Epoch: 1211/10000 Iteration: 8478 Train loss: 0.007144\n",
      "Epoch: 1212/10000 Iteration: 8485 Train loss: 0.007145\n",
      "Epoch: 1213/10000 Iteration: 8492 Train loss: 0.007146\n",
      "Epoch: 1214/10000 Iteration: 8499 Train loss: 0.007146\n",
      "Epoch: 1215/10000 Iteration: 8506 Train loss: 0.007147\n",
      "Epoch: 1216/10000 Iteration: 8513 Train loss: 0.007148\n",
      "Epoch: 1217/10000 Iteration: 8520 Train loss: 0.007149\n",
      "Epoch: 1218/10000 Iteration: 8527 Train loss: 0.007150\n",
      "Epoch: 1219/10000 Iteration: 8534 Train loss: 0.007150\n",
      "Epoch: 1220/10000 Iteration: 8541 Train loss: 0.007151\n",
      "Epoch: 1221/10000 Iteration: 8548 Train loss: 0.007152\n",
      "Epoch: 1222/10000 Iteration: 8555 Train loss: 0.007153\n",
      "Epoch: 1223/10000 Iteration: 8562 Train loss: 0.007154\n",
      "Epoch: 1224/10000 Iteration: 8569 Train loss: 0.007154\n",
      "Epoch: 1225/10000 Iteration: 8576 Train loss: 0.007155\n",
      "Epoch: 1226/10000 Iteration: 8583 Train loss: 0.007156\n",
      "Epoch: 1227/10000 Iteration: 8590 Train loss: 0.007157\n",
      "Epoch: 1228/10000 Iteration: 8597 Train loss: 0.007157\n",
      "Epoch: 1229/10000 Iteration: 8604 Train loss: 0.007158\n",
      "Epoch: 1230/10000 Iteration: 8611 Train loss: 0.007159\n",
      "Epoch: 1231/10000 Iteration: 8618 Train loss: 0.007160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1232/10000 Iteration: 8625 Train loss: 0.007161\n",
      "Epoch: 1233/10000 Iteration: 8632 Train loss: 0.007161\n",
      "Epoch: 1234/10000 Iteration: 8639 Train loss: 0.007162\n",
      "Epoch: 1235/10000 Iteration: 8646 Train loss: 0.007163\n",
      "Epoch: 1236/10000 Iteration: 8653 Train loss: 0.007164\n",
      "Epoch: 1237/10000 Iteration: 8660 Train loss: 0.007164\n",
      "Epoch: 1238/10000 Iteration: 8667 Train loss: 0.007165\n",
      "Epoch: 1239/10000 Iteration: 8674 Train loss: 0.007166\n",
      "Epoch: 1240/10000 Iteration: 8681 Train loss: 0.007167\n",
      "Epoch: 1241/10000 Iteration: 8688 Train loss: 0.007167\n",
      "Epoch: 1242/10000 Iteration: 8695 Train loss: 0.007168\n",
      "Epoch: 1243/10000 Iteration: 8702 Train loss: 0.007169\n",
      "Epoch: 1244/10000 Iteration: 8709 Train loss: 0.007170\n",
      "Epoch: 1245/10000 Iteration: 8716 Train loss: 0.007170\n",
      "Epoch: 1246/10000 Iteration: 8723 Train loss: 0.007171\n",
      "Epoch: 1247/10000 Iteration: 8730 Train loss: 0.007172\n",
      "Epoch: 1248/10000 Iteration: 8737 Train loss: 0.007173\n",
      "Epoch: 1249/10000 Iteration: 8744 Train loss: 0.007173\n",
      "Epoch: 1250/10000 Iteration: 8751 Train loss: 0.007174\n",
      "Epoch: 1251/10000 Iteration: 8758 Train loss: 0.007175\n",
      "Epoch: 1252/10000 Iteration: 8765 Train loss: 0.007176\n",
      "Epoch: 1253/10000 Iteration: 8772 Train loss: 0.007176\n",
      "Epoch: 1254/10000 Iteration: 8779 Train loss: 0.007177\n",
      "Epoch: 1255/10000 Iteration: 8786 Train loss: 0.007178\n",
      "Epoch: 1256/10000 Iteration: 8793 Train loss: 0.007179\n",
      "Epoch: 1257/10000 Iteration: 8800 Train loss: 0.007179\n",
      "Epoch: 1258/10000 Iteration: 8807 Train loss: 0.007180\n",
      "Epoch: 1259/10000 Iteration: 8814 Train loss: 0.007181\n",
      "Epoch: 1260/10000 Iteration: 8821 Train loss: 0.007181\n",
      "Epoch: 1261/10000 Iteration: 8828 Train loss: 0.007182\n",
      "Epoch: 1262/10000 Iteration: 8835 Train loss: 0.007183\n",
      "Epoch: 1263/10000 Iteration: 8842 Train loss: 0.007184\n",
      "Epoch: 1264/10000 Iteration: 8849 Train loss: 0.007184\n",
      "Epoch: 1265/10000 Iteration: 8856 Train loss: 0.007185\n",
      "Epoch: 1266/10000 Iteration: 8863 Train loss: 0.007186\n",
      "Epoch: 1267/10000 Iteration: 8870 Train loss: 0.007186\n",
      "Epoch: 1268/10000 Iteration: 8877 Train loss: 0.007187\n",
      "Epoch: 1269/10000 Iteration: 8884 Train loss: 0.007188\n",
      "Epoch: 1270/10000 Iteration: 8891 Train loss: 0.007189\n",
      "Epoch: 1271/10000 Iteration: 8898 Train loss: 0.007189\n",
      "Epoch: 1272/10000 Iteration: 8905 Train loss: 0.007190\n",
      "Epoch: 1273/10000 Iteration: 8912 Train loss: 0.007191\n",
      "Epoch: 1274/10000 Iteration: 8919 Train loss: 0.007191\n",
      "Epoch: 1275/10000 Iteration: 8926 Train loss: 0.007192\n",
      "Epoch: 1276/10000 Iteration: 8933 Train loss: 0.007193\n",
      "Epoch: 1277/10000 Iteration: 8940 Train loss: 0.007193\n",
      "Epoch: 1278/10000 Iteration: 8947 Train loss: 0.007194\n",
      "Epoch: 1279/10000 Iteration: 8954 Train loss: 0.007195\n",
      "Epoch: 1280/10000 Iteration: 8961 Train loss: 0.007195\n",
      "Epoch: 1281/10000 Iteration: 8968 Train loss: 0.007196\n",
      "Epoch: 1282/10000 Iteration: 8975 Train loss: 0.007197\n",
      "Epoch: 1283/10000 Iteration: 8982 Train loss: 0.007197\n",
      "Epoch: 1284/10000 Iteration: 8989 Train loss: 0.007198\n",
      "Epoch: 1285/10000 Iteration: 8996 Train loss: 0.007199\n",
      "Epoch: 1286/10000 Iteration: 9003 Train loss: 0.007200\n",
      "Epoch: 1287/10000 Iteration: 9010 Train loss: 0.007200\n",
      "Epoch: 1288/10000 Iteration: 9017 Train loss: 0.007201\n",
      "Epoch: 1289/10000 Iteration: 9024 Train loss: 0.007202\n",
      "Epoch: 1290/10000 Iteration: 9031 Train loss: 0.007202\n",
      "Epoch: 1291/10000 Iteration: 9038 Train loss: 0.007203\n",
      "Epoch: 1292/10000 Iteration: 9045 Train loss: 0.007204\n",
      "Epoch: 1293/10000 Iteration: 9052 Train loss: 0.007204\n",
      "Epoch: 1294/10000 Iteration: 9059 Train loss: 0.007205\n",
      "Epoch: 1295/10000 Iteration: 9066 Train loss: 0.007205\n",
      "Epoch: 1296/10000 Iteration: 9073 Train loss: 0.007206\n",
      "Epoch: 1297/10000 Iteration: 9080 Train loss: 0.007207\n",
      "Epoch: 1298/10000 Iteration: 9087 Train loss: 0.007207\n",
      "Epoch: 1299/10000 Iteration: 9094 Train loss: 0.007208\n",
      "Epoch: 1300/10000 Iteration: 9101 Train loss: 0.007209\n",
      "Epoch: 1301/10000 Iteration: 9108 Train loss: 0.007209\n",
      "Epoch: 1302/10000 Iteration: 9115 Train loss: 0.007210\n",
      "Epoch: 1303/10000 Iteration: 9122 Train loss: 0.007211\n",
      "Epoch: 1304/10000 Iteration: 9129 Train loss: 0.007211\n",
      "Epoch: 1305/10000 Iteration: 9136 Train loss: 0.007212\n",
      "Epoch: 1306/10000 Iteration: 9143 Train loss: 0.007213\n",
      "Epoch: 1307/10000 Iteration: 9150 Train loss: 0.007213\n",
      "Epoch: 1308/10000 Iteration: 9157 Train loss: 0.007214\n",
      "Epoch: 1309/10000 Iteration: 9164 Train loss: 0.007214\n",
      "Epoch: 1310/10000 Iteration: 9171 Train loss: 0.007215\n",
      "Epoch: 1311/10000 Iteration: 9178 Train loss: 0.007216\n",
      "Epoch: 1312/10000 Iteration: 9185 Train loss: 0.007216\n",
      "Epoch: 1313/10000 Iteration: 9192 Train loss: 0.007217\n",
      "Epoch: 1314/10000 Iteration: 9199 Train loss: 0.007218\n",
      "Epoch: 1315/10000 Iteration: 9206 Train loss: 0.007218\n",
      "Epoch: 1316/10000 Iteration: 9213 Train loss: 0.007219\n",
      "Epoch: 1317/10000 Iteration: 9220 Train loss: 0.007219\n",
      "Epoch: 1318/10000 Iteration: 9227 Train loss: 0.007220\n",
      "Epoch: 1319/10000 Iteration: 9234 Train loss: 0.007221\n",
      "Epoch: 1320/10000 Iteration: 9241 Train loss: 0.007221\n",
      "Epoch: 1321/10000 Iteration: 9248 Train loss: 0.007222\n",
      "Epoch: 1322/10000 Iteration: 9255 Train loss: 0.007222\n",
      "Epoch: 1323/10000 Iteration: 9262 Train loss: 0.007223\n",
      "Epoch: 1324/10000 Iteration: 9269 Train loss: 0.007224\n",
      "Epoch: 1325/10000 Iteration: 9276 Train loss: 0.007224\n",
      "Epoch: 1326/10000 Iteration: 9283 Train loss: 0.007225\n",
      "Epoch: 1327/10000 Iteration: 9290 Train loss: 0.007225\n",
      "Epoch: 1328/10000 Iteration: 9297 Train loss: 0.007226\n",
      "Epoch: 1329/10000 Iteration: 9304 Train loss: 0.007226\n",
      "Epoch: 1330/10000 Iteration: 9311 Train loss: 0.007227\n",
      "Epoch: 1331/10000 Iteration: 9318 Train loss: 0.007228\n",
      "Epoch: 1332/10000 Iteration: 9325 Train loss: 0.007228\n",
      "Epoch: 1333/10000 Iteration: 9332 Train loss: 0.007229\n",
      "Epoch: 1334/10000 Iteration: 9339 Train loss: 0.007229\n",
      "Epoch: 1335/10000 Iteration: 9346 Train loss: 0.007230\n",
      "Epoch: 1336/10000 Iteration: 9353 Train loss: 0.007231\n",
      "Epoch: 1337/10000 Iteration: 9360 Train loss: 0.007231\n",
      "Epoch: 1338/10000 Iteration: 9367 Train loss: 0.007232\n",
      "Epoch: 1339/10000 Iteration: 9374 Train loss: 0.007232\n",
      "Epoch: 1340/10000 Iteration: 9381 Train loss: 0.007233\n",
      "Epoch: 1341/10000 Iteration: 9388 Train loss: 0.007233\n",
      "Epoch: 1342/10000 Iteration: 9395 Train loss: 0.007234\n",
      "Epoch: 1343/10000 Iteration: 9402 Train loss: 0.007234\n",
      "Epoch: 1344/10000 Iteration: 9409 Train loss: 0.007235\n",
      "Epoch: 1345/10000 Iteration: 9416 Train loss: 0.007236\n",
      "Epoch: 1346/10000 Iteration: 9423 Train loss: 0.007236\n",
      "Epoch: 1347/10000 Iteration: 9430 Train loss: 0.007237\n",
      "Epoch: 1348/10000 Iteration: 9437 Train loss: 0.007237\n",
      "Epoch: 1349/10000 Iteration: 9444 Train loss: 0.007238\n",
      "Epoch: 1350/10000 Iteration: 9451 Train loss: 0.007238\n",
      "Epoch: 1351/10000 Iteration: 9458 Train loss: 0.007239\n",
      "Epoch: 1352/10000 Iteration: 9465 Train loss: 0.007239\n",
      "Epoch: 1353/10000 Iteration: 9472 Train loss: 0.007240\n",
      "Epoch: 1354/10000 Iteration: 9479 Train loss: 0.007240\n",
      "Epoch: 1355/10000 Iteration: 9486 Train loss: 0.007241\n",
      "Epoch: 1356/10000 Iteration: 9493 Train loss: 0.007241\n",
      "Epoch: 1357/10000 Iteration: 9500 Train loss: 0.007242\n",
      "Epoch: 1358/10000 Iteration: 9507 Train loss: 0.007243\n",
      "Epoch: 1359/10000 Iteration: 9514 Train loss: 0.007243\n",
      "Epoch: 1360/10000 Iteration: 9521 Train loss: 0.007244\n",
      "Epoch: 1361/10000 Iteration: 9528 Train loss: 0.007244\n",
      "Epoch: 1362/10000 Iteration: 9535 Train loss: 0.007245\n",
      "Epoch: 1363/10000 Iteration: 9542 Train loss: 0.007245\n",
      "Epoch: 1364/10000 Iteration: 9549 Train loss: 0.007246\n",
      "Epoch: 1365/10000 Iteration: 9556 Train loss: 0.007246\n",
      "Epoch: 1366/10000 Iteration: 9563 Train loss: 0.007247\n",
      "Epoch: 1367/10000 Iteration: 9570 Train loss: 0.007247\n",
      "Epoch: 1368/10000 Iteration: 9577 Train loss: 0.007248\n",
      "Epoch: 1369/10000 Iteration: 9584 Train loss: 0.007248\n",
      "Epoch: 1370/10000 Iteration: 9591 Train loss: 0.007249\n",
      "Epoch: 1371/10000 Iteration: 9598 Train loss: 0.007249\n",
      "Epoch: 1372/10000 Iteration: 9605 Train loss: 0.007250\n",
      "Epoch: 1373/10000 Iteration: 9612 Train loss: 0.007250\n",
      "Epoch: 1374/10000 Iteration: 9619 Train loss: 0.007251\n",
      "Epoch: 1375/10000 Iteration: 9626 Train loss: 0.007251\n",
      "Epoch: 1376/10000 Iteration: 9633 Train loss: 0.007252\n",
      "Epoch: 1377/10000 Iteration: 9640 Train loss: 0.007252\n",
      "Epoch: 1378/10000 Iteration: 9647 Train loss: 0.007253\n",
      "Epoch: 1379/10000 Iteration: 9654 Train loss: 0.007253\n",
      "Epoch: 1380/10000 Iteration: 9661 Train loss: 0.007254\n",
      "Epoch: 1381/10000 Iteration: 9668 Train loss: 0.007254\n",
      "Epoch: 1382/10000 Iteration: 9675 Train loss: 0.007254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1383/10000 Iteration: 9682 Train loss: 0.007255\n",
      "Epoch: 1384/10000 Iteration: 9689 Train loss: 0.007255\n",
      "Epoch: 1385/10000 Iteration: 9696 Train loss: 0.007256\n",
      "Epoch: 1386/10000 Iteration: 9703 Train loss: 0.007256\n",
      "Epoch: 1387/10000 Iteration: 9710 Train loss: 0.007257\n",
      "Epoch: 1388/10000 Iteration: 9717 Train loss: 0.007257\n",
      "Epoch: 1389/10000 Iteration: 9724 Train loss: 0.007258\n",
      "Epoch: 1390/10000 Iteration: 9731 Train loss: 0.007258\n",
      "Epoch: 1391/10000 Iteration: 9738 Train loss: 0.007259\n",
      "Epoch: 1392/10000 Iteration: 9745 Train loss: 0.007259\n",
      "Epoch: 1393/10000 Iteration: 9752 Train loss: 0.007259\n",
      "Epoch: 1394/10000 Iteration: 9759 Train loss: 0.007260\n",
      "Epoch: 1395/10000 Iteration: 9766 Train loss: 0.007260\n",
      "Epoch: 1396/10000 Iteration: 9773 Train loss: 0.007261\n",
      "Epoch: 1397/10000 Iteration: 9780 Train loss: 0.007261\n",
      "Epoch: 1398/10000 Iteration: 9787 Train loss: 0.007262\n",
      "Epoch: 1399/10000 Iteration: 9794 Train loss: 0.007262\n",
      "Epoch: 1400/10000 Iteration: 9801 Train loss: 0.007263\n",
      "Epoch: 1401/10000 Iteration: 9808 Train loss: 0.007263\n",
      "Epoch: 1402/10000 Iteration: 9815 Train loss: 0.007263\n",
      "Epoch: 1403/10000 Iteration: 9822 Train loss: 0.007264\n",
      "Epoch: 1404/10000 Iteration: 9829 Train loss: 0.007264\n",
      "Epoch: 1405/10000 Iteration: 9836 Train loss: 0.007265\n",
      "Epoch: 1406/10000 Iteration: 9843 Train loss: 0.007265\n",
      "Epoch: 1407/10000 Iteration: 9850 Train loss: 0.007266\n",
      "Epoch: 1408/10000 Iteration: 9857 Train loss: 0.007266\n",
      "Epoch: 1409/10000 Iteration: 9864 Train loss: 0.007266\n",
      "Epoch: 1410/10000 Iteration: 9871 Train loss: 0.007267\n",
      "Epoch: 1411/10000 Iteration: 9878 Train loss: 0.007267\n",
      "Epoch: 1412/10000 Iteration: 9885 Train loss: 0.007268\n",
      "Epoch: 1413/10000 Iteration: 9892 Train loss: 0.007268\n",
      "Epoch: 1414/10000 Iteration: 9899 Train loss: 0.007268\n",
      "Epoch: 1415/10000 Iteration: 9906 Train loss: 0.007269\n",
      "Epoch: 1416/10000 Iteration: 9913 Train loss: 0.007269\n",
      "Epoch: 1417/10000 Iteration: 9920 Train loss: 0.007270\n",
      "Epoch: 1418/10000 Iteration: 9927 Train loss: 0.007270\n",
      "Epoch: 1419/10000 Iteration: 9934 Train loss: 0.007270\n",
      "Epoch: 1420/10000 Iteration: 9941 Train loss: 0.007271\n",
      "Epoch: 1421/10000 Iteration: 9948 Train loss: 0.007271\n",
      "Epoch: 1422/10000 Iteration: 9955 Train loss: 0.007272\n",
      "Epoch: 1423/10000 Iteration: 9962 Train loss: 0.007272\n",
      "Epoch: 1424/10000 Iteration: 9969 Train loss: 0.007272\n",
      "Epoch: 1425/10000 Iteration: 9976 Train loss: 0.007273\n",
      "Epoch: 1426/10000 Iteration: 9983 Train loss: 0.007273\n",
      "Epoch: 1427/10000 Iteration: 9990 Train loss: 0.007273\n",
      "Epoch: 1428/10000 Iteration: 9997 Train loss: 0.007274\n",
      "Epoch: 1429/10000 Iteration: 10004 Train loss: 0.007274\n",
      "Epoch: 1430/10000 Iteration: 10011 Train loss: 0.007275\n",
      "Epoch: 1431/10000 Iteration: 10018 Train loss: 0.007275\n",
      "Epoch: 1432/10000 Iteration: 10025 Train loss: 0.007275\n",
      "Epoch: 1433/10000 Iteration: 10032 Train loss: 0.007276\n",
      "Epoch: 1434/10000 Iteration: 10039 Train loss: 0.007276\n",
      "Epoch: 1435/10000 Iteration: 10046 Train loss: 0.007276\n",
      "Epoch: 1436/10000 Iteration: 10053 Train loss: 0.007277\n",
      "Epoch: 1437/10000 Iteration: 10060 Train loss: 0.007277\n",
      "Epoch: 1438/10000 Iteration: 10067 Train loss: 0.007277\n",
      "Epoch: 1439/10000 Iteration: 10074 Train loss: 0.007278\n",
      "Epoch: 1440/10000 Iteration: 10081 Train loss: 0.007278\n",
      "Epoch: 1441/10000 Iteration: 10088 Train loss: 0.007278\n",
      "Epoch: 1442/10000 Iteration: 10095 Train loss: 0.007279\n",
      "Epoch: 1443/10000 Iteration: 10102 Train loss: 0.007279\n",
      "Epoch: 1444/10000 Iteration: 10109 Train loss: 0.007279\n",
      "Epoch: 1445/10000 Iteration: 10116 Train loss: 0.007280\n",
      "Epoch: 1446/10000 Iteration: 10123 Train loss: 0.007280\n",
      "Epoch: 1447/10000 Iteration: 10130 Train loss: 0.007280\n",
      "Epoch: 1448/10000 Iteration: 10137 Train loss: 0.007281\n",
      "Epoch: 1449/10000 Iteration: 10144 Train loss: 0.007281\n",
      "Epoch: 1450/10000 Iteration: 10151 Train loss: 0.007281\n",
      "Epoch: 1451/10000 Iteration: 10158 Train loss: 0.007282\n",
      "Epoch: 1452/10000 Iteration: 10165 Train loss: 0.007282\n",
      "Epoch: 1453/10000 Iteration: 10172 Train loss: 0.007282\n",
      "Epoch: 1454/10000 Iteration: 10179 Train loss: 0.007283\n",
      "Epoch: 1455/10000 Iteration: 10186 Train loss: 0.007283\n",
      "Epoch: 1456/10000 Iteration: 10193 Train loss: 0.007283\n",
      "Epoch: 1457/10000 Iteration: 10200 Train loss: 0.007284\n",
      "Epoch: 1458/10000 Iteration: 10207 Train loss: 0.007284\n",
      "Epoch: 1459/10000 Iteration: 10214 Train loss: 0.007284\n",
      "Epoch: 1460/10000 Iteration: 10221 Train loss: 0.007285\n",
      "Epoch: 1461/10000 Iteration: 10228 Train loss: 0.007285\n",
      "Epoch: 1462/10000 Iteration: 10235 Train loss: 0.007285\n",
      "Epoch: 1463/10000 Iteration: 10242 Train loss: 0.007285\n",
      "Epoch: 1464/10000 Iteration: 10249 Train loss: 0.007286\n",
      "Epoch: 1465/10000 Iteration: 10256 Train loss: 0.007286\n",
      "Epoch: 1466/10000 Iteration: 10263 Train loss: 0.007286\n",
      "Epoch: 1467/10000 Iteration: 10270 Train loss: 0.007287\n",
      "Epoch: 1468/10000 Iteration: 10277 Train loss: 0.007287\n",
      "Epoch: 1469/10000 Iteration: 10284 Train loss: 0.007287\n",
      "Epoch: 1470/10000 Iteration: 10291 Train loss: 0.007287\n",
      "Epoch: 1471/10000 Iteration: 10298 Train loss: 0.007288\n",
      "Epoch: 1472/10000 Iteration: 10305 Train loss: 0.007288\n",
      "Epoch: 1473/10000 Iteration: 10312 Train loss: 0.007288\n",
      "Epoch: 1474/10000 Iteration: 10319 Train loss: 0.007289\n",
      "Epoch: 1475/10000 Iteration: 10326 Train loss: 0.007289\n",
      "Epoch: 1476/10000 Iteration: 10333 Train loss: 0.007289\n",
      "Epoch: 1477/10000 Iteration: 10340 Train loss: 0.007289\n",
      "Epoch: 1478/10000 Iteration: 10347 Train loss: 0.007290\n",
      "Epoch: 1479/10000 Iteration: 10354 Train loss: 0.007290\n",
      "Epoch: 1480/10000 Iteration: 10361 Train loss: 0.007290\n",
      "Epoch: 1481/10000 Iteration: 10368 Train loss: 0.007290\n",
      "Epoch: 1482/10000 Iteration: 10375 Train loss: 0.007291\n",
      "Epoch: 1483/10000 Iteration: 10382 Train loss: 0.007291\n",
      "Epoch: 1484/10000 Iteration: 10389 Train loss: 0.007291\n",
      "Epoch: 1485/10000 Iteration: 10396 Train loss: 0.007291\n",
      "Epoch: 1486/10000 Iteration: 10403 Train loss: 0.007292\n",
      "Epoch: 1487/10000 Iteration: 10410 Train loss: 0.007292\n",
      "Epoch: 1488/10000 Iteration: 10417 Train loss: 0.007292\n",
      "Epoch: 1489/10000 Iteration: 10424 Train loss: 0.007292\n",
      "Epoch: 1490/10000 Iteration: 10431 Train loss: 0.007293\n",
      "Epoch: 1491/10000 Iteration: 10438 Train loss: 0.007293\n",
      "Epoch: 1492/10000 Iteration: 10445 Train loss: 0.007293\n",
      "Epoch: 1493/10000 Iteration: 10452 Train loss: 0.007293\n",
      "Epoch: 1494/10000 Iteration: 10459 Train loss: 0.007293\n",
      "Epoch: 1495/10000 Iteration: 10466 Train loss: 0.007294\n",
      "Epoch: 1496/10000 Iteration: 10473 Train loss: 0.007294\n",
      "Epoch: 1497/10000 Iteration: 10480 Train loss: 0.007294\n",
      "Epoch: 1498/10000 Iteration: 10487 Train loss: 0.007294\n",
      "Epoch: 1499/10000 Iteration: 10494 Train loss: 0.007295\n",
      "Epoch: 1500/10000 Iteration: 10501 Train loss: 0.007295\n",
      "Epoch: 1501/10000 Iteration: 10508 Train loss: 0.007295\n",
      "Epoch: 1502/10000 Iteration: 10515 Train loss: 0.007295\n",
      "Epoch: 1503/10000 Iteration: 10522 Train loss: 0.007295\n",
      "Epoch: 1504/10000 Iteration: 10529 Train loss: 0.007296\n",
      "Epoch: 1505/10000 Iteration: 10536 Train loss: 0.007296\n",
      "Epoch: 1506/10000 Iteration: 10543 Train loss: 0.007296\n",
      "Epoch: 1507/10000 Iteration: 10550 Train loss: 0.007296\n",
      "Epoch: 1508/10000 Iteration: 10557 Train loss: 0.007296\n",
      "Epoch: 1509/10000 Iteration: 10564 Train loss: 0.007297\n",
      "Epoch: 1510/10000 Iteration: 10571 Train loss: 0.007297\n",
      "Epoch: 1511/10000 Iteration: 10578 Train loss: 0.007297\n",
      "Epoch: 1512/10000 Iteration: 10585 Train loss: 0.007297\n",
      "Epoch: 1513/10000 Iteration: 10592 Train loss: 0.007297\n",
      "Epoch: 1514/10000 Iteration: 10599 Train loss: 0.007297\n",
      "Epoch: 1515/10000 Iteration: 10606 Train loss: 0.007298\n",
      "Epoch: 1516/10000 Iteration: 10613 Train loss: 0.007298\n",
      "Epoch: 1517/10000 Iteration: 10620 Train loss: 0.007298\n",
      "Epoch: 1518/10000 Iteration: 10627 Train loss: 0.007298\n",
      "Epoch: 1519/10000 Iteration: 10634 Train loss: 0.007298\n",
      "Epoch: 1520/10000 Iteration: 10641 Train loss: 0.007299\n",
      "Epoch: 1521/10000 Iteration: 10648 Train loss: 0.007299\n",
      "Epoch: 1522/10000 Iteration: 10655 Train loss: 0.007299\n",
      "Epoch: 1523/10000 Iteration: 10662 Train loss: 0.007299\n",
      "Epoch: 1524/10000 Iteration: 10669 Train loss: 0.007299\n",
      "Epoch: 1525/10000 Iteration: 10676 Train loss: 0.007299\n",
      "Epoch: 1526/10000 Iteration: 10683 Train loss: 0.007300\n",
      "Epoch: 1527/10000 Iteration: 10690 Train loss: 0.007300\n",
      "Epoch: 1528/10000 Iteration: 10697 Train loss: 0.007300\n",
      "Epoch: 1529/10000 Iteration: 10704 Train loss: 0.007300\n",
      "Epoch: 1530/10000 Iteration: 10711 Train loss: 0.007300\n",
      "Epoch: 1531/10000 Iteration: 10718 Train loss: 0.007300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1532/10000 Iteration: 10725 Train loss: 0.007300\n",
      "Epoch: 1533/10000 Iteration: 10732 Train loss: 0.007301\n",
      "Epoch: 1534/10000 Iteration: 10739 Train loss: 0.007301\n",
      "Epoch: 1535/10000 Iteration: 10746 Train loss: 0.007301\n",
      "Epoch: 1536/10000 Iteration: 10753 Train loss: 0.007301\n",
      "Epoch: 1537/10000 Iteration: 10760 Train loss: 0.007301\n",
      "Epoch: 1538/10000 Iteration: 10767 Train loss: 0.007301\n",
      "Epoch: 1539/10000 Iteration: 10774 Train loss: 0.007301\n",
      "Epoch: 1540/10000 Iteration: 10781 Train loss: 0.007301\n",
      "Epoch: 1541/10000 Iteration: 10788 Train loss: 0.007302\n",
      "Epoch: 1542/10000 Iteration: 10795 Train loss: 0.007302\n",
      "Epoch: 1543/10000 Iteration: 10802 Train loss: 0.007302\n",
      "Epoch: 1544/10000 Iteration: 10809 Train loss: 0.007302\n",
      "Epoch: 1545/10000 Iteration: 10816 Train loss: 0.007302\n",
      "Epoch: 1546/10000 Iteration: 10823 Train loss: 0.007302\n",
      "Epoch: 1547/10000 Iteration: 10830 Train loss: 0.007302\n",
      "Epoch: 1548/10000 Iteration: 10837 Train loss: 0.007302\n",
      "Epoch: 1549/10000 Iteration: 10844 Train loss: 0.007302\n",
      "Epoch: 1550/10000 Iteration: 10851 Train loss: 0.007303\n",
      "Epoch: 1551/10000 Iteration: 10858 Train loss: 0.007303\n",
      "Epoch: 1552/10000 Iteration: 10865 Train loss: 0.007303\n",
      "Epoch: 1553/10000 Iteration: 10872 Train loss: 0.007303\n",
      "Epoch: 1554/10000 Iteration: 10879 Train loss: 0.007303\n",
      "Epoch: 1555/10000 Iteration: 10886 Train loss: 0.007303\n",
      "Epoch: 1556/10000 Iteration: 10893 Train loss: 0.007303\n",
      "Epoch: 1557/10000 Iteration: 10900 Train loss: 0.007303\n",
      "Epoch: 1558/10000 Iteration: 10907 Train loss: 0.007303\n",
      "Epoch: 1559/10000 Iteration: 10914 Train loss: 0.007303\n",
      "Epoch: 1560/10000 Iteration: 10921 Train loss: 0.007304\n",
      "Epoch: 1561/10000 Iteration: 10928 Train loss: 0.007304\n",
      "Epoch: 1562/10000 Iteration: 10935 Train loss: 0.007304\n",
      "Epoch: 1563/10000 Iteration: 10942 Train loss: 0.007304\n",
      "Epoch: 1564/10000 Iteration: 10949 Train loss: 0.007304\n",
      "Epoch: 1565/10000 Iteration: 10956 Train loss: 0.007304\n",
      "Epoch: 1566/10000 Iteration: 10963 Train loss: 0.007304\n",
      "Epoch: 1567/10000 Iteration: 10970 Train loss: 0.007304\n",
      "Epoch: 1568/10000 Iteration: 10977 Train loss: 0.007304\n",
      "Epoch: 1569/10000 Iteration: 10984 Train loss: 0.007304\n",
      "Epoch: 1570/10000 Iteration: 10991 Train loss: 0.007304\n",
      "Epoch: 1571/10000 Iteration: 10998 Train loss: 0.007304\n",
      "Epoch: 1572/10000 Iteration: 11005 Train loss: 0.007304\n",
      "Epoch: 1573/10000 Iteration: 11012 Train loss: 0.007304\n",
      "Epoch: 1574/10000 Iteration: 11019 Train loss: 0.007304\n",
      "Epoch: 1575/10000 Iteration: 11026 Train loss: 0.007304\n",
      "Epoch: 1576/10000 Iteration: 11033 Train loss: 0.007305\n",
      "Epoch: 1577/10000 Iteration: 11040 Train loss: 0.007305\n",
      "Epoch: 1578/10000 Iteration: 11047 Train loss: 0.007305\n",
      "Epoch: 1579/10000 Iteration: 11054 Train loss: 0.007305\n",
      "Epoch: 1580/10000 Iteration: 11061 Train loss: 0.007305\n",
      "Epoch: 1581/10000 Iteration: 11068 Train loss: 0.007305\n",
      "Epoch: 1582/10000 Iteration: 11075 Train loss: 0.007305\n",
      "Epoch: 1583/10000 Iteration: 11082 Train loss: 0.007305\n",
      "Epoch: 1584/10000 Iteration: 11089 Train loss: 0.007305\n",
      "Epoch: 1585/10000 Iteration: 11096 Train loss: 0.007305\n",
      "Epoch: 1586/10000 Iteration: 11103 Train loss: 0.007305\n",
      "Epoch: 1587/10000 Iteration: 11110 Train loss: 0.007305\n",
      "Epoch: 1588/10000 Iteration: 11117 Train loss: 0.007305\n",
      "Epoch: 1589/10000 Iteration: 11124 Train loss: 0.007305\n",
      "Epoch: 1590/10000 Iteration: 11131 Train loss: 0.007305\n",
      "Epoch: 1591/10000 Iteration: 11138 Train loss: 0.007305\n",
      "Epoch: 1592/10000 Iteration: 11145 Train loss: 0.007305\n",
      "Epoch: 1593/10000 Iteration: 11152 Train loss: 0.007305\n",
      "Epoch: 1594/10000 Iteration: 11159 Train loss: 0.007305\n",
      "Epoch: 1595/10000 Iteration: 11166 Train loss: 0.007305\n",
      "Epoch: 1596/10000 Iteration: 11173 Train loss: 0.007305\n",
      "Epoch: 1597/10000 Iteration: 11180 Train loss: 0.007305\n",
      "Epoch: 1598/10000 Iteration: 11187 Train loss: 0.007305\n",
      "Epoch: 1599/10000 Iteration: 11194 Train loss: 0.007305\n",
      "Epoch: 1600/10000 Iteration: 11201 Train loss: 0.007305\n",
      "Epoch: 1601/10000 Iteration: 11208 Train loss: 0.007305\n",
      "Epoch: 1602/10000 Iteration: 11215 Train loss: 0.007305\n",
      "Epoch: 1603/10000 Iteration: 11222 Train loss: 0.007305\n",
      "Epoch: 1604/10000 Iteration: 11229 Train loss: 0.007305\n",
      "Epoch: 1605/10000 Iteration: 11236 Train loss: 0.007305\n",
      "Epoch: 1606/10000 Iteration: 11243 Train loss: 0.007305\n",
      "Epoch: 1607/10000 Iteration: 11250 Train loss: 0.007305\n",
      "Epoch: 1608/10000 Iteration: 11257 Train loss: 0.007305\n",
      "Epoch: 1609/10000 Iteration: 11264 Train loss: 0.007305\n",
      "Epoch: 1610/10000 Iteration: 11271 Train loss: 0.007305\n",
      "Epoch: 1611/10000 Iteration: 11278 Train loss: 0.007305\n",
      "Epoch: 1612/10000 Iteration: 11285 Train loss: 0.007305\n",
      "Epoch: 1613/10000 Iteration: 11292 Train loss: 0.007305\n",
      "Epoch: 1614/10000 Iteration: 11299 Train loss: 0.007305\n",
      "Epoch: 1615/10000 Iteration: 11306 Train loss: 0.007305\n",
      "Epoch: 1616/10000 Iteration: 11313 Train loss: 0.007305\n",
      "Epoch: 1617/10000 Iteration: 11320 Train loss: 0.007305\n",
      "Epoch: 1618/10000 Iteration: 11327 Train loss: 0.007305\n",
      "Epoch: 1619/10000 Iteration: 11334 Train loss: 0.007305\n",
      "Epoch: 1620/10000 Iteration: 11341 Train loss: 0.007305\n",
      "Epoch: 1621/10000 Iteration: 11348 Train loss: 0.007304\n",
      "Epoch: 1622/10000 Iteration: 11355 Train loss: 0.007304\n",
      "Epoch: 1623/10000 Iteration: 11362 Train loss: 0.007304\n",
      "Epoch: 1624/10000 Iteration: 11369 Train loss: 0.007304\n",
      "Epoch: 1625/10000 Iteration: 11376 Train loss: 0.007304\n",
      "Epoch: 1626/10000 Iteration: 11383 Train loss: 0.007304\n",
      "Epoch: 1627/10000 Iteration: 11390 Train loss: 0.007304\n",
      "Epoch: 1628/10000 Iteration: 11397 Train loss: 0.007304\n",
      "Epoch: 1629/10000 Iteration: 11404 Train loss: 0.007304\n",
      "Epoch: 1630/10000 Iteration: 11411 Train loss: 0.007304\n",
      "Epoch: 1631/10000 Iteration: 11418 Train loss: 0.007304\n",
      "Epoch: 1632/10000 Iteration: 11425 Train loss: 0.007304\n",
      "Epoch: 1633/10000 Iteration: 11432 Train loss: 0.007304\n",
      "Epoch: 1634/10000 Iteration: 11439 Train loss: 0.007304\n",
      "Epoch: 1635/10000 Iteration: 11446 Train loss: 0.007304\n",
      "Epoch: 1636/10000 Iteration: 11453 Train loss: 0.007304\n",
      "Epoch: 1637/10000 Iteration: 11460 Train loss: 0.007303\n",
      "Epoch: 1638/10000 Iteration: 11467 Train loss: 0.007303\n",
      "Epoch: 1639/10000 Iteration: 11474 Train loss: 0.007303\n",
      "Epoch: 1640/10000 Iteration: 11481 Train loss: 0.007303\n",
      "Epoch: 1641/10000 Iteration: 11488 Train loss: 0.007303\n",
      "Epoch: 1642/10000 Iteration: 11495 Train loss: 0.007303\n",
      "Epoch: 1643/10000 Iteration: 11502 Train loss: 0.007303\n",
      "Epoch: 1644/10000 Iteration: 11509 Train loss: 0.007303\n",
      "Epoch: 1645/10000 Iteration: 11516 Train loss: 0.007303\n",
      "Epoch: 1646/10000 Iteration: 11523 Train loss: 0.007303\n",
      "Epoch: 1647/10000 Iteration: 11530 Train loss: 0.007303\n",
      "Epoch: 1648/10000 Iteration: 11537 Train loss: 0.007302\n",
      "Epoch: 1649/10000 Iteration: 11544 Train loss: 0.007302\n",
      "Epoch: 1650/10000 Iteration: 11551 Train loss: 0.007302\n",
      "Epoch: 1651/10000 Iteration: 11558 Train loss: 0.007302\n",
      "Epoch: 1652/10000 Iteration: 11565 Train loss: 0.007302\n",
      "Epoch: 1653/10000 Iteration: 11572 Train loss: 0.007302\n",
      "Epoch: 1654/10000 Iteration: 11579 Train loss: 0.007302\n",
      "Epoch: 1655/10000 Iteration: 11586 Train loss: 0.007302\n",
      "Epoch: 1656/10000 Iteration: 11593 Train loss: 0.007302\n",
      "Epoch: 1657/10000 Iteration: 11600 Train loss: 0.007302\n",
      "Epoch: 1658/10000 Iteration: 11607 Train loss: 0.007301\n",
      "Epoch: 1659/10000 Iteration: 11614 Train loss: 0.007301\n",
      "Epoch: 1660/10000 Iteration: 11621 Train loss: 0.007301\n",
      "Epoch: 1661/10000 Iteration: 11628 Train loss: 0.007301\n",
      "Epoch: 1662/10000 Iteration: 11635 Train loss: 0.007301\n",
      "Epoch: 1663/10000 Iteration: 11642 Train loss: 0.007301\n",
      "Epoch: 1664/10000 Iteration: 11649 Train loss: 0.007301\n",
      "Epoch: 1665/10000 Iteration: 11656 Train loss: 0.007301\n",
      "Epoch: 1666/10000 Iteration: 11663 Train loss: 0.007300\n",
      "Epoch: 1667/10000 Iteration: 11670 Train loss: 0.007300\n",
      "Epoch: 1668/10000 Iteration: 11677 Train loss: 0.007300\n",
      "Epoch: 1669/10000 Iteration: 11684 Train loss: 0.007300\n",
      "Epoch: 1670/10000 Iteration: 11691 Train loss: 0.007300\n",
      "Epoch: 1671/10000 Iteration: 11698 Train loss: 0.007300\n",
      "Epoch: 1672/10000 Iteration: 11705 Train loss: 0.007300\n",
      "Epoch: 1673/10000 Iteration: 11712 Train loss: 0.007299\n",
      "Epoch: 1674/10000 Iteration: 11719 Train loss: 0.007299\n",
      "Epoch: 1675/10000 Iteration: 11726 Train loss: 0.007299\n",
      "Epoch: 1676/10000 Iteration: 11733 Train loss: 0.007299\n",
      "Epoch: 1677/10000 Iteration: 11740 Train loss: 0.007299\n",
      "Epoch: 1678/10000 Iteration: 11747 Train loss: 0.007299\n",
      "Epoch: 1679/10000 Iteration: 11754 Train loss: 0.007299\n",
      "Epoch: 1680/10000 Iteration: 11761 Train loss: 0.007298\n",
      "Epoch: 1681/10000 Iteration: 11768 Train loss: 0.007298\n",
      "Epoch: 1682/10000 Iteration: 11775 Train loss: 0.007298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1683/10000 Iteration: 11782 Train loss: 0.007298\n",
      "Epoch: 1684/10000 Iteration: 11789 Train loss: 0.007298\n",
      "Epoch: 1685/10000 Iteration: 11796 Train loss: 0.007298\n",
      "Epoch: 1686/10000 Iteration: 11803 Train loss: 0.007297\n",
      "Epoch: 1687/10000 Iteration: 11810 Train loss: 0.007297\n",
      "Epoch: 1688/10000 Iteration: 11817 Train loss: 0.007297\n",
      "Epoch: 1689/10000 Iteration: 11824 Train loss: 0.007297\n",
      "Epoch: 1690/10000 Iteration: 11831 Train loss: 0.007297\n",
      "Epoch: 1691/10000 Iteration: 11838 Train loss: 0.007297\n",
      "Epoch: 1692/10000 Iteration: 11845 Train loss: 0.007296\n",
      "Epoch: 1693/10000 Iteration: 11852 Train loss: 0.007296\n",
      "Epoch: 1694/10000 Iteration: 11859 Train loss: 0.007296\n",
      "Epoch: 1695/10000 Iteration: 11866 Train loss: 0.007296\n",
      "Epoch: 1696/10000 Iteration: 11873 Train loss: 0.007296\n",
      "Epoch: 1697/10000 Iteration: 11880 Train loss: 0.007295\n",
      "Epoch: 1698/10000 Iteration: 11887 Train loss: 0.007295\n",
      "Epoch: 1699/10000 Iteration: 11894 Train loss: 0.007295\n",
      "Epoch: 1700/10000 Iteration: 11901 Train loss: 0.007295\n",
      "Epoch: 1701/10000 Iteration: 11908 Train loss: 0.007295\n",
      "Epoch: 1702/10000 Iteration: 11915 Train loss: 0.007295\n",
      "Epoch: 1703/10000 Iteration: 11922 Train loss: 0.007294\n",
      "Epoch: 1704/10000 Iteration: 11929 Train loss: 0.007294\n",
      "Epoch: 1705/10000 Iteration: 11936 Train loss: 0.007294\n",
      "Epoch: 1706/10000 Iteration: 11943 Train loss: 0.007294\n",
      "Epoch: 1707/10000 Iteration: 11950 Train loss: 0.007294\n",
      "Epoch: 1708/10000 Iteration: 11957 Train loss: 0.007293\n",
      "Epoch: 1709/10000 Iteration: 11964 Train loss: 0.007293\n",
      "Epoch: 1710/10000 Iteration: 11971 Train loss: 0.007293\n",
      "Epoch: 1711/10000 Iteration: 11978 Train loss: 0.007293\n",
      "Epoch: 1712/10000 Iteration: 11985 Train loss: 0.007292\n",
      "Epoch: 1713/10000 Iteration: 11992 Train loss: 0.007292\n",
      "Epoch: 1714/10000 Iteration: 11999 Train loss: 0.007292\n",
      "Epoch: 1715/10000 Iteration: 12006 Train loss: 0.007292\n",
      "Epoch: 1716/10000 Iteration: 12013 Train loss: 0.007292\n",
      "Epoch: 1717/10000 Iteration: 12020 Train loss: 0.007291\n",
      "Epoch: 1718/10000 Iteration: 12027 Train loss: 0.007291\n",
      "Epoch: 1719/10000 Iteration: 12034 Train loss: 0.007291\n",
      "Epoch: 1720/10000 Iteration: 12041 Train loss: 0.007291\n",
      "Epoch: 1721/10000 Iteration: 12048 Train loss: 0.007291\n",
      "Epoch: 1722/10000 Iteration: 12055 Train loss: 0.007290\n",
      "Epoch: 1723/10000 Iteration: 12062 Train loss: 0.007290\n",
      "Epoch: 1724/10000 Iteration: 12069 Train loss: 0.007290\n",
      "Epoch: 1725/10000 Iteration: 12076 Train loss: 0.007290\n",
      "Epoch: 1726/10000 Iteration: 12083 Train loss: 0.007289\n",
      "Epoch: 1727/10000 Iteration: 12090 Train loss: 0.007289\n",
      "Epoch: 1728/10000 Iteration: 12097 Train loss: 0.007289\n",
      "Epoch: 1729/10000 Iteration: 12104 Train loss: 0.007289\n",
      "Epoch: 1730/10000 Iteration: 12111 Train loss: 0.007288\n",
      "Epoch: 1731/10000 Iteration: 12118 Train loss: 0.007288\n",
      "Epoch: 1732/10000 Iteration: 12125 Train loss: 0.007288\n",
      "Epoch: 1733/10000 Iteration: 12132 Train loss: 0.007288\n",
      "Epoch: 1734/10000 Iteration: 12139 Train loss: 0.007287\n",
      "Epoch: 1735/10000 Iteration: 12146 Train loss: 0.007287\n",
      "Epoch: 1736/10000 Iteration: 12153 Train loss: 0.007287\n",
      "Epoch: 1737/10000 Iteration: 12160 Train loss: 0.007287\n",
      "Epoch: 1738/10000 Iteration: 12167 Train loss: 0.007287\n",
      "Epoch: 1739/10000 Iteration: 12174 Train loss: 0.007286\n",
      "Epoch: 1740/10000 Iteration: 12181 Train loss: 0.007286\n",
      "Epoch: 1741/10000 Iteration: 12188 Train loss: 0.007286\n",
      "Epoch: 1742/10000 Iteration: 12195 Train loss: 0.007285\n",
      "Epoch: 1743/10000 Iteration: 12202 Train loss: 0.007285\n",
      "Epoch: 1744/10000 Iteration: 12209 Train loss: 0.007285\n",
      "Epoch: 1745/10000 Iteration: 12216 Train loss: 0.007285\n",
      "Epoch: 1746/10000 Iteration: 12223 Train loss: 0.007284\n",
      "Epoch: 1747/10000 Iteration: 12230 Train loss: 0.007284\n",
      "Epoch: 1748/10000 Iteration: 12237 Train loss: 0.007284\n",
      "Epoch: 1749/10000 Iteration: 12244 Train loss: 0.007284\n",
      "Epoch: 1750/10000 Iteration: 12251 Train loss: 0.007283\n",
      "Epoch: 1751/10000 Iteration: 12258 Train loss: 0.007283\n",
      "Epoch: 1752/10000 Iteration: 12265 Train loss: 0.007283\n",
      "Epoch: 1753/10000 Iteration: 12272 Train loss: 0.007283\n",
      "Epoch: 1754/10000 Iteration: 12279 Train loss: 0.007282\n",
      "Epoch: 1755/10000 Iteration: 12286 Train loss: 0.007282\n",
      "Epoch: 1756/10000 Iteration: 12293 Train loss: 0.007282\n",
      "Epoch: 1757/10000 Iteration: 12300 Train loss: 0.007281\n",
      "Epoch: 1758/10000 Iteration: 12307 Train loss: 0.007281\n",
      "Epoch: 1759/10000 Iteration: 12314 Train loss: 0.007281\n",
      "Epoch: 1760/10000 Iteration: 12321 Train loss: 0.007281\n",
      "Epoch: 1761/10000 Iteration: 12328 Train loss: 0.007280\n",
      "Epoch: 1762/10000 Iteration: 12335 Train loss: 0.007280\n",
      "Epoch: 1763/10000 Iteration: 12342 Train loss: 0.007280\n",
      "Epoch: 1764/10000 Iteration: 12349 Train loss: 0.007280\n",
      "Epoch: 1765/10000 Iteration: 12356 Train loss: 0.007279\n",
      "Epoch: 1766/10000 Iteration: 12363 Train loss: 0.007279\n",
      "Epoch: 1767/10000 Iteration: 12370 Train loss: 0.007279\n",
      "Epoch: 1768/10000 Iteration: 12377 Train loss: 0.007278\n",
      "Epoch: 1769/10000 Iteration: 12384 Train loss: 0.007278\n",
      "Epoch: 1770/10000 Iteration: 12391 Train loss: 0.007278\n",
      "Epoch: 1771/10000 Iteration: 12398 Train loss: 0.007277\n",
      "Epoch: 1772/10000 Iteration: 12405 Train loss: 0.007277\n",
      "Epoch: 1773/10000 Iteration: 12412 Train loss: 0.007277\n",
      "Epoch: 1774/10000 Iteration: 12419 Train loss: 0.007277\n",
      "Epoch: 1775/10000 Iteration: 12426 Train loss: 0.007276\n",
      "Epoch: 1776/10000 Iteration: 12433 Train loss: 0.007276\n",
      "Epoch: 1777/10000 Iteration: 12440 Train loss: 0.007276\n",
      "Epoch: 1778/10000 Iteration: 12447 Train loss: 0.007275\n",
      "Epoch: 1779/10000 Iteration: 12454 Train loss: 0.007275\n",
      "Epoch: 1780/10000 Iteration: 12461 Train loss: 0.007275\n",
      "Epoch: 1781/10000 Iteration: 12468 Train loss: 0.007274\n",
      "Epoch: 1782/10000 Iteration: 12475 Train loss: 0.007274\n",
      "Epoch: 1783/10000 Iteration: 12482 Train loss: 0.007274\n",
      "Epoch: 1784/10000 Iteration: 12489 Train loss: 0.007273\n",
      "Epoch: 1785/10000 Iteration: 12496 Train loss: 0.007273\n",
      "Epoch: 1786/10000 Iteration: 12503 Train loss: 0.007273\n",
      "Epoch: 1787/10000 Iteration: 12510 Train loss: 0.007273\n",
      "Epoch: 1788/10000 Iteration: 12517 Train loss: 0.007272\n",
      "Epoch: 1789/10000 Iteration: 12524 Train loss: 0.007272\n",
      "Epoch: 1790/10000 Iteration: 12531 Train loss: 0.007272\n",
      "Epoch: 1791/10000 Iteration: 12538 Train loss: 0.007271\n",
      "Epoch: 1792/10000 Iteration: 12545 Train loss: 0.007271\n",
      "Epoch: 1793/10000 Iteration: 12552 Train loss: 0.007271\n",
      "Epoch: 1794/10000 Iteration: 12559 Train loss: 0.007270\n",
      "Epoch: 1795/10000 Iteration: 12566 Train loss: 0.007270\n",
      "Epoch: 1796/10000 Iteration: 12573 Train loss: 0.007270\n",
      "Epoch: 1797/10000 Iteration: 12580 Train loss: 0.007269\n",
      "Epoch: 1798/10000 Iteration: 12587 Train loss: 0.007269\n",
      "Epoch: 1799/10000 Iteration: 12594 Train loss: 0.007269\n",
      "Epoch: 1800/10000 Iteration: 12601 Train loss: 0.007268\n",
      "Epoch: 1801/10000 Iteration: 12608 Train loss: 0.007268\n",
      "Epoch: 1802/10000 Iteration: 12615 Train loss: 0.007268\n",
      "Epoch: 1803/10000 Iteration: 12622 Train loss: 0.007267\n",
      "Epoch: 1804/10000 Iteration: 12629 Train loss: 0.007267\n",
      "Epoch: 1805/10000 Iteration: 12636 Train loss: 0.007267\n",
      "Epoch: 1806/10000 Iteration: 12643 Train loss: 0.007266\n",
      "Epoch: 1807/10000 Iteration: 12650 Train loss: 0.007266\n",
      "Epoch: 1808/10000 Iteration: 12657 Train loss: 0.007266\n",
      "Epoch: 1809/10000 Iteration: 12664 Train loss: 0.007265\n",
      "Epoch: 1810/10000 Iteration: 12671 Train loss: 0.007265\n",
      "Epoch: 1811/10000 Iteration: 12678 Train loss: 0.007265\n",
      "Epoch: 1812/10000 Iteration: 12685 Train loss: 0.007264\n",
      "Epoch: 1813/10000 Iteration: 12692 Train loss: 0.007264\n",
      "Epoch: 1814/10000 Iteration: 12699 Train loss: 0.007263\n",
      "Epoch: 1815/10000 Iteration: 12706 Train loss: 0.007263\n",
      "Epoch: 1816/10000 Iteration: 12713 Train loss: 0.007263\n",
      "Epoch: 1817/10000 Iteration: 12720 Train loss: 0.007262\n",
      "Epoch: 1818/10000 Iteration: 12727 Train loss: 0.007262\n",
      "Epoch: 1819/10000 Iteration: 12734 Train loss: 0.007262\n",
      "Epoch: 1820/10000 Iteration: 12741 Train loss: 0.007261\n",
      "Epoch: 1821/10000 Iteration: 12748 Train loss: 0.007261\n",
      "Epoch: 1822/10000 Iteration: 12755 Train loss: 0.007261\n",
      "Epoch: 1823/10000 Iteration: 12762 Train loss: 0.007260\n",
      "Epoch: 1824/10000 Iteration: 12769 Train loss: 0.007260\n",
      "Epoch: 1825/10000 Iteration: 12776 Train loss: 0.007260\n",
      "Epoch: 1826/10000 Iteration: 12783 Train loss: 0.007259\n",
      "Epoch: 1827/10000 Iteration: 12790 Train loss: 0.007259\n",
      "Epoch: 1828/10000 Iteration: 12797 Train loss: 0.007259\n",
      "Epoch: 1829/10000 Iteration: 12804 Train loss: 0.007258\n",
      "Epoch: 1830/10000 Iteration: 12811 Train loss: 0.007258\n",
      "Epoch: 1831/10000 Iteration: 12818 Train loss: 0.007257\n",
      "Epoch: 1832/10000 Iteration: 12825 Train loss: 0.007257\n",
      "Epoch: 1833/10000 Iteration: 12832 Train loss: 0.007257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1834/10000 Iteration: 12839 Train loss: 0.007256\n",
      "Epoch: 1835/10000 Iteration: 12846 Train loss: 0.007256\n",
      "Epoch: 1836/10000 Iteration: 12853 Train loss: 0.007256\n",
      "Epoch: 1837/10000 Iteration: 12860 Train loss: 0.007255\n",
      "Epoch: 1838/10000 Iteration: 12867 Train loss: 0.007255\n",
      "Epoch: 1839/10000 Iteration: 12874 Train loss: 0.007254\n",
      "Epoch: 1840/10000 Iteration: 12881 Train loss: 0.007254\n",
      "Epoch: 1841/10000 Iteration: 12888 Train loss: 0.007254\n",
      "Epoch: 1842/10000 Iteration: 12895 Train loss: 0.007253\n",
      "Epoch: 1843/10000 Iteration: 12902 Train loss: 0.007253\n",
      "Epoch: 1844/10000 Iteration: 12909 Train loss: 0.007253\n",
      "Epoch: 1845/10000 Iteration: 12916 Train loss: 0.007252\n",
      "Epoch: 1846/10000 Iteration: 12923 Train loss: 0.007252\n",
      "Epoch: 1847/10000 Iteration: 12930 Train loss: 0.007251\n",
      "Epoch: 1848/10000 Iteration: 12937 Train loss: 0.007251\n",
      "Epoch: 1849/10000 Iteration: 12944 Train loss: 0.007251\n",
      "Epoch: 1850/10000 Iteration: 12951 Train loss: 0.007250\n",
      "Epoch: 1851/10000 Iteration: 12958 Train loss: 0.007250\n",
      "Epoch: 1852/10000 Iteration: 12965 Train loss: 0.007250\n",
      "Epoch: 1853/10000 Iteration: 12972 Train loss: 0.007249\n",
      "Epoch: 1854/10000 Iteration: 12979 Train loss: 0.007249\n",
      "Epoch: 1855/10000 Iteration: 12986 Train loss: 0.007248\n",
      "Epoch: 1856/10000 Iteration: 12993 Train loss: 0.007248\n",
      "Epoch: 1857/10000 Iteration: 13000 Train loss: 0.007248\n",
      "Epoch: 1858/10000 Iteration: 13007 Train loss: 0.007247\n",
      "Epoch: 1859/10000 Iteration: 13014 Train loss: 0.007247\n",
      "Epoch: 1860/10000 Iteration: 13021 Train loss: 0.007246\n",
      "Epoch: 1861/10000 Iteration: 13028 Train loss: 0.007246\n",
      "Epoch: 1862/10000 Iteration: 13035 Train loss: 0.007246\n",
      "Epoch: 1863/10000 Iteration: 13042 Train loss: 0.007245\n",
      "Epoch: 1864/10000 Iteration: 13049 Train loss: 0.007245\n",
      "Epoch: 1865/10000 Iteration: 13056 Train loss: 0.007245\n",
      "Epoch: 1866/10000 Iteration: 13063 Train loss: 0.007244\n",
      "Epoch: 1867/10000 Iteration: 13070 Train loss: 0.007244\n",
      "Epoch: 1868/10000 Iteration: 13077 Train loss: 0.007243\n",
      "Epoch: 1869/10000 Iteration: 13084 Train loss: 0.007243\n",
      "Epoch: 1870/10000 Iteration: 13091 Train loss: 0.007243\n",
      "Epoch: 1871/10000 Iteration: 13098 Train loss: 0.007242\n",
      "Epoch: 1872/10000 Iteration: 13105 Train loss: 0.007242\n",
      "Epoch: 1873/10000 Iteration: 13112 Train loss: 0.007241\n",
      "Epoch: 1874/10000 Iteration: 13119 Train loss: 0.007241\n",
      "Epoch: 1875/10000 Iteration: 13126 Train loss: 0.007241\n",
      "Epoch: 1876/10000 Iteration: 13133 Train loss: 0.007240\n",
      "Epoch: 1877/10000 Iteration: 13140 Train loss: 0.007240\n",
      "Epoch: 1878/10000 Iteration: 13147 Train loss: 0.007239\n",
      "Epoch: 1879/10000 Iteration: 13154 Train loss: 0.007239\n",
      "Epoch: 1880/10000 Iteration: 13161 Train loss: 0.007239\n",
      "Epoch: 1881/10000 Iteration: 13168 Train loss: 0.007238\n",
      "Epoch: 1882/10000 Iteration: 13175 Train loss: 0.007238\n",
      "Epoch: 1883/10000 Iteration: 13182 Train loss: 0.007237\n",
      "Epoch: 1884/10000 Iteration: 13189 Train loss: 0.007237\n",
      "Epoch: 1885/10000 Iteration: 13196 Train loss: 0.007237\n",
      "Epoch: 1886/10000 Iteration: 13203 Train loss: 0.007236\n",
      "Epoch: 1887/10000 Iteration: 13210 Train loss: 0.007236\n",
      "Epoch: 1888/10000 Iteration: 13217 Train loss: 0.007235\n",
      "Epoch: 1889/10000 Iteration: 13224 Train loss: 0.007235\n",
      "Epoch: 1890/10000 Iteration: 13231 Train loss: 0.007234\n",
      "Epoch: 1891/10000 Iteration: 13238 Train loss: 0.007234\n",
      "Epoch: 1892/10000 Iteration: 13245 Train loss: 0.007234\n",
      "Epoch: 1893/10000 Iteration: 13252 Train loss: 0.007233\n",
      "Epoch: 1894/10000 Iteration: 13259 Train loss: 0.007233\n",
      "Epoch: 1895/10000 Iteration: 13266 Train loss: 0.007232\n",
      "Epoch: 1896/10000 Iteration: 13273 Train loss: 0.007232\n",
      "Epoch: 1897/10000 Iteration: 13280 Train loss: 0.007232\n",
      "Epoch: 1898/10000 Iteration: 13287 Train loss: 0.007231\n",
      "Epoch: 1899/10000 Iteration: 13294 Train loss: 0.007231\n",
      "Epoch: 1900/10000 Iteration: 13301 Train loss: 0.007230\n",
      "Epoch: 1901/10000 Iteration: 13308 Train loss: 0.007230\n",
      "Epoch: 1902/10000 Iteration: 13315 Train loss: 0.007230\n",
      "Epoch: 1903/10000 Iteration: 13322 Train loss: 0.007229\n",
      "Epoch: 1904/10000 Iteration: 13329 Train loss: 0.007229\n",
      "Epoch: 1905/10000 Iteration: 13336 Train loss: 0.007228\n",
      "Epoch: 1906/10000 Iteration: 13343 Train loss: 0.007228\n",
      "Epoch: 1907/10000 Iteration: 13350 Train loss: 0.007227\n",
      "Epoch: 1908/10000 Iteration: 13357 Train loss: 0.007227\n",
      "Epoch: 1909/10000 Iteration: 13364 Train loss: 0.007227\n",
      "Epoch: 1910/10000 Iteration: 13371 Train loss: 0.007226\n",
      "Epoch: 1911/10000 Iteration: 13378 Train loss: 0.007226\n",
      "Epoch: 1912/10000 Iteration: 13385 Train loss: 0.007225\n",
      "Epoch: 1913/10000 Iteration: 13392 Train loss: 0.007225\n",
      "Epoch: 1914/10000 Iteration: 13399 Train loss: 0.007225\n",
      "Epoch: 1915/10000 Iteration: 13406 Train loss: 0.007224\n",
      "Epoch: 1916/10000 Iteration: 13413 Train loss: 0.007224\n",
      "Epoch: 1917/10000 Iteration: 13420 Train loss: 0.007223\n",
      "Epoch: 1918/10000 Iteration: 13427 Train loss: 0.007223\n",
      "Epoch: 1919/10000 Iteration: 13434 Train loss: 0.007222\n",
      "Epoch: 1920/10000 Iteration: 13441 Train loss: 0.007222\n",
      "Epoch: 1921/10000 Iteration: 13448 Train loss: 0.007222\n",
      "Epoch: 1922/10000 Iteration: 13455 Train loss: 0.007221\n",
      "Epoch: 1923/10000 Iteration: 13462 Train loss: 0.007221\n",
      "Epoch: 1924/10000 Iteration: 13469 Train loss: 0.007220\n",
      "Epoch: 1925/10000 Iteration: 13476 Train loss: 0.007220\n",
      "Epoch: 1926/10000 Iteration: 13483 Train loss: 0.007219\n",
      "Epoch: 1927/10000 Iteration: 13490 Train loss: 0.007219\n",
      "Epoch: 1928/10000 Iteration: 13497 Train loss: 0.007219\n",
      "Epoch: 1929/10000 Iteration: 13504 Train loss: 0.007218\n",
      "Epoch: 1930/10000 Iteration: 13511 Train loss: 0.007218\n",
      "Epoch: 1931/10000 Iteration: 13518 Train loss: 0.007217\n",
      "Epoch: 1932/10000 Iteration: 13525 Train loss: 0.007217\n",
      "Epoch: 1933/10000 Iteration: 13532 Train loss: 0.007217\n",
      "Epoch: 1934/10000 Iteration: 13539 Train loss: 0.007216\n",
      "Epoch: 1935/10000 Iteration: 13546 Train loss: 0.007216\n",
      "Epoch: 1936/10000 Iteration: 13553 Train loss: 0.007215\n",
      "Epoch: 1937/10000 Iteration: 13560 Train loss: 0.007215\n",
      "Epoch: 1938/10000 Iteration: 13567 Train loss: 0.007214\n",
      "Epoch: 1939/10000 Iteration: 13574 Train loss: 0.007214\n",
      "Epoch: 1940/10000 Iteration: 13581 Train loss: 0.007214\n",
      "Epoch: 1941/10000 Iteration: 13588 Train loss: 0.007213\n",
      "Epoch: 1942/10000 Iteration: 13595 Train loss: 0.007213\n",
      "Epoch: 1943/10000 Iteration: 13602 Train loss: 0.007212\n",
      "Epoch: 1944/10000 Iteration: 13609 Train loss: 0.007212\n",
      "Epoch: 1945/10000 Iteration: 13616 Train loss: 0.007211\n",
      "Epoch: 1946/10000 Iteration: 13623 Train loss: 0.007211\n",
      "Epoch: 1947/10000 Iteration: 13630 Train loss: 0.007211\n",
      "Epoch: 1948/10000 Iteration: 13637 Train loss: 0.007210\n",
      "Epoch: 1949/10000 Iteration: 13644 Train loss: 0.007210\n",
      "Epoch: 1950/10000 Iteration: 13651 Train loss: 0.007209\n",
      "Epoch: 1951/10000 Iteration: 13658 Train loss: 0.007209\n",
      "Epoch: 1952/10000 Iteration: 13665 Train loss: 0.007208\n",
      "Epoch: 1953/10000 Iteration: 13672 Train loss: 0.007208\n",
      "Epoch: 1954/10000 Iteration: 13679 Train loss: 0.007208\n",
      "Epoch: 1955/10000 Iteration: 13686 Train loss: 0.007207\n",
      "Epoch: 1956/10000 Iteration: 13693 Train loss: 0.007207\n",
      "Epoch: 1957/10000 Iteration: 13700 Train loss: 0.007206\n",
      "Epoch: 1958/10000 Iteration: 13707 Train loss: 0.007206\n",
      "Epoch: 1959/10000 Iteration: 13714 Train loss: 0.007205\n",
      "Epoch: 1960/10000 Iteration: 13721 Train loss: 0.007205\n",
      "Epoch: 1961/10000 Iteration: 13728 Train loss: 0.007205\n",
      "Epoch: 1962/10000 Iteration: 13735 Train loss: 0.007204\n",
      "Epoch: 1963/10000 Iteration: 13742 Train loss: 0.007204\n",
      "Epoch: 1964/10000 Iteration: 13749 Train loss: 0.007203\n",
      "Epoch: 1965/10000 Iteration: 13756 Train loss: 0.007203\n",
      "Epoch: 1966/10000 Iteration: 13763 Train loss: 0.007202\n",
      "Epoch: 1967/10000 Iteration: 13770 Train loss: 0.007202\n",
      "Epoch: 1968/10000 Iteration: 13777 Train loss: 0.007202\n",
      "Epoch: 1969/10000 Iteration: 13784 Train loss: 0.007201\n",
      "Epoch: 1970/10000 Iteration: 13791 Train loss: 0.007201\n",
      "Epoch: 1971/10000 Iteration: 13798 Train loss: 0.007200\n",
      "Epoch: 1972/10000 Iteration: 13805 Train loss: 0.007200\n",
      "Epoch: 1973/10000 Iteration: 13812 Train loss: 0.007199\n",
      "Epoch: 1974/10000 Iteration: 13819 Train loss: 0.007199\n",
      "Epoch: 1975/10000 Iteration: 13826 Train loss: 0.007199\n",
      "Epoch: 1976/10000 Iteration: 13833 Train loss: 0.007198\n",
      "Epoch: 1977/10000 Iteration: 13840 Train loss: 0.007198\n",
      "Epoch: 1978/10000 Iteration: 13847 Train loss: 0.007197\n",
      "Epoch: 1979/10000 Iteration: 13854 Train loss: 0.007197\n",
      "Epoch: 1980/10000 Iteration: 13861 Train loss: 0.007196\n",
      "Epoch: 1981/10000 Iteration: 13868 Train loss: 0.007196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1982/10000 Iteration: 13875 Train loss: 0.007196\n",
      "Epoch: 1983/10000 Iteration: 13882 Train loss: 0.007195\n",
      "Epoch: 1984/10000 Iteration: 13889 Train loss: 0.007195\n",
      "Epoch: 1985/10000 Iteration: 13896 Train loss: 0.007194\n",
      "Epoch: 1986/10000 Iteration: 13903 Train loss: 0.007194\n",
      "Epoch: 1987/10000 Iteration: 13910 Train loss: 0.007193\n",
      "Epoch: 1988/10000 Iteration: 13917 Train loss: 0.007193\n",
      "Epoch: 1989/10000 Iteration: 13924 Train loss: 0.007193\n",
      "Epoch: 1990/10000 Iteration: 13931 Train loss: 0.007192\n",
      "Epoch: 1991/10000 Iteration: 13938 Train loss: 0.007192\n",
      "Epoch: 1992/10000 Iteration: 13945 Train loss: 0.007191\n",
      "Epoch: 1993/10000 Iteration: 13952 Train loss: 0.007191\n",
      "Epoch: 1994/10000 Iteration: 13959 Train loss: 0.007190\n",
      "Epoch: 1995/10000 Iteration: 13966 Train loss: 0.007190\n",
      "Epoch: 1996/10000 Iteration: 13973 Train loss: 0.007190\n",
      "Epoch: 1997/10000 Iteration: 13980 Train loss: 0.007189\n",
      "Epoch: 1998/10000 Iteration: 13987 Train loss: 0.007189\n",
      "Epoch: 1999/10000 Iteration: 13994 Train loss: 0.007188\n",
      "Epoch: 2000/10000 Iteration: 14001 Train loss: 0.007188\n",
      "Epoch: 2001/10000 Iteration: 14008 Train loss: 0.007187\n",
      "Epoch: 2002/10000 Iteration: 14015 Train loss: 0.007187\n",
      "Epoch: 2003/10000 Iteration: 14022 Train loss: 0.007187\n",
      "Epoch: 2004/10000 Iteration: 14029 Train loss: 0.007186\n",
      "Epoch: 2005/10000 Iteration: 14036 Train loss: 0.007186\n",
      "Epoch: 2006/10000 Iteration: 14043 Train loss: 0.007185\n",
      "Epoch: 2007/10000 Iteration: 14050 Train loss: 0.007185\n",
      "Epoch: 2008/10000 Iteration: 14057 Train loss: 0.007184\n",
      "Epoch: 2009/10000 Iteration: 14064 Train loss: 0.007184\n",
      "Epoch: 2010/10000 Iteration: 14071 Train loss: 0.007184\n",
      "Epoch: 2011/10000 Iteration: 14078 Train loss: 0.007183\n",
      "Epoch: 2012/10000 Iteration: 14085 Train loss: 0.007183\n",
      "Epoch: 2013/10000 Iteration: 14092 Train loss: 0.007182\n",
      "Epoch: 2014/10000 Iteration: 14099 Train loss: 0.007182\n",
      "Epoch: 2015/10000 Iteration: 14106 Train loss: 0.007181\n",
      "Epoch: 2016/10000 Iteration: 14113 Train loss: 0.007181\n",
      "Epoch: 2017/10000 Iteration: 14120 Train loss: 0.007181\n",
      "Epoch: 2018/10000 Iteration: 14127 Train loss: 0.007180\n",
      "Epoch: 2019/10000 Iteration: 14134 Train loss: 0.007180\n",
      "Epoch: 2020/10000 Iteration: 14141 Train loss: 0.007179\n",
      "Epoch: 2021/10000 Iteration: 14148 Train loss: 0.007179\n",
      "Epoch: 2022/10000 Iteration: 14155 Train loss: 0.007178\n",
      "Epoch: 2023/10000 Iteration: 14162 Train loss: 0.007178\n",
      "Epoch: 2024/10000 Iteration: 14169 Train loss: 0.007178\n",
      "Epoch: 2025/10000 Iteration: 14176 Train loss: 0.007177\n",
      "Epoch: 2026/10000 Iteration: 14183 Train loss: 0.007177\n",
      "Epoch: 2027/10000 Iteration: 14190 Train loss: 0.007176\n",
      "Epoch: 2028/10000 Iteration: 14197 Train loss: 0.007176\n",
      "Epoch: 2029/10000 Iteration: 14204 Train loss: 0.007176\n",
      "Epoch: 2030/10000 Iteration: 14211 Train loss: 0.007175\n",
      "Epoch: 2031/10000 Iteration: 14218 Train loss: 0.007175\n",
      "Epoch: 2032/10000 Iteration: 14225 Train loss: 0.007174\n",
      "Epoch: 2033/10000 Iteration: 14232 Train loss: 0.007174\n",
      "Epoch: 2034/10000 Iteration: 14239 Train loss: 0.007173\n",
      "Epoch: 2035/10000 Iteration: 14246 Train loss: 0.007173\n",
      "Epoch: 2036/10000 Iteration: 14253 Train loss: 0.007173\n",
      "Epoch: 2037/10000 Iteration: 14260 Train loss: 0.007172\n",
      "Epoch: 2038/10000 Iteration: 14267 Train loss: 0.007172\n",
      "Epoch: 2039/10000 Iteration: 14274 Train loss: 0.007171\n",
      "Epoch: 2040/10000 Iteration: 14281 Train loss: 0.007171\n",
      "Epoch: 2041/10000 Iteration: 14288 Train loss: 0.007171\n",
      "Epoch: 2042/10000 Iteration: 14295 Train loss: 0.007170\n",
      "Epoch: 2043/10000 Iteration: 14302 Train loss: 0.007170\n",
      "Epoch: 2044/10000 Iteration: 14309 Train loss: 0.007169\n",
      "Epoch: 2045/10000 Iteration: 14316 Train loss: 0.007169\n",
      "Epoch: 2046/10000 Iteration: 14323 Train loss: 0.007169\n",
      "Epoch: 2047/10000 Iteration: 14330 Train loss: 0.007168\n",
      "Epoch: 2048/10000 Iteration: 14337 Train loss: 0.007168\n",
      "Epoch: 2049/10000 Iteration: 14344 Train loss: 0.007167\n",
      "Epoch: 2050/10000 Iteration: 14351 Train loss: 0.007167\n",
      "Epoch: 2051/10000 Iteration: 14358 Train loss: 0.007166\n",
      "Epoch: 2052/10000 Iteration: 14365 Train loss: 0.007166\n",
      "Epoch: 2053/10000 Iteration: 14372 Train loss: 0.007166\n",
      "Epoch: 2054/10000 Iteration: 14379 Train loss: 0.007165\n",
      "Epoch: 2055/10000 Iteration: 14386 Train loss: 0.007165\n",
      "Epoch: 2056/10000 Iteration: 14393 Train loss: 0.007164\n",
      "Epoch: 2057/10000 Iteration: 14400 Train loss: 0.007164\n",
      "Epoch: 2058/10000 Iteration: 14407 Train loss: 0.007164\n",
      "Epoch: 2059/10000 Iteration: 14414 Train loss: 0.007163\n",
      "Epoch: 2060/10000 Iteration: 14421 Train loss: 0.007163\n",
      "Epoch: 2061/10000 Iteration: 14428 Train loss: 0.007162\n",
      "Epoch: 2062/10000 Iteration: 14435 Train loss: 0.007162\n",
      "Epoch: 2063/10000 Iteration: 14442 Train loss: 0.007162\n",
      "Epoch: 2064/10000 Iteration: 14449 Train loss: 0.007161\n",
      "Epoch: 2065/10000 Iteration: 14456 Train loss: 0.007161\n",
      "Epoch: 2066/10000 Iteration: 14463 Train loss: 0.007160\n",
      "Epoch: 2067/10000 Iteration: 14470 Train loss: 0.007160\n",
      "Epoch: 2068/10000 Iteration: 14477 Train loss: 0.007160\n",
      "Epoch: 2069/10000 Iteration: 14484 Train loss: 0.007159\n",
      "Epoch: 2070/10000 Iteration: 14491 Train loss: 0.007159\n",
      "Epoch: 2071/10000 Iteration: 14498 Train loss: 0.007158\n",
      "Epoch: 2072/10000 Iteration: 14505 Train loss: 0.007158\n",
      "Epoch: 2073/10000 Iteration: 14512 Train loss: 0.007158\n",
      "Epoch: 2074/10000 Iteration: 14519 Train loss: 0.007157\n",
      "Epoch: 2075/10000 Iteration: 14526 Train loss: 0.007157\n",
      "Epoch: 2076/10000 Iteration: 14533 Train loss: 0.007156\n",
      "Epoch: 2077/10000 Iteration: 14540 Train loss: 0.007156\n",
      "Epoch: 2078/10000 Iteration: 14547 Train loss: 0.007156\n",
      "Epoch: 2079/10000 Iteration: 14554 Train loss: 0.007155\n",
      "Epoch: 2080/10000 Iteration: 14561 Train loss: 0.007155\n",
      "Epoch: 2081/10000 Iteration: 14568 Train loss: 0.007155\n",
      "Epoch: 2082/10000 Iteration: 14575 Train loss: 0.007154\n",
      "Epoch: 2083/10000 Iteration: 14582 Train loss: 0.007154\n",
      "Epoch: 2084/10000 Iteration: 14589 Train loss: 0.007153\n",
      "Epoch: 2085/10000 Iteration: 14596 Train loss: 0.007153\n",
      "Epoch: 2086/10000 Iteration: 14603 Train loss: 0.007153\n",
      "Epoch: 2087/10000 Iteration: 14610 Train loss: 0.007152\n",
      "Epoch: 2088/10000 Iteration: 14617 Train loss: 0.007152\n",
      "Epoch: 2089/10000 Iteration: 14624 Train loss: 0.007151\n",
      "Epoch: 2090/10000 Iteration: 14631 Train loss: 0.007151\n",
      "Epoch: 2091/10000 Iteration: 14638 Train loss: 0.007151\n",
      "Epoch: 2092/10000 Iteration: 14645 Train loss: 0.007150\n",
      "Epoch: 2093/10000 Iteration: 14652 Train loss: 0.007150\n",
      "Epoch: 2094/10000 Iteration: 14659 Train loss: 0.007150\n",
      "Epoch: 2095/10000 Iteration: 14666 Train loss: 0.007149\n",
      "Epoch: 2096/10000 Iteration: 14673 Train loss: 0.007149\n",
      "Epoch: 2097/10000 Iteration: 14680 Train loss: 0.007148\n",
      "Epoch: 2098/10000 Iteration: 14687 Train loss: 0.007148\n",
      "Epoch: 2099/10000 Iteration: 14694 Train loss: 0.007148\n",
      "Epoch: 2100/10000 Iteration: 14701 Train loss: 0.007147\n",
      "Epoch: 2101/10000 Iteration: 14708 Train loss: 0.007147\n",
      "Epoch: 2102/10000 Iteration: 14715 Train loss: 0.007147\n",
      "Epoch: 2103/10000 Iteration: 14722 Train loss: 0.007146\n",
      "Epoch: 2104/10000 Iteration: 14729 Train loss: 0.007146\n",
      "Epoch: 2105/10000 Iteration: 14736 Train loss: 0.007145\n",
      "Epoch: 2106/10000 Iteration: 14743 Train loss: 0.007145\n",
      "Epoch: 2107/10000 Iteration: 14750 Train loss: 0.007145\n",
      "Epoch: 2108/10000 Iteration: 14757 Train loss: 0.007144\n",
      "Epoch: 2109/10000 Iteration: 14764 Train loss: 0.007144\n",
      "Epoch: 2110/10000 Iteration: 14771 Train loss: 0.007144\n",
      "Epoch: 2111/10000 Iteration: 14778 Train loss: 0.007143\n",
      "Epoch: 2112/10000 Iteration: 14785 Train loss: 0.007143\n",
      "Epoch: 2113/10000 Iteration: 14792 Train loss: 0.007142\n",
      "Epoch: 2114/10000 Iteration: 14799 Train loss: 0.007142\n",
      "Epoch: 2115/10000 Iteration: 14806 Train loss: 0.007142\n",
      "Epoch: 2116/10000 Iteration: 14813 Train loss: 0.007141\n",
      "Epoch: 2117/10000 Iteration: 14820 Train loss: 0.007141\n",
      "Epoch: 2118/10000 Iteration: 14827 Train loss: 0.007141\n",
      "Epoch: 2119/10000 Iteration: 14834 Train loss: 0.007140\n",
      "Epoch: 2120/10000 Iteration: 14841 Train loss: 0.007140\n",
      "Epoch: 2121/10000 Iteration: 14848 Train loss: 0.007140\n",
      "Epoch: 2122/10000 Iteration: 14855 Train loss: 0.007139\n",
      "Epoch: 2123/10000 Iteration: 14862 Train loss: 0.007139\n",
      "Epoch: 2124/10000 Iteration: 14869 Train loss: 0.007139\n",
      "Epoch: 2125/10000 Iteration: 14876 Train loss: 0.007138\n",
      "Epoch: 2126/10000 Iteration: 14883 Train loss: 0.007138\n",
      "Epoch: 2127/10000 Iteration: 14890 Train loss: 0.007137\n",
      "Epoch: 2128/10000 Iteration: 14897 Train loss: 0.007137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2129/10000 Iteration: 14904 Train loss: 0.007137\n",
      "Epoch: 2130/10000 Iteration: 14911 Train loss: 0.007136\n",
      "Epoch: 2131/10000 Iteration: 14918 Train loss: 0.007136\n",
      "Epoch: 2132/10000 Iteration: 14925 Train loss: 0.007136\n",
      "Epoch: 2133/10000 Iteration: 14932 Train loss: 0.007135\n",
      "Epoch: 2134/10000 Iteration: 14939 Train loss: 0.007135\n",
      "Epoch: 2135/10000 Iteration: 14946 Train loss: 0.007135\n",
      "Epoch: 2136/10000 Iteration: 14953 Train loss: 0.007134\n",
      "Epoch: 2137/10000 Iteration: 14960 Train loss: 0.007134\n",
      "Epoch: 2138/10000 Iteration: 14967 Train loss: 0.007134\n",
      "Epoch: 2139/10000 Iteration: 14974 Train loss: 0.007133\n",
      "Epoch: 2140/10000 Iteration: 14981 Train loss: 0.007133\n",
      "Epoch: 2141/10000 Iteration: 14988 Train loss: 0.007133\n",
      "Epoch: 2142/10000 Iteration: 14995 Train loss: 0.007132\n",
      "Epoch: 2143/10000 Iteration: 15002 Train loss: 0.007132\n",
      "Epoch: 2144/10000 Iteration: 15009 Train loss: 0.007132\n",
      "Epoch: 2145/10000 Iteration: 15016 Train loss: 0.007131\n",
      "Epoch: 2146/10000 Iteration: 15023 Train loss: 0.007131\n",
      "Epoch: 2147/10000 Iteration: 15030 Train loss: 0.007131\n",
      "Epoch: 2148/10000 Iteration: 15037 Train loss: 0.007130\n",
      "Epoch: 2149/10000 Iteration: 15044 Train loss: 0.007130\n",
      "Epoch: 2150/10000 Iteration: 15051 Train loss: 0.007130\n",
      "Epoch: 2151/10000 Iteration: 15058 Train loss: 0.007129\n",
      "Epoch: 2152/10000 Iteration: 15065 Train loss: 0.007129\n",
      "Epoch: 2153/10000 Iteration: 15072 Train loss: 0.007129\n",
      "Epoch: 2154/10000 Iteration: 15079 Train loss: 0.007128\n",
      "Epoch: 2155/10000 Iteration: 15086 Train loss: 0.007128\n",
      "Epoch: 2156/10000 Iteration: 15093 Train loss: 0.007128\n",
      "Epoch: 2157/10000 Iteration: 15100 Train loss: 0.007127\n",
      "Epoch: 2158/10000 Iteration: 15107 Train loss: 0.007127\n",
      "Epoch: 2159/10000 Iteration: 15114 Train loss: 0.007127\n",
      "Epoch: 2160/10000 Iteration: 15121 Train loss: 0.007127\n",
      "Epoch: 2161/10000 Iteration: 15128 Train loss: 0.007126\n",
      "Epoch: 2162/10000 Iteration: 15135 Train loss: 0.007126\n",
      "Epoch: 2163/10000 Iteration: 15142 Train loss: 0.007126\n",
      "Epoch: 2164/10000 Iteration: 15149 Train loss: 0.007125\n",
      "Epoch: 2165/10000 Iteration: 15156 Train loss: 0.007125\n",
      "Epoch: 2166/10000 Iteration: 15163 Train loss: 0.007125\n",
      "Epoch: 2167/10000 Iteration: 15170 Train loss: 0.007124\n",
      "Epoch: 2168/10000 Iteration: 15177 Train loss: 0.007124\n",
      "Epoch: 2169/10000 Iteration: 15184 Train loss: 0.007124\n",
      "Epoch: 2170/10000 Iteration: 15191 Train loss: 0.007123\n",
      "Epoch: 2171/10000 Iteration: 15198 Train loss: 0.007123\n",
      "Epoch: 2172/10000 Iteration: 15205 Train loss: 0.007123\n",
      "Epoch: 2173/10000 Iteration: 15212 Train loss: 0.007123\n",
      "Epoch: 2174/10000 Iteration: 15219 Train loss: 0.007122\n",
      "Epoch: 2175/10000 Iteration: 15226 Train loss: 0.007122\n",
      "Epoch: 2176/10000 Iteration: 15233 Train loss: 0.007122\n",
      "Epoch: 2177/10000 Iteration: 15240 Train loss: 0.007121\n",
      "Epoch: 2178/10000 Iteration: 15247 Train loss: 0.007121\n",
      "Epoch: 2179/10000 Iteration: 15254 Train loss: 0.007121\n",
      "Epoch: 2180/10000 Iteration: 15261 Train loss: 0.007121\n",
      "Epoch: 2181/10000 Iteration: 15268 Train loss: 0.007120\n",
      "Epoch: 2182/10000 Iteration: 15275 Train loss: 0.007120\n",
      "Epoch: 2183/10000 Iteration: 15282 Train loss: 0.007120\n",
      "Epoch: 2184/10000 Iteration: 15289 Train loss: 0.007119\n",
      "Epoch: 2185/10000 Iteration: 15296 Train loss: 0.007119\n",
      "Epoch: 2186/10000 Iteration: 15303 Train loss: 0.007119\n",
      "Epoch: 2187/10000 Iteration: 15310 Train loss: 0.007119\n",
      "Epoch: 2188/10000 Iteration: 15317 Train loss: 0.007118\n",
      "Epoch: 2189/10000 Iteration: 15324 Train loss: 0.007118\n",
      "Epoch: 2190/10000 Iteration: 15331 Train loss: 0.007118\n",
      "Epoch: 2191/10000 Iteration: 15338 Train loss: 0.007117\n",
      "Epoch: 2192/10000 Iteration: 15345 Train loss: 0.007117\n",
      "Epoch: 2193/10000 Iteration: 15352 Train loss: 0.007117\n",
      "Epoch: 2194/10000 Iteration: 15359 Train loss: 0.007117\n",
      "Epoch: 2195/10000 Iteration: 15366 Train loss: 0.007116\n",
      "Epoch: 2196/10000 Iteration: 15373 Train loss: 0.007116\n",
      "Epoch: 2197/10000 Iteration: 15380 Train loss: 0.007116\n",
      "Epoch: 2198/10000 Iteration: 15387 Train loss: 0.007115\n",
      "Epoch: 2199/10000 Iteration: 15394 Train loss: 0.007115\n",
      "Epoch: 2200/10000 Iteration: 15401 Train loss: 0.007115\n",
      "Epoch: 2201/10000 Iteration: 15408 Train loss: 0.007115\n",
      "Epoch: 2202/10000 Iteration: 15415 Train loss: 0.007114\n",
      "Epoch: 2203/10000 Iteration: 15422 Train loss: 0.007114\n",
      "Epoch: 2204/10000 Iteration: 15429 Train loss: 0.007114\n",
      "Epoch: 2205/10000 Iteration: 15436 Train loss: 0.007114\n",
      "Epoch: 2206/10000 Iteration: 15443 Train loss: 0.007113\n",
      "Epoch: 2207/10000 Iteration: 15450 Train loss: 0.007113\n",
      "Epoch: 2208/10000 Iteration: 15457 Train loss: 0.007113\n",
      "Epoch: 2209/10000 Iteration: 15464 Train loss: 0.007113\n",
      "Epoch: 2210/10000 Iteration: 15471 Train loss: 0.007112\n",
      "Epoch: 2211/10000 Iteration: 15478 Train loss: 0.007112\n",
      "Epoch: 2212/10000 Iteration: 15485 Train loss: 0.007112\n",
      "Epoch: 2213/10000 Iteration: 15492 Train loss: 0.007112\n",
      "Epoch: 2214/10000 Iteration: 15499 Train loss: 0.007111\n",
      "Epoch: 2215/10000 Iteration: 15506 Train loss: 0.007111\n",
      "Epoch: 2216/10000 Iteration: 15513 Train loss: 0.007111\n",
      "Epoch: 2217/10000 Iteration: 15520 Train loss: 0.007111\n",
      "Epoch: 2218/10000 Iteration: 15527 Train loss: 0.007110\n",
      "Epoch: 2219/10000 Iteration: 15534 Train loss: 0.007110\n",
      "Epoch: 2220/10000 Iteration: 15541 Train loss: 0.007110\n",
      "Epoch: 2221/10000 Iteration: 15548 Train loss: 0.007110\n",
      "Epoch: 2222/10000 Iteration: 15555 Train loss: 0.007110\n",
      "Epoch: 2223/10000 Iteration: 15562 Train loss: 0.007109\n",
      "Epoch: 2224/10000 Iteration: 15569 Train loss: 0.007109\n",
      "Epoch: 2225/10000 Iteration: 15576 Train loss: 0.007109\n",
      "Epoch: 2226/10000 Iteration: 15583 Train loss: 0.007109\n",
      "Epoch: 2227/10000 Iteration: 15590 Train loss: 0.007108\n",
      "Epoch: 2228/10000 Iteration: 15597 Train loss: 0.007108\n",
      "Epoch: 2229/10000 Iteration: 15604 Train loss: 0.007108\n",
      "Epoch: 2230/10000 Iteration: 15611 Train loss: 0.007108\n",
      "Epoch: 2231/10000 Iteration: 15618 Train loss: 0.007107\n",
      "Epoch: 2232/10000 Iteration: 15625 Train loss: 0.007107\n",
      "Epoch: 2233/10000 Iteration: 15632 Train loss: 0.007107\n",
      "Epoch: 2234/10000 Iteration: 15639 Train loss: 0.007107\n",
      "Epoch: 2235/10000 Iteration: 15646 Train loss: 0.007107\n",
      "Epoch: 2236/10000 Iteration: 15653 Train loss: 0.007106\n",
      "Epoch: 2237/10000 Iteration: 15660 Train loss: 0.007106\n",
      "Epoch: 2238/10000 Iteration: 15667 Train loss: 0.007106\n",
      "Epoch: 2239/10000 Iteration: 15674 Train loss: 0.007106\n",
      "Epoch: 2240/10000 Iteration: 15681 Train loss: 0.007106\n",
      "Epoch: 2241/10000 Iteration: 15688 Train loss: 0.007105\n",
      "Epoch: 2242/10000 Iteration: 15695 Train loss: 0.007105\n",
      "Epoch: 2243/10000 Iteration: 15702 Train loss: 0.007105\n",
      "Epoch: 2244/10000 Iteration: 15709 Train loss: 0.007105\n",
      "Epoch: 2245/10000 Iteration: 15716 Train loss: 0.007105\n",
      "Epoch: 2246/10000 Iteration: 15723 Train loss: 0.007104\n",
      "Epoch: 2247/10000 Iteration: 15730 Train loss: 0.007104\n",
      "Epoch: 2248/10000 Iteration: 15737 Train loss: 0.007104\n",
      "Epoch: 2249/10000 Iteration: 15744 Train loss: 0.007104\n",
      "Epoch: 2250/10000 Iteration: 15751 Train loss: 0.007104\n",
      "Epoch: 2251/10000 Iteration: 15758 Train loss: 0.007103\n",
      "Epoch: 2252/10000 Iteration: 15765 Train loss: 0.007103\n",
      "Epoch: 2253/10000 Iteration: 15772 Train loss: 0.007103\n",
      "Epoch: 2254/10000 Iteration: 15779 Train loss: 0.007103\n",
      "Epoch: 2255/10000 Iteration: 15786 Train loss: 0.007103\n",
      "Epoch: 2256/10000 Iteration: 15793 Train loss: 0.007102\n",
      "Epoch: 2257/10000 Iteration: 15800 Train loss: 0.007102\n",
      "Epoch: 2258/10000 Iteration: 15807 Train loss: 0.007102\n",
      "Epoch: 2259/10000 Iteration: 15814 Train loss: 0.007102\n",
      "Epoch: 2260/10000 Iteration: 15821 Train loss: 0.007102\n",
      "Epoch: 2261/10000 Iteration: 15828 Train loss: 0.007102\n",
      "Epoch: 2262/10000 Iteration: 15835 Train loss: 0.007101\n",
      "Epoch: 2263/10000 Iteration: 15842 Train loss: 0.007101\n",
      "Epoch: 2264/10000 Iteration: 15849 Train loss: 0.007101\n",
      "Epoch: 2265/10000 Iteration: 15856 Train loss: 0.007101\n",
      "Epoch: 2266/10000 Iteration: 15863 Train loss: 0.007101\n",
      "Epoch: 2267/10000 Iteration: 15870 Train loss: 0.007101\n",
      "Epoch: 2268/10000 Iteration: 15877 Train loss: 0.007100\n",
      "Epoch: 2269/10000 Iteration: 15884 Train loss: 0.007100\n",
      "Epoch: 2270/10000 Iteration: 15891 Train loss: 0.007100\n",
      "Epoch: 2271/10000 Iteration: 15898 Train loss: 0.007100\n",
      "Epoch: 2272/10000 Iteration: 15905 Train loss: 0.007100\n",
      "Epoch: 2273/10000 Iteration: 15912 Train loss: 0.007100\n",
      "Epoch: 2274/10000 Iteration: 15919 Train loss: 0.007099\n",
      "Epoch: 2275/10000 Iteration: 15926 Train loss: 0.007099\n",
      "Epoch: 2276/10000 Iteration: 15933 Train loss: 0.007099\n",
      "Epoch: 2277/10000 Iteration: 15940 Train loss: 0.007099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2278/10000 Iteration: 15947 Train loss: 0.007099\n",
      "Epoch: 2279/10000 Iteration: 15954 Train loss: 0.007099\n",
      "Epoch: 2280/10000 Iteration: 15961 Train loss: 0.007099\n",
      "Epoch: 2281/10000 Iteration: 15968 Train loss: 0.007098\n",
      "Epoch: 2282/10000 Iteration: 15975 Train loss: 0.007098\n",
      "Epoch: 2283/10000 Iteration: 15982 Train loss: 0.007098\n",
      "Epoch: 2284/10000 Iteration: 15989 Train loss: 0.007098\n",
      "Epoch: 2285/10000 Iteration: 15996 Train loss: 0.007098\n",
      "Epoch: 2286/10000 Iteration: 16003 Train loss: 0.007098\n",
      "Epoch: 2287/10000 Iteration: 16010 Train loss: 0.007098\n",
      "Epoch: 2288/10000 Iteration: 16017 Train loss: 0.007097\n",
      "Epoch: 2289/10000 Iteration: 16024 Train loss: 0.007097\n",
      "Epoch: 2290/10000 Iteration: 16031 Train loss: 0.007097\n",
      "Epoch: 2291/10000 Iteration: 16038 Train loss: 0.007097\n",
      "Epoch: 2292/10000 Iteration: 16045 Train loss: 0.007097\n",
      "Epoch: 2293/10000 Iteration: 16052 Train loss: 0.007097\n",
      "Epoch: 2294/10000 Iteration: 16059 Train loss: 0.007097\n",
      "Epoch: 2295/10000 Iteration: 16066 Train loss: 0.007097\n",
      "Epoch: 2296/10000 Iteration: 16073 Train loss: 0.007097\n",
      "Epoch: 2297/10000 Iteration: 16080 Train loss: 0.007096\n",
      "Epoch: 2298/10000 Iteration: 16087 Train loss: 0.007096\n",
      "Epoch: 2299/10000 Iteration: 16094 Train loss: 0.007096\n",
      "Epoch: 2300/10000 Iteration: 16101 Train loss: 0.007096\n",
      "Epoch: 2301/10000 Iteration: 16108 Train loss: 0.007096\n",
      "Epoch: 2302/10000 Iteration: 16115 Train loss: 0.007096\n",
      "Epoch: 2303/10000 Iteration: 16122 Train loss: 0.007096\n",
      "Epoch: 2304/10000 Iteration: 16129 Train loss: 0.007096\n",
      "Epoch: 2305/10000 Iteration: 16136 Train loss: 0.007096\n",
      "Epoch: 2306/10000 Iteration: 16143 Train loss: 0.007095\n",
      "Epoch: 2307/10000 Iteration: 16150 Train loss: 0.007095\n",
      "Epoch: 2308/10000 Iteration: 16157 Train loss: 0.007095\n",
      "Epoch: 2309/10000 Iteration: 16164 Train loss: 0.007095\n",
      "Epoch: 2310/10000 Iteration: 16171 Train loss: 0.007095\n",
      "Epoch: 2311/10000 Iteration: 16178 Train loss: 0.007095\n",
      "Epoch: 2312/10000 Iteration: 16185 Train loss: 0.007095\n",
      "Epoch: 2313/10000 Iteration: 16192 Train loss: 0.007095\n",
      "Epoch: 2314/10000 Iteration: 16199 Train loss: 0.007095\n",
      "Epoch: 2315/10000 Iteration: 16206 Train loss: 0.007095\n",
      "Epoch: 2316/10000 Iteration: 16213 Train loss: 0.007095\n",
      "Epoch: 2317/10000 Iteration: 16220 Train loss: 0.007094\n",
      "Epoch: 2318/10000 Iteration: 16227 Train loss: 0.007094\n",
      "Epoch: 2319/10000 Iteration: 16234 Train loss: 0.007094\n",
      "Epoch: 2320/10000 Iteration: 16241 Train loss: 0.007094\n",
      "Epoch: 2321/10000 Iteration: 16248 Train loss: 0.007094\n",
      "Epoch: 2322/10000 Iteration: 16255 Train loss: 0.007094\n",
      "Epoch: 2323/10000 Iteration: 16262 Train loss: 0.007094\n",
      "Epoch: 2324/10000 Iteration: 16269 Train loss: 0.007094\n",
      "Epoch: 2325/10000 Iteration: 16276 Train loss: 0.007094\n",
      "Epoch: 2326/10000 Iteration: 16283 Train loss: 0.007094\n",
      "Epoch: 2327/10000 Iteration: 16290 Train loss: 0.007094\n",
      "Epoch: 2328/10000 Iteration: 16297 Train loss: 0.007094\n",
      "Epoch: 2329/10000 Iteration: 16304 Train loss: 0.007094\n",
      "Epoch: 2330/10000 Iteration: 16311 Train loss: 0.007094\n",
      "Epoch: 2331/10000 Iteration: 16318 Train loss: 0.007093\n",
      "Epoch: 2332/10000 Iteration: 16325 Train loss: 0.007093\n",
      "Epoch: 2333/10000 Iteration: 16332 Train loss: 0.007093\n",
      "Epoch: 2334/10000 Iteration: 16339 Train loss: 0.007093\n",
      "Epoch: 2335/10000 Iteration: 16346 Train loss: 0.007093\n",
      "Epoch: 2336/10000 Iteration: 16353 Train loss: 0.007093\n",
      "Epoch: 2337/10000 Iteration: 16360 Train loss: 0.007093\n",
      "Epoch: 2338/10000 Iteration: 16367 Train loss: 0.007093\n",
      "Epoch: 2339/10000 Iteration: 16374 Train loss: 0.007093\n",
      "Epoch: 2340/10000 Iteration: 16381 Train loss: 0.007093\n",
      "Epoch: 2341/10000 Iteration: 16388 Train loss: 0.007093\n",
      "Epoch: 2342/10000 Iteration: 16395 Train loss: 0.007093\n",
      "Epoch: 2343/10000 Iteration: 16402 Train loss: 0.007093\n",
      "Epoch: 2344/10000 Iteration: 16409 Train loss: 0.007093\n",
      "Epoch: 2345/10000 Iteration: 16416 Train loss: 0.007093\n",
      "Epoch: 2346/10000 Iteration: 16423 Train loss: 0.007093\n",
      "Epoch: 2347/10000 Iteration: 16430 Train loss: 0.007093\n",
      "Epoch: 2348/10000 Iteration: 16437 Train loss: 0.007093\n",
      "Epoch: 2349/10000 Iteration: 16444 Train loss: 0.007093\n",
      "Epoch: 2350/10000 Iteration: 16451 Train loss: 0.007093\n",
      "Epoch: 2351/10000 Iteration: 16458 Train loss: 0.007093\n",
      "Epoch: 2352/10000 Iteration: 16465 Train loss: 0.007093\n",
      "Epoch: 2353/10000 Iteration: 16472 Train loss: 0.007093\n",
      "Epoch: 2354/10000 Iteration: 16479 Train loss: 0.007093\n",
      "Epoch: 2355/10000 Iteration: 16486 Train loss: 0.007093\n",
      "Epoch: 2356/10000 Iteration: 16493 Train loss: 0.007093\n",
      "Epoch: 2357/10000 Iteration: 16500 Train loss: 0.007093\n",
      "Epoch: 2358/10000 Iteration: 16507 Train loss: 0.007093\n",
      "Epoch: 2359/10000 Iteration: 16514 Train loss: 0.007093\n",
      "Epoch: 2360/10000 Iteration: 16521 Train loss: 0.007093\n",
      "Epoch: 2361/10000 Iteration: 16528 Train loss: 0.007093\n",
      "Epoch: 2362/10000 Iteration: 16535 Train loss: 0.007093\n",
      "Epoch: 2363/10000 Iteration: 16542 Train loss: 0.007093\n",
      "Epoch: 2364/10000 Iteration: 16549 Train loss: 0.007093\n",
      "Epoch: 2365/10000 Iteration: 16556 Train loss: 0.007093\n",
      "Epoch: 2366/10000 Iteration: 16563 Train loss: 0.007093\n",
      "Epoch: 2367/10000 Iteration: 16570 Train loss: 0.007093\n",
      "Epoch: 2368/10000 Iteration: 16577 Train loss: 0.007093\n",
      "Epoch: 2369/10000 Iteration: 16584 Train loss: 0.007093\n",
      "Epoch: 2370/10000 Iteration: 16591 Train loss: 0.007093\n",
      "Epoch: 2371/10000 Iteration: 16598 Train loss: 0.007093\n",
      "Epoch: 2372/10000 Iteration: 16605 Train loss: 0.007093\n",
      "Epoch: 2373/10000 Iteration: 16612 Train loss: 0.007093\n",
      "Epoch: 2374/10000 Iteration: 16619 Train loss: 0.007093\n",
      "Epoch: 2375/10000 Iteration: 16626 Train loss: 0.007093\n",
      "Epoch: 2376/10000 Iteration: 16633 Train loss: 0.007093\n",
      "Epoch: 2377/10000 Iteration: 16640 Train loss: 0.007093\n",
      "Epoch: 2378/10000 Iteration: 16647 Train loss: 0.007093\n",
      "Epoch: 2379/10000 Iteration: 16654 Train loss: 0.007093\n",
      "Epoch: 2380/10000 Iteration: 16661 Train loss: 0.007093\n",
      "Epoch: 2381/10000 Iteration: 16668 Train loss: 0.007093\n",
      "Epoch: 2382/10000 Iteration: 16675 Train loss: 0.007093\n",
      "Epoch: 2383/10000 Iteration: 16682 Train loss: 0.007093\n",
      "Epoch: 2384/10000 Iteration: 16689 Train loss: 0.007093\n",
      "Epoch: 2385/10000 Iteration: 16696 Train loss: 0.007093\n",
      "Epoch: 2386/10000 Iteration: 16703 Train loss: 0.007093\n",
      "Epoch: 2387/10000 Iteration: 16710 Train loss: 0.007093\n",
      "Epoch: 2388/10000 Iteration: 16717 Train loss: 0.007093\n",
      "Epoch: 2389/10000 Iteration: 16724 Train loss: 0.007093\n",
      "Epoch: 2390/10000 Iteration: 16731 Train loss: 0.007093\n",
      "Epoch: 2391/10000 Iteration: 16738 Train loss: 0.007093\n",
      "Epoch: 2392/10000 Iteration: 16745 Train loss: 0.007093\n",
      "Epoch: 2393/10000 Iteration: 16752 Train loss: 0.007093\n",
      "Epoch: 2394/10000 Iteration: 16759 Train loss: 0.007093\n",
      "Epoch: 2395/10000 Iteration: 16766 Train loss: 0.007093\n",
      "Epoch: 2396/10000 Iteration: 16773 Train loss: 0.007094\n",
      "Epoch: 2397/10000 Iteration: 16780 Train loss: 0.007094\n",
      "Epoch: 2398/10000 Iteration: 16787 Train loss: 0.007094\n",
      "Epoch: 2399/10000 Iteration: 16794 Train loss: 0.007094\n",
      "Epoch: 2400/10000 Iteration: 16801 Train loss: 0.007094\n",
      "Epoch: 2401/10000 Iteration: 16808 Train loss: 0.007094\n",
      "Epoch: 2402/10000 Iteration: 16815 Train loss: 0.007094\n",
      "Epoch: 2403/10000 Iteration: 16822 Train loss: 0.007094\n",
      "Epoch: 2404/10000 Iteration: 16829 Train loss: 0.007094\n",
      "Epoch: 2405/10000 Iteration: 16836 Train loss: 0.007094\n",
      "Epoch: 2406/10000 Iteration: 16843 Train loss: 0.007094\n",
      "Epoch: 2407/10000 Iteration: 16850 Train loss: 0.007094\n",
      "Epoch: 2408/10000 Iteration: 16857 Train loss: 0.007094\n",
      "Epoch: 2409/10000 Iteration: 16864 Train loss: 0.007094\n",
      "Epoch: 2410/10000 Iteration: 16871 Train loss: 0.007095\n",
      "Epoch: 2411/10000 Iteration: 16878 Train loss: 0.007095\n",
      "Epoch: 2412/10000 Iteration: 16885 Train loss: 0.007095\n",
      "Epoch: 2413/10000 Iteration: 16892 Train loss: 0.007095\n",
      "Epoch: 2414/10000 Iteration: 16899 Train loss: 0.007095\n",
      "Epoch: 2415/10000 Iteration: 16906 Train loss: 0.007095\n",
      "Epoch: 2416/10000 Iteration: 16913 Train loss: 0.007095\n",
      "Epoch: 2417/10000 Iteration: 16920 Train loss: 0.007095\n",
      "Epoch: 2418/10000 Iteration: 16927 Train loss: 0.007095\n",
      "Epoch: 2419/10000 Iteration: 16934 Train loss: 0.007095\n",
      "Epoch: 2420/10000 Iteration: 16941 Train loss: 0.007095\n",
      "Epoch: 2421/10000 Iteration: 16948 Train loss: 0.007096\n",
      "Epoch: 2422/10000 Iteration: 16955 Train loss: 0.007096\n",
      "Epoch: 2423/10000 Iteration: 16962 Train loss: 0.007096\n",
      "Epoch: 2424/10000 Iteration: 16969 Train loss: 0.007096\n",
      "Epoch: 2425/10000 Iteration: 16976 Train loss: 0.007096\n",
      "Epoch: 2426/10000 Iteration: 16983 Train loss: 0.007096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2427/10000 Iteration: 16990 Train loss: 0.007096\n",
      "Epoch: 2428/10000 Iteration: 16997 Train loss: 0.007096\n",
      "Epoch: 2429/10000 Iteration: 17004 Train loss: 0.007096\n",
      "Epoch: 2430/10000 Iteration: 17011 Train loss: 0.007097\n",
      "Epoch: 2431/10000 Iteration: 17018 Train loss: 0.007097\n",
      "Epoch: 2432/10000 Iteration: 17025 Train loss: 0.007097\n",
      "Epoch: 2433/10000 Iteration: 17032 Train loss: 0.007097\n",
      "Epoch: 2434/10000 Iteration: 17039 Train loss: 0.007097\n",
      "Epoch: 2435/10000 Iteration: 17046 Train loss: 0.007097\n",
      "Epoch: 2436/10000 Iteration: 17053 Train loss: 0.007097\n",
      "Epoch: 2437/10000 Iteration: 17060 Train loss: 0.007097\n",
      "Epoch: 2438/10000 Iteration: 17067 Train loss: 0.007098\n",
      "Epoch: 2439/10000 Iteration: 17074 Train loss: 0.007098\n",
      "Epoch: 2440/10000 Iteration: 17081 Train loss: 0.007098\n",
      "Epoch: 2441/10000 Iteration: 17088 Train loss: 0.007098\n",
      "Epoch: 2442/10000 Iteration: 17095 Train loss: 0.007098\n",
      "Epoch: 2443/10000 Iteration: 17102 Train loss: 0.007098\n",
      "Epoch: 2444/10000 Iteration: 17109 Train loss: 0.007098\n",
      "Epoch: 2445/10000 Iteration: 17116 Train loss: 0.007099\n",
      "Epoch: 2446/10000 Iteration: 17123 Train loss: 0.007099\n",
      "Epoch: 2447/10000 Iteration: 17130 Train loss: 0.007099\n",
      "Epoch: 2448/10000 Iteration: 17137 Train loss: 0.007099\n",
      "Epoch: 2449/10000 Iteration: 17144 Train loss: 0.007099\n",
      "Epoch: 2450/10000 Iteration: 17151 Train loss: 0.007099\n",
      "Epoch: 2451/10000 Iteration: 17158 Train loss: 0.007099\n",
      "Epoch: 2452/10000 Iteration: 17165 Train loss: 0.007100\n",
      "Epoch: 2453/10000 Iteration: 17172 Train loss: 0.007100\n",
      "Epoch: 2454/10000 Iteration: 17179 Train loss: 0.007100\n",
      "Epoch: 2455/10000 Iteration: 17186 Train loss: 0.007100\n",
      "Epoch: 2456/10000 Iteration: 17193 Train loss: 0.007100\n",
      "Epoch: 2457/10000 Iteration: 17200 Train loss: 0.007100\n",
      "Epoch: 2458/10000 Iteration: 17207 Train loss: 0.007101\n",
      "Epoch: 2459/10000 Iteration: 17214 Train loss: 0.007101\n",
      "Epoch: 2460/10000 Iteration: 17221 Train loss: 0.007101\n",
      "Epoch: 2461/10000 Iteration: 17228 Train loss: 0.007101\n",
      "Epoch: 2462/10000 Iteration: 17235 Train loss: 0.007101\n",
      "Epoch: 2463/10000 Iteration: 17242 Train loss: 0.007102\n",
      "Epoch: 2464/10000 Iteration: 17249 Train loss: 0.007102\n",
      "Epoch: 2465/10000 Iteration: 17256 Train loss: 0.007102\n",
      "Epoch: 2466/10000 Iteration: 17263 Train loss: 0.007102\n",
      "Epoch: 2467/10000 Iteration: 17270 Train loss: 0.007102\n",
      "Epoch: 2468/10000 Iteration: 17277 Train loss: 0.007102\n",
      "Epoch: 2469/10000 Iteration: 17284 Train loss: 0.007103\n",
      "Epoch: 2470/10000 Iteration: 17291 Train loss: 0.007103\n",
      "Epoch: 2471/10000 Iteration: 17298 Train loss: 0.007103\n",
      "Epoch: 2472/10000 Iteration: 17305 Train loss: 0.007103\n",
      "Epoch: 2473/10000 Iteration: 17312 Train loss: 0.007103\n",
      "Epoch: 2474/10000 Iteration: 17319 Train loss: 0.007104\n",
      "Epoch: 2475/10000 Iteration: 17326 Train loss: 0.007104\n",
      "Epoch: 2476/10000 Iteration: 17333 Train loss: 0.007104\n",
      "Epoch: 2477/10000 Iteration: 17340 Train loss: 0.007104\n",
      "Epoch: 2478/10000 Iteration: 17347 Train loss: 0.007104\n",
      "Epoch: 2479/10000 Iteration: 17354 Train loss: 0.007105\n",
      "Epoch: 2480/10000 Iteration: 17361 Train loss: 0.007105\n",
      "Epoch: 2481/10000 Iteration: 17368 Train loss: 0.007105\n",
      "Epoch: 2482/10000 Iteration: 17375 Train loss: 0.007105\n",
      "Epoch: 2483/10000 Iteration: 17382 Train loss: 0.007105\n",
      "Epoch: 2484/10000 Iteration: 17389 Train loss: 0.007106\n",
      "Epoch: 2485/10000 Iteration: 17396 Train loss: 0.007106\n",
      "Epoch: 2486/10000 Iteration: 17403 Train loss: 0.007106\n",
      "Epoch: 2487/10000 Iteration: 17410 Train loss: 0.007106\n",
      "Epoch: 2488/10000 Iteration: 17417 Train loss: 0.007107\n",
      "Epoch: 2489/10000 Iteration: 17424 Train loss: 0.007107\n",
      "Epoch: 2490/10000 Iteration: 17431 Train loss: 0.007107\n",
      "Epoch: 2491/10000 Iteration: 17438 Train loss: 0.007107\n",
      "Epoch: 2492/10000 Iteration: 17445 Train loss: 0.007107\n",
      "Epoch: 2493/10000 Iteration: 17452 Train loss: 0.007108\n",
      "Epoch: 2494/10000 Iteration: 17459 Train loss: 0.007108\n",
      "Epoch: 2495/10000 Iteration: 17466 Train loss: 0.007108\n",
      "Epoch: 2496/10000 Iteration: 17473 Train loss: 0.007108\n",
      "Epoch: 2497/10000 Iteration: 17480 Train loss: 0.007109\n",
      "Epoch: 2498/10000 Iteration: 17487 Train loss: 0.007109\n",
      "Epoch: 2499/10000 Iteration: 17494 Train loss: 0.007109\n",
      "Epoch: 2500/10000 Iteration: 17501 Train loss: 0.007109\n",
      "Epoch: 2501/10000 Iteration: 17508 Train loss: 0.007110\n",
      "Epoch: 2502/10000 Iteration: 17515 Train loss: 0.007110\n",
      "Epoch: 2503/10000 Iteration: 17522 Train loss: 0.007110\n",
      "Epoch: 2504/10000 Iteration: 17529 Train loss: 0.007110\n",
      "Epoch: 2505/10000 Iteration: 17536 Train loss: 0.007111\n",
      "Epoch: 2506/10000 Iteration: 17543 Train loss: 0.007111\n",
      "Epoch: 2507/10000 Iteration: 17550 Train loss: 0.007111\n",
      "Epoch: 2508/10000 Iteration: 17557 Train loss: 0.007111\n",
      "Epoch: 2509/10000 Iteration: 17564 Train loss: 0.007112\n",
      "Epoch: 2510/10000 Iteration: 17571 Train loss: 0.007112\n",
      "Epoch: 2511/10000 Iteration: 17578 Train loss: 0.007112\n",
      "Epoch: 2512/10000 Iteration: 17585 Train loss: 0.007112\n",
      "Epoch: 2513/10000 Iteration: 17592 Train loss: 0.007113\n",
      "Epoch: 2514/10000 Iteration: 17599 Train loss: 0.007113\n",
      "Epoch: 2515/10000 Iteration: 17606 Train loss: 0.007113\n",
      "Epoch: 2516/10000 Iteration: 17613 Train loss: 0.007113\n",
      "Epoch: 2517/10000 Iteration: 17620 Train loss: 0.007114\n",
      "Epoch: 2518/10000 Iteration: 17627 Train loss: 0.007114\n",
      "Epoch: 2519/10000 Iteration: 17634 Train loss: 0.007114\n",
      "Epoch: 2520/10000 Iteration: 17641 Train loss: 0.007115\n",
      "Epoch: 2521/10000 Iteration: 17648 Train loss: 0.007115\n",
      "Epoch: 2522/10000 Iteration: 17655 Train loss: 0.007115\n",
      "Epoch: 2523/10000 Iteration: 17662 Train loss: 0.007115\n",
      "Epoch: 2524/10000 Iteration: 17669 Train loss: 0.007116\n",
      "Epoch: 2525/10000 Iteration: 17676 Train loss: 0.007116\n",
      "Epoch: 2526/10000 Iteration: 17683 Train loss: 0.007116\n",
      "Epoch: 2527/10000 Iteration: 17690 Train loss: 0.007117\n",
      "Epoch: 2528/10000 Iteration: 17697 Train loss: 0.007117\n",
      "Epoch: 2529/10000 Iteration: 17704 Train loss: 0.007117\n",
      "Epoch: 2530/10000 Iteration: 17711 Train loss: 0.007117\n",
      "Epoch: 2531/10000 Iteration: 17718 Train loss: 0.007118\n",
      "Epoch: 2532/10000 Iteration: 17725 Train loss: 0.007118\n",
      "Epoch: 2533/10000 Iteration: 17732 Train loss: 0.007118\n",
      "Epoch: 2534/10000 Iteration: 17739 Train loss: 0.007119\n",
      "Epoch: 2535/10000 Iteration: 17746 Train loss: 0.007119\n",
      "Epoch: 2536/10000 Iteration: 17753 Train loss: 0.007119\n",
      "Epoch: 2537/10000 Iteration: 17760 Train loss: 0.007119\n",
      "Epoch: 2538/10000 Iteration: 17767 Train loss: 0.007120\n",
      "Epoch: 2539/10000 Iteration: 17774 Train loss: 0.007120\n",
      "Epoch: 2540/10000 Iteration: 17781 Train loss: 0.007120\n",
      "Epoch: 2541/10000 Iteration: 17788 Train loss: 0.007121\n",
      "Epoch: 2542/10000 Iteration: 17795 Train loss: 0.007121\n",
      "Epoch: 2543/10000 Iteration: 17802 Train loss: 0.007121\n",
      "Epoch: 2544/10000 Iteration: 17809 Train loss: 0.007122\n",
      "Epoch: 2545/10000 Iteration: 17816 Train loss: 0.007122\n",
      "Epoch: 2546/10000 Iteration: 17823 Train loss: 0.007122\n",
      "Epoch: 2547/10000 Iteration: 17830 Train loss: 0.007123\n",
      "Epoch: 2548/10000 Iteration: 17837 Train loss: 0.007123\n",
      "Epoch: 2549/10000 Iteration: 17844 Train loss: 0.007123\n",
      "Epoch: 2550/10000 Iteration: 17851 Train loss: 0.007124\n",
      "Epoch: 2551/10000 Iteration: 17858 Train loss: 0.007124\n",
      "Epoch: 2552/10000 Iteration: 17865 Train loss: 0.007124\n",
      "Epoch: 2553/10000 Iteration: 17872 Train loss: 0.007125\n",
      "Epoch: 2554/10000 Iteration: 17879 Train loss: 0.007125\n",
      "Epoch: 2555/10000 Iteration: 17886 Train loss: 0.007125\n",
      "Epoch: 2556/10000 Iteration: 17893 Train loss: 0.007126\n",
      "Epoch: 2557/10000 Iteration: 17900 Train loss: 0.007126\n",
      "Epoch: 2558/10000 Iteration: 17907 Train loss: 0.007126\n",
      "Epoch: 2559/10000 Iteration: 17914 Train loss: 0.007127\n",
      "Epoch: 2560/10000 Iteration: 17921 Train loss: 0.007127\n",
      "Epoch: 2561/10000 Iteration: 17928 Train loss: 0.007127\n",
      "Epoch: 2562/10000 Iteration: 17935 Train loss: 0.007128\n",
      "Epoch: 2563/10000 Iteration: 17942 Train loss: 0.007128\n",
      "Epoch: 2564/10000 Iteration: 17949 Train loss: 0.007128\n",
      "Epoch: 2565/10000 Iteration: 17956 Train loss: 0.007129\n",
      "Epoch: 2566/10000 Iteration: 17963 Train loss: 0.007129\n",
      "Epoch: 2567/10000 Iteration: 17970 Train loss: 0.007129\n",
      "Epoch: 2568/10000 Iteration: 17977 Train loss: 0.007130\n",
      "Epoch: 2569/10000 Iteration: 17984 Train loss: 0.007130\n",
      "Epoch: 2570/10000 Iteration: 17991 Train loss: 0.007130\n",
      "Epoch: 2571/10000 Iteration: 17998 Train loss: 0.007131\n",
      "Epoch: 2572/10000 Iteration: 18005 Train loss: 0.007131\n",
      "Epoch: 2573/10000 Iteration: 18012 Train loss: 0.007131\n",
      "Epoch: 2574/10000 Iteration: 18019 Train loss: 0.007132\n",
      "Epoch: 2575/10000 Iteration: 18026 Train loss: 0.007132\n",
      "Epoch: 2576/10000 Iteration: 18033 Train loss: 0.007133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2577/10000 Iteration: 18040 Train loss: 0.007133\n",
      "Epoch: 2578/10000 Iteration: 18047 Train loss: 0.007133\n",
      "Epoch: 2579/10000 Iteration: 18054 Train loss: 0.007134\n",
      "Epoch: 2580/10000 Iteration: 18061 Train loss: 0.007134\n",
      "Epoch: 2581/10000 Iteration: 18068 Train loss: 0.007134\n",
      "Epoch: 2582/10000 Iteration: 18075 Train loss: 0.007135\n",
      "Epoch: 2583/10000 Iteration: 18082 Train loss: 0.007135\n",
      "Epoch: 2584/10000 Iteration: 18089 Train loss: 0.007136\n",
      "Epoch: 2585/10000 Iteration: 18096 Train loss: 0.007136\n",
      "Epoch: 2586/10000 Iteration: 18103 Train loss: 0.007136\n",
      "Epoch: 2587/10000 Iteration: 18110 Train loss: 0.007137\n",
      "Epoch: 2588/10000 Iteration: 18117 Train loss: 0.007137\n",
      "Epoch: 2589/10000 Iteration: 18124 Train loss: 0.007137\n",
      "Epoch: 2590/10000 Iteration: 18131 Train loss: 0.007138\n",
      "Epoch: 2591/10000 Iteration: 18138 Train loss: 0.007138\n",
      "Epoch: 2592/10000 Iteration: 18145 Train loss: 0.007139\n",
      "Epoch: 2593/10000 Iteration: 18152 Train loss: 0.007139\n",
      "Epoch: 2594/10000 Iteration: 18159 Train loss: 0.007139\n",
      "Epoch: 2595/10000 Iteration: 18166 Train loss: 0.007140\n",
      "Epoch: 2596/10000 Iteration: 18173 Train loss: 0.007140\n",
      "Epoch: 2597/10000 Iteration: 18180 Train loss: 0.007141\n",
      "Epoch: 2598/10000 Iteration: 18187 Train loss: 0.007141\n",
      "Epoch: 2599/10000 Iteration: 18194 Train loss: 0.007141\n",
      "Epoch: 2600/10000 Iteration: 18201 Train loss: 0.007142\n",
      "Epoch: 2601/10000 Iteration: 18208 Train loss: 0.007142\n",
      "Epoch: 2602/10000 Iteration: 18215 Train loss: 0.007143\n",
      "Epoch: 2603/10000 Iteration: 18222 Train loss: 0.007143\n",
      "Epoch: 2604/10000 Iteration: 18229 Train loss: 0.007143\n",
      "Epoch: 2605/10000 Iteration: 18236 Train loss: 0.007144\n",
      "Epoch: 2606/10000 Iteration: 18243 Train loss: 0.007144\n",
      "Epoch: 2607/10000 Iteration: 18250 Train loss: 0.007145\n",
      "Epoch: 2608/10000 Iteration: 18257 Train loss: 0.007145\n",
      "Epoch: 2609/10000 Iteration: 18264 Train loss: 0.007145\n",
      "Epoch: 2610/10000 Iteration: 18271 Train loss: 0.007146\n",
      "Epoch: 2611/10000 Iteration: 18278 Train loss: 0.007146\n",
      "Epoch: 2612/10000 Iteration: 18285 Train loss: 0.007147\n",
      "Epoch: 2613/10000 Iteration: 18292 Train loss: 0.007147\n",
      "Epoch: 2614/10000 Iteration: 18299 Train loss: 0.007148\n",
      "Epoch: 2615/10000 Iteration: 18306 Train loss: 0.007148\n",
      "Epoch: 2616/10000 Iteration: 18313 Train loss: 0.007148\n",
      "Epoch: 2617/10000 Iteration: 18320 Train loss: 0.007149\n",
      "Epoch: 2618/10000 Iteration: 18327 Train loss: 0.007149\n",
      "Epoch: 2619/10000 Iteration: 18334 Train loss: 0.007150\n",
      "Epoch: 2620/10000 Iteration: 18341 Train loss: 0.007150\n",
      "Epoch: 2621/10000 Iteration: 18348 Train loss: 0.007151\n",
      "Epoch: 2622/10000 Iteration: 18355 Train loss: 0.007151\n",
      "Epoch: 2623/10000 Iteration: 18362 Train loss: 0.007151\n",
      "Epoch: 2624/10000 Iteration: 18369 Train loss: 0.007152\n",
      "Epoch: 2625/10000 Iteration: 18376 Train loss: 0.007152\n",
      "Epoch: 2626/10000 Iteration: 18383 Train loss: 0.007153\n",
      "Epoch: 2627/10000 Iteration: 18390 Train loss: 0.007153\n",
      "Epoch: 2628/10000 Iteration: 18397 Train loss: 0.007154\n",
      "Epoch: 2629/10000 Iteration: 18404 Train loss: 0.007154\n",
      "Epoch: 2630/10000 Iteration: 18411 Train loss: 0.007154\n",
      "Epoch: 2631/10000 Iteration: 18418 Train loss: 0.007155\n",
      "Epoch: 2632/10000 Iteration: 18425 Train loss: 0.007155\n",
      "Epoch: 2633/10000 Iteration: 18432 Train loss: 0.007156\n",
      "Epoch: 2634/10000 Iteration: 18439 Train loss: 0.007156\n",
      "Epoch: 2635/10000 Iteration: 18446 Train loss: 0.007157\n",
      "Epoch: 2636/10000 Iteration: 18453 Train loss: 0.007157\n",
      "Epoch: 2637/10000 Iteration: 18460 Train loss: 0.007158\n",
      "Epoch: 2638/10000 Iteration: 18467 Train loss: 0.007158\n",
      "Epoch: 2639/10000 Iteration: 18474 Train loss: 0.007159\n",
      "Epoch: 2640/10000 Iteration: 18481 Train loss: 0.007159\n",
      "Epoch: 2641/10000 Iteration: 18488 Train loss: 0.007159\n",
      "Epoch: 2642/10000 Iteration: 18495 Train loss: 0.007160\n",
      "Epoch: 2643/10000 Iteration: 18502 Train loss: 0.007160\n",
      "Epoch: 2644/10000 Iteration: 18509 Train loss: 0.007161\n",
      "Epoch: 2645/10000 Iteration: 18516 Train loss: 0.007161\n",
      "Epoch: 2646/10000 Iteration: 18523 Train loss: 0.007162\n",
      "Epoch: 2647/10000 Iteration: 18530 Train loss: 0.007162\n",
      "Epoch: 2648/10000 Iteration: 18537 Train loss: 0.007163\n",
      "Epoch: 2649/10000 Iteration: 18544 Train loss: 0.007163\n",
      "Epoch: 2650/10000 Iteration: 18551 Train loss: 0.007164\n",
      "Epoch: 2651/10000 Iteration: 18558 Train loss: 0.007164\n",
      "Epoch: 2652/10000 Iteration: 18565 Train loss: 0.007165\n",
      "Epoch: 2653/10000 Iteration: 18572 Train loss: 0.007165\n",
      "Epoch: 2654/10000 Iteration: 18579 Train loss: 0.007165\n",
      "Epoch: 2655/10000 Iteration: 18586 Train loss: 0.007166\n",
      "Epoch: 2656/10000 Iteration: 18593 Train loss: 0.007166\n",
      "Epoch: 2657/10000 Iteration: 18600 Train loss: 0.007167\n",
      "Epoch: 2658/10000 Iteration: 18607 Train loss: 0.007167\n",
      "Epoch: 2659/10000 Iteration: 18614 Train loss: 0.007168\n",
      "Epoch: 2660/10000 Iteration: 18621 Train loss: 0.007168\n",
      "Epoch: 2661/10000 Iteration: 18628 Train loss: 0.007169\n",
      "Epoch: 2662/10000 Iteration: 18635 Train loss: 0.007169\n",
      "Epoch: 2663/10000 Iteration: 18642 Train loss: 0.007170\n",
      "Epoch: 2664/10000 Iteration: 18649 Train loss: 0.007170\n",
      "Epoch: 2665/10000 Iteration: 18656 Train loss: 0.007171\n",
      "Epoch: 2666/10000 Iteration: 18663 Train loss: 0.007171\n",
      "Epoch: 2667/10000 Iteration: 18670 Train loss: 0.007172\n",
      "Epoch: 2668/10000 Iteration: 18677 Train loss: 0.007172\n",
      "Epoch: 2669/10000 Iteration: 18684 Train loss: 0.007173\n",
      "Epoch: 2670/10000 Iteration: 18691 Train loss: 0.007173\n",
      "Epoch: 2671/10000 Iteration: 18698 Train loss: 0.007174\n",
      "Epoch: 2672/10000 Iteration: 18705 Train loss: 0.007174\n",
      "Epoch: 2673/10000 Iteration: 18712 Train loss: 0.007175\n",
      "Epoch: 2674/10000 Iteration: 18719 Train loss: 0.007175\n",
      "Epoch: 2675/10000 Iteration: 18726 Train loss: 0.007176\n",
      "Epoch: 2676/10000 Iteration: 18733 Train loss: 0.007176\n",
      "Epoch: 2677/10000 Iteration: 18740 Train loss: 0.007177\n",
      "Epoch: 2678/10000 Iteration: 18747 Train loss: 0.007177\n",
      "Epoch: 2679/10000 Iteration: 18754 Train loss: 0.007178\n",
      "Epoch: 2680/10000 Iteration: 18761 Train loss: 0.007178\n",
      "Epoch: 2681/10000 Iteration: 18768 Train loss: 0.007179\n",
      "Epoch: 2682/10000 Iteration: 18775 Train loss: 0.007179\n",
      "Epoch: 2683/10000 Iteration: 18782 Train loss: 0.007180\n",
      "Epoch: 2684/10000 Iteration: 18789 Train loss: 0.007180\n",
      "Epoch: 2685/10000 Iteration: 18796 Train loss: 0.007181\n",
      "Epoch: 2686/10000 Iteration: 18803 Train loss: 0.007181\n",
      "Epoch: 2687/10000 Iteration: 18810 Train loss: 0.007182\n",
      "Epoch: 2688/10000 Iteration: 18817 Train loss: 0.007182\n",
      "Epoch: 2689/10000 Iteration: 18824 Train loss: 0.007183\n",
      "Epoch: 2690/10000 Iteration: 18831 Train loss: 0.007183\n",
      "Epoch: 2691/10000 Iteration: 18838 Train loss: 0.007184\n",
      "Epoch: 2692/10000 Iteration: 18845 Train loss: 0.007184\n",
      "Epoch: 2693/10000 Iteration: 18852 Train loss: 0.007185\n",
      "Epoch: 2694/10000 Iteration: 18859 Train loss: 0.007186\n",
      "Epoch: 2695/10000 Iteration: 18866 Train loss: 0.007186\n",
      "Epoch: 2696/10000 Iteration: 18873 Train loss: 0.007187\n",
      "Epoch: 2697/10000 Iteration: 18880 Train loss: 0.007187\n",
      "Epoch: 2698/10000 Iteration: 18887 Train loss: 0.007188\n",
      "Epoch: 2699/10000 Iteration: 18894 Train loss: 0.007188\n",
      "Epoch: 2700/10000 Iteration: 18901 Train loss: 0.007189\n",
      "Epoch: 2701/10000 Iteration: 18908 Train loss: 0.007189\n",
      "Epoch: 2702/10000 Iteration: 18915 Train loss: 0.007190\n",
      "Epoch: 2703/10000 Iteration: 18922 Train loss: 0.007190\n",
      "Epoch: 2704/10000 Iteration: 18929 Train loss: 0.007191\n",
      "Epoch: 2705/10000 Iteration: 18936 Train loss: 0.007191\n",
      "Epoch: 2706/10000 Iteration: 18943 Train loss: 0.007192\n",
      "Epoch: 2707/10000 Iteration: 18950 Train loss: 0.007192\n",
      "Epoch: 2708/10000 Iteration: 18957 Train loss: 0.007193\n",
      "Epoch: 2709/10000 Iteration: 18964 Train loss: 0.007194\n",
      "Epoch: 2710/10000 Iteration: 18971 Train loss: 0.007194\n",
      "Epoch: 2711/10000 Iteration: 18978 Train loss: 0.007195\n",
      "Epoch: 2712/10000 Iteration: 18985 Train loss: 0.007195\n",
      "Epoch: 2713/10000 Iteration: 18992 Train loss: 0.007196\n",
      "Epoch: 2714/10000 Iteration: 18999 Train loss: 0.007196\n",
      "Epoch: 2715/10000 Iteration: 19006 Train loss: 0.007197\n",
      "Epoch: 2716/10000 Iteration: 19013 Train loss: 0.007197\n",
      "Epoch: 2717/10000 Iteration: 19020 Train loss: 0.007198\n",
      "Epoch: 2718/10000 Iteration: 19027 Train loss: 0.007198\n",
      "Epoch: 2719/10000 Iteration: 19034 Train loss: 0.007199\n",
      "Epoch: 2720/10000 Iteration: 19041 Train loss: 0.007200\n",
      "Epoch: 2721/10000 Iteration: 19048 Train loss: 0.007200\n",
      "Epoch: 2722/10000 Iteration: 19055 Train loss: 0.007201\n",
      "Epoch: 2723/10000 Iteration: 19062 Train loss: 0.007201\n",
      "Epoch: 2724/10000 Iteration: 19069 Train loss: 0.007202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2725/10000 Iteration: 19076 Train loss: 0.007202\n",
      "Epoch: 2726/10000 Iteration: 19083 Train loss: 0.007203\n",
      "Epoch: 2727/10000 Iteration: 19090 Train loss: 0.007203\n",
      "Epoch: 2728/10000 Iteration: 19097 Train loss: 0.007204\n",
      "Epoch: 2729/10000 Iteration: 19104 Train loss: 0.007205\n",
      "Epoch: 2730/10000 Iteration: 19111 Train loss: 0.007205\n",
      "Epoch: 2731/10000 Iteration: 19118 Train loss: 0.007206\n",
      "Epoch: 2732/10000 Iteration: 19125 Train loss: 0.007206\n",
      "Epoch: 2733/10000 Iteration: 19132 Train loss: 0.007207\n",
      "Epoch: 2734/10000 Iteration: 19139 Train loss: 0.007207\n",
      "Epoch: 2735/10000 Iteration: 19146 Train loss: 0.007208\n",
      "Epoch: 2736/10000 Iteration: 19153 Train loss: 0.007208\n",
      "Epoch: 2737/10000 Iteration: 19160 Train loss: 0.007209\n",
      "Epoch: 2738/10000 Iteration: 19167 Train loss: 0.007210\n",
      "Epoch: 2739/10000 Iteration: 19174 Train loss: 0.007210\n",
      "Epoch: 2740/10000 Iteration: 19181 Train loss: 0.007211\n",
      "Epoch: 2741/10000 Iteration: 19188 Train loss: 0.007211\n",
      "Epoch: 2742/10000 Iteration: 19195 Train loss: 0.007212\n",
      "Epoch: 2743/10000 Iteration: 19202 Train loss: 0.007213\n",
      "Epoch: 2744/10000 Iteration: 19209 Train loss: 0.007213\n",
      "Epoch: 2745/10000 Iteration: 19216 Train loss: 0.007214\n",
      "Epoch: 2746/10000 Iteration: 19223 Train loss: 0.007214\n",
      "Epoch: 2747/10000 Iteration: 19230 Train loss: 0.007215\n",
      "Epoch: 2748/10000 Iteration: 19237 Train loss: 0.007215\n",
      "Epoch: 2749/10000 Iteration: 19244 Train loss: 0.007216\n",
      "Epoch: 2750/10000 Iteration: 19251 Train loss: 0.007217\n",
      "Epoch: 2751/10000 Iteration: 19258 Train loss: 0.007217\n",
      "Epoch: 2752/10000 Iteration: 19265 Train loss: 0.007218\n",
      "Epoch: 2753/10000 Iteration: 19272 Train loss: 0.007218\n",
      "Epoch: 2754/10000 Iteration: 19279 Train loss: 0.007219\n",
      "Epoch: 2755/10000 Iteration: 19286 Train loss: 0.007219\n",
      "Epoch: 2756/10000 Iteration: 19293 Train loss: 0.007220\n",
      "Epoch: 2757/10000 Iteration: 19300 Train loss: 0.007221\n",
      "Epoch: 2758/10000 Iteration: 19307 Train loss: 0.007221\n",
      "Epoch: 2759/10000 Iteration: 19314 Train loss: 0.007222\n",
      "Epoch: 2760/10000 Iteration: 19321 Train loss: 0.007222\n",
      "Epoch: 2761/10000 Iteration: 19328 Train loss: 0.007223\n",
      "Epoch: 2762/10000 Iteration: 19335 Train loss: 0.007224\n",
      "Epoch: 2763/10000 Iteration: 19342 Train loss: 0.007224\n",
      "Epoch: 2764/10000 Iteration: 19349 Train loss: 0.007225\n",
      "Epoch: 2765/10000 Iteration: 19356 Train loss: 0.007225\n",
      "Epoch: 2766/10000 Iteration: 19363 Train loss: 0.007226\n",
      "Epoch: 2767/10000 Iteration: 19370 Train loss: 0.007227\n",
      "Epoch: 2768/10000 Iteration: 19377 Train loss: 0.007227\n",
      "Epoch: 2769/10000 Iteration: 19384 Train loss: 0.007228\n",
      "Epoch: 2770/10000 Iteration: 19391 Train loss: 0.007228\n",
      "Epoch: 2771/10000 Iteration: 19398 Train loss: 0.007229\n",
      "Epoch: 2772/10000 Iteration: 19405 Train loss: 0.007230\n",
      "Epoch: 2773/10000 Iteration: 19412 Train loss: 0.007230\n",
      "Epoch: 2774/10000 Iteration: 19419 Train loss: 0.007231\n",
      "Epoch: 2775/10000 Iteration: 19426 Train loss: 0.007231\n",
      "Epoch: 2776/10000 Iteration: 19433 Train loss: 0.007232\n",
      "Epoch: 2777/10000 Iteration: 19440 Train loss: 0.007233\n",
      "Epoch: 2778/10000 Iteration: 19447 Train loss: 0.007233\n",
      "Epoch: 2779/10000 Iteration: 19454 Train loss: 0.007234\n",
      "Epoch: 2780/10000 Iteration: 19461 Train loss: 0.007234\n",
      "Epoch: 2781/10000 Iteration: 19468 Train loss: 0.007235\n",
      "Epoch: 2782/10000 Iteration: 19475 Train loss: 0.007236\n",
      "Epoch: 2783/10000 Iteration: 19482 Train loss: 0.007236\n",
      "Epoch: 2784/10000 Iteration: 19489 Train loss: 0.007237\n",
      "Epoch: 2785/10000 Iteration: 19496 Train loss: 0.007238\n",
      "Epoch: 2786/10000 Iteration: 19503 Train loss: 0.007238\n",
      "Epoch: 2787/10000 Iteration: 19510 Train loss: 0.007239\n",
      "Epoch: 2788/10000 Iteration: 19517 Train loss: 0.007239\n",
      "Epoch: 2789/10000 Iteration: 19524 Train loss: 0.007240\n",
      "Epoch: 2790/10000 Iteration: 19531 Train loss: 0.007241\n",
      "Epoch: 2791/10000 Iteration: 19538 Train loss: 0.007241\n",
      "Epoch: 2792/10000 Iteration: 19545 Train loss: 0.007242\n",
      "Epoch: 2793/10000 Iteration: 19552 Train loss: 0.007242\n",
      "Epoch: 2794/10000 Iteration: 19559 Train loss: 0.007243\n",
      "Epoch: 2795/10000 Iteration: 19566 Train loss: 0.007244\n",
      "Epoch: 2796/10000 Iteration: 19573 Train loss: 0.007244\n",
      "Epoch: 2797/10000 Iteration: 19580 Train loss: 0.007245\n",
      "Epoch: 2798/10000 Iteration: 19587 Train loss: 0.007246\n",
      "Epoch: 2799/10000 Iteration: 19594 Train loss: 0.007246\n",
      "Epoch: 2800/10000 Iteration: 19601 Train loss: 0.007247\n",
      "Epoch: 2801/10000 Iteration: 19608 Train loss: 0.007247\n",
      "Epoch: 2802/10000 Iteration: 19615 Train loss: 0.007248\n",
      "Epoch: 2803/10000 Iteration: 19622 Train loss: 0.007249\n",
      "Epoch: 2804/10000 Iteration: 19629 Train loss: 0.007249\n",
      "Epoch: 2805/10000 Iteration: 19636 Train loss: 0.007250\n",
      "Epoch: 2806/10000 Iteration: 19643 Train loss: 0.007251\n",
      "Epoch: 2807/10000 Iteration: 19650 Train loss: 0.007251\n",
      "Epoch: 2808/10000 Iteration: 19657 Train loss: 0.007252\n",
      "Epoch: 2809/10000 Iteration: 19664 Train loss: 0.007253\n",
      "Epoch: 2810/10000 Iteration: 19671 Train loss: 0.007253\n",
      "Epoch: 2811/10000 Iteration: 19678 Train loss: 0.007254\n",
      "Epoch: 2812/10000 Iteration: 19685 Train loss: 0.007254\n",
      "Epoch: 2813/10000 Iteration: 19692 Train loss: 0.007255\n",
      "Epoch: 2814/10000 Iteration: 19699 Train loss: 0.007256\n",
      "Epoch: 2815/10000 Iteration: 19706 Train loss: 0.007256\n",
      "Epoch: 2816/10000 Iteration: 19713 Train loss: 0.007257\n",
      "Epoch: 2817/10000 Iteration: 19720 Train loss: 0.007258\n",
      "Epoch: 2818/10000 Iteration: 19727 Train loss: 0.007258\n",
      "Epoch: 2819/10000 Iteration: 19734 Train loss: 0.007259\n",
      "Epoch: 2820/10000 Iteration: 19741 Train loss: 0.007260\n",
      "Epoch: 2821/10000 Iteration: 19748 Train loss: 0.007260\n",
      "Epoch: 2822/10000 Iteration: 19755 Train loss: 0.007261\n",
      "Epoch: 2823/10000 Iteration: 19762 Train loss: 0.007261\n",
      "Epoch: 2824/10000 Iteration: 19769 Train loss: 0.007262\n",
      "Epoch: 2825/10000 Iteration: 19776 Train loss: 0.007263\n",
      "Epoch: 2826/10000 Iteration: 19783 Train loss: 0.007263\n",
      "Epoch: 2827/10000 Iteration: 19790 Train loss: 0.007264\n",
      "Epoch: 2828/10000 Iteration: 19797 Train loss: 0.007265\n",
      "Epoch: 2829/10000 Iteration: 19804 Train loss: 0.007265\n",
      "Epoch: 2830/10000 Iteration: 19811 Train loss: 0.007266\n",
      "Epoch: 2831/10000 Iteration: 19818 Train loss: 0.007267\n",
      "Epoch: 2832/10000 Iteration: 19825 Train loss: 0.007267\n",
      "Epoch: 2833/10000 Iteration: 19832 Train loss: 0.007268\n",
      "Epoch: 2834/10000 Iteration: 19839 Train loss: 0.007269\n",
      "Epoch: 2835/10000 Iteration: 19846 Train loss: 0.007269\n",
      "Epoch: 2836/10000 Iteration: 19853 Train loss: 0.007270\n",
      "Epoch: 2837/10000 Iteration: 19860 Train loss: 0.007271\n",
      "Epoch: 2838/10000 Iteration: 19867 Train loss: 0.007271\n",
      "Epoch: 2839/10000 Iteration: 19874 Train loss: 0.007272\n",
      "Epoch: 2840/10000 Iteration: 19881 Train loss: 0.007272\n",
      "Epoch: 2841/10000 Iteration: 19888 Train loss: 0.007273\n",
      "Epoch: 2842/10000 Iteration: 19895 Train loss: 0.007274\n",
      "Epoch: 2843/10000 Iteration: 19902 Train loss: 0.007274\n",
      "Epoch: 2844/10000 Iteration: 19909 Train loss: 0.007275\n",
      "Epoch: 2845/10000 Iteration: 19916 Train loss: 0.007276\n",
      "Epoch: 2846/10000 Iteration: 19923 Train loss: 0.007276\n",
      "Epoch: 2847/10000 Iteration: 19930 Train loss: 0.007277\n",
      "Epoch: 2848/10000 Iteration: 19937 Train loss: 0.007278\n",
      "Epoch: 2849/10000 Iteration: 19944 Train loss: 0.007278\n",
      "Epoch: 2850/10000 Iteration: 19951 Train loss: 0.007279\n",
      "Epoch: 2851/10000 Iteration: 19958 Train loss: 0.007280\n",
      "Epoch: 2852/10000 Iteration: 19965 Train loss: 0.007280\n",
      "Epoch: 2853/10000 Iteration: 19972 Train loss: 0.007281\n",
      "Epoch: 2854/10000 Iteration: 19979 Train loss: 0.007282\n",
      "Epoch: 2855/10000 Iteration: 19986 Train loss: 0.007282\n",
      "Epoch: 2856/10000 Iteration: 19993 Train loss: 0.007283\n",
      "Epoch: 2857/10000 Iteration: 20000 Train loss: 0.007284\n",
      "Epoch: 2858/10000 Iteration: 20007 Train loss: 0.007284\n",
      "Epoch: 2859/10000 Iteration: 20014 Train loss: 0.007285\n",
      "Epoch: 2860/10000 Iteration: 20021 Train loss: 0.007286\n",
      "Epoch: 2861/10000 Iteration: 20028 Train loss: 0.007286\n",
      "Epoch: 2862/10000 Iteration: 20035 Train loss: 0.007287\n",
      "Epoch: 2863/10000 Iteration: 20042 Train loss: 0.007288\n",
      "Epoch: 2864/10000 Iteration: 20049 Train loss: 0.007288\n",
      "Epoch: 2865/10000 Iteration: 20056 Train loss: 0.007289\n",
      "Epoch: 2866/10000 Iteration: 20063 Train loss: 0.007290\n",
      "Epoch: 2867/10000 Iteration: 20070 Train loss: 0.007290\n",
      "Epoch: 2868/10000 Iteration: 20077 Train loss: 0.007291\n",
      "Epoch: 2869/10000 Iteration: 20084 Train loss: 0.007292\n",
      "Epoch: 2870/10000 Iteration: 20091 Train loss: 0.007292\n",
      "Epoch: 2871/10000 Iteration: 20098 Train loss: 0.007293\n",
      "Epoch: 2872/10000 Iteration: 20105 Train loss: 0.007294\n",
      "Epoch: 2873/10000 Iteration: 20112 Train loss: 0.007294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2874/10000 Iteration: 20119 Train loss: 0.007295\n",
      "Epoch: 2875/10000 Iteration: 20126 Train loss: 0.007296\n",
      "Epoch: 2876/10000 Iteration: 20133 Train loss: 0.007296\n",
      "Epoch: 2877/10000 Iteration: 20140 Train loss: 0.007297\n",
      "Epoch: 2878/10000 Iteration: 20147 Train loss: 0.007298\n",
      "Epoch: 2879/10000 Iteration: 20154 Train loss: 0.007298\n",
      "Epoch: 2880/10000 Iteration: 20161 Train loss: 0.007299\n",
      "Epoch: 2881/10000 Iteration: 20168 Train loss: 0.007300\n",
      "Epoch: 2882/10000 Iteration: 20175 Train loss: 0.007300\n",
      "Epoch: 2883/10000 Iteration: 20182 Train loss: 0.007301\n",
      "Epoch: 2884/10000 Iteration: 20189 Train loss: 0.007302\n",
      "Epoch: 2885/10000 Iteration: 20196 Train loss: 0.007303\n",
      "Epoch: 2886/10000 Iteration: 20203 Train loss: 0.007303\n",
      "Epoch: 2887/10000 Iteration: 20210 Train loss: 0.007304\n",
      "Epoch: 2888/10000 Iteration: 20217 Train loss: 0.007305\n",
      "Epoch: 2889/10000 Iteration: 20224 Train loss: 0.007305\n",
      "Epoch: 2890/10000 Iteration: 20231 Train loss: 0.007306\n",
      "Epoch: 2891/10000 Iteration: 20238 Train loss: 0.007307\n",
      "Epoch: 2892/10000 Iteration: 20245 Train loss: 0.007307\n",
      "Epoch: 2893/10000 Iteration: 20252 Train loss: 0.007308\n",
      "Epoch: 2894/10000 Iteration: 20259 Train loss: 0.007309\n",
      "Epoch: 2895/10000 Iteration: 20266 Train loss: 0.007309\n",
      "Epoch: 2896/10000 Iteration: 20273 Train loss: 0.007310\n",
      "Epoch: 2897/10000 Iteration: 20280 Train loss: 0.007311\n",
      "Epoch: 2898/10000 Iteration: 20287 Train loss: 0.007311\n",
      "Epoch: 2899/10000 Iteration: 20294 Train loss: 0.007312\n",
      "Epoch: 2900/10000 Iteration: 20301 Train loss: 0.007313\n",
      "Epoch: 2901/10000 Iteration: 20308 Train loss: 0.007313\n",
      "Epoch: 2902/10000 Iteration: 20315 Train loss: 0.007314\n",
      "Epoch: 2903/10000 Iteration: 20322 Train loss: 0.007315\n",
      "Epoch: 2904/10000 Iteration: 20329 Train loss: 0.007316\n",
      "Epoch: 2905/10000 Iteration: 20336 Train loss: 0.007316\n",
      "Epoch: 2906/10000 Iteration: 20343 Train loss: 0.007317\n",
      "Epoch: 2907/10000 Iteration: 20350 Train loss: 0.007318\n",
      "Epoch: 2908/10000 Iteration: 20357 Train loss: 0.007318\n",
      "Epoch: 2909/10000 Iteration: 20364 Train loss: 0.007319\n",
      "Epoch: 2910/10000 Iteration: 20371 Train loss: 0.007320\n",
      "Epoch: 2911/10000 Iteration: 20378 Train loss: 0.007320\n",
      "Epoch: 2912/10000 Iteration: 20385 Train loss: 0.007321\n",
      "Epoch: 2913/10000 Iteration: 20392 Train loss: 0.007322\n",
      "Epoch: 2914/10000 Iteration: 20399 Train loss: 0.007322\n",
      "Epoch: 2915/10000 Iteration: 20406 Train loss: 0.007323\n",
      "Epoch: 2916/10000 Iteration: 20413 Train loss: 0.007324\n",
      "Epoch: 2917/10000 Iteration: 20420 Train loss: 0.007325\n",
      "Epoch: 2918/10000 Iteration: 20427 Train loss: 0.007325\n",
      "Epoch: 2919/10000 Iteration: 20434 Train loss: 0.007326\n",
      "Epoch: 2920/10000 Iteration: 20441 Train loss: 0.007327\n",
      "Epoch: 2921/10000 Iteration: 20448 Train loss: 0.007327\n",
      "Epoch: 2922/10000 Iteration: 20455 Train loss: 0.007328\n",
      "Epoch: 2923/10000 Iteration: 20462 Train loss: 0.007329\n",
      "Epoch: 2924/10000 Iteration: 20469 Train loss: 0.007329\n",
      "Epoch: 2925/10000 Iteration: 20476 Train loss: 0.007330\n",
      "Epoch: 2926/10000 Iteration: 20483 Train loss: 0.007331\n",
      "Epoch: 2927/10000 Iteration: 20490 Train loss: 0.007331\n",
      "Epoch: 2928/10000 Iteration: 20497 Train loss: 0.007332\n",
      "Epoch: 2929/10000 Iteration: 20504 Train loss: 0.007333\n",
      "Epoch: 2930/10000 Iteration: 20511 Train loss: 0.007334\n",
      "Epoch: 2931/10000 Iteration: 20518 Train loss: 0.007334\n",
      "Epoch: 2932/10000 Iteration: 20525 Train loss: 0.007335\n",
      "Epoch: 2933/10000 Iteration: 20532 Train loss: 0.007336\n",
      "Epoch: 2934/10000 Iteration: 20539 Train loss: 0.007336\n",
      "Epoch: 2935/10000 Iteration: 20546 Train loss: 0.007337\n",
      "Epoch: 2936/10000 Iteration: 20553 Train loss: 0.007338\n",
      "Epoch: 2937/10000 Iteration: 20560 Train loss: 0.007338\n",
      "Epoch: 2938/10000 Iteration: 20567 Train loss: 0.007339\n",
      "Epoch: 2939/10000 Iteration: 20574 Train loss: 0.007340\n",
      "Epoch: 2940/10000 Iteration: 20581 Train loss: 0.007341\n",
      "Epoch: 2941/10000 Iteration: 20588 Train loss: 0.007341\n",
      "Epoch: 2942/10000 Iteration: 20595 Train loss: 0.007342\n",
      "Epoch: 2943/10000 Iteration: 20602 Train loss: 0.007343\n",
      "Epoch: 2944/10000 Iteration: 20609 Train loss: 0.007343\n",
      "Epoch: 2945/10000 Iteration: 20616 Train loss: 0.007344\n",
      "Epoch: 2946/10000 Iteration: 20623 Train loss: 0.007345\n",
      "Epoch: 2947/10000 Iteration: 20630 Train loss: 0.007346\n",
      "Epoch: 2948/10000 Iteration: 20637 Train loss: 0.007346\n",
      "Epoch: 2949/10000 Iteration: 20644 Train loss: 0.007347\n",
      "Epoch: 2950/10000 Iteration: 20651 Train loss: 0.007348\n",
      "Epoch: 2951/10000 Iteration: 20658 Train loss: 0.007348\n",
      "Epoch: 2952/10000 Iteration: 20665 Train loss: 0.007349\n",
      "Epoch: 2953/10000 Iteration: 20672 Train loss: 0.007350\n",
      "Epoch: 2954/10000 Iteration: 20679 Train loss: 0.007350\n",
      "Epoch: 2955/10000 Iteration: 20686 Train loss: 0.007351\n",
      "Epoch: 2956/10000 Iteration: 20693 Train loss: 0.007352\n",
      "Epoch: 2957/10000 Iteration: 20700 Train loss: 0.007353\n",
      "Epoch: 2958/10000 Iteration: 20707 Train loss: 0.007353\n",
      "Epoch: 2959/10000 Iteration: 20714 Train loss: 0.007354\n",
      "Epoch: 2960/10000 Iteration: 20721 Train loss: 0.007355\n",
      "Epoch: 2961/10000 Iteration: 20728 Train loss: 0.007355\n",
      "Epoch: 2962/10000 Iteration: 20735 Train loss: 0.007356\n",
      "Epoch: 2963/10000 Iteration: 20742 Train loss: 0.007357\n",
      "Epoch: 2964/10000 Iteration: 20749 Train loss: 0.007358\n",
      "Epoch: 2965/10000 Iteration: 20756 Train loss: 0.007358\n",
      "Epoch: 2966/10000 Iteration: 20763 Train loss: 0.007359\n",
      "Epoch: 2967/10000 Iteration: 20770 Train loss: 0.007360\n",
      "Epoch: 2968/10000 Iteration: 20777 Train loss: 0.007360\n",
      "Epoch: 2969/10000 Iteration: 20784 Train loss: 0.007361\n",
      "Epoch: 2970/10000 Iteration: 20791 Train loss: 0.007362\n",
      "Epoch: 2971/10000 Iteration: 20798 Train loss: 0.007363\n",
      "Epoch: 2972/10000 Iteration: 20805 Train loss: 0.007363\n",
      "Epoch: 2973/10000 Iteration: 20812 Train loss: 0.007364\n",
      "Epoch: 2974/10000 Iteration: 20819 Train loss: 0.007365\n",
      "Epoch: 2975/10000 Iteration: 20826 Train loss: 0.007365\n",
      "Epoch: 2976/10000 Iteration: 20833 Train loss: 0.007366\n",
      "Epoch: 2977/10000 Iteration: 20840 Train loss: 0.007367\n",
      "Epoch: 2978/10000 Iteration: 20847 Train loss: 0.007368\n",
      "Epoch: 2979/10000 Iteration: 20854 Train loss: 0.007368\n",
      "Epoch: 2980/10000 Iteration: 20861 Train loss: 0.007369\n",
      "Epoch: 2981/10000 Iteration: 20868 Train loss: 0.007370\n",
      "Epoch: 2982/10000 Iteration: 20875 Train loss: 0.007370\n",
      "Epoch: 2983/10000 Iteration: 20882 Train loss: 0.007371\n",
      "Epoch: 2984/10000 Iteration: 20889 Train loss: 0.007372\n",
      "Epoch: 2985/10000 Iteration: 20896 Train loss: 0.007373\n",
      "Epoch: 2986/10000 Iteration: 20903 Train loss: 0.007373\n",
      "Epoch: 2987/10000 Iteration: 20910 Train loss: 0.007374\n",
      "Epoch: 2988/10000 Iteration: 20917 Train loss: 0.007375\n",
      "Epoch: 2989/10000 Iteration: 20924 Train loss: 0.007375\n",
      "Epoch: 2990/10000 Iteration: 20931 Train loss: 0.007376\n",
      "Epoch: 2991/10000 Iteration: 20938 Train loss: 0.007377\n",
      "Epoch: 2992/10000 Iteration: 20945 Train loss: 0.007378\n",
      "Epoch: 2993/10000 Iteration: 20952 Train loss: 0.007378\n",
      "Epoch: 2994/10000 Iteration: 20959 Train loss: 0.007379\n",
      "Epoch: 2995/10000 Iteration: 20966 Train loss: 0.007380\n",
      "Epoch: 2996/10000 Iteration: 20973 Train loss: 0.007380\n",
      "Epoch: 2997/10000 Iteration: 20980 Train loss: 0.007381\n",
      "Epoch: 2998/10000 Iteration: 20987 Train loss: 0.007382\n",
      "Epoch: 2999/10000 Iteration: 20994 Train loss: 0.007383\n",
      "Epoch: 3000/10000 Iteration: 21001 Train loss: 0.007383\n",
      "Epoch: 3001/10000 Iteration: 21008 Train loss: 0.007384\n",
      "Epoch: 3002/10000 Iteration: 21015 Train loss: 0.007385\n",
      "Epoch: 3003/10000 Iteration: 21022 Train loss: 0.007385\n",
      "Epoch: 3004/10000 Iteration: 21029 Train loss: 0.007386\n",
      "Epoch: 3005/10000 Iteration: 21036 Train loss: 0.007387\n",
      "Epoch: 3006/10000 Iteration: 21043 Train loss: 0.007388\n",
      "Epoch: 3007/10000 Iteration: 21050 Train loss: 0.007388\n",
      "Epoch: 3008/10000 Iteration: 21057 Train loss: 0.007389\n",
      "Epoch: 3009/10000 Iteration: 21064 Train loss: 0.007390\n",
      "Epoch: 3010/10000 Iteration: 21071 Train loss: 0.007390\n",
      "Epoch: 3011/10000 Iteration: 21078 Train loss: 0.007391\n",
      "Epoch: 3012/10000 Iteration: 21085 Train loss: 0.007392\n",
      "Epoch: 3013/10000 Iteration: 21092 Train loss: 0.007393\n",
      "Epoch: 3014/10000 Iteration: 21099 Train loss: 0.007393\n",
      "Epoch: 3015/10000 Iteration: 21106 Train loss: 0.007394\n",
      "Epoch: 3016/10000 Iteration: 21113 Train loss: 0.007395\n",
      "Epoch: 3017/10000 Iteration: 21120 Train loss: 0.007396\n",
      "Epoch: 3018/10000 Iteration: 21127 Train loss: 0.007396\n",
      "Epoch: 3019/10000 Iteration: 21134 Train loss: 0.007397\n",
      "Epoch: 3020/10000 Iteration: 21141 Train loss: 0.007398\n",
      "Epoch: 3021/10000 Iteration: 21148 Train loss: 0.007398\n",
      "Epoch: 3022/10000 Iteration: 21155 Train loss: 0.007399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3023/10000 Iteration: 21162 Train loss: 0.007400\n",
      "Epoch: 3024/10000 Iteration: 21169 Train loss: 0.007401\n",
      "Epoch: 3025/10000 Iteration: 21176 Train loss: 0.007401\n",
      "Epoch: 3026/10000 Iteration: 21183 Train loss: 0.007402\n",
      "Epoch: 3027/10000 Iteration: 21190 Train loss: 0.007403\n",
      "Epoch: 3028/10000 Iteration: 21197 Train loss: 0.007403\n",
      "Epoch: 3029/10000 Iteration: 21204 Train loss: 0.007404\n",
      "Epoch: 3030/10000 Iteration: 21211 Train loss: 0.007405\n",
      "Epoch: 3031/10000 Iteration: 21218 Train loss: 0.007406\n",
      "Epoch: 3032/10000 Iteration: 21225 Train loss: 0.007406\n",
      "Epoch: 3033/10000 Iteration: 21232 Train loss: 0.007407\n",
      "Epoch: 3034/10000 Iteration: 21239 Train loss: 0.007408\n",
      "Epoch: 3035/10000 Iteration: 21246 Train loss: 0.007409\n",
      "Epoch: 3036/10000 Iteration: 21253 Train loss: 0.007409\n",
      "Epoch: 3037/10000 Iteration: 21260 Train loss: 0.007410\n",
      "Epoch: 3038/10000 Iteration: 21267 Train loss: 0.007411\n",
      "Epoch: 3039/10000 Iteration: 21274 Train loss: 0.007411\n",
      "Epoch: 3040/10000 Iteration: 21281 Train loss: 0.007412\n",
      "Epoch: 3041/10000 Iteration: 21288 Train loss: 0.007413\n",
      "Epoch: 3042/10000 Iteration: 21295 Train loss: 0.007414\n",
      "Epoch: 3043/10000 Iteration: 21302 Train loss: 0.007414\n",
      "Epoch: 3044/10000 Iteration: 21309 Train loss: 0.007415\n",
      "Epoch: 3045/10000 Iteration: 21316 Train loss: 0.007416\n",
      "Epoch: 3046/10000 Iteration: 21323 Train loss: 0.007416\n",
      "Epoch: 3047/10000 Iteration: 21330 Train loss: 0.007417\n",
      "Epoch: 3048/10000 Iteration: 21337 Train loss: 0.007418\n",
      "Epoch: 3049/10000 Iteration: 21344 Train loss: 0.007419\n",
      "Epoch: 3050/10000 Iteration: 21351 Train loss: 0.007419\n",
      "Epoch: 3051/10000 Iteration: 21358 Train loss: 0.007420\n",
      "Epoch: 3052/10000 Iteration: 21365 Train loss: 0.007421\n",
      "Epoch: 3053/10000 Iteration: 21372 Train loss: 0.007422\n",
      "Epoch: 3054/10000 Iteration: 21379 Train loss: 0.007422\n",
      "Epoch: 3055/10000 Iteration: 21386 Train loss: 0.007423\n",
      "Epoch: 3056/10000 Iteration: 21393 Train loss: 0.007424\n",
      "Epoch: 3057/10000 Iteration: 21400 Train loss: 0.007424\n",
      "Epoch: 3058/10000 Iteration: 21407 Train loss: 0.007425\n",
      "Epoch: 3059/10000 Iteration: 21414 Train loss: 0.007426\n",
      "Epoch: 3060/10000 Iteration: 21421 Train loss: 0.007427\n",
      "Epoch: 3061/10000 Iteration: 21428 Train loss: 0.007427\n",
      "Epoch: 3062/10000 Iteration: 21435 Train loss: 0.007428\n",
      "Epoch: 3063/10000 Iteration: 21442 Train loss: 0.007429\n",
      "Epoch: 3064/10000 Iteration: 21449 Train loss: 0.007430\n",
      "Epoch: 3065/10000 Iteration: 21456 Train loss: 0.007430\n",
      "Epoch: 3066/10000 Iteration: 21463 Train loss: 0.007431\n",
      "Epoch: 3067/10000 Iteration: 21470 Train loss: 0.007432\n",
      "Epoch: 3068/10000 Iteration: 21477 Train loss: 0.007432\n",
      "Epoch: 3069/10000 Iteration: 21484 Train loss: 0.007433\n",
      "Epoch: 3070/10000 Iteration: 21491 Train loss: 0.007434\n",
      "Epoch: 3071/10000 Iteration: 21498 Train loss: 0.007435\n",
      "Epoch: 3072/10000 Iteration: 21505 Train loss: 0.007435\n",
      "Epoch: 3073/10000 Iteration: 21512 Train loss: 0.007436\n",
      "Epoch: 3074/10000 Iteration: 21519 Train loss: 0.007437\n",
      "Epoch: 3075/10000 Iteration: 21526 Train loss: 0.007438\n",
      "Epoch: 3076/10000 Iteration: 21533 Train loss: 0.007438\n",
      "Epoch: 3077/10000 Iteration: 21540 Train loss: 0.007439\n",
      "Epoch: 3078/10000 Iteration: 21547 Train loss: 0.007440\n",
      "Epoch: 3079/10000 Iteration: 21554 Train loss: 0.007440\n",
      "Epoch: 3080/10000 Iteration: 21561 Train loss: 0.007441\n",
      "Epoch: 3081/10000 Iteration: 21568 Train loss: 0.007442\n",
      "Epoch: 3082/10000 Iteration: 21575 Train loss: 0.007443\n",
      "Epoch: 3083/10000 Iteration: 21582 Train loss: 0.007443\n",
      "Epoch: 3084/10000 Iteration: 21589 Train loss: 0.007444\n",
      "Epoch: 3085/10000 Iteration: 21596 Train loss: 0.007445\n",
      "Epoch: 3086/10000 Iteration: 21603 Train loss: 0.007445\n",
      "Epoch: 3087/10000 Iteration: 21610 Train loss: 0.007446\n",
      "Epoch: 3088/10000 Iteration: 21617 Train loss: 0.007447\n",
      "Epoch: 3089/10000 Iteration: 21624 Train loss: 0.007448\n",
      "Epoch: 3090/10000 Iteration: 21631 Train loss: 0.007448\n",
      "Epoch: 3091/10000 Iteration: 21638 Train loss: 0.007449\n",
      "Epoch: 3092/10000 Iteration: 21645 Train loss: 0.007450\n",
      "Epoch: 3093/10000 Iteration: 21652 Train loss: 0.007451\n",
      "Epoch: 3094/10000 Iteration: 21659 Train loss: 0.007451\n",
      "Epoch: 3095/10000 Iteration: 21666 Train loss: 0.007452\n",
      "Epoch: 3096/10000 Iteration: 21673 Train loss: 0.007453\n",
      "Epoch: 3097/10000 Iteration: 21680 Train loss: 0.007453\n",
      "Epoch: 3098/10000 Iteration: 21687 Train loss: 0.007454\n",
      "Epoch: 3099/10000 Iteration: 21694 Train loss: 0.007455\n",
      "Epoch: 3100/10000 Iteration: 21701 Train loss: 0.007456\n",
      "Epoch: 3101/10000 Iteration: 21708 Train loss: 0.007456\n",
      "Epoch: 3102/10000 Iteration: 21715 Train loss: 0.007457\n",
      "Epoch: 3103/10000 Iteration: 21722 Train loss: 0.007458\n",
      "Epoch: 3104/10000 Iteration: 21729 Train loss: 0.007459\n",
      "Epoch: 3105/10000 Iteration: 21736 Train loss: 0.007459\n",
      "Epoch: 3106/10000 Iteration: 21743 Train loss: 0.007460\n",
      "Epoch: 3107/10000 Iteration: 21750 Train loss: 0.007461\n",
      "Epoch: 3108/10000 Iteration: 21757 Train loss: 0.007461\n",
      "Epoch: 3109/10000 Iteration: 21764 Train loss: 0.007462\n",
      "Epoch: 3110/10000 Iteration: 21771 Train loss: 0.007463\n",
      "Epoch: 3111/10000 Iteration: 21778 Train loss: 0.007464\n",
      "Epoch: 3112/10000 Iteration: 21785 Train loss: 0.007464\n",
      "Epoch: 3113/10000 Iteration: 21792 Train loss: 0.007465\n",
      "Epoch: 3114/10000 Iteration: 21799 Train loss: 0.007466\n",
      "Epoch: 3115/10000 Iteration: 21806 Train loss: 0.007466\n",
      "Epoch: 3116/10000 Iteration: 21813 Train loss: 0.007467\n",
      "Epoch: 3117/10000 Iteration: 21820 Train loss: 0.007468\n",
      "Epoch: 3118/10000 Iteration: 21827 Train loss: 0.007469\n",
      "Epoch: 3119/10000 Iteration: 21834 Train loss: 0.007469\n",
      "Epoch: 3120/10000 Iteration: 21841 Train loss: 0.007470\n",
      "Epoch: 3121/10000 Iteration: 21848 Train loss: 0.007471\n",
      "Epoch: 3122/10000 Iteration: 21855 Train loss: 0.007472\n",
      "Epoch: 3123/10000 Iteration: 21862 Train loss: 0.007472\n",
      "Epoch: 3124/10000 Iteration: 21869 Train loss: 0.007473\n",
      "Epoch: 3125/10000 Iteration: 21876 Train loss: 0.007474\n",
      "Epoch: 3126/10000 Iteration: 21883 Train loss: 0.007474\n",
      "Epoch: 3127/10000 Iteration: 21890 Train loss: 0.007475\n",
      "Epoch: 3128/10000 Iteration: 21897 Train loss: 0.007476\n",
      "Epoch: 3129/10000 Iteration: 21904 Train loss: 0.007477\n",
      "Epoch: 3130/10000 Iteration: 21911 Train loss: 0.007477\n",
      "Epoch: 3131/10000 Iteration: 21918 Train loss: 0.007478\n",
      "Epoch: 3132/10000 Iteration: 21925 Train loss: 0.007479\n",
      "Epoch: 3133/10000 Iteration: 21932 Train loss: 0.007480\n",
      "Epoch: 3134/10000 Iteration: 21939 Train loss: 0.007480\n",
      "Epoch: 3135/10000 Iteration: 21946 Train loss: 0.007481\n",
      "Epoch: 3136/10000 Iteration: 21953 Train loss: 0.007482\n",
      "Epoch: 3137/10000 Iteration: 21960 Train loss: 0.007482\n",
      "Epoch: 3138/10000 Iteration: 21967 Train loss: 0.007483\n",
      "Epoch: 3139/10000 Iteration: 21974 Train loss: 0.007484\n",
      "Epoch: 3140/10000 Iteration: 21981 Train loss: 0.007485\n",
      "Epoch: 3141/10000 Iteration: 21988 Train loss: 0.007485\n",
      "Epoch: 3142/10000 Iteration: 21995 Train loss: 0.007486\n",
      "Epoch: 3143/10000 Iteration: 22002 Train loss: 0.007487\n",
      "Epoch: 3144/10000 Iteration: 22009 Train loss: 0.007487\n",
      "Epoch: 3145/10000 Iteration: 22016 Train loss: 0.007488\n",
      "Epoch: 3146/10000 Iteration: 22023 Train loss: 0.007489\n",
      "Epoch: 3147/10000 Iteration: 22030 Train loss: 0.007490\n",
      "Epoch: 3148/10000 Iteration: 22037 Train loss: 0.007490\n",
      "Epoch: 3149/10000 Iteration: 22044 Train loss: 0.007491\n",
      "Epoch: 3150/10000 Iteration: 22051 Train loss: 0.007492\n",
      "Epoch: 3151/10000 Iteration: 22058 Train loss: 0.007492\n",
      "Epoch: 3152/10000 Iteration: 22065 Train loss: 0.007493\n",
      "Epoch: 3153/10000 Iteration: 22072 Train loss: 0.007494\n",
      "Epoch: 3154/10000 Iteration: 22079 Train loss: 0.007495\n",
      "Epoch: 3155/10000 Iteration: 22086 Train loss: 0.007495\n",
      "Epoch: 3156/10000 Iteration: 22093 Train loss: 0.007496\n",
      "Epoch: 3157/10000 Iteration: 22100 Train loss: 0.007497\n",
      "Epoch: 3158/10000 Iteration: 22107 Train loss: 0.007498\n",
      "Epoch: 3159/10000 Iteration: 22114 Train loss: 0.007498\n",
      "Epoch: 3160/10000 Iteration: 22121 Train loss: 0.007499\n",
      "Epoch: 3161/10000 Iteration: 22128 Train loss: 0.007500\n",
      "Epoch: 3162/10000 Iteration: 22135 Train loss: 0.007500\n",
      "Epoch: 3163/10000 Iteration: 22142 Train loss: 0.007501\n",
      "Epoch: 3164/10000 Iteration: 22149 Train loss: 0.007502\n",
      "Epoch: 3165/10000 Iteration: 22156 Train loss: 0.007503\n",
      "Epoch: 3166/10000 Iteration: 22163 Train loss: 0.007503\n",
      "Epoch: 3167/10000 Iteration: 22170 Train loss: 0.007504\n",
      "Epoch: 3168/10000 Iteration: 22177 Train loss: 0.007505\n",
      "Epoch: 3169/10000 Iteration: 22184 Train loss: 0.007505\n",
      "Epoch: 3170/10000 Iteration: 22191 Train loss: 0.007506\n",
      "Epoch: 3171/10000 Iteration: 22198 Train loss: 0.007507\n",
      "Epoch: 3172/10000 Iteration: 22205 Train loss: 0.007508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3173/10000 Iteration: 22212 Train loss: 0.007508\n",
      "Epoch: 3174/10000 Iteration: 22219 Train loss: 0.007509\n",
      "Epoch: 3175/10000 Iteration: 22226 Train loss: 0.007510\n",
      "Epoch: 3176/10000 Iteration: 22233 Train loss: 0.007510\n",
      "Epoch: 3177/10000 Iteration: 22240 Train loss: 0.007511\n",
      "Epoch: 3178/10000 Iteration: 22247 Train loss: 0.007512\n",
      "Epoch: 3179/10000 Iteration: 22254 Train loss: 0.007513\n",
      "Epoch: 3180/10000 Iteration: 22261 Train loss: 0.007513\n",
      "Epoch: 3181/10000 Iteration: 22268 Train loss: 0.007514\n",
      "Epoch: 3182/10000 Iteration: 22275 Train loss: 0.007515\n",
      "Epoch: 3183/10000 Iteration: 22282 Train loss: 0.007515\n",
      "Epoch: 3184/10000 Iteration: 22289 Train loss: 0.007516\n",
      "Epoch: 3185/10000 Iteration: 22296 Train loss: 0.007517\n",
      "Epoch: 3186/10000 Iteration: 22303 Train loss: 0.007518\n",
      "Epoch: 3187/10000 Iteration: 22310 Train loss: 0.007518\n",
      "Epoch: 3188/10000 Iteration: 22317 Train loss: 0.007519\n",
      "Epoch: 3189/10000 Iteration: 22324 Train loss: 0.007520\n",
      "Epoch: 3190/10000 Iteration: 22331 Train loss: 0.007520\n",
      "Epoch: 3191/10000 Iteration: 22338 Train loss: 0.007521\n",
      "Epoch: 3192/10000 Iteration: 22345 Train loss: 0.007522\n",
      "Epoch: 3193/10000 Iteration: 22352 Train loss: 0.007523\n",
      "Epoch: 3194/10000 Iteration: 22359 Train loss: 0.007523\n",
      "Epoch: 3195/10000 Iteration: 22366 Train loss: 0.007524\n",
      "Epoch: 3196/10000 Iteration: 22373 Train loss: 0.007525\n",
      "Epoch: 3197/10000 Iteration: 22380 Train loss: 0.007525\n",
      "Epoch: 3198/10000 Iteration: 22387 Train loss: 0.007526\n",
      "Epoch: 3199/10000 Iteration: 22394 Train loss: 0.007527\n",
      "Epoch: 3200/10000 Iteration: 22401 Train loss: 0.007528\n",
      "Epoch: 3201/10000 Iteration: 22408 Train loss: 0.007528\n",
      "Epoch: 3202/10000 Iteration: 22415 Train loss: 0.007529\n",
      "Epoch: 3203/10000 Iteration: 22422 Train loss: 0.007530\n",
      "Epoch: 3204/10000 Iteration: 22429 Train loss: 0.007530\n",
      "Epoch: 3205/10000 Iteration: 22436 Train loss: 0.007531\n",
      "Epoch: 3206/10000 Iteration: 22443 Train loss: 0.007532\n",
      "Epoch: 3207/10000 Iteration: 22450 Train loss: 0.007533\n",
      "Epoch: 3208/10000 Iteration: 22457 Train loss: 0.007533\n",
      "Epoch: 3209/10000 Iteration: 22464 Train loss: 0.007534\n",
      "Epoch: 3210/10000 Iteration: 22471 Train loss: 0.007535\n",
      "Epoch: 3211/10000 Iteration: 22478 Train loss: 0.007535\n",
      "Epoch: 3212/10000 Iteration: 22485 Train loss: 0.007536\n",
      "Epoch: 3213/10000 Iteration: 22492 Train loss: 0.007537\n",
      "Epoch: 3214/10000 Iteration: 22499 Train loss: 0.007537\n",
      "Epoch: 3215/10000 Iteration: 22506 Train loss: 0.007538\n",
      "Epoch: 3216/10000 Iteration: 22513 Train loss: 0.007539\n",
      "Epoch: 3217/10000 Iteration: 22520 Train loss: 0.007540\n",
      "Epoch: 3218/10000 Iteration: 22527 Train loss: 0.007540\n",
      "Epoch: 3219/10000 Iteration: 22534 Train loss: 0.007541\n",
      "Epoch: 3220/10000 Iteration: 22541 Train loss: 0.007542\n",
      "Epoch: 3221/10000 Iteration: 22548 Train loss: 0.007542\n",
      "Epoch: 3222/10000 Iteration: 22555 Train loss: 0.007543\n",
      "Epoch: 3223/10000 Iteration: 22562 Train loss: 0.007544\n",
      "Epoch: 3224/10000 Iteration: 22569 Train loss: 0.007545\n",
      "Epoch: 3225/10000 Iteration: 22576 Train loss: 0.007545\n",
      "Epoch: 3226/10000 Iteration: 22583 Train loss: 0.007546\n",
      "Epoch: 3227/10000 Iteration: 22590 Train loss: 0.007547\n",
      "Epoch: 3228/10000 Iteration: 22597 Train loss: 0.007547\n",
      "Epoch: 3229/10000 Iteration: 22604 Train loss: 0.007548\n",
      "Epoch: 3230/10000 Iteration: 22611 Train loss: 0.007549\n",
      "Epoch: 3231/10000 Iteration: 22618 Train loss: 0.007549\n",
      "Epoch: 3232/10000 Iteration: 22625 Train loss: 0.007550\n",
      "Epoch: 3233/10000 Iteration: 22632 Train loss: 0.007551\n",
      "Epoch: 3234/10000 Iteration: 22639 Train loss: 0.007552\n",
      "Epoch: 3235/10000 Iteration: 22646 Train loss: 0.007552\n",
      "Epoch: 3236/10000 Iteration: 22653 Train loss: 0.007553\n",
      "Epoch: 3237/10000 Iteration: 22660 Train loss: 0.007554\n",
      "Epoch: 3238/10000 Iteration: 22667 Train loss: 0.007554\n",
      "Epoch: 3239/10000 Iteration: 22674 Train loss: 0.007555\n",
      "Epoch: 3240/10000 Iteration: 22681 Train loss: 0.007556\n",
      "Epoch: 3241/10000 Iteration: 22688 Train loss: 0.007556\n",
      "Epoch: 3242/10000 Iteration: 22695 Train loss: 0.007557\n",
      "Epoch: 3243/10000 Iteration: 22702 Train loss: 0.007558\n",
      "Epoch: 3244/10000 Iteration: 22709 Train loss: 0.007559\n",
      "Epoch: 3245/10000 Iteration: 22716 Train loss: 0.007559\n",
      "Epoch: 3246/10000 Iteration: 22723 Train loss: 0.007560\n",
      "Epoch: 3247/10000 Iteration: 22730 Train loss: 0.007561\n",
      "Epoch: 3248/10000 Iteration: 22737 Train loss: 0.007561\n",
      "Epoch: 3249/10000 Iteration: 22744 Train loss: 0.007562\n",
      "Epoch: 3250/10000 Iteration: 22751 Train loss: 0.007563\n",
      "Epoch: 3251/10000 Iteration: 22758 Train loss: 0.007563\n",
      "Epoch: 3252/10000 Iteration: 22765 Train loss: 0.007564\n",
      "Epoch: 3253/10000 Iteration: 22772 Train loss: 0.007565\n",
      "Epoch: 3254/10000 Iteration: 22779 Train loss: 0.007566\n",
      "Epoch: 3255/10000 Iteration: 22786 Train loss: 0.007566\n",
      "Epoch: 3256/10000 Iteration: 22793 Train loss: 0.007567\n",
      "Epoch: 3257/10000 Iteration: 22800 Train loss: 0.007568\n",
      "Epoch: 3258/10000 Iteration: 22807 Train loss: 0.007568\n",
      "Epoch: 3259/10000 Iteration: 22814 Train loss: 0.007569\n",
      "Epoch: 3260/10000 Iteration: 22821 Train loss: 0.007570\n",
      "Epoch: 3261/10000 Iteration: 22828 Train loss: 0.007570\n",
      "Epoch: 3262/10000 Iteration: 22835 Train loss: 0.007571\n",
      "Epoch: 3263/10000 Iteration: 22842 Train loss: 0.007572\n",
      "Epoch: 3264/10000 Iteration: 22849 Train loss: 0.007572\n",
      "Epoch: 3265/10000 Iteration: 22856 Train loss: 0.007573\n",
      "Epoch: 3266/10000 Iteration: 22863 Train loss: 0.007574\n",
      "Epoch: 3267/10000 Iteration: 22870 Train loss: 0.007575\n",
      "Epoch: 3268/10000 Iteration: 22877 Train loss: 0.007575\n",
      "Epoch: 3269/10000 Iteration: 22884 Train loss: 0.007576\n",
      "Epoch: 3270/10000 Iteration: 22891 Train loss: 0.007577\n",
      "Epoch: 3271/10000 Iteration: 22898 Train loss: 0.007577\n",
      "Epoch: 3272/10000 Iteration: 22905 Train loss: 0.007578\n",
      "Epoch: 3273/10000 Iteration: 22912 Train loss: 0.007579\n",
      "Epoch: 3274/10000 Iteration: 22919 Train loss: 0.007579\n",
      "Epoch: 3275/10000 Iteration: 22926 Train loss: 0.007580\n",
      "Epoch: 3276/10000 Iteration: 22933 Train loss: 0.007581\n",
      "Epoch: 3277/10000 Iteration: 22940 Train loss: 0.007581\n",
      "Epoch: 3278/10000 Iteration: 22947 Train loss: 0.007582\n",
      "Epoch: 3279/10000 Iteration: 22954 Train loss: 0.007583\n",
      "Epoch: 3280/10000 Iteration: 22961 Train loss: 0.007584\n",
      "Epoch: 3281/10000 Iteration: 22968 Train loss: 0.007584\n",
      "Epoch: 3282/10000 Iteration: 22975 Train loss: 0.007585\n",
      "Epoch: 3283/10000 Iteration: 22982 Train loss: 0.007586\n",
      "Epoch: 3284/10000 Iteration: 22989 Train loss: 0.007586\n",
      "Epoch: 3285/10000 Iteration: 22996 Train loss: 0.007587\n",
      "Epoch: 3286/10000 Iteration: 23003 Train loss: 0.007588\n",
      "Epoch: 3287/10000 Iteration: 23010 Train loss: 0.007588\n",
      "Epoch: 3288/10000 Iteration: 23017 Train loss: 0.007589\n",
      "Epoch: 3289/10000 Iteration: 23024 Train loss: 0.007590\n",
      "Epoch: 3290/10000 Iteration: 23031 Train loss: 0.007590\n",
      "Epoch: 3291/10000 Iteration: 23038 Train loss: 0.007591\n",
      "Epoch: 3292/10000 Iteration: 23045 Train loss: 0.007592\n",
      "Epoch: 3293/10000 Iteration: 23052 Train loss: 0.007592\n",
      "Epoch: 3294/10000 Iteration: 23059 Train loss: 0.007593\n",
      "Epoch: 3295/10000 Iteration: 23066 Train loss: 0.007594\n",
      "Epoch: 3296/10000 Iteration: 23073 Train loss: 0.007595\n",
      "Epoch: 3297/10000 Iteration: 23080 Train loss: 0.007595\n",
      "Epoch: 3298/10000 Iteration: 23087 Train loss: 0.007596\n",
      "Epoch: 3299/10000 Iteration: 23094 Train loss: 0.007597\n",
      "Epoch: 3300/10000 Iteration: 23101 Train loss: 0.007597\n",
      "Epoch: 3301/10000 Iteration: 23108 Train loss: 0.007598\n",
      "Epoch: 3302/10000 Iteration: 23115 Train loss: 0.007599\n",
      "Epoch: 3303/10000 Iteration: 23122 Train loss: 0.007599\n",
      "Epoch: 3304/10000 Iteration: 23129 Train loss: 0.007600\n",
      "Epoch: 3305/10000 Iteration: 23136 Train loss: 0.007601\n",
      "Epoch: 3306/10000 Iteration: 23143 Train loss: 0.007601\n",
      "Epoch: 3307/10000 Iteration: 23150 Train loss: 0.007602\n",
      "Epoch: 3308/10000 Iteration: 23157 Train loss: 0.007603\n",
      "Epoch: 3309/10000 Iteration: 23164 Train loss: 0.007603\n",
      "Epoch: 3310/10000 Iteration: 23171 Train loss: 0.007604\n",
      "Epoch: 3311/10000 Iteration: 23178 Train loss: 0.007605\n",
      "Epoch: 3312/10000 Iteration: 23185 Train loss: 0.007605\n",
      "Epoch: 3313/10000 Iteration: 23192 Train loss: 0.007606\n",
      "Epoch: 3314/10000 Iteration: 23199 Train loss: 0.007607\n",
      "Epoch: 3315/10000 Iteration: 23206 Train loss: 0.007607\n",
      "Epoch: 3316/10000 Iteration: 23213 Train loss: 0.007608\n",
      "Epoch: 3317/10000 Iteration: 23220 Train loss: 0.007609\n",
      "Epoch: 3318/10000 Iteration: 23227 Train loss: 0.007609\n",
      "Epoch: 3319/10000 Iteration: 23234 Train loss: 0.007610\n",
      "Epoch: 3320/10000 Iteration: 23241 Train loss: 0.007611\n",
      "Epoch: 3321/10000 Iteration: 23248 Train loss: 0.007612\n",
      "Epoch: 3322/10000 Iteration: 23255 Train loss: 0.007612\n",
      "Epoch: 3323/10000 Iteration: 23262 Train loss: 0.007613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3324/10000 Iteration: 23269 Train loss: 0.007614\n",
      "Epoch: 3325/10000 Iteration: 23276 Train loss: 0.007614\n",
      "Epoch: 3326/10000 Iteration: 23283 Train loss: 0.007615\n",
      "Epoch: 3327/10000 Iteration: 23290 Train loss: 0.007616\n",
      "Epoch: 3328/10000 Iteration: 23297 Train loss: 0.007616\n",
      "Epoch: 3329/10000 Iteration: 23304 Train loss: 0.007617\n",
      "Epoch: 3330/10000 Iteration: 23311 Train loss: 0.007618\n",
      "Epoch: 3331/10000 Iteration: 23318 Train loss: 0.007618\n",
      "Epoch: 3332/10000 Iteration: 23325 Train loss: 0.007619\n",
      "Epoch: 3333/10000 Iteration: 23332 Train loss: 0.007620\n",
      "Epoch: 3334/10000 Iteration: 23339 Train loss: 0.007620\n",
      "Epoch: 3335/10000 Iteration: 23346 Train loss: 0.007621\n",
      "Epoch: 3336/10000 Iteration: 23353 Train loss: 0.007622\n",
      "Epoch: 3337/10000 Iteration: 23360 Train loss: 0.007622\n",
      "Epoch: 3338/10000 Iteration: 23367 Train loss: 0.007623\n",
      "Epoch: 3339/10000 Iteration: 23374 Train loss: 0.007624\n",
      "Epoch: 3340/10000 Iteration: 23381 Train loss: 0.007624\n",
      "Epoch: 3341/10000 Iteration: 23388 Train loss: 0.007625\n",
      "Epoch: 3342/10000 Iteration: 23395 Train loss: 0.007626\n",
      "Epoch: 3343/10000 Iteration: 23402 Train loss: 0.007626\n",
      "Epoch: 3344/10000 Iteration: 23409 Train loss: 0.007627\n",
      "Epoch: 3345/10000 Iteration: 23416 Train loss: 0.007628\n",
      "Epoch: 3346/10000 Iteration: 23423 Train loss: 0.007628\n",
      "Epoch: 3347/10000 Iteration: 23430 Train loss: 0.007629\n",
      "Epoch: 3348/10000 Iteration: 23437 Train loss: 0.007630\n",
      "Epoch: 3349/10000 Iteration: 23444 Train loss: 0.007630\n",
      "Epoch: 3350/10000 Iteration: 23451 Train loss: 0.007631\n",
      "Epoch: 3351/10000 Iteration: 23458 Train loss: 0.007632\n",
      "Epoch: 3352/10000 Iteration: 23465 Train loss: 0.007632\n",
      "Epoch: 3353/10000 Iteration: 23472 Train loss: 0.007633\n",
      "Epoch: 3354/10000 Iteration: 23479 Train loss: 0.007634\n",
      "Epoch: 3355/10000 Iteration: 23486 Train loss: 0.007634\n",
      "Epoch: 3356/10000 Iteration: 23493 Train loss: 0.007635\n",
      "Epoch: 3357/10000 Iteration: 23500 Train loss: 0.007636\n",
      "Epoch: 3358/10000 Iteration: 23507 Train loss: 0.007636\n",
      "Epoch: 3359/10000 Iteration: 23514 Train loss: 0.007637\n",
      "Epoch: 3360/10000 Iteration: 23521 Train loss: 0.007638\n",
      "Epoch: 3361/10000 Iteration: 23528 Train loss: 0.007638\n",
      "Epoch: 3362/10000 Iteration: 23535 Train loss: 0.007639\n",
      "Epoch: 3363/10000 Iteration: 23542 Train loss: 0.007639\n",
      "Epoch: 3364/10000 Iteration: 23549 Train loss: 0.007640\n",
      "Epoch: 3365/10000 Iteration: 23556 Train loss: 0.007641\n",
      "Epoch: 3366/10000 Iteration: 23563 Train loss: 0.007641\n",
      "Epoch: 3367/10000 Iteration: 23570 Train loss: 0.007642\n",
      "Epoch: 3368/10000 Iteration: 23577 Train loss: 0.007643\n",
      "Epoch: 3369/10000 Iteration: 23584 Train loss: 0.007643\n",
      "Epoch: 3370/10000 Iteration: 23591 Train loss: 0.007644\n",
      "Epoch: 3371/10000 Iteration: 23598 Train loss: 0.007645\n",
      "Epoch: 3372/10000 Iteration: 23605 Train loss: 0.007645\n",
      "Epoch: 3373/10000 Iteration: 23612 Train loss: 0.007646\n",
      "Epoch: 3374/10000 Iteration: 23619 Train loss: 0.007647\n",
      "Epoch: 3375/10000 Iteration: 23626 Train loss: 0.007647\n",
      "Epoch: 3376/10000 Iteration: 23633 Train loss: 0.007648\n",
      "Epoch: 3377/10000 Iteration: 23640 Train loss: 0.007649\n",
      "Epoch: 3378/10000 Iteration: 23647 Train loss: 0.007649\n",
      "Epoch: 3379/10000 Iteration: 23654 Train loss: 0.007650\n",
      "Epoch: 3380/10000 Iteration: 23661 Train loss: 0.007651\n",
      "Epoch: 3381/10000 Iteration: 23668 Train loss: 0.007651\n",
      "Epoch: 3382/10000 Iteration: 23675 Train loss: 0.007652\n",
      "Epoch: 3383/10000 Iteration: 23682 Train loss: 0.007653\n",
      "Epoch: 3384/10000 Iteration: 23689 Train loss: 0.007653\n",
      "Epoch: 3385/10000 Iteration: 23696 Train loss: 0.007654\n",
      "Epoch: 3386/10000 Iteration: 23703 Train loss: 0.007655\n",
      "Epoch: 3387/10000 Iteration: 23710 Train loss: 0.007655\n",
      "Epoch: 3388/10000 Iteration: 23717 Train loss: 0.007656\n",
      "Epoch: 3389/10000 Iteration: 23724 Train loss: 0.007656\n",
      "Epoch: 3390/10000 Iteration: 23731 Train loss: 0.007657\n",
      "Epoch: 3391/10000 Iteration: 23738 Train loss: 0.007658\n",
      "Epoch: 3392/10000 Iteration: 23745 Train loss: 0.007658\n",
      "Epoch: 3393/10000 Iteration: 23752 Train loss: 0.007659\n",
      "Epoch: 3394/10000 Iteration: 23759 Train loss: 0.007660\n",
      "Epoch: 3395/10000 Iteration: 23766 Train loss: 0.007660\n",
      "Epoch: 3396/10000 Iteration: 23773 Train loss: 0.007661\n",
      "Epoch: 3397/10000 Iteration: 23780 Train loss: 0.007662\n",
      "Epoch: 3398/10000 Iteration: 23787 Train loss: 0.007662\n",
      "Epoch: 3399/10000 Iteration: 23794 Train loss: 0.007663\n",
      "Epoch: 3400/10000 Iteration: 23801 Train loss: 0.007664\n",
      "Epoch: 3401/10000 Iteration: 23808 Train loss: 0.007664\n",
      "Epoch: 3402/10000 Iteration: 23815 Train loss: 0.007665\n",
      "Epoch: 3403/10000 Iteration: 23822 Train loss: 0.007665\n",
      "Epoch: 3404/10000 Iteration: 23829 Train loss: 0.007666\n",
      "Epoch: 3405/10000 Iteration: 23836 Train loss: 0.007667\n",
      "Epoch: 3406/10000 Iteration: 23843 Train loss: 0.007667\n",
      "Epoch: 3407/10000 Iteration: 23850 Train loss: 0.007668\n",
      "Epoch: 3408/10000 Iteration: 23857 Train loss: 0.007669\n",
      "Epoch: 3409/10000 Iteration: 23864 Train loss: 0.007669\n",
      "Epoch: 3410/10000 Iteration: 23871 Train loss: 0.007670\n",
      "Epoch: 3411/10000 Iteration: 23878 Train loss: 0.007671\n",
      "Epoch: 3412/10000 Iteration: 23885 Train loss: 0.007671\n",
      "Epoch: 3413/10000 Iteration: 23892 Train loss: 0.007672\n",
      "Epoch: 3414/10000 Iteration: 23899 Train loss: 0.007673\n",
      "Epoch: 3415/10000 Iteration: 23906 Train loss: 0.007673\n",
      "Epoch: 3416/10000 Iteration: 23913 Train loss: 0.007674\n",
      "Epoch: 3417/10000 Iteration: 23920 Train loss: 0.007674\n",
      "Epoch: 3418/10000 Iteration: 23927 Train loss: 0.007675\n",
      "Epoch: 3419/10000 Iteration: 23934 Train loss: 0.007676\n",
      "Epoch: 3420/10000 Iteration: 23941 Train loss: 0.007676\n",
      "Epoch: 3421/10000 Iteration: 23948 Train loss: 0.007677\n",
      "Epoch: 3422/10000 Iteration: 23955 Train loss: 0.007678\n",
      "Epoch: 3423/10000 Iteration: 23962 Train loss: 0.007678\n",
      "Epoch: 3424/10000 Iteration: 23969 Train loss: 0.007679\n",
      "Epoch: 3425/10000 Iteration: 23976 Train loss: 0.007679\n",
      "Epoch: 3426/10000 Iteration: 23983 Train loss: 0.007680\n",
      "Epoch: 3427/10000 Iteration: 23990 Train loss: 0.007681\n",
      "Epoch: 3428/10000 Iteration: 23997 Train loss: 0.007681\n",
      "Epoch: 3429/10000 Iteration: 24004 Train loss: 0.007682\n",
      "Epoch: 3430/10000 Iteration: 24011 Train loss: 0.007683\n",
      "Epoch: 3431/10000 Iteration: 24018 Train loss: 0.007683\n",
      "Epoch: 3432/10000 Iteration: 24025 Train loss: 0.007684\n",
      "Epoch: 3433/10000 Iteration: 24032 Train loss: 0.007685\n",
      "Epoch: 3434/10000 Iteration: 24039 Train loss: 0.007685\n",
      "Epoch: 3435/10000 Iteration: 24046 Train loss: 0.007686\n",
      "Epoch: 3436/10000 Iteration: 24053 Train loss: 0.007686\n",
      "Epoch: 3437/10000 Iteration: 24060 Train loss: 0.007687\n",
      "Epoch: 3438/10000 Iteration: 24067 Train loss: 0.007688\n",
      "Epoch: 3439/10000 Iteration: 24074 Train loss: 0.007688\n",
      "Epoch: 3440/10000 Iteration: 24081 Train loss: 0.007689\n",
      "Epoch: 3441/10000 Iteration: 24088 Train loss: 0.007690\n",
      "Epoch: 3442/10000 Iteration: 24095 Train loss: 0.007690\n",
      "Epoch: 3443/10000 Iteration: 24102 Train loss: 0.007691\n",
      "Epoch: 3444/10000 Iteration: 24109 Train loss: 0.007691\n",
      "Epoch: 3445/10000 Iteration: 24116 Train loss: 0.007692\n",
      "Epoch: 3446/10000 Iteration: 24123 Train loss: 0.007693\n",
      "Epoch: 3447/10000 Iteration: 24130 Train loss: 0.007693\n",
      "Epoch: 3448/10000 Iteration: 24137 Train loss: 0.007694\n",
      "Epoch: 3449/10000 Iteration: 24144 Train loss: 0.007695\n",
      "Epoch: 3450/10000 Iteration: 24151 Train loss: 0.007695\n",
      "Epoch: 3451/10000 Iteration: 24158 Train loss: 0.007696\n",
      "Epoch: 3452/10000 Iteration: 24165 Train loss: 0.007696\n",
      "Epoch: 3453/10000 Iteration: 24172 Train loss: 0.007697\n",
      "Epoch: 3454/10000 Iteration: 24179 Train loss: 0.007698\n",
      "Epoch: 3455/10000 Iteration: 24186 Train loss: 0.007698\n",
      "Epoch: 3456/10000 Iteration: 24193 Train loss: 0.007699\n",
      "Epoch: 3457/10000 Iteration: 24200 Train loss: 0.007699\n",
      "Epoch: 3458/10000 Iteration: 24207 Train loss: 0.007700\n",
      "Epoch: 3459/10000 Iteration: 24214 Train loss: 0.007701\n",
      "Epoch: 3460/10000 Iteration: 24221 Train loss: 0.007701\n",
      "Epoch: 3461/10000 Iteration: 24228 Train loss: 0.007702\n",
      "Epoch: 3462/10000 Iteration: 24235 Train loss: 0.007703\n",
      "Epoch: 3463/10000 Iteration: 24242 Train loss: 0.007703\n",
      "Epoch: 3464/10000 Iteration: 24249 Train loss: 0.007704\n",
      "Epoch: 3465/10000 Iteration: 24256 Train loss: 0.007704\n",
      "Epoch: 3466/10000 Iteration: 24263 Train loss: 0.007705\n",
      "Epoch: 3467/10000 Iteration: 24270 Train loss: 0.007706\n",
      "Epoch: 3468/10000 Iteration: 24277 Train loss: 0.007706\n",
      "Epoch: 3469/10000 Iteration: 24284 Train loss: 0.007707\n",
      "Epoch: 3470/10000 Iteration: 24291 Train loss: 0.007707\n",
      "Epoch: 3471/10000 Iteration: 24298 Train loss: 0.007708\n",
      "Epoch: 3472/10000 Iteration: 24305 Train loss: 0.007709\n",
      "Epoch: 3473/10000 Iteration: 24312 Train loss: 0.007709\n",
      "Epoch: 3474/10000 Iteration: 24319 Train loss: 0.007710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3475/10000 Iteration: 24326 Train loss: 0.007710\n",
      "Epoch: 3476/10000 Iteration: 24333 Train loss: 0.007711\n",
      "Epoch: 3477/10000 Iteration: 24340 Train loss: 0.007712\n",
      "Epoch: 3478/10000 Iteration: 24347 Train loss: 0.007712\n",
      "Epoch: 3479/10000 Iteration: 24354 Train loss: 0.007713\n",
      "Epoch: 3480/10000 Iteration: 24361 Train loss: 0.007714\n",
      "Epoch: 3481/10000 Iteration: 24368 Train loss: 0.007714\n",
      "Epoch: 3482/10000 Iteration: 24375 Train loss: 0.007715\n",
      "Epoch: 3483/10000 Iteration: 24382 Train loss: 0.007715\n",
      "Epoch: 3484/10000 Iteration: 24389 Train loss: 0.007716\n",
      "Epoch: 3485/10000 Iteration: 24396 Train loss: 0.007717\n",
      "Epoch: 3486/10000 Iteration: 24403 Train loss: 0.007717\n",
      "Epoch: 3487/10000 Iteration: 24410 Train loss: 0.007718\n",
      "Epoch: 3488/10000 Iteration: 24417 Train loss: 0.007718\n",
      "Epoch: 3489/10000 Iteration: 24424 Train loss: 0.007719\n",
      "Epoch: 3490/10000 Iteration: 24431 Train loss: 0.007720\n",
      "Epoch: 3491/10000 Iteration: 24438 Train loss: 0.007720\n",
      "Epoch: 3492/10000 Iteration: 24445 Train loss: 0.007721\n",
      "Epoch: 3493/10000 Iteration: 24452 Train loss: 0.007721\n",
      "Epoch: 3494/10000 Iteration: 24459 Train loss: 0.007722\n",
      "Epoch: 3495/10000 Iteration: 24466 Train loss: 0.007723\n",
      "Epoch: 3496/10000 Iteration: 24473 Train loss: 0.007723\n",
      "Epoch: 3497/10000 Iteration: 24480 Train loss: 0.007724\n",
      "Epoch: 3498/10000 Iteration: 24487 Train loss: 0.007724\n",
      "Epoch: 3499/10000 Iteration: 24494 Train loss: 0.007725\n",
      "Epoch: 3500/10000 Iteration: 24501 Train loss: 0.007726\n",
      "Epoch: 3501/10000 Iteration: 24508 Train loss: 0.007726\n",
      "Epoch: 3502/10000 Iteration: 24515 Train loss: 0.007727\n",
      "Epoch: 3503/10000 Iteration: 24522 Train loss: 0.007727\n",
      "Epoch: 3504/10000 Iteration: 24529 Train loss: 0.007728\n",
      "Epoch: 3505/10000 Iteration: 24536 Train loss: 0.007728\n",
      "Epoch: 3506/10000 Iteration: 24543 Train loss: 0.007729\n",
      "Epoch: 3507/10000 Iteration: 24550 Train loss: 0.007730\n",
      "Epoch: 3508/10000 Iteration: 24557 Train loss: 0.007730\n",
      "Epoch: 3509/10000 Iteration: 24564 Train loss: 0.007731\n",
      "Epoch: 3510/10000 Iteration: 24571 Train loss: 0.007731\n",
      "Epoch: 3511/10000 Iteration: 24578 Train loss: 0.007732\n",
      "Epoch: 3512/10000 Iteration: 24585 Train loss: 0.007733\n",
      "Epoch: 3513/10000 Iteration: 24592 Train loss: 0.007733\n",
      "Epoch: 3514/10000 Iteration: 24599 Train loss: 0.007734\n",
      "Epoch: 3515/10000 Iteration: 24606 Train loss: 0.007734\n",
      "Epoch: 3516/10000 Iteration: 24613 Train loss: 0.007735\n",
      "Epoch: 3517/10000 Iteration: 24620 Train loss: 0.007736\n",
      "Epoch: 3518/10000 Iteration: 24627 Train loss: 0.007736\n",
      "Epoch: 3519/10000 Iteration: 24634 Train loss: 0.007737\n",
      "Epoch: 3520/10000 Iteration: 24641 Train loss: 0.007737\n",
      "Epoch: 3521/10000 Iteration: 24648 Train loss: 0.007738\n",
      "Epoch: 3522/10000 Iteration: 24655 Train loss: 0.007739\n",
      "Epoch: 3523/10000 Iteration: 24662 Train loss: 0.007739\n",
      "Epoch: 3524/10000 Iteration: 24669 Train loss: 0.007740\n",
      "Epoch: 3525/10000 Iteration: 24676 Train loss: 0.007740\n",
      "Epoch: 3526/10000 Iteration: 24683 Train loss: 0.007741\n",
      "Epoch: 3527/10000 Iteration: 24690 Train loss: 0.007741\n",
      "Epoch: 3528/10000 Iteration: 24697 Train loss: 0.007742\n",
      "Epoch: 3529/10000 Iteration: 24704 Train loss: 0.007743\n",
      "Epoch: 3530/10000 Iteration: 24711 Train loss: 0.007743\n",
      "Epoch: 3531/10000 Iteration: 24718 Train loss: 0.007744\n",
      "Epoch: 3532/10000 Iteration: 24725 Train loss: 0.007744\n",
      "Epoch: 3533/10000 Iteration: 24732 Train loss: 0.007745\n",
      "Epoch: 3534/10000 Iteration: 24739 Train loss: 0.007745\n",
      "Epoch: 3535/10000 Iteration: 24746 Train loss: 0.007746\n",
      "Epoch: 3536/10000 Iteration: 24753 Train loss: 0.007747\n",
      "Epoch: 3537/10000 Iteration: 24760 Train loss: 0.007747\n",
      "Epoch: 3538/10000 Iteration: 24767 Train loss: 0.007748\n",
      "Epoch: 3539/10000 Iteration: 24774 Train loss: 0.007748\n",
      "Epoch: 3540/10000 Iteration: 24781 Train loss: 0.007749\n",
      "Epoch: 3541/10000 Iteration: 24788 Train loss: 0.007750\n",
      "Epoch: 3542/10000 Iteration: 24795 Train loss: 0.007750\n",
      "Epoch: 3543/10000 Iteration: 24802 Train loss: 0.007751\n",
      "Epoch: 3544/10000 Iteration: 24809 Train loss: 0.007751\n",
      "Epoch: 3545/10000 Iteration: 24816 Train loss: 0.007752\n",
      "Epoch: 3546/10000 Iteration: 24823 Train loss: 0.007752\n",
      "Epoch: 3547/10000 Iteration: 24830 Train loss: 0.007753\n",
      "Epoch: 3548/10000 Iteration: 24837 Train loss: 0.007754\n",
      "Epoch: 3549/10000 Iteration: 24844 Train loss: 0.007754\n",
      "Epoch: 3550/10000 Iteration: 24851 Train loss: 0.007755\n",
      "Epoch: 3551/10000 Iteration: 24858 Train loss: 0.007755\n",
      "Epoch: 3552/10000 Iteration: 24865 Train loss: 0.007756\n",
      "Epoch: 3553/10000 Iteration: 24872 Train loss: 0.007756\n",
      "Epoch: 3554/10000 Iteration: 24879 Train loss: 0.007757\n",
      "Epoch: 3555/10000 Iteration: 24886 Train loss: 0.007758\n",
      "Epoch: 3556/10000 Iteration: 24893 Train loss: 0.007758\n",
      "Epoch: 3557/10000 Iteration: 24900 Train loss: 0.007759\n",
      "Epoch: 3558/10000 Iteration: 24907 Train loss: 0.007759\n",
      "Epoch: 3559/10000 Iteration: 24914 Train loss: 0.007760\n",
      "Epoch: 3560/10000 Iteration: 24921 Train loss: 0.007760\n",
      "Epoch: 3561/10000 Iteration: 24928 Train loss: 0.007761\n",
      "Epoch: 3562/10000 Iteration: 24935 Train loss: 0.007761\n",
      "Epoch: 3563/10000 Iteration: 24942 Train loss: 0.007762\n",
      "Epoch: 3564/10000 Iteration: 24949 Train loss: 0.007763\n",
      "Epoch: 3565/10000 Iteration: 24956 Train loss: 0.007763\n",
      "Epoch: 3566/10000 Iteration: 24963 Train loss: 0.007764\n",
      "Epoch: 3567/10000 Iteration: 24970 Train loss: 0.007764\n",
      "Epoch: 3568/10000 Iteration: 24977 Train loss: 0.007765\n",
      "Epoch: 3569/10000 Iteration: 24984 Train loss: 0.007765\n",
      "Epoch: 3570/10000 Iteration: 24991 Train loss: 0.007766\n",
      "Epoch: 3571/10000 Iteration: 24998 Train loss: 0.007767\n",
      "Epoch: 3572/10000 Iteration: 25005 Train loss: 0.007767\n",
      "Epoch: 3573/10000 Iteration: 25012 Train loss: 0.007768\n",
      "Epoch: 3574/10000 Iteration: 25019 Train loss: 0.007768\n",
      "Epoch: 3575/10000 Iteration: 25026 Train loss: 0.007769\n",
      "Epoch: 3576/10000 Iteration: 25033 Train loss: 0.007769\n",
      "Epoch: 3577/10000 Iteration: 25040 Train loss: 0.007770\n",
      "Epoch: 3578/10000 Iteration: 25047 Train loss: 0.007770\n",
      "Epoch: 3579/10000 Iteration: 25054 Train loss: 0.007771\n",
      "Epoch: 3580/10000 Iteration: 25061 Train loss: 0.007772\n",
      "Epoch: 3581/10000 Iteration: 25068 Train loss: 0.007772\n",
      "Epoch: 3582/10000 Iteration: 25075 Train loss: 0.007773\n",
      "Epoch: 3583/10000 Iteration: 25082 Train loss: 0.007773\n",
      "Epoch: 3584/10000 Iteration: 25089 Train loss: 0.007774\n",
      "Epoch: 3585/10000 Iteration: 25096 Train loss: 0.007774\n",
      "Epoch: 3586/10000 Iteration: 25103 Train loss: 0.007775\n",
      "Epoch: 3587/10000 Iteration: 25110 Train loss: 0.007775\n",
      "Epoch: 3588/10000 Iteration: 25117 Train loss: 0.007776\n",
      "Epoch: 3589/10000 Iteration: 25124 Train loss: 0.007777\n",
      "Epoch: 3590/10000 Iteration: 25131 Train loss: 0.007777\n",
      "Epoch: 3591/10000 Iteration: 25138 Train loss: 0.007778\n",
      "Epoch: 3592/10000 Iteration: 25145 Train loss: 0.007778\n",
      "Epoch: 3593/10000 Iteration: 25152 Train loss: 0.007779\n",
      "Epoch: 3594/10000 Iteration: 25159 Train loss: 0.007779\n",
      "Epoch: 3595/10000 Iteration: 25166 Train loss: 0.007780\n",
      "Epoch: 3596/10000 Iteration: 25173 Train loss: 0.007780\n",
      "Epoch: 3597/10000 Iteration: 25180 Train loss: 0.007781\n",
      "Epoch: 3598/10000 Iteration: 25187 Train loss: 0.007781\n",
      "Epoch: 3599/10000 Iteration: 25194 Train loss: 0.007782\n",
      "Epoch: 3600/10000 Iteration: 25201 Train loss: 0.007783\n",
      "Epoch: 3601/10000 Iteration: 25208 Train loss: 0.007783\n",
      "Epoch: 3602/10000 Iteration: 25215 Train loss: 0.007784\n",
      "Epoch: 3603/10000 Iteration: 25222 Train loss: 0.007784\n",
      "Epoch: 3604/10000 Iteration: 25229 Train loss: 0.007785\n",
      "Epoch: 3605/10000 Iteration: 25236 Train loss: 0.007785\n",
      "Epoch: 3606/10000 Iteration: 25243 Train loss: 0.007786\n",
      "Epoch: 3607/10000 Iteration: 25250 Train loss: 0.007786\n",
      "Epoch: 3608/10000 Iteration: 25257 Train loss: 0.007787\n",
      "Epoch: 3609/10000 Iteration: 25264 Train loss: 0.007787\n",
      "Epoch: 3610/10000 Iteration: 25271 Train loss: 0.007788\n",
      "Epoch: 3611/10000 Iteration: 25278 Train loss: 0.007789\n",
      "Epoch: 3612/10000 Iteration: 25285 Train loss: 0.007789\n",
      "Epoch: 3613/10000 Iteration: 25292 Train loss: 0.007790\n",
      "Epoch: 3614/10000 Iteration: 25299 Train loss: 0.007790\n",
      "Epoch: 3615/10000 Iteration: 25306 Train loss: 0.007791\n",
      "Epoch: 3616/10000 Iteration: 25313 Train loss: 0.007791\n",
      "Epoch: 3617/10000 Iteration: 25320 Train loss: 0.007792\n",
      "Epoch: 3618/10000 Iteration: 25327 Train loss: 0.007792\n",
      "Epoch: 3619/10000 Iteration: 25334 Train loss: 0.007793\n",
      "Epoch: 3620/10000 Iteration: 25341 Train loss: 0.007793\n",
      "Epoch: 3621/10000 Iteration: 25348 Train loss: 0.007794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3622/10000 Iteration: 25355 Train loss: 0.007794\n",
      "Epoch: 3623/10000 Iteration: 25362 Train loss: 0.007795\n",
      "Epoch: 3624/10000 Iteration: 25369 Train loss: 0.007795\n",
      "Epoch: 3625/10000 Iteration: 25376 Train loss: 0.007796\n",
      "Epoch: 3626/10000 Iteration: 25383 Train loss: 0.007797\n",
      "Epoch: 3627/10000 Iteration: 25390 Train loss: 0.007797\n",
      "Epoch: 3628/10000 Iteration: 25397 Train loss: 0.007798\n",
      "Epoch: 3629/10000 Iteration: 25404 Train loss: 0.007798\n",
      "Epoch: 3630/10000 Iteration: 25411 Train loss: 0.007799\n",
      "Epoch: 3631/10000 Iteration: 25418 Train loss: 0.007799\n",
      "Epoch: 3632/10000 Iteration: 25425 Train loss: 0.007800\n",
      "Epoch: 3633/10000 Iteration: 25432 Train loss: 0.007800\n",
      "Epoch: 3634/10000 Iteration: 25439 Train loss: 0.007801\n",
      "Epoch: 3635/10000 Iteration: 25446 Train loss: 0.007801\n",
      "Epoch: 3636/10000 Iteration: 25453 Train loss: 0.007802\n",
      "Epoch: 3637/10000 Iteration: 25460 Train loss: 0.007802\n",
      "Epoch: 3638/10000 Iteration: 25467 Train loss: 0.007803\n",
      "Epoch: 3639/10000 Iteration: 25474 Train loss: 0.007803\n",
      "Epoch: 3640/10000 Iteration: 25481 Train loss: 0.007804\n",
      "Epoch: 3641/10000 Iteration: 25488 Train loss: 0.007804\n",
      "Epoch: 3642/10000 Iteration: 25495 Train loss: 0.007805\n",
      "Epoch: 3643/10000 Iteration: 25502 Train loss: 0.007805\n",
      "Epoch: 3644/10000 Iteration: 25509 Train loss: 0.007806\n",
      "Epoch: 3645/10000 Iteration: 25516 Train loss: 0.007807\n",
      "Epoch: 3646/10000 Iteration: 25523 Train loss: 0.007807\n",
      "Epoch: 3647/10000 Iteration: 25530 Train loss: 0.007808\n",
      "Epoch: 3648/10000 Iteration: 25537 Train loss: 0.007808\n",
      "Epoch: 3649/10000 Iteration: 25544 Train loss: 0.007809\n",
      "Epoch: 3650/10000 Iteration: 25551 Train loss: 0.007809\n",
      "Epoch: 3651/10000 Iteration: 25558 Train loss: 0.007810\n",
      "Epoch: 3652/10000 Iteration: 25565 Train loss: 0.007810\n",
      "Epoch: 3653/10000 Iteration: 25572 Train loss: 0.007811\n",
      "Epoch: 3654/10000 Iteration: 25579 Train loss: 0.007811\n",
      "Epoch: 3655/10000 Iteration: 25586 Train loss: 0.007812\n",
      "Epoch: 3656/10000 Iteration: 25593 Train loss: 0.007812\n",
      "Epoch: 3657/10000 Iteration: 25600 Train loss: 0.007813\n",
      "Epoch: 3658/10000 Iteration: 25607 Train loss: 0.007813\n",
      "Epoch: 3659/10000 Iteration: 25614 Train loss: 0.007814\n",
      "Epoch: 3660/10000 Iteration: 25621 Train loss: 0.007814\n",
      "Epoch: 3661/10000 Iteration: 25628 Train loss: 0.007815\n",
      "Epoch: 3662/10000 Iteration: 25635 Train loss: 0.007815\n",
      "Epoch: 3663/10000 Iteration: 25642 Train loss: 0.007816\n",
      "Epoch: 3664/10000 Iteration: 25649 Train loss: 0.007816\n",
      "Epoch: 3665/10000 Iteration: 25656 Train loss: 0.007817\n",
      "Epoch: 3666/10000 Iteration: 25663 Train loss: 0.007817\n",
      "Epoch: 3667/10000 Iteration: 25670 Train loss: 0.007818\n",
      "Epoch: 3668/10000 Iteration: 25677 Train loss: 0.007818\n",
      "Epoch: 3669/10000 Iteration: 25684 Train loss: 0.007819\n",
      "Epoch: 3670/10000 Iteration: 25691 Train loss: 0.007819\n",
      "Epoch: 3671/10000 Iteration: 25698 Train loss: 0.007820\n",
      "Epoch: 3672/10000 Iteration: 25705 Train loss: 0.007820\n",
      "Epoch: 3673/10000 Iteration: 25712 Train loss: 0.007821\n",
      "Epoch: 3674/10000 Iteration: 25719 Train loss: 0.007821\n",
      "Epoch: 3675/10000 Iteration: 25726 Train loss: 0.007822\n",
      "Epoch: 3676/10000 Iteration: 25733 Train loss: 0.007822\n",
      "Epoch: 3677/10000 Iteration: 25740 Train loss: 0.007823\n",
      "Epoch: 3678/10000 Iteration: 25747 Train loss: 0.007823\n",
      "Epoch: 3679/10000 Iteration: 25754 Train loss: 0.007824\n",
      "Epoch: 3680/10000 Iteration: 25761 Train loss: 0.007824\n",
      "Epoch: 3681/10000 Iteration: 25768 Train loss: 0.007825\n",
      "Epoch: 3682/10000 Iteration: 25775 Train loss: 0.007825\n",
      "Epoch: 3683/10000 Iteration: 25782 Train loss: 0.007826\n",
      "Epoch: 3684/10000 Iteration: 25789 Train loss: 0.007826\n",
      "Epoch: 3685/10000 Iteration: 25796 Train loss: 0.007827\n",
      "Epoch: 3686/10000 Iteration: 25803 Train loss: 0.007827\n",
      "Epoch: 3687/10000 Iteration: 25810 Train loss: 0.007828\n",
      "Epoch: 3688/10000 Iteration: 25817 Train loss: 0.007828\n",
      "Epoch: 3689/10000 Iteration: 25824 Train loss: 0.007829\n",
      "Epoch: 3690/10000 Iteration: 25831 Train loss: 0.007829\n",
      "Epoch: 3691/10000 Iteration: 25838 Train loss: 0.007830\n",
      "Epoch: 3692/10000 Iteration: 25845 Train loss: 0.007830\n",
      "Epoch: 3693/10000 Iteration: 25852 Train loss: 0.007831\n",
      "Epoch: 3694/10000 Iteration: 25859 Train loss: 0.007831\n",
      "Epoch: 3695/10000 Iteration: 25866 Train loss: 0.007832\n",
      "Epoch: 3696/10000 Iteration: 25873 Train loss: 0.007832\n",
      "Epoch: 3697/10000 Iteration: 25880 Train loss: 0.007833\n",
      "Epoch: 3698/10000 Iteration: 25887 Train loss: 0.007833\n",
      "Epoch: 3699/10000 Iteration: 25894 Train loss: 0.007834\n",
      "Epoch: 3700/10000 Iteration: 25901 Train loss: 0.007834\n",
      "Epoch: 3701/10000 Iteration: 25908 Train loss: 0.007835\n",
      "Epoch: 3702/10000 Iteration: 25915 Train loss: 0.007835\n",
      "Epoch: 3703/10000 Iteration: 25922 Train loss: 0.007836\n",
      "Epoch: 3704/10000 Iteration: 25929 Train loss: 0.007836\n",
      "Epoch: 3705/10000 Iteration: 25936 Train loss: 0.007837\n",
      "Epoch: 3706/10000 Iteration: 25943 Train loss: 0.007837\n",
      "Epoch: 3707/10000 Iteration: 25950 Train loss: 0.007838\n",
      "Epoch: 3708/10000 Iteration: 25957 Train loss: 0.007838\n",
      "Epoch: 3709/10000 Iteration: 25964 Train loss: 0.007839\n",
      "Epoch: 3710/10000 Iteration: 25971 Train loss: 0.007839\n",
      "Epoch: 3711/10000 Iteration: 25978 Train loss: 0.007840\n",
      "Epoch: 3712/10000 Iteration: 25985 Train loss: 0.007840\n",
      "Epoch: 3713/10000 Iteration: 25992 Train loss: 0.007841\n",
      "Epoch: 3714/10000 Iteration: 25999 Train loss: 0.007841\n",
      "Epoch: 3715/10000 Iteration: 26006 Train loss: 0.007842\n",
      "Epoch: 3716/10000 Iteration: 26013 Train loss: 0.007842\n",
      "Epoch: 3717/10000 Iteration: 26020 Train loss: 0.007843\n",
      "Epoch: 3718/10000 Iteration: 26027 Train loss: 0.007843\n",
      "Epoch: 3719/10000 Iteration: 26034 Train loss: 0.007844\n",
      "Epoch: 3720/10000 Iteration: 26041 Train loss: 0.007844\n",
      "Epoch: 3721/10000 Iteration: 26048 Train loss: 0.007844\n",
      "Epoch: 3722/10000 Iteration: 26055 Train loss: 0.007845\n",
      "Epoch: 3723/10000 Iteration: 26062 Train loss: 0.007845\n",
      "Epoch: 3724/10000 Iteration: 26069 Train loss: 0.007846\n",
      "Epoch: 3725/10000 Iteration: 26076 Train loss: 0.007846\n",
      "Epoch: 3726/10000 Iteration: 26083 Train loss: 0.007847\n",
      "Epoch: 3727/10000 Iteration: 26090 Train loss: 0.007847\n",
      "Epoch: 3728/10000 Iteration: 26097 Train loss: 0.007848\n",
      "Epoch: 3729/10000 Iteration: 26104 Train loss: 0.007848\n",
      "Epoch: 3730/10000 Iteration: 26111 Train loss: 0.007849\n",
      "Epoch: 3731/10000 Iteration: 26118 Train loss: 0.007849\n",
      "Epoch: 3732/10000 Iteration: 26125 Train loss: 0.007850\n",
      "Epoch: 3733/10000 Iteration: 26132 Train loss: 0.007850\n",
      "Epoch: 3734/10000 Iteration: 26139 Train loss: 0.007851\n",
      "Epoch: 3735/10000 Iteration: 26146 Train loss: 0.007851\n",
      "Epoch: 3736/10000 Iteration: 26153 Train loss: 0.007852\n",
      "Epoch: 3737/10000 Iteration: 26160 Train loss: 0.007852\n",
      "Epoch: 3738/10000 Iteration: 26167 Train loss: 0.007853\n",
      "Epoch: 3739/10000 Iteration: 26174 Train loss: 0.007853\n",
      "Epoch: 3740/10000 Iteration: 26181 Train loss: 0.007853\n",
      "Epoch: 3741/10000 Iteration: 26188 Train loss: 0.007854\n",
      "Epoch: 3742/10000 Iteration: 26195 Train loss: 0.007854\n",
      "Epoch: 3743/10000 Iteration: 26202 Train loss: 0.007855\n",
      "Epoch: 3744/10000 Iteration: 26209 Train loss: 0.007855\n",
      "Epoch: 3745/10000 Iteration: 26216 Train loss: 0.007856\n",
      "Epoch: 3746/10000 Iteration: 26223 Train loss: 0.007856\n",
      "Epoch: 3747/10000 Iteration: 26230 Train loss: 0.007857\n",
      "Epoch: 3748/10000 Iteration: 26237 Train loss: 0.007857\n",
      "Epoch: 3749/10000 Iteration: 26244 Train loss: 0.007858\n",
      "Epoch: 3750/10000 Iteration: 26251 Train loss: 0.007858\n",
      "Epoch: 3751/10000 Iteration: 26258 Train loss: 0.007859\n",
      "Epoch: 3752/10000 Iteration: 26265 Train loss: 0.007859\n",
      "Epoch: 3753/10000 Iteration: 26272 Train loss: 0.007860\n",
      "Epoch: 3754/10000 Iteration: 26279 Train loss: 0.007860\n",
      "Epoch: 3755/10000 Iteration: 26286 Train loss: 0.007860\n",
      "Epoch: 3756/10000 Iteration: 26293 Train loss: 0.007861\n",
      "Epoch: 3757/10000 Iteration: 26300 Train loss: 0.007861\n",
      "Epoch: 3758/10000 Iteration: 26307 Train loss: 0.007862\n",
      "Epoch: 3759/10000 Iteration: 26314 Train loss: 0.007862\n",
      "Epoch: 3760/10000 Iteration: 26321 Train loss: 0.007863\n",
      "Epoch: 3761/10000 Iteration: 26328 Train loss: 0.007863\n",
      "Epoch: 3762/10000 Iteration: 26335 Train loss: 0.007864\n",
      "Epoch: 3763/10000 Iteration: 26342 Train loss: 0.007864\n",
      "Epoch: 3764/10000 Iteration: 26349 Train loss: 0.007865\n",
      "Epoch: 3765/10000 Iteration: 26356 Train loss: 0.007865\n",
      "Epoch: 3766/10000 Iteration: 26363 Train loss: 0.007865\n",
      "Epoch: 3767/10000 Iteration: 26370 Train loss: 0.007866\n",
      "Epoch: 3768/10000 Iteration: 26377 Train loss: 0.007866\n",
      "Epoch: 3769/10000 Iteration: 26384 Train loss: 0.007867\n",
      "Epoch: 3770/10000 Iteration: 26391 Train loss: 0.007867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3771/10000 Iteration: 26398 Train loss: 0.007868\n",
      "Epoch: 3772/10000 Iteration: 26405 Train loss: 0.007868\n",
      "Epoch: 3773/10000 Iteration: 26412 Train loss: 0.007869\n",
      "Epoch: 3774/10000 Iteration: 26419 Train loss: 0.007869\n",
      "Epoch: 3775/10000 Iteration: 26426 Train loss: 0.007870\n",
      "Epoch: 3776/10000 Iteration: 26433 Train loss: 0.007870\n",
      "Epoch: 3777/10000 Iteration: 26440 Train loss: 0.007870\n",
      "Epoch: 3778/10000 Iteration: 26447 Train loss: 0.007871\n",
      "Epoch: 3779/10000 Iteration: 26454 Train loss: 0.007871\n",
      "Epoch: 3780/10000 Iteration: 26461 Train loss: 0.007872\n",
      "Epoch: 3781/10000 Iteration: 26468 Train loss: 0.007872\n",
      "Epoch: 3782/10000 Iteration: 26475 Train loss: 0.007873\n",
      "Epoch: 3783/10000 Iteration: 26482 Train loss: 0.007873\n",
      "Epoch: 3784/10000 Iteration: 26489 Train loss: 0.007874\n",
      "Epoch: 3785/10000 Iteration: 26496 Train loss: 0.007874\n",
      "Epoch: 3786/10000 Iteration: 26503 Train loss: 0.007874\n",
      "Epoch: 3787/10000 Iteration: 26510 Train loss: 0.007875\n",
      "Epoch: 3788/10000 Iteration: 26517 Train loss: 0.007875\n",
      "Epoch: 3789/10000 Iteration: 26524 Train loss: 0.007876\n",
      "Epoch: 3790/10000 Iteration: 26531 Train loss: 0.007876\n",
      "Epoch: 3791/10000 Iteration: 26538 Train loss: 0.007877\n",
      "Epoch: 3792/10000 Iteration: 26545 Train loss: 0.007877\n",
      "Epoch: 3793/10000 Iteration: 26552 Train loss: 0.007878\n",
      "Epoch: 3794/10000 Iteration: 26559 Train loss: 0.007878\n",
      "Epoch: 3795/10000 Iteration: 26566 Train loss: 0.007878\n",
      "Epoch: 3796/10000 Iteration: 26573 Train loss: 0.007879\n",
      "Epoch: 3797/10000 Iteration: 26580 Train loss: 0.007879\n",
      "Epoch: 3798/10000 Iteration: 26587 Train loss: 0.007880\n",
      "Epoch: 3799/10000 Iteration: 26594 Train loss: 0.007880\n",
      "Epoch: 3800/10000 Iteration: 26601 Train loss: 0.007881\n",
      "Epoch: 3801/10000 Iteration: 26608 Train loss: 0.007881\n",
      "Epoch: 3802/10000 Iteration: 26615 Train loss: 0.007881\n",
      "Epoch: 3803/10000 Iteration: 26622 Train loss: 0.007882\n",
      "Epoch: 3804/10000 Iteration: 26629 Train loss: 0.007882\n",
      "Epoch: 3805/10000 Iteration: 26636 Train loss: 0.007883\n",
      "Epoch: 3806/10000 Iteration: 26643 Train loss: 0.007883\n",
      "Epoch: 3807/10000 Iteration: 26650 Train loss: 0.007884\n",
      "Epoch: 3808/10000 Iteration: 26657 Train loss: 0.007884\n",
      "Epoch: 3809/10000 Iteration: 26664 Train loss: 0.007884\n",
      "Epoch: 3810/10000 Iteration: 26671 Train loss: 0.007885\n",
      "Epoch: 3811/10000 Iteration: 26678 Train loss: 0.007885\n",
      "Epoch: 3812/10000 Iteration: 26685 Train loss: 0.007886\n",
      "Epoch: 3813/10000 Iteration: 26692 Train loss: 0.007886\n",
      "Epoch: 3814/10000 Iteration: 26699 Train loss: 0.007887\n",
      "Epoch: 3815/10000 Iteration: 26706 Train loss: 0.007887\n",
      "Epoch: 3816/10000 Iteration: 26713 Train loss: 0.007887\n",
      "Epoch: 3817/10000 Iteration: 26720 Train loss: 0.007888\n",
      "Epoch: 3818/10000 Iteration: 26727 Train loss: 0.007888\n",
      "Epoch: 3819/10000 Iteration: 26734 Train loss: 0.007889\n",
      "Epoch: 3820/10000 Iteration: 26741 Train loss: 0.007889\n",
      "Epoch: 3821/10000 Iteration: 26748 Train loss: 0.007890\n",
      "Epoch: 3822/10000 Iteration: 26755 Train loss: 0.007890\n",
      "Epoch: 3823/10000 Iteration: 26762 Train loss: 0.007890\n",
      "Epoch: 3824/10000 Iteration: 26769 Train loss: 0.007891\n",
      "Epoch: 3825/10000 Iteration: 26776 Train loss: 0.007891\n",
      "Epoch: 3826/10000 Iteration: 26783 Train loss: 0.007892\n",
      "Epoch: 3827/10000 Iteration: 26790 Train loss: 0.007892\n",
      "Epoch: 3828/10000 Iteration: 26797 Train loss: 0.007893\n",
      "Epoch: 3829/10000 Iteration: 26804 Train loss: 0.007893\n",
      "Epoch: 3830/10000 Iteration: 26811 Train loss: 0.007893\n",
      "Epoch: 3831/10000 Iteration: 26818 Train loss: 0.007894\n",
      "Epoch: 3832/10000 Iteration: 26825 Train loss: 0.007894\n",
      "Epoch: 3833/10000 Iteration: 26832 Train loss: 0.007895\n",
      "Epoch: 3834/10000 Iteration: 26839 Train loss: 0.007895\n",
      "Epoch: 3835/10000 Iteration: 26846 Train loss: 0.007896\n",
      "Epoch: 3836/10000 Iteration: 26853 Train loss: 0.007896\n",
      "Epoch: 3837/10000 Iteration: 26860 Train loss: 0.007896\n",
      "Epoch: 3838/10000 Iteration: 26867 Train loss: 0.007897\n",
      "Epoch: 3839/10000 Iteration: 26874 Train loss: 0.007897\n",
      "Epoch: 3840/10000 Iteration: 26881 Train loss: 0.007898\n",
      "Epoch: 3841/10000 Iteration: 26888 Train loss: 0.007898\n",
      "Epoch: 3842/10000 Iteration: 26895 Train loss: 0.007898\n",
      "Epoch: 3843/10000 Iteration: 26902 Train loss: 0.007899\n",
      "Epoch: 3844/10000 Iteration: 26909 Train loss: 0.007899\n",
      "Epoch: 3845/10000 Iteration: 26916 Train loss: 0.007900\n",
      "Epoch: 3846/10000 Iteration: 26923 Train loss: 0.007900\n",
      "Epoch: 3847/10000 Iteration: 26930 Train loss: 0.007900\n",
      "Epoch: 3848/10000 Iteration: 26937 Train loss: 0.007901\n",
      "Epoch: 3849/10000 Iteration: 26944 Train loss: 0.007901\n",
      "Epoch: 3850/10000 Iteration: 26951 Train loss: 0.007902\n",
      "Epoch: 3851/10000 Iteration: 26958 Train loss: 0.007902\n",
      "Epoch: 3852/10000 Iteration: 26965 Train loss: 0.007903\n",
      "Epoch: 3853/10000 Iteration: 26972 Train loss: 0.007903\n",
      "Epoch: 3854/10000 Iteration: 26979 Train loss: 0.007903\n",
      "Epoch: 3855/10000 Iteration: 26986 Train loss: 0.007904\n",
      "Epoch: 3856/10000 Iteration: 26993 Train loss: 0.007904\n",
      "Epoch: 3857/10000 Iteration: 27000 Train loss: 0.007905\n",
      "Epoch: 3858/10000 Iteration: 27007 Train loss: 0.007905\n",
      "Epoch: 3859/10000 Iteration: 27014 Train loss: 0.007905\n",
      "Epoch: 3860/10000 Iteration: 27021 Train loss: 0.007906\n",
      "Epoch: 3861/10000 Iteration: 27028 Train loss: 0.007906\n",
      "Epoch: 3862/10000 Iteration: 27035 Train loss: 0.007907\n",
      "Epoch: 3863/10000 Iteration: 27042 Train loss: 0.007907\n",
      "Epoch: 3864/10000 Iteration: 27049 Train loss: 0.007907\n",
      "Epoch: 3865/10000 Iteration: 27056 Train loss: 0.007908\n",
      "Epoch: 3866/10000 Iteration: 27063 Train loss: 0.007908\n",
      "Epoch: 3867/10000 Iteration: 27070 Train loss: 0.007909\n",
      "Epoch: 3868/10000 Iteration: 27077 Train loss: 0.007909\n",
      "Epoch: 3869/10000 Iteration: 27084 Train loss: 0.007909\n",
      "Epoch: 3870/10000 Iteration: 27091 Train loss: 0.007910\n",
      "Epoch: 3871/10000 Iteration: 27098 Train loss: 0.007910\n",
      "Epoch: 3872/10000 Iteration: 27105 Train loss: 0.007911\n",
      "Epoch: 3873/10000 Iteration: 27112 Train loss: 0.007911\n",
      "Epoch: 3874/10000 Iteration: 27119 Train loss: 0.007911\n",
      "Epoch: 3875/10000 Iteration: 27126 Train loss: 0.007912\n",
      "Epoch: 3876/10000 Iteration: 27133 Train loss: 0.007912\n",
      "Epoch: 3877/10000 Iteration: 27140 Train loss: 0.007912\n",
      "Epoch: 3878/10000 Iteration: 27147 Train loss: 0.007913\n",
      "Epoch: 3879/10000 Iteration: 27154 Train loss: 0.007913\n",
      "Epoch: 3880/10000 Iteration: 27161 Train loss: 0.007914\n",
      "Epoch: 3881/10000 Iteration: 27168 Train loss: 0.007914\n",
      "Epoch: 3882/10000 Iteration: 27175 Train loss: 0.007914\n",
      "Epoch: 3883/10000 Iteration: 27182 Train loss: 0.007915\n",
      "Epoch: 3884/10000 Iteration: 27189 Train loss: 0.007915\n",
      "Epoch: 3885/10000 Iteration: 27196 Train loss: 0.007916\n",
      "Epoch: 3886/10000 Iteration: 27203 Train loss: 0.007916\n",
      "Epoch: 3887/10000 Iteration: 27210 Train loss: 0.007916\n",
      "Epoch: 3888/10000 Iteration: 27217 Train loss: 0.007917\n",
      "Epoch: 3889/10000 Iteration: 27224 Train loss: 0.007917\n",
      "Epoch: 3890/10000 Iteration: 27231 Train loss: 0.007918\n",
      "Epoch: 3891/10000 Iteration: 27238 Train loss: 0.007918\n",
      "Epoch: 3892/10000 Iteration: 27245 Train loss: 0.007918\n",
      "Epoch: 3893/10000 Iteration: 27252 Train loss: 0.007919\n",
      "Epoch: 3894/10000 Iteration: 27259 Train loss: 0.007919\n",
      "Epoch: 3895/10000 Iteration: 27266 Train loss: 0.007919\n",
      "Epoch: 3896/10000 Iteration: 27273 Train loss: 0.007920\n",
      "Epoch: 3897/10000 Iteration: 27280 Train loss: 0.007920\n",
      "Epoch: 3898/10000 Iteration: 27287 Train loss: 0.007921\n",
      "Epoch: 3899/10000 Iteration: 27294 Train loss: 0.007921\n",
      "Epoch: 3900/10000 Iteration: 27301 Train loss: 0.007921\n",
      "Epoch: 3901/10000 Iteration: 27308 Train loss: 0.007922\n",
      "Epoch: 3902/10000 Iteration: 27315 Train loss: 0.007922\n",
      "Epoch: 3903/10000 Iteration: 27322 Train loss: 0.007923\n",
      "Epoch: 3904/10000 Iteration: 27329 Train loss: 0.007923\n",
      "Epoch: 3905/10000 Iteration: 27336 Train loss: 0.007923\n",
      "Epoch: 3906/10000 Iteration: 27343 Train loss: 0.007924\n",
      "Epoch: 3907/10000 Iteration: 27350 Train loss: 0.007924\n",
      "Epoch: 3908/10000 Iteration: 27357 Train loss: 0.007924\n",
      "Epoch: 3909/10000 Iteration: 27364 Train loss: 0.007925\n",
      "Epoch: 3910/10000 Iteration: 27371 Train loss: 0.007925\n",
      "Epoch: 3911/10000 Iteration: 27378 Train loss: 0.007926\n",
      "Epoch: 3912/10000 Iteration: 27385 Train loss: 0.007926\n",
      "Epoch: 3913/10000 Iteration: 27392 Train loss: 0.007926\n",
      "Epoch: 3914/10000 Iteration: 27399 Train loss: 0.007927\n",
      "Epoch: 3915/10000 Iteration: 27406 Train loss: 0.007927\n",
      "Epoch: 3916/10000 Iteration: 27413 Train loss: 0.007927\n",
      "Epoch: 3917/10000 Iteration: 27420 Train loss: 0.007928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3918/10000 Iteration: 27427 Train loss: 0.007928\n",
      "Epoch: 3919/10000 Iteration: 27434 Train loss: 0.007928\n",
      "Epoch: 3920/10000 Iteration: 27441 Train loss: 0.007929\n",
      "Epoch: 3921/10000 Iteration: 27448 Train loss: 0.007929\n",
      "Epoch: 3922/10000 Iteration: 27455 Train loss: 0.007930\n",
      "Epoch: 3923/10000 Iteration: 27462 Train loss: 0.007930\n",
      "Epoch: 3924/10000 Iteration: 27469 Train loss: 0.007930\n",
      "Epoch: 3925/10000 Iteration: 27476 Train loss: 0.007931\n",
      "Epoch: 3926/10000 Iteration: 27483 Train loss: 0.007931\n",
      "Epoch: 3927/10000 Iteration: 27490 Train loss: 0.007931\n",
      "Epoch: 3928/10000 Iteration: 27497 Train loss: 0.007932\n",
      "Epoch: 3929/10000 Iteration: 27504 Train loss: 0.007932\n",
      "Epoch: 3930/10000 Iteration: 27511 Train loss: 0.007933\n",
      "Epoch: 3931/10000 Iteration: 27518 Train loss: 0.007933\n",
      "Epoch: 3932/10000 Iteration: 27525 Train loss: 0.007933\n",
      "Epoch: 3933/10000 Iteration: 27532 Train loss: 0.007934\n",
      "Epoch: 3934/10000 Iteration: 27539 Train loss: 0.007934\n",
      "Epoch: 3935/10000 Iteration: 27546 Train loss: 0.007934\n",
      "Epoch: 3936/10000 Iteration: 27553 Train loss: 0.007935\n",
      "Epoch: 3937/10000 Iteration: 27560 Train loss: 0.007935\n",
      "Epoch: 3938/10000 Iteration: 27567 Train loss: 0.007935\n",
      "Epoch: 3939/10000 Iteration: 27574 Train loss: 0.007936\n",
      "Epoch: 3940/10000 Iteration: 27581 Train loss: 0.007936\n",
      "Epoch: 3941/10000 Iteration: 27588 Train loss: 0.007936\n",
      "Epoch: 3942/10000 Iteration: 27595 Train loss: 0.007937\n",
      "Epoch: 3943/10000 Iteration: 27602 Train loss: 0.007937\n",
      "Epoch: 3944/10000 Iteration: 27609 Train loss: 0.007938\n",
      "Epoch: 3945/10000 Iteration: 27616 Train loss: 0.007938\n",
      "Epoch: 3946/10000 Iteration: 27623 Train loss: 0.007938\n",
      "Epoch: 3947/10000 Iteration: 27630 Train loss: 0.007939\n",
      "Epoch: 3948/10000 Iteration: 27637 Train loss: 0.007939\n",
      "Epoch: 3949/10000 Iteration: 27644 Train loss: 0.007939\n",
      "Epoch: 3950/10000 Iteration: 27651 Train loss: 0.007940\n",
      "Epoch: 3951/10000 Iteration: 27658 Train loss: 0.007940\n",
      "Epoch: 3952/10000 Iteration: 27665 Train loss: 0.007940\n",
      "Epoch: 3953/10000 Iteration: 27672 Train loss: 0.007941\n",
      "Epoch: 3954/10000 Iteration: 27679 Train loss: 0.007941\n",
      "Epoch: 3955/10000 Iteration: 27686 Train loss: 0.007941\n",
      "Epoch: 3956/10000 Iteration: 27693 Train loss: 0.007942\n",
      "Epoch: 3957/10000 Iteration: 27700 Train loss: 0.007942\n",
      "Epoch: 3958/10000 Iteration: 27707 Train loss: 0.007942\n",
      "Epoch: 3959/10000 Iteration: 27714 Train loss: 0.007943\n",
      "Epoch: 3960/10000 Iteration: 27721 Train loss: 0.007943\n",
      "Epoch: 3961/10000 Iteration: 27728 Train loss: 0.007944\n",
      "Epoch: 3962/10000 Iteration: 27735 Train loss: 0.007944\n",
      "Epoch: 3963/10000 Iteration: 27742 Train loss: 0.007944\n",
      "Epoch: 3964/10000 Iteration: 27749 Train loss: 0.007945\n",
      "Epoch: 3965/10000 Iteration: 27756 Train loss: 0.007945\n",
      "Epoch: 3966/10000 Iteration: 27763 Train loss: 0.007945\n",
      "Epoch: 3967/10000 Iteration: 27770 Train loss: 0.007946\n",
      "Epoch: 3968/10000 Iteration: 27777 Train loss: 0.007946\n",
      "Epoch: 3969/10000 Iteration: 27784 Train loss: 0.007946\n",
      "Epoch: 3970/10000 Iteration: 27791 Train loss: 0.007947\n",
      "Epoch: 3971/10000 Iteration: 27798 Train loss: 0.007947\n",
      "Epoch: 3972/10000 Iteration: 27805 Train loss: 0.007947\n",
      "Epoch: 3973/10000 Iteration: 27812 Train loss: 0.007948\n",
      "Epoch: 3974/10000 Iteration: 27819 Train loss: 0.007948\n",
      "Epoch: 3975/10000 Iteration: 27826 Train loss: 0.007948\n",
      "Epoch: 3976/10000 Iteration: 27833 Train loss: 0.007949\n",
      "Epoch: 3977/10000 Iteration: 27840 Train loss: 0.007949\n",
      "Epoch: 3978/10000 Iteration: 27847 Train loss: 0.007949\n",
      "Epoch: 3979/10000 Iteration: 27854 Train loss: 0.007950\n",
      "Epoch: 3980/10000 Iteration: 27861 Train loss: 0.007950\n",
      "Epoch: 3981/10000 Iteration: 27868 Train loss: 0.007950\n",
      "Epoch: 3982/10000 Iteration: 27875 Train loss: 0.007951\n",
      "Epoch: 3983/10000 Iteration: 27882 Train loss: 0.007951\n",
      "Epoch: 3984/10000 Iteration: 27889 Train loss: 0.007951\n",
      "Epoch: 3985/10000 Iteration: 27896 Train loss: 0.007952\n",
      "Epoch: 3986/10000 Iteration: 27903 Train loss: 0.007952\n",
      "Epoch: 3987/10000 Iteration: 27910 Train loss: 0.007952\n",
      "Epoch: 3988/10000 Iteration: 27917 Train loss: 0.007953\n",
      "Epoch: 3989/10000 Iteration: 27924 Train loss: 0.007953\n",
      "Epoch: 3990/10000 Iteration: 27931 Train loss: 0.007953\n",
      "Epoch: 3991/10000 Iteration: 27938 Train loss: 0.007954\n",
      "Epoch: 3992/10000 Iteration: 27945 Train loss: 0.007954\n",
      "Epoch: 3993/10000 Iteration: 27952 Train loss: 0.007954\n",
      "Epoch: 3994/10000 Iteration: 27959 Train loss: 0.007955\n",
      "Epoch: 3995/10000 Iteration: 27966 Train loss: 0.007955\n",
      "Epoch: 3996/10000 Iteration: 27973 Train loss: 0.007955\n",
      "Epoch: 3997/10000 Iteration: 27980 Train loss: 0.007956\n",
      "Epoch: 3998/10000 Iteration: 27987 Train loss: 0.007956\n",
      "Epoch: 3999/10000 Iteration: 27994 Train loss: 0.007956\n",
      "Epoch: 4000/10000 Iteration: 28001 Train loss: 0.007957\n",
      "Epoch: 4001/10000 Iteration: 28008 Train loss: 0.007957\n",
      "Epoch: 4002/10000 Iteration: 28015 Train loss: 0.007957\n",
      "Epoch: 4003/10000 Iteration: 28022 Train loss: 0.007958\n",
      "Epoch: 4004/10000 Iteration: 28029 Train loss: 0.007958\n",
      "Epoch: 4005/10000 Iteration: 28036 Train loss: 0.007958\n",
      "Epoch: 4006/10000 Iteration: 28043 Train loss: 0.007959\n",
      "Epoch: 4007/10000 Iteration: 28050 Train loss: 0.007959\n",
      "Epoch: 4008/10000 Iteration: 28057 Train loss: 0.007959\n",
      "Epoch: 4009/10000 Iteration: 28064 Train loss: 0.007960\n",
      "Epoch: 4010/10000 Iteration: 28071 Train loss: 0.007960\n",
      "Epoch: 4011/10000 Iteration: 28078 Train loss: 0.007960\n",
      "Epoch: 4012/10000 Iteration: 28085 Train loss: 0.007960\n",
      "Epoch: 4013/10000 Iteration: 28092 Train loss: 0.007961\n",
      "Epoch: 4014/10000 Iteration: 28099 Train loss: 0.007961\n",
      "Epoch: 4015/10000 Iteration: 28106 Train loss: 0.007961\n",
      "Epoch: 4016/10000 Iteration: 28113 Train loss: 0.007962\n",
      "Epoch: 4017/10000 Iteration: 28120 Train loss: 0.007962\n",
      "Epoch: 4018/10000 Iteration: 28127 Train loss: 0.007962\n",
      "Epoch: 4019/10000 Iteration: 28134 Train loss: 0.007963\n",
      "Epoch: 4020/10000 Iteration: 28141 Train loss: 0.007963\n",
      "Epoch: 4021/10000 Iteration: 28148 Train loss: 0.007963\n",
      "Epoch: 4022/10000 Iteration: 28155 Train loss: 0.007964\n",
      "Epoch: 4023/10000 Iteration: 28162 Train loss: 0.007964\n",
      "Epoch: 4024/10000 Iteration: 28169 Train loss: 0.007964\n",
      "Epoch: 4025/10000 Iteration: 28176 Train loss: 0.007965\n",
      "Epoch: 4026/10000 Iteration: 28183 Train loss: 0.007965\n",
      "Epoch: 4027/10000 Iteration: 28190 Train loss: 0.007965\n",
      "Epoch: 4028/10000 Iteration: 28197 Train loss: 0.007965\n",
      "Epoch: 4029/10000 Iteration: 28204 Train loss: 0.007966\n",
      "Epoch: 4030/10000 Iteration: 28211 Train loss: 0.007966\n",
      "Epoch: 4031/10000 Iteration: 28218 Train loss: 0.007966\n",
      "Epoch: 4032/10000 Iteration: 28225 Train loss: 0.007967\n",
      "Epoch: 4033/10000 Iteration: 28232 Train loss: 0.007967\n",
      "Epoch: 4034/10000 Iteration: 28239 Train loss: 0.007967\n",
      "Epoch: 4035/10000 Iteration: 28246 Train loss: 0.007968\n",
      "Epoch: 4036/10000 Iteration: 28253 Train loss: 0.007968\n",
      "Epoch: 4037/10000 Iteration: 28260 Train loss: 0.007968\n",
      "Epoch: 4038/10000 Iteration: 28267 Train loss: 0.007969\n",
      "Epoch: 4039/10000 Iteration: 28274 Train loss: 0.007969\n",
      "Epoch: 4040/10000 Iteration: 28281 Train loss: 0.007969\n",
      "Epoch: 4041/10000 Iteration: 28288 Train loss: 0.007969\n",
      "Epoch: 4042/10000 Iteration: 28295 Train loss: 0.007970\n",
      "Epoch: 4043/10000 Iteration: 28302 Train loss: 0.007970\n",
      "Epoch: 4044/10000 Iteration: 28309 Train loss: 0.007970\n",
      "Epoch: 4045/10000 Iteration: 28316 Train loss: 0.007971\n",
      "Epoch: 4046/10000 Iteration: 28323 Train loss: 0.007971\n",
      "Epoch: 4047/10000 Iteration: 28330 Train loss: 0.007971\n",
      "Epoch: 4048/10000 Iteration: 28337 Train loss: 0.007972\n",
      "Epoch: 4049/10000 Iteration: 28344 Train loss: 0.007972\n",
      "Epoch: 4050/10000 Iteration: 28351 Train loss: 0.007972\n",
      "Epoch: 4051/10000 Iteration: 28358 Train loss: 0.007972\n",
      "Epoch: 4052/10000 Iteration: 28365 Train loss: 0.007973\n",
      "Epoch: 4053/10000 Iteration: 28372 Train loss: 0.007973\n",
      "Epoch: 4054/10000 Iteration: 28379 Train loss: 0.007973\n",
      "Epoch: 4055/10000 Iteration: 28386 Train loss: 0.007974\n",
      "Epoch: 4056/10000 Iteration: 28393 Train loss: 0.007974\n",
      "Epoch: 4057/10000 Iteration: 28400 Train loss: 0.007974\n",
      "Epoch: 4058/10000 Iteration: 28407 Train loss: 0.007975\n",
      "Epoch: 4059/10000 Iteration: 28414 Train loss: 0.007975\n",
      "Epoch: 4060/10000 Iteration: 28421 Train loss: 0.007975\n",
      "Epoch: 4061/10000 Iteration: 28428 Train loss: 0.007975\n",
      "Epoch: 4062/10000 Iteration: 28435 Train loss: 0.007976\n",
      "Epoch: 4063/10000 Iteration: 28442 Train loss: 0.007976\n",
      "Epoch: 4064/10000 Iteration: 28449 Train loss: 0.007976\n",
      "Epoch: 4065/10000 Iteration: 28456 Train loss: 0.007977\n",
      "Epoch: 4066/10000 Iteration: 28463 Train loss: 0.007977\n",
      "Epoch: 4067/10000 Iteration: 28470 Train loss: 0.007977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4068/10000 Iteration: 28477 Train loss: 0.007977\n",
      "Epoch: 4069/10000 Iteration: 28484 Train loss: 0.007978\n",
      "Epoch: 4070/10000 Iteration: 28491 Train loss: 0.007978\n",
      "Epoch: 4071/10000 Iteration: 28498 Train loss: 0.007978\n",
      "Epoch: 4072/10000 Iteration: 28505 Train loss: 0.007979\n",
      "Epoch: 4073/10000 Iteration: 28512 Train loss: 0.007979\n",
      "Epoch: 4074/10000 Iteration: 28519 Train loss: 0.007979\n",
      "Epoch: 4075/10000 Iteration: 28526 Train loss: 0.007979\n",
      "Epoch: 4076/10000 Iteration: 28533 Train loss: 0.007980\n",
      "Epoch: 4077/10000 Iteration: 28540 Train loss: 0.007980\n",
      "Epoch: 4078/10000 Iteration: 28547 Train loss: 0.007980\n",
      "Epoch: 4079/10000 Iteration: 28554 Train loss: 0.007981\n",
      "Epoch: 4080/10000 Iteration: 28561 Train loss: 0.007981\n",
      "Epoch: 4081/10000 Iteration: 28568 Train loss: 0.007981\n",
      "Epoch: 4082/10000 Iteration: 28575 Train loss: 0.007981\n",
      "Epoch: 4083/10000 Iteration: 28582 Train loss: 0.007982\n",
      "Epoch: 4084/10000 Iteration: 28589 Train loss: 0.007982\n",
      "Epoch: 4085/10000 Iteration: 28596 Train loss: 0.007982\n",
      "Epoch: 4086/10000 Iteration: 28603 Train loss: 0.007983\n",
      "Epoch: 4087/10000 Iteration: 28610 Train loss: 0.007983\n",
      "Epoch: 4088/10000 Iteration: 28617 Train loss: 0.007983\n",
      "Epoch: 4089/10000 Iteration: 28624 Train loss: 0.007983\n",
      "Epoch: 4090/10000 Iteration: 28631 Train loss: 0.007984\n",
      "Epoch: 4091/10000 Iteration: 28638 Train loss: 0.007984\n",
      "Epoch: 4092/10000 Iteration: 28645 Train loss: 0.007984\n",
      "Epoch: 4093/10000 Iteration: 28652 Train loss: 0.007985\n",
      "Epoch: 4094/10000 Iteration: 28659 Train loss: 0.007985\n",
      "Epoch: 4095/10000 Iteration: 28666 Train loss: 0.007985\n",
      "Epoch: 4096/10000 Iteration: 28673 Train loss: 0.007985\n",
      "Epoch: 4097/10000 Iteration: 28680 Train loss: 0.007986\n",
      "Epoch: 4098/10000 Iteration: 28687 Train loss: 0.007986\n",
      "Epoch: 4099/10000 Iteration: 28694 Train loss: 0.007986\n",
      "Epoch: 4100/10000 Iteration: 28701 Train loss: 0.007986\n",
      "Epoch: 4101/10000 Iteration: 28708 Train loss: 0.007987\n",
      "Epoch: 4102/10000 Iteration: 28715 Train loss: 0.007987\n",
      "Epoch: 4103/10000 Iteration: 28722 Train loss: 0.007987\n",
      "Epoch: 4104/10000 Iteration: 28729 Train loss: 0.007988\n",
      "Epoch: 4105/10000 Iteration: 28736 Train loss: 0.007988\n",
      "Epoch: 4106/10000 Iteration: 28743 Train loss: 0.007988\n",
      "Epoch: 4107/10000 Iteration: 28750 Train loss: 0.007988\n",
      "Epoch: 4108/10000 Iteration: 28757 Train loss: 0.007989\n",
      "Epoch: 4109/10000 Iteration: 28764 Train loss: 0.007989\n",
      "Epoch: 4110/10000 Iteration: 28771 Train loss: 0.007989\n",
      "Epoch: 4111/10000 Iteration: 28778 Train loss: 0.007989\n",
      "Epoch: 4112/10000 Iteration: 28785 Train loss: 0.007990\n",
      "Epoch: 4113/10000 Iteration: 28792 Train loss: 0.007990\n",
      "Epoch: 4114/10000 Iteration: 28799 Train loss: 0.007990\n",
      "Epoch: 4115/10000 Iteration: 28806 Train loss: 0.007990\n",
      "Epoch: 4116/10000 Iteration: 28813 Train loss: 0.007991\n",
      "Epoch: 4117/10000 Iteration: 28820 Train loss: 0.007991\n",
      "Epoch: 4118/10000 Iteration: 28827 Train loss: 0.007991\n",
      "Epoch: 4119/10000 Iteration: 28834 Train loss: 0.007991\n",
      "Epoch: 4120/10000 Iteration: 28841 Train loss: 0.007992\n",
      "Epoch: 4121/10000 Iteration: 28848 Train loss: 0.007992\n",
      "Epoch: 4122/10000 Iteration: 28855 Train loss: 0.007992\n",
      "Epoch: 4123/10000 Iteration: 28862 Train loss: 0.007993\n",
      "Epoch: 4124/10000 Iteration: 28869 Train loss: 0.007993\n",
      "Epoch: 4125/10000 Iteration: 28876 Train loss: 0.007993\n",
      "Epoch: 4126/10000 Iteration: 28883 Train loss: 0.007993\n",
      "Epoch: 4127/10000 Iteration: 28890 Train loss: 0.007994\n",
      "Epoch: 4128/10000 Iteration: 28897 Train loss: 0.007994\n",
      "Epoch: 4129/10000 Iteration: 28904 Train loss: 0.007994\n",
      "Epoch: 4130/10000 Iteration: 28911 Train loss: 0.007994\n",
      "Epoch: 4131/10000 Iteration: 28918 Train loss: 0.007995\n",
      "Epoch: 4132/10000 Iteration: 28925 Train loss: 0.007995\n",
      "Epoch: 4133/10000 Iteration: 28932 Train loss: 0.007995\n",
      "Epoch: 4134/10000 Iteration: 28939 Train loss: 0.007995\n",
      "Epoch: 4135/10000 Iteration: 28946 Train loss: 0.007996\n",
      "Epoch: 4136/10000 Iteration: 28953 Train loss: 0.007996\n",
      "Epoch: 4137/10000 Iteration: 28960 Train loss: 0.007996\n",
      "Epoch: 4138/10000 Iteration: 28967 Train loss: 0.007996\n",
      "Epoch: 4139/10000 Iteration: 28974 Train loss: 0.007997\n",
      "Epoch: 4140/10000 Iteration: 28981 Train loss: 0.007997\n",
      "Epoch: 4141/10000 Iteration: 28988 Train loss: 0.007997\n",
      "Epoch: 4142/10000 Iteration: 28995 Train loss: 0.007997\n",
      "Epoch: 4143/10000 Iteration: 29002 Train loss: 0.007998\n",
      "Epoch: 4144/10000 Iteration: 29009 Train loss: 0.007998\n",
      "Epoch: 4145/10000 Iteration: 29016 Train loss: 0.007998\n",
      "Epoch: 4146/10000 Iteration: 29023 Train loss: 0.007998\n",
      "Epoch: 4147/10000 Iteration: 29030 Train loss: 0.007999\n",
      "Epoch: 4148/10000 Iteration: 29037 Train loss: 0.007999\n",
      "Epoch: 4149/10000 Iteration: 29044 Train loss: 0.007999\n",
      "Epoch: 4150/10000 Iteration: 29051 Train loss: 0.007999\n",
      "Epoch: 4151/10000 Iteration: 29058 Train loss: 0.008000\n",
      "Epoch: 4152/10000 Iteration: 29065 Train loss: 0.008000\n",
      "Epoch: 4153/10000 Iteration: 29072 Train loss: 0.008000\n",
      "Epoch: 4154/10000 Iteration: 29079 Train loss: 0.008000\n",
      "Epoch: 4155/10000 Iteration: 29086 Train loss: 0.008001\n",
      "Epoch: 4156/10000 Iteration: 29093 Train loss: 0.008001\n",
      "Epoch: 4157/10000 Iteration: 29100 Train loss: 0.008001\n",
      "Epoch: 4158/10000 Iteration: 29107 Train loss: 0.008001\n",
      "Epoch: 4159/10000 Iteration: 29114 Train loss: 0.008002\n",
      "Epoch: 4160/10000 Iteration: 29121 Train loss: 0.008002\n",
      "Epoch: 4161/10000 Iteration: 29128 Train loss: 0.008002\n",
      "Epoch: 4162/10000 Iteration: 29135 Train loss: 0.008002\n",
      "Epoch: 4163/10000 Iteration: 29142 Train loss: 0.008003\n",
      "Epoch: 4164/10000 Iteration: 29149 Train loss: 0.008003\n",
      "Epoch: 4165/10000 Iteration: 29156 Train loss: 0.008003\n",
      "Epoch: 4166/10000 Iteration: 29163 Train loss: 0.008003\n",
      "Epoch: 4167/10000 Iteration: 29170 Train loss: 0.008003\n",
      "Epoch: 4168/10000 Iteration: 29177 Train loss: 0.008004\n",
      "Epoch: 4169/10000 Iteration: 29184 Train loss: 0.008004\n",
      "Epoch: 4170/10000 Iteration: 29191 Train loss: 0.008004\n",
      "Epoch: 4171/10000 Iteration: 29198 Train loss: 0.008004\n",
      "Epoch: 4172/10000 Iteration: 29205 Train loss: 0.008005\n",
      "Epoch: 4173/10000 Iteration: 29212 Train loss: 0.008005\n",
      "Epoch: 4174/10000 Iteration: 29219 Train loss: 0.008005\n",
      "Epoch: 4175/10000 Iteration: 29226 Train loss: 0.008005\n",
      "Epoch: 4176/10000 Iteration: 29233 Train loss: 0.008006\n",
      "Epoch: 4177/10000 Iteration: 29240 Train loss: 0.008006\n",
      "Epoch: 4178/10000 Iteration: 29247 Train loss: 0.008006\n",
      "Epoch: 4179/10000 Iteration: 29254 Train loss: 0.008006\n",
      "Epoch: 4180/10000 Iteration: 29261 Train loss: 0.008006\n",
      "Epoch: 4181/10000 Iteration: 29268 Train loss: 0.008007\n",
      "Epoch: 4182/10000 Iteration: 29275 Train loss: 0.008007\n",
      "Epoch: 4183/10000 Iteration: 29282 Train loss: 0.008007\n",
      "Epoch: 4184/10000 Iteration: 29289 Train loss: 0.008007\n",
      "Epoch: 4185/10000 Iteration: 29296 Train loss: 0.008008\n",
      "Epoch: 4186/10000 Iteration: 29303 Train loss: 0.008008\n",
      "Epoch: 4187/10000 Iteration: 29310 Train loss: 0.008008\n",
      "Epoch: 4188/10000 Iteration: 29317 Train loss: 0.008008\n",
      "Epoch: 4189/10000 Iteration: 29324 Train loss: 0.008009\n",
      "Epoch: 4190/10000 Iteration: 29331 Train loss: 0.008009\n",
      "Epoch: 4191/10000 Iteration: 29338 Train loss: 0.008009\n",
      "Epoch: 4192/10000 Iteration: 29345 Train loss: 0.008009\n",
      "Epoch: 4193/10000 Iteration: 29352 Train loss: 0.008009\n",
      "Epoch: 4194/10000 Iteration: 29359 Train loss: 0.008010\n",
      "Epoch: 4195/10000 Iteration: 29366 Train loss: 0.008010\n",
      "Epoch: 4196/10000 Iteration: 29373 Train loss: 0.008010\n",
      "Epoch: 4197/10000 Iteration: 29380 Train loss: 0.008010\n",
      "Epoch: 4198/10000 Iteration: 29387 Train loss: 0.008011\n",
      "Epoch: 4199/10000 Iteration: 29394 Train loss: 0.008011\n",
      "Epoch: 4200/10000 Iteration: 29401 Train loss: 0.008011\n",
      "Epoch: 4201/10000 Iteration: 29408 Train loss: 0.008011\n",
      "Epoch: 4202/10000 Iteration: 29415 Train loss: 0.008011\n",
      "Epoch: 4203/10000 Iteration: 29422 Train loss: 0.008012\n",
      "Epoch: 4204/10000 Iteration: 29429 Train loss: 0.008012\n",
      "Epoch: 4205/10000 Iteration: 29436 Train loss: 0.008012\n",
      "Epoch: 4206/10000 Iteration: 29443 Train loss: 0.008012\n",
      "Epoch: 4207/10000 Iteration: 29450 Train loss: 0.008013\n",
      "Epoch: 4208/10000 Iteration: 29457 Train loss: 0.008013\n",
      "Epoch: 4209/10000 Iteration: 29464 Train loss: 0.008013\n",
      "Epoch: 4210/10000 Iteration: 29471 Train loss: 0.008013\n",
      "Epoch: 4211/10000 Iteration: 29478 Train loss: 0.008013\n",
      "Epoch: 4212/10000 Iteration: 29485 Train loss: 0.008014\n",
      "Epoch: 4213/10000 Iteration: 29492 Train loss: 0.008014\n",
      "Epoch: 4214/10000 Iteration: 29499 Train loss: 0.008014\n",
      "Epoch: 4215/10000 Iteration: 29506 Train loss: 0.008014\n",
      "Epoch: 4216/10000 Iteration: 29513 Train loss: 0.008014\n",
      "Epoch: 4217/10000 Iteration: 29520 Train loss: 0.008015\n",
      "Epoch: 4218/10000 Iteration: 29527 Train loss: 0.008015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4219/10000 Iteration: 29534 Train loss: 0.008015\n",
      "Epoch: 4220/10000 Iteration: 29541 Train loss: 0.008015\n",
      "Epoch: 4221/10000 Iteration: 29548 Train loss: 0.008015\n",
      "Epoch: 4222/10000 Iteration: 29555 Train loss: 0.008016\n",
      "Epoch: 4223/10000 Iteration: 29562 Train loss: 0.008016\n",
      "Epoch: 4224/10000 Iteration: 29569 Train loss: 0.008016\n",
      "Epoch: 4225/10000 Iteration: 29576 Train loss: 0.008016\n",
      "Epoch: 4226/10000 Iteration: 29583 Train loss: 0.008017\n",
      "Epoch: 4227/10000 Iteration: 29590 Train loss: 0.008017\n",
      "Epoch: 4228/10000 Iteration: 29597 Train loss: 0.008017\n",
      "Epoch: 4229/10000 Iteration: 29604 Train loss: 0.008017\n",
      "Epoch: 4230/10000 Iteration: 29611 Train loss: 0.008017\n",
      "Epoch: 4231/10000 Iteration: 29618 Train loss: 0.008018\n",
      "Epoch: 4232/10000 Iteration: 29625 Train loss: 0.008018\n",
      "Epoch: 4233/10000 Iteration: 29632 Train loss: 0.008018\n",
      "Epoch: 4234/10000 Iteration: 29639 Train loss: 0.008018\n",
      "Epoch: 4235/10000 Iteration: 29646 Train loss: 0.008018\n",
      "Epoch: 4236/10000 Iteration: 29653 Train loss: 0.008019\n",
      "Epoch: 4237/10000 Iteration: 29660 Train loss: 0.008019\n",
      "Epoch: 4238/10000 Iteration: 29667 Train loss: 0.008019\n",
      "Epoch: 4239/10000 Iteration: 29674 Train loss: 0.008019\n",
      "Epoch: 4240/10000 Iteration: 29681 Train loss: 0.008019\n",
      "Epoch: 4241/10000 Iteration: 29688 Train loss: 0.008020\n",
      "Epoch: 4242/10000 Iteration: 29695 Train loss: 0.008020\n",
      "Epoch: 4243/10000 Iteration: 29702 Train loss: 0.008020\n",
      "Epoch: 4244/10000 Iteration: 29709 Train loss: 0.008020\n",
      "Epoch: 4245/10000 Iteration: 29716 Train loss: 0.008020\n",
      "Epoch: 4246/10000 Iteration: 29723 Train loss: 0.008021\n",
      "Epoch: 4247/10000 Iteration: 29730 Train loss: 0.008021\n",
      "Epoch: 4248/10000 Iteration: 29737 Train loss: 0.008021\n",
      "Epoch: 4249/10000 Iteration: 29744 Train loss: 0.008021\n",
      "Epoch: 4250/10000 Iteration: 29751 Train loss: 0.008021\n",
      "Epoch: 4251/10000 Iteration: 29758 Train loss: 0.008022\n",
      "Epoch: 4252/10000 Iteration: 29765 Train loss: 0.008022\n",
      "Epoch: 4253/10000 Iteration: 29772 Train loss: 0.008022\n",
      "Epoch: 4254/10000 Iteration: 29779 Train loss: 0.008022\n",
      "Epoch: 4255/10000 Iteration: 29786 Train loss: 0.008022\n",
      "Epoch: 4256/10000 Iteration: 29793 Train loss: 0.008023\n",
      "Epoch: 4257/10000 Iteration: 29800 Train loss: 0.008023\n",
      "Epoch: 4258/10000 Iteration: 29807 Train loss: 0.008023\n",
      "Epoch: 4259/10000 Iteration: 29814 Train loss: 0.008023\n",
      "Epoch: 4260/10000 Iteration: 29821 Train loss: 0.008023\n",
      "Epoch: 4261/10000 Iteration: 29828 Train loss: 0.008023\n",
      "Epoch: 4262/10000 Iteration: 29835 Train loss: 0.008024\n",
      "Epoch: 4263/10000 Iteration: 29842 Train loss: 0.008024\n",
      "Epoch: 4264/10000 Iteration: 29849 Train loss: 0.008024\n",
      "Epoch: 4265/10000 Iteration: 29856 Train loss: 0.008024\n",
      "Epoch: 4266/10000 Iteration: 29863 Train loss: 0.008024\n",
      "Epoch: 4267/10000 Iteration: 29870 Train loss: 0.008025\n",
      "Epoch: 4268/10000 Iteration: 29877 Train loss: 0.008025\n",
      "Epoch: 4269/10000 Iteration: 29884 Train loss: 0.008025\n",
      "Epoch: 4270/10000 Iteration: 29891 Train loss: 0.008025\n",
      "Epoch: 4271/10000 Iteration: 29898 Train loss: 0.008025\n",
      "Epoch: 4272/10000 Iteration: 29905 Train loss: 0.008026\n",
      "Epoch: 4273/10000 Iteration: 29912 Train loss: 0.008026\n",
      "Epoch: 4274/10000 Iteration: 29919 Train loss: 0.008026\n",
      "Epoch: 4275/10000 Iteration: 29926 Train loss: 0.008026\n",
      "Epoch: 4276/10000 Iteration: 29933 Train loss: 0.008026\n",
      "Epoch: 4277/10000 Iteration: 29940 Train loss: 0.008026\n",
      "Epoch: 4278/10000 Iteration: 29947 Train loss: 0.008027\n",
      "Epoch: 4279/10000 Iteration: 29954 Train loss: 0.008027\n",
      "Epoch: 4280/10000 Iteration: 29961 Train loss: 0.008027\n",
      "Epoch: 4281/10000 Iteration: 29968 Train loss: 0.008027\n",
      "Epoch: 4282/10000 Iteration: 29975 Train loss: 0.008027\n",
      "Epoch: 4283/10000 Iteration: 29982 Train loss: 0.008027\n",
      "Epoch: 4284/10000 Iteration: 29989 Train loss: 0.008028\n",
      "Epoch: 4285/10000 Iteration: 29996 Train loss: 0.008028\n",
      "Epoch: 4286/10000 Iteration: 30003 Train loss: 0.008028\n",
      "Epoch: 4287/10000 Iteration: 30010 Train loss: 0.008028\n",
      "Epoch: 4288/10000 Iteration: 30017 Train loss: 0.008028\n",
      "Epoch: 4289/10000 Iteration: 30024 Train loss: 0.008029\n",
      "Epoch: 4290/10000 Iteration: 30031 Train loss: 0.008029\n",
      "Epoch: 4291/10000 Iteration: 30038 Train loss: 0.008029\n",
      "Epoch: 4292/10000 Iteration: 30045 Train loss: 0.008029\n",
      "Epoch: 4293/10000 Iteration: 30052 Train loss: 0.008029\n",
      "Epoch: 4294/10000 Iteration: 30059 Train loss: 0.008029\n",
      "Epoch: 4295/10000 Iteration: 30066 Train loss: 0.008030\n",
      "Epoch: 4296/10000 Iteration: 30073 Train loss: 0.008030\n",
      "Epoch: 4297/10000 Iteration: 30080 Train loss: 0.008030\n",
      "Epoch: 4298/10000 Iteration: 30087 Train loss: 0.008030\n",
      "Epoch: 4299/10000 Iteration: 30094 Train loss: 0.008030\n",
      "Epoch: 4300/10000 Iteration: 30101 Train loss: 0.008030\n",
      "Epoch: 4301/10000 Iteration: 30108 Train loss: 0.008031\n",
      "Epoch: 4302/10000 Iteration: 30115 Train loss: 0.008031\n",
      "Epoch: 4303/10000 Iteration: 30122 Train loss: 0.008031\n",
      "Epoch: 4304/10000 Iteration: 30129 Train loss: 0.008031\n",
      "Epoch: 4305/10000 Iteration: 30136 Train loss: 0.008031\n",
      "Epoch: 4306/10000 Iteration: 30143 Train loss: 0.008031\n",
      "Epoch: 4307/10000 Iteration: 30150 Train loss: 0.008032\n",
      "Epoch: 4308/10000 Iteration: 30157 Train loss: 0.008032\n",
      "Epoch: 4309/10000 Iteration: 30164 Train loss: 0.008032\n",
      "Epoch: 4310/10000 Iteration: 30171 Train loss: 0.008032\n",
      "Epoch: 4311/10000 Iteration: 30178 Train loss: 0.008032\n",
      "Epoch: 4312/10000 Iteration: 30185 Train loss: 0.008032\n",
      "Epoch: 4313/10000 Iteration: 30192 Train loss: 0.008033\n",
      "Epoch: 4314/10000 Iteration: 30199 Train loss: 0.008033\n",
      "Epoch: 4315/10000 Iteration: 30206 Train loss: 0.008033\n",
      "Epoch: 4316/10000 Iteration: 30213 Train loss: 0.008033\n",
      "Epoch: 4317/10000 Iteration: 30220 Train loss: 0.008033\n",
      "Epoch: 4318/10000 Iteration: 30227 Train loss: 0.008033\n",
      "Epoch: 4319/10000 Iteration: 30234 Train loss: 0.008034\n",
      "Epoch: 4320/10000 Iteration: 30241 Train loss: 0.008034\n",
      "Epoch: 4321/10000 Iteration: 30248 Train loss: 0.008034\n",
      "Epoch: 4322/10000 Iteration: 30255 Train loss: 0.008034\n",
      "Epoch: 4323/10000 Iteration: 30262 Train loss: 0.008034\n",
      "Epoch: 4324/10000 Iteration: 30269 Train loss: 0.008034\n",
      "Epoch: 4325/10000 Iteration: 30276 Train loss: 0.008035\n",
      "Epoch: 4326/10000 Iteration: 30283 Train loss: 0.008035\n",
      "Epoch: 4327/10000 Iteration: 30290 Train loss: 0.008035\n",
      "Epoch: 4328/10000 Iteration: 30297 Train loss: 0.008035\n",
      "Epoch: 4329/10000 Iteration: 30304 Train loss: 0.008035\n",
      "Epoch: 4330/10000 Iteration: 30311 Train loss: 0.008035\n",
      "Epoch: 4331/10000 Iteration: 30318 Train loss: 0.008035\n",
      "Epoch: 4332/10000 Iteration: 30325 Train loss: 0.008036\n",
      "Epoch: 4333/10000 Iteration: 30332 Train loss: 0.008036\n",
      "Epoch: 4334/10000 Iteration: 30339 Train loss: 0.008036\n",
      "Epoch: 4335/10000 Iteration: 30346 Train loss: 0.008036\n",
      "Epoch: 4336/10000 Iteration: 30353 Train loss: 0.008036\n",
      "Epoch: 4337/10000 Iteration: 30360 Train loss: 0.008036\n",
      "Epoch: 4338/10000 Iteration: 30367 Train loss: 0.008037\n",
      "Epoch: 4339/10000 Iteration: 30374 Train loss: 0.008037\n",
      "Epoch: 4340/10000 Iteration: 30381 Train loss: 0.008037\n",
      "Epoch: 4341/10000 Iteration: 30388 Train loss: 0.008037\n",
      "Epoch: 4342/10000 Iteration: 30395 Train loss: 0.008037\n",
      "Epoch: 4343/10000 Iteration: 30402 Train loss: 0.008037\n",
      "Epoch: 4344/10000 Iteration: 30409 Train loss: 0.008037\n",
      "Epoch: 4345/10000 Iteration: 30416 Train loss: 0.008038\n",
      "Epoch: 4346/10000 Iteration: 30423 Train loss: 0.008038\n",
      "Epoch: 4347/10000 Iteration: 30430 Train loss: 0.008038\n",
      "Epoch: 4348/10000 Iteration: 30437 Train loss: 0.008038\n",
      "Epoch: 4349/10000 Iteration: 30444 Train loss: 0.008038\n",
      "Epoch: 4350/10000 Iteration: 30451 Train loss: 0.008038\n",
      "Epoch: 4351/10000 Iteration: 30458 Train loss: 0.008038\n",
      "Epoch: 4352/10000 Iteration: 30465 Train loss: 0.008039\n",
      "Epoch: 4353/10000 Iteration: 30472 Train loss: 0.008039\n",
      "Epoch: 4354/10000 Iteration: 30479 Train loss: 0.008039\n",
      "Epoch: 4355/10000 Iteration: 30486 Train loss: 0.008039\n",
      "Epoch: 4356/10000 Iteration: 30493 Train loss: 0.008039\n",
      "Epoch: 4357/10000 Iteration: 30500 Train loss: 0.008039\n",
      "Epoch: 4358/10000 Iteration: 30507 Train loss: 0.008039\n",
      "Epoch: 4359/10000 Iteration: 30514 Train loss: 0.008040\n",
      "Epoch: 4360/10000 Iteration: 30521 Train loss: 0.008040\n",
      "Epoch: 4361/10000 Iteration: 30528 Train loss: 0.008040\n",
      "Epoch: 4362/10000 Iteration: 30535 Train loss: 0.008040\n",
      "Epoch: 4363/10000 Iteration: 30542 Train loss: 0.008040\n",
      "Epoch: 4364/10000 Iteration: 30549 Train loss: 0.008040\n",
      "Epoch: 4365/10000 Iteration: 30556 Train loss: 0.008040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4366/10000 Iteration: 30563 Train loss: 0.008041\n",
      "Epoch: 4367/10000 Iteration: 30570 Train loss: 0.008041\n",
      "Epoch: 4368/10000 Iteration: 30577 Train loss: 0.008041\n",
      "Epoch: 4369/10000 Iteration: 30584 Train loss: 0.008041\n",
      "Epoch: 4370/10000 Iteration: 30591 Train loss: 0.008041\n",
      "Epoch: 4371/10000 Iteration: 30598 Train loss: 0.008041\n",
      "Epoch: 4372/10000 Iteration: 30605 Train loss: 0.008041\n",
      "Epoch: 4373/10000 Iteration: 30612 Train loss: 0.008042\n",
      "Epoch: 4374/10000 Iteration: 30619 Train loss: 0.008042\n",
      "Epoch: 4375/10000 Iteration: 30626 Train loss: 0.008042\n",
      "Epoch: 4376/10000 Iteration: 30633 Train loss: 0.008042\n",
      "Epoch: 4377/10000 Iteration: 30640 Train loss: 0.008042\n",
      "Epoch: 4378/10000 Iteration: 30647 Train loss: 0.008042\n",
      "Epoch: 4379/10000 Iteration: 30654 Train loss: 0.008042\n",
      "Epoch: 4380/10000 Iteration: 30661 Train loss: 0.008042\n",
      "Epoch: 4381/10000 Iteration: 30668 Train loss: 0.008043\n",
      "Epoch: 4382/10000 Iteration: 30675 Train loss: 0.008043\n",
      "Epoch: 4383/10000 Iteration: 30682 Train loss: 0.008043\n",
      "Epoch: 4384/10000 Iteration: 30689 Train loss: 0.008043\n",
      "Epoch: 4385/10000 Iteration: 30696 Train loss: 0.008043\n",
      "Epoch: 4386/10000 Iteration: 30703 Train loss: 0.008043\n",
      "Epoch: 4387/10000 Iteration: 30710 Train loss: 0.008043\n",
      "Epoch: 4388/10000 Iteration: 30717 Train loss: 0.008043\n",
      "Epoch: 4389/10000 Iteration: 30724 Train loss: 0.008044\n",
      "Epoch: 4390/10000 Iteration: 30731 Train loss: 0.008044\n",
      "Epoch: 4391/10000 Iteration: 30738 Train loss: 0.008044\n",
      "Epoch: 4392/10000 Iteration: 30745 Train loss: 0.008044\n",
      "Epoch: 4393/10000 Iteration: 30752 Train loss: 0.008044\n",
      "Epoch: 4394/10000 Iteration: 30759 Train loss: 0.008044\n",
      "Epoch: 4395/10000 Iteration: 30766 Train loss: 0.008044\n",
      "Epoch: 4396/10000 Iteration: 30773 Train loss: 0.008044\n",
      "Epoch: 4397/10000 Iteration: 30780 Train loss: 0.008045\n",
      "Epoch: 4398/10000 Iteration: 30787 Train loss: 0.008045\n",
      "Epoch: 4399/10000 Iteration: 30794 Train loss: 0.008045\n",
      "Epoch: 4400/10000 Iteration: 30801 Train loss: 0.008045\n",
      "Epoch: 4401/10000 Iteration: 30808 Train loss: 0.008045\n",
      "Epoch: 4402/10000 Iteration: 30815 Train loss: 0.008045\n",
      "Epoch: 4403/10000 Iteration: 30822 Train loss: 0.008045\n",
      "Epoch: 4404/10000 Iteration: 30829 Train loss: 0.008045\n",
      "Epoch: 4405/10000 Iteration: 30836 Train loss: 0.008046\n",
      "Epoch: 4406/10000 Iteration: 30843 Train loss: 0.008046\n",
      "Epoch: 4407/10000 Iteration: 30850 Train loss: 0.008046\n",
      "Epoch: 4408/10000 Iteration: 30857 Train loss: 0.008046\n",
      "Epoch: 4409/10000 Iteration: 30864 Train loss: 0.008046\n",
      "Epoch: 4410/10000 Iteration: 30871 Train loss: 0.008046\n",
      "Epoch: 4411/10000 Iteration: 30878 Train loss: 0.008046\n",
      "Epoch: 4412/10000 Iteration: 30885 Train loss: 0.008046\n",
      "Epoch: 4413/10000 Iteration: 30892 Train loss: 0.008047\n",
      "Epoch: 4414/10000 Iteration: 30899 Train loss: 0.008047\n",
      "Epoch: 4415/10000 Iteration: 30906 Train loss: 0.008047\n",
      "Epoch: 4416/10000 Iteration: 30913 Train loss: 0.008047\n",
      "Epoch: 4417/10000 Iteration: 30920 Train loss: 0.008047\n",
      "Epoch: 4418/10000 Iteration: 30927 Train loss: 0.008047\n",
      "Epoch: 4419/10000 Iteration: 30934 Train loss: 0.008047\n",
      "Epoch: 4420/10000 Iteration: 30941 Train loss: 0.008047\n",
      "Epoch: 4421/10000 Iteration: 30948 Train loss: 0.008047\n",
      "Epoch: 4422/10000 Iteration: 30955 Train loss: 0.008048\n",
      "Epoch: 4423/10000 Iteration: 30962 Train loss: 0.008048\n",
      "Epoch: 4424/10000 Iteration: 30969 Train loss: 0.008048\n",
      "Epoch: 4425/10000 Iteration: 30976 Train loss: 0.008048\n",
      "Epoch: 4426/10000 Iteration: 30983 Train loss: 0.008048\n",
      "Epoch: 4427/10000 Iteration: 30990 Train loss: 0.008048\n",
      "Epoch: 4428/10000 Iteration: 30997 Train loss: 0.008048\n",
      "Epoch: 4429/10000 Iteration: 31004 Train loss: 0.008048\n",
      "Epoch: 4430/10000 Iteration: 31011 Train loss: 0.008048\n",
      "Epoch: 4431/10000 Iteration: 31018 Train loss: 0.008049\n",
      "Epoch: 4432/10000 Iteration: 31025 Train loss: 0.008049\n",
      "Epoch: 4433/10000 Iteration: 31032 Train loss: 0.008049\n",
      "Epoch: 4434/10000 Iteration: 31039 Train loss: 0.008049\n",
      "Epoch: 4435/10000 Iteration: 31046 Train loss: 0.008049\n",
      "Epoch: 4436/10000 Iteration: 31053 Train loss: 0.008049\n",
      "Epoch: 4437/10000 Iteration: 31060 Train loss: 0.008049\n",
      "Epoch: 4438/10000 Iteration: 31067 Train loss: 0.008049\n",
      "Epoch: 4439/10000 Iteration: 31074 Train loss: 0.008049\n",
      "Epoch: 4440/10000 Iteration: 31081 Train loss: 0.008049\n",
      "Epoch: 4441/10000 Iteration: 31088 Train loss: 0.008050\n",
      "Epoch: 4442/10000 Iteration: 31095 Train loss: 0.008050\n",
      "Epoch: 4443/10000 Iteration: 31102 Train loss: 0.008050\n",
      "Epoch: 4444/10000 Iteration: 31109 Train loss: 0.008050\n",
      "Epoch: 4445/10000 Iteration: 31116 Train loss: 0.008050\n",
      "Epoch: 4446/10000 Iteration: 31123 Train loss: 0.008050\n",
      "Epoch: 4447/10000 Iteration: 31130 Train loss: 0.008050\n",
      "Epoch: 4448/10000 Iteration: 31137 Train loss: 0.008050\n",
      "Epoch: 4449/10000 Iteration: 31144 Train loss: 0.008050\n",
      "Epoch: 4450/10000 Iteration: 31151 Train loss: 0.008050\n",
      "Epoch: 4451/10000 Iteration: 31158 Train loss: 0.008051\n",
      "Epoch: 4452/10000 Iteration: 31165 Train loss: 0.008051\n",
      "Epoch: 4453/10000 Iteration: 31172 Train loss: 0.008051\n",
      "Epoch: 4454/10000 Iteration: 31179 Train loss: 0.008051\n",
      "Epoch: 4455/10000 Iteration: 31186 Train loss: 0.008051\n",
      "Epoch: 4456/10000 Iteration: 31193 Train loss: 0.008051\n",
      "Epoch: 4457/10000 Iteration: 31200 Train loss: 0.008051\n",
      "Epoch: 4458/10000 Iteration: 31207 Train loss: 0.008051\n",
      "Epoch: 4459/10000 Iteration: 31214 Train loss: 0.008051\n",
      "Epoch: 4460/10000 Iteration: 31221 Train loss: 0.008051\n",
      "Epoch: 4461/10000 Iteration: 31228 Train loss: 0.008052\n",
      "Epoch: 4462/10000 Iteration: 31235 Train loss: 0.008052\n",
      "Epoch: 4463/10000 Iteration: 31242 Train loss: 0.008052\n",
      "Epoch: 4464/10000 Iteration: 31249 Train loss: 0.008052\n",
      "Epoch: 4465/10000 Iteration: 31256 Train loss: 0.008052\n",
      "Epoch: 4466/10000 Iteration: 31263 Train loss: 0.008052\n",
      "Epoch: 4467/10000 Iteration: 31270 Train loss: 0.008052\n",
      "Epoch: 4468/10000 Iteration: 31277 Train loss: 0.008052\n",
      "Epoch: 4469/10000 Iteration: 31284 Train loss: 0.008052\n",
      "Epoch: 4470/10000 Iteration: 31291 Train loss: 0.008052\n",
      "Epoch: 4471/10000 Iteration: 31298 Train loss: 0.008052\n",
      "Epoch: 4472/10000 Iteration: 31305 Train loss: 0.008053\n",
      "Epoch: 4473/10000 Iteration: 31312 Train loss: 0.008053\n",
      "Epoch: 4474/10000 Iteration: 31319 Train loss: 0.008053\n",
      "Epoch: 4475/10000 Iteration: 31326 Train loss: 0.008053\n",
      "Epoch: 4476/10000 Iteration: 31333 Train loss: 0.008053\n",
      "Epoch: 4477/10000 Iteration: 31340 Train loss: 0.008053\n",
      "Epoch: 4478/10000 Iteration: 31347 Train loss: 0.008053\n",
      "Epoch: 4479/10000 Iteration: 31354 Train loss: 0.008053\n",
      "Epoch: 4480/10000 Iteration: 31361 Train loss: 0.008053\n",
      "Epoch: 4481/10000 Iteration: 31368 Train loss: 0.008053\n",
      "Epoch: 4482/10000 Iteration: 31375 Train loss: 0.008053\n",
      "Epoch: 4483/10000 Iteration: 31382 Train loss: 0.008053\n",
      "Epoch: 4484/10000 Iteration: 31389 Train loss: 0.008054\n",
      "Epoch: 4485/10000 Iteration: 31396 Train loss: 0.008054\n",
      "Epoch: 4486/10000 Iteration: 31403 Train loss: 0.008054\n",
      "Epoch: 4487/10000 Iteration: 31410 Train loss: 0.008054\n",
      "Epoch: 4488/10000 Iteration: 31417 Train loss: 0.008054\n",
      "Epoch: 4489/10000 Iteration: 31424 Train loss: 0.008054\n",
      "Epoch: 4490/10000 Iteration: 31431 Train loss: 0.008054\n",
      "Epoch: 4491/10000 Iteration: 31438 Train loss: 0.008054\n",
      "Epoch: 4492/10000 Iteration: 31445 Train loss: 0.008054\n",
      "Epoch: 4493/10000 Iteration: 31452 Train loss: 0.008054\n",
      "Epoch: 4494/10000 Iteration: 31459 Train loss: 0.008054\n",
      "Epoch: 4495/10000 Iteration: 31466 Train loss: 0.008054\n",
      "Epoch: 4496/10000 Iteration: 31473 Train loss: 0.008055\n",
      "Epoch: 4497/10000 Iteration: 31480 Train loss: 0.008055\n",
      "Epoch: 4498/10000 Iteration: 31487 Train loss: 0.008055\n",
      "Epoch: 4499/10000 Iteration: 31494 Train loss: 0.008055\n",
      "Epoch: 4500/10000 Iteration: 31501 Train loss: 0.008055\n",
      "Epoch: 4501/10000 Iteration: 31508 Train loss: 0.008055\n",
      "Epoch: 4502/10000 Iteration: 31515 Train loss: 0.008055\n",
      "Epoch: 4503/10000 Iteration: 31522 Train loss: 0.008055\n",
      "Epoch: 4504/10000 Iteration: 31529 Train loss: 0.008055\n",
      "Epoch: 4505/10000 Iteration: 31536 Train loss: 0.008055\n",
      "Epoch: 4506/10000 Iteration: 31543 Train loss: 0.008055\n",
      "Epoch: 4507/10000 Iteration: 31550 Train loss: 0.008055\n",
      "Epoch: 4508/10000 Iteration: 31557 Train loss: 0.008055\n",
      "Epoch: 4509/10000 Iteration: 31564 Train loss: 0.008056\n",
      "Epoch: 4510/10000 Iteration: 31571 Train loss: 0.008056\n",
      "Epoch: 4511/10000 Iteration: 31578 Train loss: 0.008056\n",
      "Epoch: 4512/10000 Iteration: 31585 Train loss: 0.008056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4513/10000 Iteration: 31592 Train loss: 0.008056\n",
      "Epoch: 4514/10000 Iteration: 31599 Train loss: 0.008056\n",
      "Epoch: 4515/10000 Iteration: 31606 Train loss: 0.008056\n",
      "Epoch: 4516/10000 Iteration: 31613 Train loss: 0.008056\n",
      "Epoch: 4517/10000 Iteration: 31620 Train loss: 0.008056\n",
      "Epoch: 4518/10000 Iteration: 31627 Train loss: 0.008056\n",
      "Epoch: 4519/10000 Iteration: 31634 Train loss: 0.008056\n",
      "Epoch: 4520/10000 Iteration: 31641 Train loss: 0.008056\n",
      "Epoch: 4521/10000 Iteration: 31648 Train loss: 0.008056\n",
      "Epoch: 4522/10000 Iteration: 31655 Train loss: 0.008056\n",
      "Epoch: 4523/10000 Iteration: 31662 Train loss: 0.008056\n",
      "Epoch: 4524/10000 Iteration: 31669 Train loss: 0.008057\n",
      "Epoch: 4525/10000 Iteration: 31676 Train loss: 0.008057\n",
      "Epoch: 4526/10000 Iteration: 31683 Train loss: 0.008057\n",
      "Epoch: 4527/10000 Iteration: 31690 Train loss: 0.008057\n",
      "Epoch: 4528/10000 Iteration: 31697 Train loss: 0.008057\n",
      "Epoch: 4529/10000 Iteration: 31704 Train loss: 0.008057\n",
      "Epoch: 4530/10000 Iteration: 31711 Train loss: 0.008057\n",
      "Epoch: 4531/10000 Iteration: 31718 Train loss: 0.008057\n",
      "Epoch: 4532/10000 Iteration: 31725 Train loss: 0.008057\n",
      "Epoch: 4533/10000 Iteration: 31732 Train loss: 0.008057\n",
      "Epoch: 4534/10000 Iteration: 31739 Train loss: 0.008057\n",
      "Epoch: 4535/10000 Iteration: 31746 Train loss: 0.008057\n",
      "Epoch: 4536/10000 Iteration: 31753 Train loss: 0.008057\n",
      "Epoch: 4537/10000 Iteration: 31760 Train loss: 0.008057\n",
      "Epoch: 4538/10000 Iteration: 31767 Train loss: 0.008057\n",
      "Epoch: 4539/10000 Iteration: 31774 Train loss: 0.008057\n",
      "Epoch: 4540/10000 Iteration: 31781 Train loss: 0.008058\n",
      "Epoch: 4541/10000 Iteration: 31788 Train loss: 0.008058\n",
      "Epoch: 4542/10000 Iteration: 31795 Train loss: 0.008058\n",
      "Epoch: 4543/10000 Iteration: 31802 Train loss: 0.008058\n",
      "Epoch: 4544/10000 Iteration: 31809 Train loss: 0.008058\n",
      "Epoch: 4545/10000 Iteration: 31816 Train loss: 0.008058\n",
      "Epoch: 4546/10000 Iteration: 31823 Train loss: 0.008058\n",
      "Epoch: 4547/10000 Iteration: 31830 Train loss: 0.008058\n",
      "Epoch: 4548/10000 Iteration: 31837 Train loss: 0.008058\n",
      "Epoch: 4549/10000 Iteration: 31844 Train loss: 0.008058\n",
      "Epoch: 4550/10000 Iteration: 31851 Train loss: 0.008058\n",
      "Epoch: 4551/10000 Iteration: 31858 Train loss: 0.008058\n",
      "Epoch: 4552/10000 Iteration: 31865 Train loss: 0.008058\n",
      "Epoch: 4553/10000 Iteration: 31872 Train loss: 0.008058\n",
      "Epoch: 4554/10000 Iteration: 31879 Train loss: 0.008058\n",
      "Epoch: 4555/10000 Iteration: 31886 Train loss: 0.008058\n",
      "Epoch: 4556/10000 Iteration: 31893 Train loss: 0.008058\n",
      "Epoch: 4557/10000 Iteration: 31900 Train loss: 0.008058\n",
      "Epoch: 4558/10000 Iteration: 31907 Train loss: 0.008059\n",
      "Epoch: 4559/10000 Iteration: 31914 Train loss: 0.008059\n",
      "Epoch: 4560/10000 Iteration: 31921 Train loss: 0.008059\n",
      "Epoch: 4561/10000 Iteration: 31928 Train loss: 0.008059\n",
      "Epoch: 4562/10000 Iteration: 31935 Train loss: 0.008059\n",
      "Epoch: 4563/10000 Iteration: 31942 Train loss: 0.008059\n",
      "Epoch: 4564/10000 Iteration: 31949 Train loss: 0.008059\n",
      "Epoch: 4565/10000 Iteration: 31956 Train loss: 0.008059\n",
      "Epoch: 4566/10000 Iteration: 31963 Train loss: 0.008059\n",
      "Epoch: 4567/10000 Iteration: 31970 Train loss: 0.008059\n",
      "Epoch: 4568/10000 Iteration: 31977 Train loss: 0.008059\n",
      "Epoch: 4569/10000 Iteration: 31984 Train loss: 0.008059\n",
      "Epoch: 4570/10000 Iteration: 31991 Train loss: 0.008059\n",
      "Epoch: 4571/10000 Iteration: 31998 Train loss: 0.008059\n",
      "Epoch: 4572/10000 Iteration: 32005 Train loss: 0.008059\n",
      "Epoch: 4573/10000 Iteration: 32012 Train loss: 0.008059\n",
      "Epoch: 4574/10000 Iteration: 32019 Train loss: 0.008059\n",
      "Epoch: 4575/10000 Iteration: 32026 Train loss: 0.008059\n",
      "Epoch: 4576/10000 Iteration: 32033 Train loss: 0.008059\n",
      "Epoch: 4577/10000 Iteration: 32040 Train loss: 0.008059\n",
      "Epoch: 4578/10000 Iteration: 32047 Train loss: 0.008059\n",
      "Epoch: 4579/10000 Iteration: 32054 Train loss: 0.008059\n",
      "Epoch: 4580/10000 Iteration: 32061 Train loss: 0.008060\n",
      "Epoch: 4581/10000 Iteration: 32068 Train loss: 0.008060\n",
      "Epoch: 4582/10000 Iteration: 32075 Train loss: 0.008060\n",
      "Epoch: 4583/10000 Iteration: 32082 Train loss: 0.008060\n",
      "Epoch: 4584/10000 Iteration: 32089 Train loss: 0.008060\n",
      "Epoch: 4585/10000 Iteration: 32096 Train loss: 0.008060\n",
      "Epoch: 4586/10000 Iteration: 32103 Train loss: 0.008060\n",
      "Epoch: 4587/10000 Iteration: 32110 Train loss: 0.008060\n",
      "Epoch: 4588/10000 Iteration: 32117 Train loss: 0.008060\n",
      "Epoch: 4589/10000 Iteration: 32124 Train loss: 0.008060\n",
      "Epoch: 4590/10000 Iteration: 32131 Train loss: 0.008060\n",
      "Epoch: 4591/10000 Iteration: 32138 Train loss: 0.008060\n",
      "Epoch: 4592/10000 Iteration: 32145 Train loss: 0.008060\n",
      "Epoch: 4593/10000 Iteration: 32152 Train loss: 0.008060\n",
      "Epoch: 4594/10000 Iteration: 32159 Train loss: 0.008060\n",
      "Epoch: 4595/10000 Iteration: 32166 Train loss: 0.008060\n",
      "Epoch: 4596/10000 Iteration: 32173 Train loss: 0.008060\n",
      "Epoch: 4597/10000 Iteration: 32180 Train loss: 0.008060\n",
      "Epoch: 4598/10000 Iteration: 32187 Train loss: 0.008060\n",
      "Epoch: 4599/10000 Iteration: 32194 Train loss: 0.008060\n",
      "Epoch: 4600/10000 Iteration: 32201 Train loss: 0.008060\n",
      "Epoch: 4601/10000 Iteration: 32208 Train loss: 0.008060\n",
      "Epoch: 4602/10000 Iteration: 32215 Train loss: 0.008060\n",
      "Epoch: 4603/10000 Iteration: 32222 Train loss: 0.008060\n",
      "Epoch: 4604/10000 Iteration: 32229 Train loss: 0.008060\n",
      "Epoch: 4605/10000 Iteration: 32236 Train loss: 0.008060\n",
      "Epoch: 4606/10000 Iteration: 32243 Train loss: 0.008060\n",
      "Epoch: 4607/10000 Iteration: 32250 Train loss: 0.008061\n",
      "Epoch: 4608/10000 Iteration: 32257 Train loss: 0.008061\n",
      "Epoch: 4609/10000 Iteration: 32264 Train loss: 0.008061\n",
      "Epoch: 4610/10000 Iteration: 32271 Train loss: 0.008061\n",
      "Epoch: 4611/10000 Iteration: 32278 Train loss: 0.008061\n",
      "Epoch: 4612/10000 Iteration: 32285 Train loss: 0.008061\n",
      "Epoch: 4613/10000 Iteration: 32292 Train loss: 0.008061\n",
      "Epoch: 4614/10000 Iteration: 32299 Train loss: 0.008061\n",
      "Epoch: 4615/10000 Iteration: 32306 Train loss: 0.008061\n",
      "Epoch: 4616/10000 Iteration: 32313 Train loss: 0.008061\n",
      "Epoch: 4617/10000 Iteration: 32320 Train loss: 0.008061\n",
      "Epoch: 4618/10000 Iteration: 32327 Train loss: 0.008061\n",
      "Epoch: 4619/10000 Iteration: 32334 Train loss: 0.008061\n",
      "Epoch: 4620/10000 Iteration: 32341 Train loss: 0.008061\n",
      "Epoch: 4621/10000 Iteration: 32348 Train loss: 0.008061\n",
      "Epoch: 4622/10000 Iteration: 32355 Train loss: 0.008061\n",
      "Epoch: 4623/10000 Iteration: 32362 Train loss: 0.008061\n",
      "Epoch: 4624/10000 Iteration: 32369 Train loss: 0.008061\n",
      "Epoch: 4625/10000 Iteration: 32376 Train loss: 0.008061\n",
      "Epoch: 4626/10000 Iteration: 32383 Train loss: 0.008061\n",
      "Epoch: 4627/10000 Iteration: 32390 Train loss: 0.008061\n",
      "Epoch: 4628/10000 Iteration: 32397 Train loss: 0.008061\n",
      "Epoch: 4629/10000 Iteration: 32404 Train loss: 0.008061\n",
      "Epoch: 4630/10000 Iteration: 32411 Train loss: 0.008061\n",
      "Epoch: 4631/10000 Iteration: 32418 Train loss: 0.008061\n",
      "Epoch: 4632/10000 Iteration: 32425 Train loss: 0.008061\n",
      "Epoch: 4633/10000 Iteration: 32432 Train loss: 0.008061\n",
      "Epoch: 4634/10000 Iteration: 32439 Train loss: 0.008061\n",
      "Epoch: 4635/10000 Iteration: 32446 Train loss: 0.008061\n",
      "Epoch: 4636/10000 Iteration: 32453 Train loss: 0.008061\n",
      "Epoch: 4637/10000 Iteration: 32460 Train loss: 0.008061\n",
      "Epoch: 4638/10000 Iteration: 32467 Train loss: 0.008061\n",
      "Epoch: 4639/10000 Iteration: 32474 Train loss: 0.008061\n",
      "Epoch: 4640/10000 Iteration: 32481 Train loss: 0.008061\n",
      "Epoch: 4641/10000 Iteration: 32488 Train loss: 0.008061\n",
      "Epoch: 4642/10000 Iteration: 32495 Train loss: 0.008061\n",
      "Epoch: 4643/10000 Iteration: 32502 Train loss: 0.008061\n",
      "Epoch: 4644/10000 Iteration: 32509 Train loss: 0.008061\n",
      "Epoch: 4645/10000 Iteration: 32516 Train loss: 0.008061\n",
      "Epoch: 4646/10000 Iteration: 32523 Train loss: 0.008061\n",
      "Epoch: 4647/10000 Iteration: 32530 Train loss: 0.008061\n",
      "Epoch: 4648/10000 Iteration: 32537 Train loss: 0.008061\n",
      "Epoch: 4649/10000 Iteration: 32544 Train loss: 0.008061\n",
      "Epoch: 4650/10000 Iteration: 32551 Train loss: 0.008061\n",
      "Epoch: 4651/10000 Iteration: 32558 Train loss: 0.008061\n",
      "Epoch: 4652/10000 Iteration: 32565 Train loss: 0.008061\n",
      "Epoch: 4653/10000 Iteration: 32572 Train loss: 0.008062\n",
      "Epoch: 4654/10000 Iteration: 32579 Train loss: 0.008062\n",
      "Epoch: 4655/10000 Iteration: 32586 Train loss: 0.008062\n",
      "Epoch: 4656/10000 Iteration: 32593 Train loss: 0.008062\n",
      "Epoch: 4657/10000 Iteration: 32600 Train loss: 0.008062\n",
      "Epoch: 4658/10000 Iteration: 32607 Train loss: 0.008062\n",
      "Epoch: 4659/10000 Iteration: 32614 Train loss: 0.008062\n",
      "Epoch: 4660/10000 Iteration: 32621 Train loss: 0.008062\n",
      "Epoch: 4661/10000 Iteration: 32628 Train loss: 0.008062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4662/10000 Iteration: 32635 Train loss: 0.008062\n",
      "Epoch: 4663/10000 Iteration: 32642 Train loss: 0.008062\n",
      "Epoch: 4664/10000 Iteration: 32649 Train loss: 0.008062\n",
      "Epoch: 4665/10000 Iteration: 32656 Train loss: 0.008062\n",
      "Epoch: 4666/10000 Iteration: 32663 Train loss: 0.008062\n",
      "Epoch: 4667/10000 Iteration: 32670 Train loss: 0.008062\n",
      "Epoch: 4668/10000 Iteration: 32677 Train loss: 0.008062\n",
      "Epoch: 4669/10000 Iteration: 32684 Train loss: 0.008062\n",
      "Epoch: 4670/10000 Iteration: 32691 Train loss: 0.008062\n",
      "Epoch: 4671/10000 Iteration: 32698 Train loss: 0.008062\n",
      "Epoch: 4672/10000 Iteration: 32705 Train loss: 0.008062\n",
      "Epoch: 4673/10000 Iteration: 32712 Train loss: 0.008062\n",
      "Epoch: 4674/10000 Iteration: 32719 Train loss: 0.008062\n",
      "Epoch: 4675/10000 Iteration: 32726 Train loss: 0.008062\n",
      "Epoch: 4676/10000 Iteration: 32733 Train loss: 0.008062\n",
      "Epoch: 4677/10000 Iteration: 32740 Train loss: 0.008062\n",
      "Epoch: 4678/10000 Iteration: 32747 Train loss: 0.008062\n",
      "Epoch: 4679/10000 Iteration: 32754 Train loss: 0.008062\n",
      "Epoch: 4680/10000 Iteration: 32761 Train loss: 0.008062\n",
      "Epoch: 4681/10000 Iteration: 32768 Train loss: 0.008062\n",
      "Epoch: 4682/10000 Iteration: 32775 Train loss: 0.008062\n",
      "Epoch: 4683/10000 Iteration: 32782 Train loss: 0.008062\n",
      "Epoch: 4684/10000 Iteration: 32789 Train loss: 0.008062\n",
      "Epoch: 4685/10000 Iteration: 32796 Train loss: 0.008062\n",
      "Epoch: 4686/10000 Iteration: 32803 Train loss: 0.008062\n",
      "Epoch: 4687/10000 Iteration: 32810 Train loss: 0.008062\n",
      "Epoch: 4688/10000 Iteration: 32817 Train loss: 0.008062\n",
      "Epoch: 4689/10000 Iteration: 32824 Train loss: 0.008062\n",
      "Epoch: 4690/10000 Iteration: 32831 Train loss: 0.008062\n",
      "Epoch: 4691/10000 Iteration: 32838 Train loss: 0.008062\n",
      "Epoch: 4692/10000 Iteration: 32845 Train loss: 0.008062\n",
      "Epoch: 4693/10000 Iteration: 32852 Train loss: 0.008062\n",
      "Epoch: 4694/10000 Iteration: 32859 Train loss: 0.008062\n",
      "Epoch: 4695/10000 Iteration: 32866 Train loss: 0.008062\n",
      "Epoch: 4696/10000 Iteration: 32873 Train loss: 0.008062\n",
      "Epoch: 4697/10000 Iteration: 32880 Train loss: 0.008062\n",
      "Epoch: 4698/10000 Iteration: 32887 Train loss: 0.008062\n",
      "Epoch: 4699/10000 Iteration: 32894 Train loss: 0.008062\n",
      "Epoch: 4700/10000 Iteration: 32901 Train loss: 0.008062\n",
      "Epoch: 4701/10000 Iteration: 32908 Train loss: 0.008062\n",
      "Epoch: 4702/10000 Iteration: 32915 Train loss: 0.008062\n",
      "Epoch: 4703/10000 Iteration: 32922 Train loss: 0.008062\n",
      "Epoch: 4704/10000 Iteration: 32929 Train loss: 0.008062\n",
      "Epoch: 4705/10000 Iteration: 32936 Train loss: 0.008062\n",
      "Epoch: 4706/10000 Iteration: 32943 Train loss: 0.008062\n",
      "Epoch: 4707/10000 Iteration: 32950 Train loss: 0.008062\n",
      "Epoch: 4708/10000 Iteration: 32957 Train loss: 0.008062\n",
      "Epoch: 4709/10000 Iteration: 32964 Train loss: 0.008062\n",
      "Epoch: 4710/10000 Iteration: 32971 Train loss: 0.008062\n",
      "Epoch: 4711/10000 Iteration: 32978 Train loss: 0.008062\n",
      "Epoch: 4712/10000 Iteration: 32985 Train loss: 0.008062\n",
      "Epoch: 4713/10000 Iteration: 32992 Train loss: 0.008062\n",
      "Epoch: 4714/10000 Iteration: 32999 Train loss: 0.008062\n",
      "Epoch: 4715/10000 Iteration: 33006 Train loss: 0.008062\n",
      "Epoch: 4716/10000 Iteration: 33013 Train loss: 0.008062\n",
      "Epoch: 4717/10000 Iteration: 33020 Train loss: 0.008061\n",
      "Epoch: 4718/10000 Iteration: 33027 Train loss: 0.008061\n",
      "Epoch: 4719/10000 Iteration: 33034 Train loss: 0.008061\n",
      "Epoch: 4720/10000 Iteration: 33041 Train loss: 0.008061\n",
      "Epoch: 4721/10000 Iteration: 33048 Train loss: 0.008061\n",
      "Epoch: 4722/10000 Iteration: 33055 Train loss: 0.008061\n",
      "Epoch: 4723/10000 Iteration: 33062 Train loss: 0.008061\n",
      "Epoch: 4724/10000 Iteration: 33069 Train loss: 0.008061\n",
      "Epoch: 4725/10000 Iteration: 33076 Train loss: 0.008061\n",
      "Epoch: 4726/10000 Iteration: 33083 Train loss: 0.008061\n",
      "Epoch: 4727/10000 Iteration: 33090 Train loss: 0.008061\n",
      "Epoch: 4728/10000 Iteration: 33097 Train loss: 0.008061\n",
      "Epoch: 4729/10000 Iteration: 33104 Train loss: 0.008061\n",
      "Epoch: 4730/10000 Iteration: 33111 Train loss: 0.008061\n",
      "Epoch: 4731/10000 Iteration: 33118 Train loss: 0.008061\n",
      "Epoch: 4732/10000 Iteration: 33125 Train loss: 0.008061\n",
      "Epoch: 4733/10000 Iteration: 33132 Train loss: 0.008061\n",
      "Epoch: 4734/10000 Iteration: 33139 Train loss: 0.008061\n",
      "Epoch: 4735/10000 Iteration: 33146 Train loss: 0.008061\n",
      "Epoch: 4736/10000 Iteration: 33153 Train loss: 0.008061\n",
      "Epoch: 4737/10000 Iteration: 33160 Train loss: 0.008061\n",
      "Epoch: 4738/10000 Iteration: 33167 Train loss: 0.008061\n",
      "Epoch: 4739/10000 Iteration: 33174 Train loss: 0.008061\n",
      "Epoch: 4740/10000 Iteration: 33181 Train loss: 0.008061\n",
      "Epoch: 4741/10000 Iteration: 33188 Train loss: 0.008061\n",
      "Epoch: 4742/10000 Iteration: 33195 Train loss: 0.008061\n",
      "Epoch: 4743/10000 Iteration: 33202 Train loss: 0.008061\n",
      "Epoch: 4744/10000 Iteration: 33209 Train loss: 0.008061\n",
      "Epoch: 4745/10000 Iteration: 33216 Train loss: 0.008061\n",
      "Epoch: 4746/10000 Iteration: 33223 Train loss: 0.008061\n",
      "Epoch: 4747/10000 Iteration: 33230 Train loss: 0.008061\n",
      "Epoch: 4748/10000 Iteration: 33237 Train loss: 0.008061\n",
      "Epoch: 4749/10000 Iteration: 33244 Train loss: 0.008061\n",
      "Epoch: 4750/10000 Iteration: 33251 Train loss: 0.008061\n",
      "Epoch: 4751/10000 Iteration: 33258 Train loss: 0.008061\n",
      "Epoch: 4752/10000 Iteration: 33265 Train loss: 0.008061\n",
      "Epoch: 4753/10000 Iteration: 33272 Train loss: 0.008061\n",
      "Epoch: 4754/10000 Iteration: 33279 Train loss: 0.008061\n",
      "Epoch: 4755/10000 Iteration: 33286 Train loss: 0.008061\n",
      "Epoch: 4756/10000 Iteration: 33293 Train loss: 0.008061\n",
      "Epoch: 4757/10000 Iteration: 33300 Train loss: 0.008061\n",
      "Epoch: 4758/10000 Iteration: 33307 Train loss: 0.008061\n",
      "Epoch: 4759/10000 Iteration: 33314 Train loss: 0.008061\n",
      "Epoch: 4760/10000 Iteration: 33321 Train loss: 0.008061\n",
      "Epoch: 4761/10000 Iteration: 33328 Train loss: 0.008061\n",
      "Epoch: 4762/10000 Iteration: 33335 Train loss: 0.008061\n",
      "Epoch: 4763/10000 Iteration: 33342 Train loss: 0.008061\n",
      "Epoch: 4764/10000 Iteration: 33349 Train loss: 0.008061\n",
      "Epoch: 4765/10000 Iteration: 33356 Train loss: 0.008060\n",
      "Epoch: 4766/10000 Iteration: 33363 Train loss: 0.008060\n",
      "Epoch: 4767/10000 Iteration: 33370 Train loss: 0.008060\n",
      "Epoch: 4768/10000 Iteration: 33377 Train loss: 0.008060\n",
      "Epoch: 4769/10000 Iteration: 33384 Train loss: 0.008060\n",
      "Epoch: 4770/10000 Iteration: 33391 Train loss: 0.008060\n",
      "Epoch: 4771/10000 Iteration: 33398 Train loss: 0.008060\n",
      "Epoch: 4772/10000 Iteration: 33405 Train loss: 0.008060\n",
      "Epoch: 4773/10000 Iteration: 33412 Train loss: 0.008060\n",
      "Epoch: 4774/10000 Iteration: 33419 Train loss: 0.008060\n",
      "Epoch: 4775/10000 Iteration: 33426 Train loss: 0.008060\n",
      "Epoch: 4776/10000 Iteration: 33433 Train loss: 0.008060\n",
      "Epoch: 4777/10000 Iteration: 33440 Train loss: 0.008060\n",
      "Epoch: 4778/10000 Iteration: 33447 Train loss: 0.008060\n",
      "Epoch: 4779/10000 Iteration: 33454 Train loss: 0.008060\n",
      "Epoch: 4780/10000 Iteration: 33461 Train loss: 0.008060\n",
      "Epoch: 4781/10000 Iteration: 33468 Train loss: 0.008060\n",
      "Epoch: 4782/10000 Iteration: 33475 Train loss: 0.008060\n",
      "Epoch: 4783/10000 Iteration: 33482 Train loss: 0.008060\n",
      "Epoch: 4784/10000 Iteration: 33489 Train loss: 0.008060\n",
      "Epoch: 4785/10000 Iteration: 33496 Train loss: 0.008060\n",
      "Epoch: 4786/10000 Iteration: 33503 Train loss: 0.008060\n",
      "Epoch: 4787/10000 Iteration: 33510 Train loss: 0.008060\n",
      "Epoch: 4788/10000 Iteration: 33517 Train loss: 0.008060\n",
      "Epoch: 4789/10000 Iteration: 33524 Train loss: 0.008060\n",
      "Epoch: 4790/10000 Iteration: 33531 Train loss: 0.008060\n",
      "Epoch: 4791/10000 Iteration: 33538 Train loss: 0.008060\n",
      "Epoch: 4792/10000 Iteration: 33545 Train loss: 0.008060\n",
      "Epoch: 4793/10000 Iteration: 33552 Train loss: 0.008060\n",
      "Epoch: 4794/10000 Iteration: 33559 Train loss: 0.008059\n",
      "Epoch: 4795/10000 Iteration: 33566 Train loss: 0.008059\n",
      "Epoch: 4796/10000 Iteration: 33573 Train loss: 0.008059\n",
      "Epoch: 4797/10000 Iteration: 33580 Train loss: 0.008059\n",
      "Epoch: 4798/10000 Iteration: 33587 Train loss: 0.008059\n",
      "Epoch: 4799/10000 Iteration: 33594 Train loss: 0.008059\n",
      "Epoch: 4800/10000 Iteration: 33601 Train loss: 0.008059\n",
      "Epoch: 4801/10000 Iteration: 33608 Train loss: 0.008059\n",
      "Epoch: 4802/10000 Iteration: 33615 Train loss: 0.008059\n",
      "Epoch: 4803/10000 Iteration: 33622 Train loss: 0.008059\n",
      "Epoch: 4804/10000 Iteration: 33629 Train loss: 0.008059\n",
      "Epoch: 4805/10000 Iteration: 33636 Train loss: 0.008059\n",
      "Epoch: 4806/10000 Iteration: 33643 Train loss: 0.008059\n",
      "Epoch: 4807/10000 Iteration: 33650 Train loss: 0.008059\n",
      "Epoch: 4808/10000 Iteration: 33657 Train loss: 0.008059\n",
      "Epoch: 4809/10000 Iteration: 33664 Train loss: 0.008059\n",
      "Epoch: 4810/10000 Iteration: 33671 Train loss: 0.008059\n",
      "Epoch: 4811/10000 Iteration: 33678 Train loss: 0.008059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4812/10000 Iteration: 33685 Train loss: 0.008059\n",
      "Epoch: 4813/10000 Iteration: 33692 Train loss: 0.008059\n",
      "Epoch: 4814/10000 Iteration: 33699 Train loss: 0.008059\n",
      "Epoch: 4815/10000 Iteration: 33706 Train loss: 0.008059\n",
      "Epoch: 4816/10000 Iteration: 33713 Train loss: 0.008058\n",
      "Epoch: 4817/10000 Iteration: 33720 Train loss: 0.008058\n",
      "Epoch: 4818/10000 Iteration: 33727 Train loss: 0.008058\n",
      "Epoch: 4819/10000 Iteration: 33734 Train loss: 0.008058\n",
      "Epoch: 4820/10000 Iteration: 33741 Train loss: 0.008058\n",
      "Epoch: 4821/10000 Iteration: 33748 Train loss: 0.008058\n",
      "Epoch: 4822/10000 Iteration: 33755 Train loss: 0.008058\n",
      "Epoch: 4823/10000 Iteration: 33762 Train loss: 0.008058\n",
      "Epoch: 4824/10000 Iteration: 33769 Train loss: 0.008058\n",
      "Epoch: 4825/10000 Iteration: 33776 Train loss: 0.008058\n",
      "Epoch: 4826/10000 Iteration: 33783 Train loss: 0.008058\n",
      "Epoch: 4827/10000 Iteration: 33790 Train loss: 0.008058\n",
      "Epoch: 4828/10000 Iteration: 33797 Train loss: 0.008058\n",
      "Epoch: 4829/10000 Iteration: 33804 Train loss: 0.008058\n",
      "Epoch: 4830/10000 Iteration: 33811 Train loss: 0.008058\n",
      "Epoch: 4831/10000 Iteration: 33818 Train loss: 0.008058\n",
      "Epoch: 4832/10000 Iteration: 33825 Train loss: 0.008058\n",
      "Epoch: 4833/10000 Iteration: 33832 Train loss: 0.008058\n",
      "Epoch: 4834/10000 Iteration: 33839 Train loss: 0.008058\n",
      "Epoch: 4835/10000 Iteration: 33846 Train loss: 0.008058\n",
      "Epoch: 4836/10000 Iteration: 33853 Train loss: 0.008057\n",
      "Epoch: 4837/10000 Iteration: 33860 Train loss: 0.008057\n",
      "Epoch: 4838/10000 Iteration: 33867 Train loss: 0.008057\n",
      "Epoch: 4839/10000 Iteration: 33874 Train loss: 0.008057\n",
      "Epoch: 4840/10000 Iteration: 33881 Train loss: 0.008057\n",
      "Epoch: 4841/10000 Iteration: 33888 Train loss: 0.008057\n",
      "Epoch: 4842/10000 Iteration: 33895 Train loss: 0.008057\n",
      "Epoch: 4843/10000 Iteration: 33902 Train loss: 0.008057\n",
      "Epoch: 4844/10000 Iteration: 33909 Train loss: 0.008057\n",
      "Epoch: 4845/10000 Iteration: 33916 Train loss: 0.008057\n",
      "Epoch: 4846/10000 Iteration: 33923 Train loss: 0.008057\n",
      "Epoch: 4847/10000 Iteration: 33930 Train loss: 0.008057\n",
      "Epoch: 4848/10000 Iteration: 33937 Train loss: 0.008057\n",
      "Epoch: 4849/10000 Iteration: 33944 Train loss: 0.008057\n",
      "Epoch: 4850/10000 Iteration: 33951 Train loss: 0.008057\n",
      "Epoch: 4851/10000 Iteration: 33958 Train loss: 0.008057\n",
      "Epoch: 4852/10000 Iteration: 33965 Train loss: 0.008057\n",
      "Epoch: 4853/10000 Iteration: 33972 Train loss: 0.008056\n",
      "Epoch: 4854/10000 Iteration: 33979 Train loss: 0.008056\n",
      "Epoch: 4855/10000 Iteration: 33986 Train loss: 0.008056\n",
      "Epoch: 4856/10000 Iteration: 33993 Train loss: 0.008056\n",
      "Epoch: 4857/10000 Iteration: 34000 Train loss: 0.008056\n",
      "Epoch: 4858/10000 Iteration: 34007 Train loss: 0.008056\n",
      "Epoch: 4859/10000 Iteration: 34014 Train loss: 0.008056\n",
      "Epoch: 4860/10000 Iteration: 34021 Train loss: 0.008056\n",
      "Epoch: 4861/10000 Iteration: 34028 Train loss: 0.008056\n",
      "Epoch: 4862/10000 Iteration: 34035 Train loss: 0.008056\n",
      "Epoch: 4863/10000 Iteration: 34042 Train loss: 0.008056\n",
      "Epoch: 4864/10000 Iteration: 34049 Train loss: 0.008056\n",
      "Epoch: 4865/10000 Iteration: 34056 Train loss: 0.008056\n",
      "Epoch: 4866/10000 Iteration: 34063 Train loss: 0.008056\n",
      "Epoch: 4867/10000 Iteration: 34070 Train loss: 0.008056\n",
      "Epoch: 4868/10000 Iteration: 34077 Train loss: 0.008056\n",
      "Epoch: 4869/10000 Iteration: 34084 Train loss: 0.008055\n",
      "Epoch: 4870/10000 Iteration: 34091 Train loss: 0.008055\n",
      "Epoch: 4871/10000 Iteration: 34098 Train loss: 0.008055\n",
      "Epoch: 4872/10000 Iteration: 34105 Train loss: 0.008055\n",
      "Epoch: 4873/10000 Iteration: 34112 Train loss: 0.008055\n",
      "Epoch: 4874/10000 Iteration: 34119 Train loss: 0.008055\n",
      "Epoch: 4875/10000 Iteration: 34126 Train loss: 0.008055\n",
      "Epoch: 4876/10000 Iteration: 34133 Train loss: 0.008055\n",
      "Epoch: 4877/10000 Iteration: 34140 Train loss: 0.008055\n",
      "Epoch: 4878/10000 Iteration: 34147 Train loss: 0.008055\n",
      "Epoch: 4879/10000 Iteration: 34154 Train loss: 0.008055\n",
      "Epoch: 4880/10000 Iteration: 34161 Train loss: 0.008055\n",
      "Epoch: 4881/10000 Iteration: 34168 Train loss: 0.008055\n",
      "Epoch: 4882/10000 Iteration: 34175 Train loss: 0.008055\n",
      "Epoch: 4883/10000 Iteration: 34182 Train loss: 0.008055\n",
      "Epoch: 4884/10000 Iteration: 34189 Train loss: 0.008054\n",
      "Epoch: 4885/10000 Iteration: 34196 Train loss: 0.008054\n",
      "Epoch: 4886/10000 Iteration: 34203 Train loss: 0.008054\n",
      "Epoch: 4887/10000 Iteration: 34210 Train loss: 0.008054\n",
      "Epoch: 4888/10000 Iteration: 34217 Train loss: 0.008054\n",
      "Epoch: 4889/10000 Iteration: 34224 Train loss: 0.008054\n",
      "Epoch: 4890/10000 Iteration: 34231 Train loss: 0.008054\n",
      "Epoch: 4891/10000 Iteration: 34238 Train loss: 0.008054\n",
      "Epoch: 4892/10000 Iteration: 34245 Train loss: 0.008054\n",
      "Epoch: 4893/10000 Iteration: 34252 Train loss: 0.008054\n",
      "Epoch: 4894/10000 Iteration: 34259 Train loss: 0.008054\n",
      "Epoch: 4895/10000 Iteration: 34266 Train loss: 0.008054\n",
      "Epoch: 4896/10000 Iteration: 34273 Train loss: 0.008054\n",
      "Epoch: 4897/10000 Iteration: 34280 Train loss: 0.008054\n",
      "Epoch: 4898/10000 Iteration: 34287 Train loss: 0.008053\n",
      "Epoch: 4899/10000 Iteration: 34294 Train loss: 0.008053\n",
      "Epoch: 4900/10000 Iteration: 34301 Train loss: 0.008053\n",
      "Epoch: 4901/10000 Iteration: 34308 Train loss: 0.008053\n",
      "Epoch: 4902/10000 Iteration: 34315 Train loss: 0.008053\n",
      "Epoch: 4903/10000 Iteration: 34322 Train loss: 0.008053\n",
      "Epoch: 4904/10000 Iteration: 34329 Train loss: 0.008053\n",
      "Epoch: 4905/10000 Iteration: 34336 Train loss: 0.008053\n",
      "Epoch: 4906/10000 Iteration: 34343 Train loss: 0.008053\n",
      "Epoch: 4907/10000 Iteration: 34350 Train loss: 0.008053\n",
      "Epoch: 4908/10000 Iteration: 34357 Train loss: 0.008053\n",
      "Epoch: 4909/10000 Iteration: 34364 Train loss: 0.008053\n",
      "Epoch: 4910/10000 Iteration: 34371 Train loss: 0.008053\n",
      "Epoch: 4911/10000 Iteration: 34378 Train loss: 0.008052\n",
      "Epoch: 4912/10000 Iteration: 34385 Train loss: 0.008052\n",
      "Epoch: 4913/10000 Iteration: 34392 Train loss: 0.008052\n",
      "Epoch: 4914/10000 Iteration: 34399 Train loss: 0.008052\n",
      "Epoch: 4915/10000 Iteration: 34406 Train loss: 0.008052\n",
      "Epoch: 4916/10000 Iteration: 34413 Train loss: 0.008052\n",
      "Epoch: 4917/10000 Iteration: 34420 Train loss: 0.008052\n",
      "Epoch: 4918/10000 Iteration: 34427 Train loss: 0.008052\n",
      "Epoch: 4919/10000 Iteration: 34434 Train loss: 0.008052\n",
      "Epoch: 4920/10000 Iteration: 34441 Train loss: 0.008052\n",
      "Epoch: 4921/10000 Iteration: 34448 Train loss: 0.008052\n",
      "Epoch: 4922/10000 Iteration: 34455 Train loss: 0.008052\n",
      "Epoch: 4923/10000 Iteration: 34462 Train loss: 0.008051\n",
      "Epoch: 4924/10000 Iteration: 34469 Train loss: 0.008051\n",
      "Epoch: 4925/10000 Iteration: 34476 Train loss: 0.008051\n",
      "Epoch: 4926/10000 Iteration: 34483 Train loss: 0.008051\n",
      "Epoch: 4927/10000 Iteration: 34490 Train loss: 0.008051\n",
      "Epoch: 4928/10000 Iteration: 34497 Train loss: 0.008051\n",
      "Epoch: 4929/10000 Iteration: 34504 Train loss: 0.008051\n",
      "Epoch: 4930/10000 Iteration: 34511 Train loss: 0.008051\n",
      "Epoch: 4931/10000 Iteration: 34518 Train loss: 0.008051\n",
      "Epoch: 4932/10000 Iteration: 34525 Train loss: 0.008051\n",
      "Epoch: 4933/10000 Iteration: 34532 Train loss: 0.008051\n",
      "Epoch: 4934/10000 Iteration: 34539 Train loss: 0.008051\n",
      "Epoch: 4935/10000 Iteration: 34546 Train loss: 0.008050\n",
      "Epoch: 4936/10000 Iteration: 34553 Train loss: 0.008050\n",
      "Epoch: 4937/10000 Iteration: 34560 Train loss: 0.008050\n",
      "Epoch: 4938/10000 Iteration: 34567 Train loss: 0.008050\n",
      "Epoch: 4939/10000 Iteration: 34574 Train loss: 0.008050\n",
      "Epoch: 4940/10000 Iteration: 34581 Train loss: 0.008050\n",
      "Epoch: 4941/10000 Iteration: 34588 Train loss: 0.008050\n",
      "Epoch: 4942/10000 Iteration: 34595 Train loss: 0.008050\n",
      "Epoch: 4943/10000 Iteration: 34602 Train loss: 0.008050\n",
      "Epoch: 4944/10000 Iteration: 34609 Train loss: 0.008050\n",
      "Epoch: 4945/10000 Iteration: 34616 Train loss: 0.008050\n",
      "Epoch: 4946/10000 Iteration: 34623 Train loss: 0.008050\n",
      "Epoch: 4947/10000 Iteration: 34630 Train loss: 0.008049\n",
      "Epoch: 4948/10000 Iteration: 34637 Train loss: 0.008049\n",
      "Epoch: 4949/10000 Iteration: 34644 Train loss: 0.008049\n",
      "Epoch: 4950/10000 Iteration: 34651 Train loss: 0.008049\n",
      "Epoch: 4951/10000 Iteration: 34658 Train loss: 0.008049\n",
      "Epoch: 4952/10000 Iteration: 34665 Train loss: 0.008049\n",
      "Epoch: 4953/10000 Iteration: 34672 Train loss: 0.008049\n",
      "Epoch: 4954/10000 Iteration: 34679 Train loss: 0.008049\n",
      "Epoch: 4955/10000 Iteration: 34686 Train loss: 0.008049\n",
      "Epoch: 4956/10000 Iteration: 34693 Train loss: 0.008049\n",
      "Epoch: 4957/10000 Iteration: 34700 Train loss: 0.008049\n",
      "Epoch: 4958/10000 Iteration: 34707 Train loss: 0.008048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4959/10000 Iteration: 34714 Train loss: 0.008048\n",
      "Epoch: 4960/10000 Iteration: 34721 Train loss: 0.008048\n",
      "Epoch: 4961/10000 Iteration: 34728 Train loss: 0.008048\n",
      "Epoch: 4962/10000 Iteration: 34735 Train loss: 0.008048\n",
      "Epoch: 4963/10000 Iteration: 34742 Train loss: 0.008048\n",
      "Epoch: 4964/10000 Iteration: 34749 Train loss: 0.008048\n",
      "Epoch: 4965/10000 Iteration: 34756 Train loss: 0.008048\n",
      "Epoch: 4966/10000 Iteration: 34763 Train loss: 0.008048\n",
      "Epoch: 4967/10000 Iteration: 34770 Train loss: 0.008048\n",
      "Epoch: 4968/10000 Iteration: 34777 Train loss: 0.008048\n",
      "Epoch: 4969/10000 Iteration: 34784 Train loss: 0.008047\n",
      "Epoch: 4970/10000 Iteration: 34791 Train loss: 0.008047\n",
      "Epoch: 4971/10000 Iteration: 34798 Train loss: 0.008047\n",
      "Epoch: 4972/10000 Iteration: 34805 Train loss: 0.008047\n",
      "Epoch: 4973/10000 Iteration: 34812 Train loss: 0.008047\n",
      "Epoch: 4974/10000 Iteration: 34819 Train loss: 0.008047\n",
      "Epoch: 4975/10000 Iteration: 34826 Train loss: 0.008047\n",
      "Epoch: 4976/10000 Iteration: 34833 Train loss: 0.008047\n",
      "Epoch: 4977/10000 Iteration: 34840 Train loss: 0.008047\n",
      "Epoch: 4978/10000 Iteration: 34847 Train loss: 0.008047\n",
      "Epoch: 4979/10000 Iteration: 34854 Train loss: 0.008046\n",
      "Epoch: 4980/10000 Iteration: 34861 Train loss: 0.008046\n",
      "Epoch: 4981/10000 Iteration: 34868 Train loss: 0.008046\n",
      "Epoch: 4982/10000 Iteration: 34875 Train loss: 0.008046\n",
      "Epoch: 4983/10000 Iteration: 34882 Train loss: 0.008046\n",
      "Epoch: 4984/10000 Iteration: 34889 Train loss: 0.008046\n",
      "Epoch: 4985/10000 Iteration: 34896 Train loss: 0.008046\n",
      "Epoch: 4986/10000 Iteration: 34903 Train loss: 0.008046\n",
      "Epoch: 4987/10000 Iteration: 34910 Train loss: 0.008046\n",
      "Epoch: 4988/10000 Iteration: 34917 Train loss: 0.008046\n",
      "Epoch: 4989/10000 Iteration: 34924 Train loss: 0.008045\n",
      "Epoch: 4990/10000 Iteration: 34931 Train loss: 0.008045\n",
      "Epoch: 4991/10000 Iteration: 34938 Train loss: 0.008045\n",
      "Epoch: 4992/10000 Iteration: 34945 Train loss: 0.008045\n",
      "Epoch: 4993/10000 Iteration: 34952 Train loss: 0.008045\n",
      "Epoch: 4994/10000 Iteration: 34959 Train loss: 0.008045\n",
      "Epoch: 4995/10000 Iteration: 34966 Train loss: 0.008045\n",
      "Epoch: 4996/10000 Iteration: 34973 Train loss: 0.008045\n",
      "Epoch: 4997/10000 Iteration: 34980 Train loss: 0.008045\n",
      "Epoch: 4998/10000 Iteration: 34987 Train loss: 0.008045\n",
      "Epoch: 4999/10000 Iteration: 34994 Train loss: 0.008044\n",
      "Epoch: 5000/10000 Iteration: 35001 Train loss: 0.008044\n",
      "Epoch: 5001/10000 Iteration: 35008 Train loss: 0.008044\n",
      "Epoch: 5002/10000 Iteration: 35015 Train loss: 0.008044\n",
      "Epoch: 5003/10000 Iteration: 35022 Train loss: 0.008044\n",
      "Epoch: 5004/10000 Iteration: 35029 Train loss: 0.008044\n",
      "Epoch: 5005/10000 Iteration: 35036 Train loss: 0.008044\n",
      "Epoch: 5006/10000 Iteration: 35043 Train loss: 0.008044\n",
      "Epoch: 5007/10000 Iteration: 35050 Train loss: 0.008044\n",
      "Epoch: 5008/10000 Iteration: 35057 Train loss: 0.008043\n",
      "Epoch: 5009/10000 Iteration: 35064 Train loss: 0.008043\n",
      "Epoch: 5010/10000 Iteration: 35071 Train loss: 0.008043\n",
      "Epoch: 5011/10000 Iteration: 35078 Train loss: 0.008043\n",
      "Epoch: 5012/10000 Iteration: 35085 Train loss: 0.008043\n",
      "Epoch: 5013/10000 Iteration: 35092 Train loss: 0.008043\n",
      "Epoch: 5014/10000 Iteration: 35099 Train loss: 0.008043\n",
      "Epoch: 5015/10000 Iteration: 35106 Train loss: 0.008043\n",
      "Epoch: 5016/10000 Iteration: 35113 Train loss: 0.008043\n",
      "Epoch: 5017/10000 Iteration: 35120 Train loss: 0.008043\n",
      "Epoch: 5018/10000 Iteration: 35127 Train loss: 0.008042\n",
      "Epoch: 5019/10000 Iteration: 35134 Train loss: 0.008042\n",
      "Epoch: 5020/10000 Iteration: 35141 Train loss: 0.008042\n",
      "Epoch: 5021/10000 Iteration: 35148 Train loss: 0.008042\n",
      "Epoch: 5022/10000 Iteration: 35155 Train loss: 0.008042\n",
      "Epoch: 5023/10000 Iteration: 35162 Train loss: 0.008042\n",
      "Epoch: 5024/10000 Iteration: 35169 Train loss: 0.008042\n",
      "Epoch: 5025/10000 Iteration: 35176 Train loss: 0.008042\n",
      "Epoch: 5026/10000 Iteration: 35183 Train loss: 0.008042\n",
      "Epoch: 5027/10000 Iteration: 35190 Train loss: 0.008041\n",
      "Epoch: 5028/10000 Iteration: 35197 Train loss: 0.008041\n",
      "Epoch: 5029/10000 Iteration: 35204 Train loss: 0.008041\n",
      "Epoch: 5030/10000 Iteration: 35211 Train loss: 0.008041\n",
      "Epoch: 5031/10000 Iteration: 35218 Train loss: 0.008041\n",
      "Epoch: 5032/10000 Iteration: 35225 Train loss: 0.008041\n",
      "Epoch: 5033/10000 Iteration: 35232 Train loss: 0.008041\n",
      "Epoch: 5034/10000 Iteration: 35239 Train loss: 0.008041\n",
      "Epoch: 5035/10000 Iteration: 35246 Train loss: 0.008041\n",
      "Epoch: 5036/10000 Iteration: 35253 Train loss: 0.008040\n",
      "Epoch: 5037/10000 Iteration: 35260 Train loss: 0.008040\n",
      "Epoch: 5038/10000 Iteration: 35267 Train loss: 0.008040\n",
      "Epoch: 5039/10000 Iteration: 35274 Train loss: 0.008040\n",
      "Epoch: 5040/10000 Iteration: 35281 Train loss: 0.008040\n",
      "Epoch: 5041/10000 Iteration: 35288 Train loss: 0.008040\n",
      "Epoch: 5042/10000 Iteration: 35295 Train loss: 0.008040\n",
      "Epoch: 5043/10000 Iteration: 35302 Train loss: 0.008040\n",
      "Epoch: 5044/10000 Iteration: 35309 Train loss: 0.008039\n",
      "Epoch: 5045/10000 Iteration: 35316 Train loss: 0.008039\n",
      "Epoch: 5046/10000 Iteration: 35323 Train loss: 0.008039\n",
      "Epoch: 5047/10000 Iteration: 35330 Train loss: 0.008039\n",
      "Epoch: 5048/10000 Iteration: 35337 Train loss: 0.008039\n",
      "Epoch: 5049/10000 Iteration: 35344 Train loss: 0.008039\n",
      "Epoch: 5050/10000 Iteration: 35351 Train loss: 0.008039\n",
      "Epoch: 5051/10000 Iteration: 35358 Train loss: 0.008039\n",
      "Epoch: 5052/10000 Iteration: 35365 Train loss: 0.008039\n",
      "Epoch: 5053/10000 Iteration: 35372 Train loss: 0.008038\n",
      "Epoch: 5054/10000 Iteration: 35379 Train loss: 0.008038\n",
      "Epoch: 5055/10000 Iteration: 35386 Train loss: 0.008038\n",
      "Epoch: 5056/10000 Iteration: 35393 Train loss: 0.008038\n",
      "Epoch: 5057/10000 Iteration: 35400 Train loss: 0.008038\n",
      "Epoch: 5058/10000 Iteration: 35407 Train loss: 0.008038\n",
      "Epoch: 5059/10000 Iteration: 35414 Train loss: 0.008038\n",
      "Epoch: 5060/10000 Iteration: 35421 Train loss: 0.008038\n",
      "Epoch: 5061/10000 Iteration: 35428 Train loss: 0.008038\n",
      "Epoch: 5062/10000 Iteration: 35435 Train loss: 0.008037\n",
      "Epoch: 5063/10000 Iteration: 35442 Train loss: 0.008037\n",
      "Epoch: 5064/10000 Iteration: 35449 Train loss: 0.008037\n",
      "Epoch: 5065/10000 Iteration: 35456 Train loss: 0.008037\n",
      "Epoch: 5066/10000 Iteration: 35463 Train loss: 0.008037\n",
      "Epoch: 5067/10000 Iteration: 35470 Train loss: 0.008037\n",
      "Epoch: 5068/10000 Iteration: 35477 Train loss: 0.008037\n",
      "Epoch: 5069/10000 Iteration: 35484 Train loss: 0.008037\n",
      "Epoch: 5070/10000 Iteration: 35491 Train loss: 0.008036\n",
      "Epoch: 5071/10000 Iteration: 35498 Train loss: 0.008036\n",
      "Epoch: 5072/10000 Iteration: 35505 Train loss: 0.008036\n",
      "Epoch: 5073/10000 Iteration: 35512 Train loss: 0.008036\n",
      "Epoch: 5074/10000 Iteration: 35519 Train loss: 0.008036\n",
      "Epoch: 5075/10000 Iteration: 35526 Train loss: 0.008036\n",
      "Epoch: 5076/10000 Iteration: 35533 Train loss: 0.008036\n",
      "Epoch: 5077/10000 Iteration: 35540 Train loss: 0.008036\n",
      "Epoch: 5078/10000 Iteration: 35547 Train loss: 0.008035\n",
      "Epoch: 5079/10000 Iteration: 35554 Train loss: 0.008035\n",
      "Epoch: 5080/10000 Iteration: 35561 Train loss: 0.008035\n",
      "Epoch: 5081/10000 Iteration: 35568 Train loss: 0.008035\n",
      "Epoch: 5082/10000 Iteration: 35575 Train loss: 0.008035\n",
      "Epoch: 5083/10000 Iteration: 35582 Train loss: 0.008035\n",
      "Epoch: 5084/10000 Iteration: 35589 Train loss: 0.008035\n",
      "Epoch: 5085/10000 Iteration: 35596 Train loss: 0.008035\n",
      "Epoch: 5086/10000 Iteration: 35603 Train loss: 0.008034\n",
      "Epoch: 5087/10000 Iteration: 35610 Train loss: 0.008034\n",
      "Epoch: 5088/10000 Iteration: 35617 Train loss: 0.008034\n",
      "Epoch: 5089/10000 Iteration: 35624 Train loss: 0.008034\n",
      "Epoch: 5090/10000 Iteration: 35631 Train loss: 0.008034\n",
      "Epoch: 5091/10000 Iteration: 35638 Train loss: 0.008034\n",
      "Epoch: 5092/10000 Iteration: 35645 Train loss: 0.008034\n",
      "Epoch: 5093/10000 Iteration: 35652 Train loss: 0.008034\n",
      "Epoch: 5094/10000 Iteration: 35659 Train loss: 0.008033\n",
      "Epoch: 5095/10000 Iteration: 35666 Train loss: 0.008033\n",
      "Epoch: 5096/10000 Iteration: 35673 Train loss: 0.008033\n",
      "Epoch: 5097/10000 Iteration: 35680 Train loss: 0.008033\n",
      "Epoch: 5098/10000 Iteration: 35687 Train loss: 0.008033\n",
      "Epoch: 5099/10000 Iteration: 35694 Train loss: 0.008033\n",
      "Epoch: 5100/10000 Iteration: 35701 Train loss: 0.008033\n",
      "Epoch: 5101/10000 Iteration: 35708 Train loss: 0.008033\n",
      "Epoch: 5102/10000 Iteration: 35715 Train loss: 0.008032\n",
      "Epoch: 5103/10000 Iteration: 35722 Train loss: 0.008032\n",
      "Epoch: 5104/10000 Iteration: 35729 Train loss: 0.008032\n",
      "Epoch: 5105/10000 Iteration: 35736 Train loss: 0.008032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5106/10000 Iteration: 35743 Train loss: 0.008032\n",
      "Epoch: 5107/10000 Iteration: 35750 Train loss: 0.008032\n",
      "Epoch: 5108/10000 Iteration: 35757 Train loss: 0.008032\n",
      "Epoch: 5109/10000 Iteration: 35764 Train loss: 0.008031\n",
      "Epoch: 5110/10000 Iteration: 35771 Train loss: 0.008031\n",
      "Epoch: 5111/10000 Iteration: 35778 Train loss: 0.008031\n",
      "Epoch: 5112/10000 Iteration: 35785 Train loss: 0.008031\n",
      "Epoch: 5113/10000 Iteration: 35792 Train loss: 0.008031\n",
      "Epoch: 5114/10000 Iteration: 35799 Train loss: 0.008031\n",
      "Epoch: 5115/10000 Iteration: 35806 Train loss: 0.008031\n",
      "Epoch: 5116/10000 Iteration: 35813 Train loss: 0.008031\n",
      "Epoch: 5117/10000 Iteration: 35820 Train loss: 0.008030\n",
      "Epoch: 5118/10000 Iteration: 35827 Train loss: 0.008030\n",
      "Epoch: 5119/10000 Iteration: 35834 Train loss: 0.008030\n",
      "Epoch: 5120/10000 Iteration: 35841 Train loss: 0.008030\n",
      "Epoch: 5121/10000 Iteration: 35848 Train loss: 0.008030\n",
      "Epoch: 5122/10000 Iteration: 35855 Train loss: 0.008030\n",
      "Epoch: 5123/10000 Iteration: 35862 Train loss: 0.008030\n",
      "Epoch: 5124/10000 Iteration: 35869 Train loss: 0.008029\n",
      "Epoch: 5125/10000 Iteration: 35876 Train loss: 0.008029\n",
      "Epoch: 5126/10000 Iteration: 35883 Train loss: 0.008029\n",
      "Epoch: 5127/10000 Iteration: 35890 Train loss: 0.008029\n",
      "Epoch: 5128/10000 Iteration: 35897 Train loss: 0.008029\n",
      "Epoch: 5129/10000 Iteration: 35904 Train loss: 0.008029\n",
      "Epoch: 5130/10000 Iteration: 35911 Train loss: 0.008029\n",
      "Epoch: 5131/10000 Iteration: 35918 Train loss: 0.008029\n",
      "Epoch: 5132/10000 Iteration: 35925 Train loss: 0.008028\n",
      "Epoch: 5133/10000 Iteration: 35932 Train loss: 0.008028\n",
      "Epoch: 5134/10000 Iteration: 35939 Train loss: 0.008028\n",
      "Epoch: 5135/10000 Iteration: 35946 Train loss: 0.008028\n",
      "Epoch: 5136/10000 Iteration: 35953 Train loss: 0.008028\n",
      "Epoch: 5137/10000 Iteration: 35960 Train loss: 0.008028\n",
      "Epoch: 5138/10000 Iteration: 35967 Train loss: 0.008028\n",
      "Epoch: 5139/10000 Iteration: 35974 Train loss: 0.008027\n",
      "Epoch: 5140/10000 Iteration: 35981 Train loss: 0.008027\n",
      "Epoch: 5141/10000 Iteration: 35988 Train loss: 0.008027\n",
      "Epoch: 5142/10000 Iteration: 35995 Train loss: 0.008027\n",
      "Epoch: 5143/10000 Iteration: 36002 Train loss: 0.008027\n",
      "Epoch: 5144/10000 Iteration: 36009 Train loss: 0.008027\n",
      "Epoch: 5145/10000 Iteration: 36016 Train loss: 0.008027\n",
      "Epoch: 5146/10000 Iteration: 36023 Train loss: 0.008026\n",
      "Epoch: 5147/10000 Iteration: 36030 Train loss: 0.008026\n",
      "Epoch: 5148/10000 Iteration: 36037 Train loss: 0.008026\n",
      "Epoch: 5149/10000 Iteration: 36044 Train loss: 0.008026\n",
      "Epoch: 5150/10000 Iteration: 36051 Train loss: 0.008026\n",
      "Epoch: 5151/10000 Iteration: 36058 Train loss: 0.008026\n",
      "Epoch: 5152/10000 Iteration: 36065 Train loss: 0.008026\n",
      "Epoch: 5153/10000 Iteration: 36072 Train loss: 0.008025\n",
      "Epoch: 5154/10000 Iteration: 36079 Train loss: 0.008025\n",
      "Epoch: 5155/10000 Iteration: 36086 Train loss: 0.008025\n",
      "Epoch: 5156/10000 Iteration: 36093 Train loss: 0.008025\n",
      "Epoch: 5157/10000 Iteration: 36100 Train loss: 0.008025\n",
      "Epoch: 5158/10000 Iteration: 36107 Train loss: 0.008025\n",
      "Epoch: 5159/10000 Iteration: 36114 Train loss: 0.008025\n",
      "Epoch: 5160/10000 Iteration: 36121 Train loss: 0.008024\n",
      "Epoch: 5161/10000 Iteration: 36128 Train loss: 0.008024\n",
      "Epoch: 5162/10000 Iteration: 36135 Train loss: 0.008024\n",
      "Epoch: 5163/10000 Iteration: 36142 Train loss: 0.008024\n",
      "Epoch: 5164/10000 Iteration: 36149 Train loss: 0.008024\n",
      "Epoch: 5165/10000 Iteration: 36156 Train loss: 0.008024\n",
      "Epoch: 5166/10000 Iteration: 36163 Train loss: 0.008024\n",
      "Epoch: 5167/10000 Iteration: 36170 Train loss: 0.008023\n",
      "Epoch: 5168/10000 Iteration: 36177 Train loss: 0.008023\n",
      "Epoch: 5169/10000 Iteration: 36184 Train loss: 0.008023\n",
      "Epoch: 5170/10000 Iteration: 36191 Train loss: 0.008023\n",
      "Epoch: 5171/10000 Iteration: 36198 Train loss: 0.008023\n",
      "Epoch: 5172/10000 Iteration: 36205 Train loss: 0.008023\n",
      "Epoch: 5173/10000 Iteration: 36212 Train loss: 0.008023\n",
      "Epoch: 5174/10000 Iteration: 36219 Train loss: 0.008022\n",
      "Epoch: 5175/10000 Iteration: 36226 Train loss: 0.008022\n",
      "Epoch: 5176/10000 Iteration: 36233 Train loss: 0.008022\n",
      "Epoch: 5177/10000 Iteration: 36240 Train loss: 0.008022\n",
      "Epoch: 5178/10000 Iteration: 36247 Train loss: 0.008022\n",
      "Epoch: 5179/10000 Iteration: 36254 Train loss: 0.008022\n",
      "Epoch: 5180/10000 Iteration: 36261 Train loss: 0.008022\n",
      "Epoch: 5181/10000 Iteration: 36268 Train loss: 0.008021\n",
      "Epoch: 5182/10000 Iteration: 36275 Train loss: 0.008021\n",
      "Epoch: 5183/10000 Iteration: 36282 Train loss: 0.008021\n",
      "Epoch: 5184/10000 Iteration: 36289 Train loss: 0.008021\n",
      "Epoch: 5185/10000 Iteration: 36296 Train loss: 0.008021\n",
      "Epoch: 5186/10000 Iteration: 36303 Train loss: 0.008021\n",
      "Epoch: 5187/10000 Iteration: 36310 Train loss: 0.008021\n",
      "Epoch: 5188/10000 Iteration: 36317 Train loss: 0.008020\n",
      "Epoch: 5189/10000 Iteration: 36324 Train loss: 0.008020\n",
      "Epoch: 5190/10000 Iteration: 36331 Train loss: 0.008020\n",
      "Epoch: 5191/10000 Iteration: 36338 Train loss: 0.008020\n",
      "Epoch: 5192/10000 Iteration: 36345 Train loss: 0.008020\n",
      "Epoch: 5193/10000 Iteration: 36352 Train loss: 0.008020\n",
      "Epoch: 5194/10000 Iteration: 36359 Train loss: 0.008020\n",
      "Epoch: 5195/10000 Iteration: 36366 Train loss: 0.008019\n",
      "Epoch: 5196/10000 Iteration: 36373 Train loss: 0.008019\n",
      "Epoch: 5197/10000 Iteration: 36380 Train loss: 0.008019\n",
      "Epoch: 5198/10000 Iteration: 36387 Train loss: 0.008019\n",
      "Epoch: 5199/10000 Iteration: 36394 Train loss: 0.008019\n",
      "Epoch: 5200/10000 Iteration: 36401 Train loss: 0.008019\n",
      "Epoch: 5201/10000 Iteration: 36408 Train loss: 0.008018\n",
      "Epoch: 5202/10000 Iteration: 36415 Train loss: 0.008018\n",
      "Epoch: 5203/10000 Iteration: 36422 Train loss: 0.008018\n",
      "Epoch: 5204/10000 Iteration: 36429 Train loss: 0.008018\n",
      "Epoch: 5205/10000 Iteration: 36436 Train loss: 0.008018\n",
      "Epoch: 5206/10000 Iteration: 36443 Train loss: 0.008018\n",
      "Epoch: 5207/10000 Iteration: 36450 Train loss: 0.008018\n",
      "Epoch: 5208/10000 Iteration: 36457 Train loss: 0.008017\n",
      "Epoch: 5209/10000 Iteration: 36464 Train loss: 0.008017\n",
      "Epoch: 5210/10000 Iteration: 36471 Train loss: 0.008017\n",
      "Epoch: 5211/10000 Iteration: 36478 Train loss: 0.008017\n",
      "Epoch: 5212/10000 Iteration: 36485 Train loss: 0.008017\n",
      "Epoch: 5213/10000 Iteration: 36492 Train loss: 0.008017\n",
      "Epoch: 5214/10000 Iteration: 36499 Train loss: 0.008016\n",
      "Epoch: 5215/10000 Iteration: 36506 Train loss: 0.008016\n",
      "Epoch: 5216/10000 Iteration: 36513 Train loss: 0.008016\n",
      "Epoch: 5217/10000 Iteration: 36520 Train loss: 0.008016\n",
      "Epoch: 5218/10000 Iteration: 36527 Train loss: 0.008016\n",
      "Epoch: 5219/10000 Iteration: 36534 Train loss: 0.008016\n",
      "Epoch: 5220/10000 Iteration: 36541 Train loss: 0.008016\n",
      "Epoch: 5221/10000 Iteration: 36548 Train loss: 0.008015\n",
      "Epoch: 5222/10000 Iteration: 36555 Train loss: 0.008015\n",
      "Epoch: 5223/10000 Iteration: 36562 Train loss: 0.008015\n",
      "Epoch: 5224/10000 Iteration: 36569 Train loss: 0.008015\n",
      "Epoch: 5225/10000 Iteration: 36576 Train loss: 0.008015\n",
      "Epoch: 5226/10000 Iteration: 36583 Train loss: 0.008015\n",
      "Epoch: 5227/10000 Iteration: 36590 Train loss: 0.008014\n",
      "Epoch: 5228/10000 Iteration: 36597 Train loss: 0.008014\n",
      "Epoch: 5229/10000 Iteration: 36604 Train loss: 0.008014\n",
      "Epoch: 5230/10000 Iteration: 36611 Train loss: 0.008014\n",
      "Epoch: 5231/10000 Iteration: 36618 Train loss: 0.008014\n",
      "Epoch: 5232/10000 Iteration: 36625 Train loss: 0.008014\n",
      "Epoch: 5233/10000 Iteration: 36632 Train loss: 0.008014\n",
      "Epoch: 5234/10000 Iteration: 36639 Train loss: 0.008013\n",
      "Epoch: 5235/10000 Iteration: 36646 Train loss: 0.008013\n",
      "Epoch: 5236/10000 Iteration: 36653 Train loss: 0.008013\n",
      "Epoch: 5237/10000 Iteration: 36660 Train loss: 0.008013\n",
      "Epoch: 5238/10000 Iteration: 36667 Train loss: 0.008013\n",
      "Epoch: 5239/10000 Iteration: 36674 Train loss: 0.008013\n",
      "Epoch: 5240/10000 Iteration: 36681 Train loss: 0.008012\n",
      "Epoch: 5241/10000 Iteration: 36688 Train loss: 0.008012\n",
      "Epoch: 5242/10000 Iteration: 36695 Train loss: 0.008012\n",
      "Epoch: 5243/10000 Iteration: 36702 Train loss: 0.008012\n",
      "Epoch: 5244/10000 Iteration: 36709 Train loss: 0.008012\n",
      "Epoch: 5245/10000 Iteration: 36716 Train loss: 0.008012\n",
      "Epoch: 5246/10000 Iteration: 36723 Train loss: 0.008011\n",
      "Epoch: 5247/10000 Iteration: 36730 Train loss: 0.008011\n",
      "Epoch: 5248/10000 Iteration: 36737 Train loss: 0.008011\n",
      "Epoch: 5249/10000 Iteration: 36744 Train loss: 0.008011\n",
      "Epoch: 5250/10000 Iteration: 36751 Train loss: 0.008011\n",
      "Epoch: 5251/10000 Iteration: 36758 Train loss: 0.008011\n",
      "Epoch: 5252/10000 Iteration: 36765 Train loss: 0.008011\n",
      "Epoch: 5253/10000 Iteration: 36772 Train loss: 0.008010\n",
      "Epoch: 5254/10000 Iteration: 36779 Train loss: 0.008010\n",
      "Epoch: 5255/10000 Iteration: 36786 Train loss: 0.008010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5256/10000 Iteration: 36793 Train loss: 0.008010\n",
      "Epoch: 5257/10000 Iteration: 36800 Train loss: 0.008010\n",
      "Epoch: 5258/10000 Iteration: 36807 Train loss: 0.008010\n",
      "Epoch: 5259/10000 Iteration: 36814 Train loss: 0.008009\n",
      "Epoch: 5260/10000 Iteration: 36821 Train loss: 0.008009\n",
      "Epoch: 5261/10000 Iteration: 36828 Train loss: 0.008009\n",
      "Epoch: 5262/10000 Iteration: 36835 Train loss: 0.008009\n",
      "Epoch: 5263/10000 Iteration: 36842 Train loss: 0.008009\n",
      "Epoch: 5264/10000 Iteration: 36849 Train loss: 0.008009\n",
      "Epoch: 5265/10000 Iteration: 36856 Train loss: 0.008008\n",
      "Epoch: 5266/10000 Iteration: 36863 Train loss: 0.008008\n",
      "Epoch: 5267/10000 Iteration: 36870 Train loss: 0.008008\n",
      "Epoch: 5268/10000 Iteration: 36877 Train loss: 0.008008\n",
      "Epoch: 5269/10000 Iteration: 36884 Train loss: 0.008008\n",
      "Epoch: 5270/10000 Iteration: 36891 Train loss: 0.008008\n",
      "Epoch: 5271/10000 Iteration: 36898 Train loss: 0.008007\n",
      "Epoch: 5272/10000 Iteration: 36905 Train loss: 0.008007\n",
      "Epoch: 5273/10000 Iteration: 36912 Train loss: 0.008007\n",
      "Epoch: 5274/10000 Iteration: 36919 Train loss: 0.008007\n",
      "Epoch: 5275/10000 Iteration: 36926 Train loss: 0.008007\n",
      "Epoch: 5276/10000 Iteration: 36933 Train loss: 0.008007\n",
      "Epoch: 5277/10000 Iteration: 36940 Train loss: 0.008006\n",
      "Epoch: 5278/10000 Iteration: 36947 Train loss: 0.008006\n",
      "Epoch: 5279/10000 Iteration: 36954 Train loss: 0.008006\n",
      "Epoch: 5280/10000 Iteration: 36961 Train loss: 0.008006\n",
      "Epoch: 5281/10000 Iteration: 36968 Train loss: 0.008006\n",
      "Epoch: 5282/10000 Iteration: 36975 Train loss: 0.008006\n",
      "Epoch: 5283/10000 Iteration: 36982 Train loss: 0.008005\n",
      "Epoch: 5284/10000 Iteration: 36989 Train loss: 0.008005\n",
      "Epoch: 5285/10000 Iteration: 36996 Train loss: 0.008005\n",
      "Epoch: 5286/10000 Iteration: 37003 Train loss: 0.008005\n",
      "Epoch: 5287/10000 Iteration: 37010 Train loss: 0.008005\n",
      "Epoch: 5288/10000 Iteration: 37017 Train loss: 0.008005\n",
      "Epoch: 5289/10000 Iteration: 37024 Train loss: 0.008004\n",
      "Epoch: 5290/10000 Iteration: 37031 Train loss: 0.008004\n",
      "Epoch: 5291/10000 Iteration: 37038 Train loss: 0.008004\n",
      "Epoch: 5292/10000 Iteration: 37045 Train loss: 0.008004\n",
      "Epoch: 5293/10000 Iteration: 37052 Train loss: 0.008004\n",
      "Epoch: 5294/10000 Iteration: 37059 Train loss: 0.008004\n",
      "Epoch: 5295/10000 Iteration: 37066 Train loss: 0.008003\n",
      "Epoch: 5296/10000 Iteration: 37073 Train loss: 0.008003\n",
      "Epoch: 5297/10000 Iteration: 37080 Train loss: 0.008003\n",
      "Epoch: 5298/10000 Iteration: 37087 Train loss: 0.008003\n",
      "Epoch: 5299/10000 Iteration: 37094 Train loss: 0.008003\n",
      "Epoch: 5300/10000 Iteration: 37101 Train loss: 0.008003\n",
      "Epoch: 5301/10000 Iteration: 37108 Train loss: 0.008002\n",
      "Epoch: 5302/10000 Iteration: 37115 Train loss: 0.008002\n",
      "Epoch: 5303/10000 Iteration: 37122 Train loss: 0.008002\n",
      "Epoch: 5304/10000 Iteration: 37129 Train loss: 0.008002\n",
      "Epoch: 5305/10000 Iteration: 37136 Train loss: 0.008002\n",
      "Epoch: 5306/10000 Iteration: 37143 Train loss: 0.008002\n",
      "Epoch: 5307/10000 Iteration: 37150 Train loss: 0.008001\n",
      "Epoch: 5308/10000 Iteration: 37157 Train loss: 0.008001\n",
      "Epoch: 5309/10000 Iteration: 37164 Train loss: 0.008001\n",
      "Epoch: 5310/10000 Iteration: 37171 Train loss: 0.008001\n",
      "Epoch: 5311/10000 Iteration: 37178 Train loss: 0.008001\n",
      "Epoch: 5312/10000 Iteration: 37185 Train loss: 0.008001\n",
      "Epoch: 5313/10000 Iteration: 37192 Train loss: 0.008000\n",
      "Epoch: 5314/10000 Iteration: 37199 Train loss: 0.008000\n",
      "Epoch: 5315/10000 Iteration: 37206 Train loss: 0.008000\n",
      "Epoch: 5316/10000 Iteration: 37213 Train loss: 0.008000\n",
      "Epoch: 5317/10000 Iteration: 37220 Train loss: 0.008000\n",
      "Epoch: 5318/10000 Iteration: 37227 Train loss: 0.008000\n",
      "Epoch: 5319/10000 Iteration: 37234 Train loss: 0.007999\n",
      "Epoch: 5320/10000 Iteration: 37241 Train loss: 0.007999\n",
      "Epoch: 5321/10000 Iteration: 37248 Train loss: 0.007999\n",
      "Epoch: 5322/10000 Iteration: 37255 Train loss: 0.007999\n",
      "Epoch: 5323/10000 Iteration: 37262 Train loss: 0.007999\n",
      "Epoch: 5324/10000 Iteration: 37269 Train loss: 0.007999\n",
      "Epoch: 5325/10000 Iteration: 37276 Train loss: 0.007998\n",
      "Epoch: 5326/10000 Iteration: 37283 Train loss: 0.007998\n",
      "Epoch: 5327/10000 Iteration: 37290 Train loss: 0.007998\n",
      "Epoch: 5328/10000 Iteration: 37297 Train loss: 0.007998\n",
      "Epoch: 5329/10000 Iteration: 37304 Train loss: 0.007998\n",
      "Epoch: 5330/10000 Iteration: 37311 Train loss: 0.007998\n",
      "Epoch: 5331/10000 Iteration: 37318 Train loss: 0.007997\n",
      "Epoch: 5332/10000 Iteration: 37325 Train loss: 0.007997\n",
      "Epoch: 5333/10000 Iteration: 37332 Train loss: 0.007997\n",
      "Epoch: 5334/10000 Iteration: 37339 Train loss: 0.007997\n",
      "Epoch: 5335/10000 Iteration: 37346 Train loss: 0.007997\n",
      "Epoch: 5336/10000 Iteration: 37353 Train loss: 0.007996\n",
      "Epoch: 5337/10000 Iteration: 37360 Train loss: 0.007996\n",
      "Epoch: 5338/10000 Iteration: 37367 Train loss: 0.007996\n",
      "Epoch: 5339/10000 Iteration: 37374 Train loss: 0.007996\n",
      "Epoch: 5340/10000 Iteration: 37381 Train loss: 0.007996\n",
      "Epoch: 5341/10000 Iteration: 37388 Train loss: 0.007996\n",
      "Epoch: 5342/10000 Iteration: 37395 Train loss: 0.007995\n",
      "Epoch: 5343/10000 Iteration: 37402 Train loss: 0.007995\n",
      "Epoch: 5344/10000 Iteration: 37409 Train loss: 0.007995\n",
      "Epoch: 5345/10000 Iteration: 37416 Train loss: 0.007995\n",
      "Epoch: 5346/10000 Iteration: 37423 Train loss: 0.007995\n",
      "Epoch: 5347/10000 Iteration: 37430 Train loss: 0.007995\n",
      "Epoch: 5348/10000 Iteration: 37437 Train loss: 0.007994\n",
      "Epoch: 5349/10000 Iteration: 37444 Train loss: 0.007994\n",
      "Epoch: 5350/10000 Iteration: 37451 Train loss: 0.007994\n",
      "Epoch: 5351/10000 Iteration: 37458 Train loss: 0.007994\n",
      "Epoch: 5352/10000 Iteration: 37465 Train loss: 0.007994\n",
      "Epoch: 5353/10000 Iteration: 37472 Train loss: 0.007994\n",
      "Epoch: 5354/10000 Iteration: 37479 Train loss: 0.007993\n",
      "Epoch: 5355/10000 Iteration: 37486 Train loss: 0.007993\n",
      "Epoch: 5356/10000 Iteration: 37493 Train loss: 0.007993\n",
      "Epoch: 5357/10000 Iteration: 37500 Train loss: 0.007993\n",
      "Epoch: 5358/10000 Iteration: 37507 Train loss: 0.007993\n",
      "Epoch: 5359/10000 Iteration: 37514 Train loss: 0.007992\n",
      "Epoch: 5360/10000 Iteration: 37521 Train loss: 0.007992\n",
      "Epoch: 5361/10000 Iteration: 37528 Train loss: 0.007992\n",
      "Epoch: 5362/10000 Iteration: 37535 Train loss: 0.007992\n",
      "Epoch: 5363/10000 Iteration: 37542 Train loss: 0.007992\n",
      "Epoch: 5364/10000 Iteration: 37549 Train loss: 0.007992\n",
      "Epoch: 5365/10000 Iteration: 37556 Train loss: 0.007991\n",
      "Epoch: 5366/10000 Iteration: 37563 Train loss: 0.007991\n",
      "Epoch: 5367/10000 Iteration: 37570 Train loss: 0.007991\n",
      "Epoch: 5368/10000 Iteration: 37577 Train loss: 0.007991\n",
      "Epoch: 5369/10000 Iteration: 37584 Train loss: 0.007991\n",
      "Epoch: 5370/10000 Iteration: 37591 Train loss: 0.007990\n",
      "Epoch: 5371/10000 Iteration: 37598 Train loss: 0.007990\n",
      "Epoch: 5372/10000 Iteration: 37605 Train loss: 0.007990\n",
      "Epoch: 5373/10000 Iteration: 37612 Train loss: 0.007990\n",
      "Epoch: 5374/10000 Iteration: 37619 Train loss: 0.007990\n",
      "Epoch: 5375/10000 Iteration: 37626 Train loss: 0.007990\n",
      "Epoch: 5376/10000 Iteration: 37633 Train loss: 0.007989\n",
      "Epoch: 5377/10000 Iteration: 37640 Train loss: 0.007989\n",
      "Epoch: 5378/10000 Iteration: 37647 Train loss: 0.007989\n",
      "Epoch: 5379/10000 Iteration: 37654 Train loss: 0.007989\n",
      "Epoch: 5380/10000 Iteration: 37661 Train loss: 0.007989\n",
      "Epoch: 5381/10000 Iteration: 37668 Train loss: 0.007989\n",
      "Epoch: 5382/10000 Iteration: 37675 Train loss: 0.007988\n",
      "Epoch: 5383/10000 Iteration: 37682 Train loss: 0.007988\n",
      "Epoch: 5384/10000 Iteration: 37689 Train loss: 0.007988\n",
      "Epoch: 5385/10000 Iteration: 37696 Train loss: 0.007988\n",
      "Epoch: 5386/10000 Iteration: 37703 Train loss: 0.007988\n",
      "Epoch: 5387/10000 Iteration: 37710 Train loss: 0.007987\n",
      "Epoch: 5388/10000 Iteration: 37717 Train loss: 0.007987\n",
      "Epoch: 5389/10000 Iteration: 37724 Train loss: 0.007987\n",
      "Epoch: 5390/10000 Iteration: 37731 Train loss: 0.007987\n",
      "Epoch: 5391/10000 Iteration: 37738 Train loss: 0.007987\n",
      "Epoch: 5392/10000 Iteration: 37745 Train loss: 0.007987\n",
      "Epoch: 5393/10000 Iteration: 37752 Train loss: 0.007986\n",
      "Epoch: 5394/10000 Iteration: 37759 Train loss: 0.007986\n",
      "Epoch: 5395/10000 Iteration: 37766 Train loss: 0.007986\n",
      "Epoch: 5396/10000 Iteration: 37773 Train loss: 0.007986\n",
      "Epoch: 5397/10000 Iteration: 37780 Train loss: 0.007986\n",
      "Epoch: 5398/10000 Iteration: 37787 Train loss: 0.007985\n",
      "Epoch: 5399/10000 Iteration: 37794 Train loss: 0.007985\n",
      "Epoch: 5400/10000 Iteration: 37801 Train loss: 0.007985\n",
      "Epoch: 5401/10000 Iteration: 37808 Train loss: 0.007985\n",
      "Epoch: 5402/10000 Iteration: 37815 Train loss: 0.007985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5403/10000 Iteration: 37822 Train loss: 0.007985\n",
      "Epoch: 5404/10000 Iteration: 37829 Train loss: 0.007984\n",
      "Epoch: 5405/10000 Iteration: 37836 Train loss: 0.007984\n",
      "Epoch: 5406/10000 Iteration: 37843 Train loss: 0.007984\n",
      "Epoch: 5407/10000 Iteration: 37850 Train loss: 0.007984\n",
      "Epoch: 5408/10000 Iteration: 37857 Train loss: 0.007984\n",
      "Epoch: 5409/10000 Iteration: 37864 Train loss: 0.007983\n",
      "Epoch: 5410/10000 Iteration: 37871 Train loss: 0.007983\n",
      "Epoch: 5411/10000 Iteration: 37878 Train loss: 0.007983\n",
      "Epoch: 5412/10000 Iteration: 37885 Train loss: 0.007983\n",
      "Epoch: 5413/10000 Iteration: 37892 Train loss: 0.007983\n",
      "Epoch: 5414/10000 Iteration: 37899 Train loss: 0.007983\n",
      "Epoch: 5415/10000 Iteration: 37906 Train loss: 0.007982\n",
      "Epoch: 5416/10000 Iteration: 37913 Train loss: 0.007982\n",
      "Epoch: 5417/10000 Iteration: 37920 Train loss: 0.007982\n",
      "Epoch: 5418/10000 Iteration: 37927 Train loss: 0.007982\n",
      "Epoch: 5419/10000 Iteration: 37934 Train loss: 0.007982\n",
      "Epoch: 5420/10000 Iteration: 37941 Train loss: 0.007981\n",
      "Epoch: 5421/10000 Iteration: 37948 Train loss: 0.007981\n",
      "Epoch: 5422/10000 Iteration: 37955 Train loss: 0.007981\n",
      "Epoch: 5423/10000 Iteration: 37962 Train loss: 0.007981\n",
      "Epoch: 5424/10000 Iteration: 37969 Train loss: 0.007981\n",
      "Epoch: 5425/10000 Iteration: 37976 Train loss: 0.007980\n",
      "Epoch: 5426/10000 Iteration: 37983 Train loss: 0.007980\n",
      "Epoch: 5427/10000 Iteration: 37990 Train loss: 0.007980\n",
      "Epoch: 5428/10000 Iteration: 37997 Train loss: 0.007980\n",
      "Epoch: 5429/10000 Iteration: 38004 Train loss: 0.007980\n",
      "Epoch: 5430/10000 Iteration: 38011 Train loss: 0.007980\n",
      "Epoch: 5431/10000 Iteration: 38018 Train loss: 0.007979\n",
      "Epoch: 5432/10000 Iteration: 38025 Train loss: 0.007979\n",
      "Epoch: 5433/10000 Iteration: 38032 Train loss: 0.007979\n",
      "Epoch: 5434/10000 Iteration: 38039 Train loss: 0.007979\n",
      "Epoch: 5435/10000 Iteration: 38046 Train loss: 0.007979\n",
      "Epoch: 5436/10000 Iteration: 38053 Train loss: 0.007978\n",
      "Epoch: 5437/10000 Iteration: 38060 Train loss: 0.007978\n",
      "Epoch: 5438/10000 Iteration: 38067 Train loss: 0.007978\n",
      "Epoch: 5439/10000 Iteration: 38074 Train loss: 0.007978\n",
      "Epoch: 5440/10000 Iteration: 38081 Train loss: 0.007978\n",
      "Epoch: 5441/10000 Iteration: 38088 Train loss: 0.007977\n",
      "Epoch: 5442/10000 Iteration: 38095 Train loss: 0.007977\n",
      "Epoch: 5443/10000 Iteration: 38102 Train loss: 0.007977\n",
      "Epoch: 5444/10000 Iteration: 38109 Train loss: 0.007977\n",
      "Epoch: 5445/10000 Iteration: 38116 Train loss: 0.007977\n",
      "Epoch: 5446/10000 Iteration: 38123 Train loss: 0.007977\n",
      "Epoch: 5447/10000 Iteration: 38130 Train loss: 0.007976\n",
      "Epoch: 5448/10000 Iteration: 38137 Train loss: 0.007976\n",
      "Epoch: 5449/10000 Iteration: 38144 Train loss: 0.007976\n",
      "Epoch: 5450/10000 Iteration: 38151 Train loss: 0.007976\n",
      "Epoch: 5451/10000 Iteration: 38158 Train loss: 0.007976\n",
      "Epoch: 5452/10000 Iteration: 38165 Train loss: 0.007975\n",
      "Epoch: 5453/10000 Iteration: 38172 Train loss: 0.007975\n",
      "Epoch: 5454/10000 Iteration: 38179 Train loss: 0.007975\n",
      "Epoch: 5455/10000 Iteration: 38186 Train loss: 0.007975\n",
      "Epoch: 5456/10000 Iteration: 38193 Train loss: 0.007975\n",
      "Epoch: 5457/10000 Iteration: 38200 Train loss: 0.007974\n",
      "Epoch: 5458/10000 Iteration: 38207 Train loss: 0.007974\n",
      "Epoch: 5459/10000 Iteration: 38214 Train loss: 0.007974\n",
      "Epoch: 5460/10000 Iteration: 38221 Train loss: 0.007974\n",
      "Epoch: 5461/10000 Iteration: 38228 Train loss: 0.007974\n",
      "Epoch: 5462/10000 Iteration: 38235 Train loss: 0.007974\n",
      "Epoch: 5463/10000 Iteration: 38242 Train loss: 0.007973\n",
      "Epoch: 5464/10000 Iteration: 38249 Train loss: 0.007973\n",
      "Epoch: 5465/10000 Iteration: 38256 Train loss: 0.007973\n",
      "Epoch: 5466/10000 Iteration: 38263 Train loss: 0.007973\n",
      "Epoch: 5467/10000 Iteration: 38270 Train loss: 0.007973\n",
      "Epoch: 5468/10000 Iteration: 38277 Train loss: 0.007972\n",
      "Epoch: 5469/10000 Iteration: 38284 Train loss: 0.007972\n",
      "Epoch: 5470/10000 Iteration: 38291 Train loss: 0.007972\n",
      "Epoch: 5471/10000 Iteration: 38298 Train loss: 0.007972\n",
      "Epoch: 5472/10000 Iteration: 38305 Train loss: 0.007972\n",
      "Epoch: 5473/10000 Iteration: 38312 Train loss: 0.007971\n",
      "Epoch: 5474/10000 Iteration: 38319 Train loss: 0.007971\n",
      "Epoch: 5475/10000 Iteration: 38326 Train loss: 0.007971\n",
      "Epoch: 5476/10000 Iteration: 38333 Train loss: 0.007971\n",
      "Epoch: 5477/10000 Iteration: 38340 Train loss: 0.007971\n",
      "Epoch: 5478/10000 Iteration: 38347 Train loss: 0.007970\n",
      "Epoch: 5479/10000 Iteration: 38354 Train loss: 0.007970\n",
      "Epoch: 5480/10000 Iteration: 38361 Train loss: 0.007970\n",
      "Epoch: 5481/10000 Iteration: 38368 Train loss: 0.007970\n",
      "Epoch: 5482/10000 Iteration: 38375 Train loss: 0.007970\n",
      "Epoch: 5483/10000 Iteration: 38382 Train loss: 0.007970\n",
      "Epoch: 5484/10000 Iteration: 38389 Train loss: 0.007969\n",
      "Epoch: 5485/10000 Iteration: 38396 Train loss: 0.007969\n",
      "Epoch: 5486/10000 Iteration: 38403 Train loss: 0.007969\n",
      "Epoch: 5487/10000 Iteration: 38410 Train loss: 0.007969\n",
      "Epoch: 5488/10000 Iteration: 38417 Train loss: 0.007969\n",
      "Epoch: 5489/10000 Iteration: 38424 Train loss: 0.007968\n",
      "Epoch: 5490/10000 Iteration: 38431 Train loss: 0.007968\n",
      "Epoch: 5491/10000 Iteration: 38438 Train loss: 0.007968\n",
      "Epoch: 5492/10000 Iteration: 38445 Train loss: 0.007968\n",
      "Epoch: 5493/10000 Iteration: 38452 Train loss: 0.007968\n",
      "Epoch: 5494/10000 Iteration: 38459 Train loss: 0.007967\n",
      "Epoch: 5495/10000 Iteration: 38466 Train loss: 0.007967\n",
      "Epoch: 5496/10000 Iteration: 38473 Train loss: 0.007967\n",
      "Epoch: 5497/10000 Iteration: 38480 Train loss: 0.007967\n",
      "Epoch: 5498/10000 Iteration: 38487 Train loss: 0.007967\n",
      "Epoch: 5499/10000 Iteration: 38494 Train loss: 0.007966\n",
      "Epoch: 5500/10000 Iteration: 38501 Train loss: 0.007966\n",
      "Epoch: 5501/10000 Iteration: 38508 Train loss: 0.007966\n",
      "Epoch: 5502/10000 Iteration: 38515 Train loss: 0.007966\n",
      "Epoch: 5503/10000 Iteration: 38522 Train loss: 0.007966\n",
      "Epoch: 5504/10000 Iteration: 38529 Train loss: 0.007966\n",
      "Epoch: 5505/10000 Iteration: 38536 Train loss: 0.007965\n",
      "Epoch: 5506/10000 Iteration: 38543 Train loss: 0.007965\n",
      "Epoch: 5507/10000 Iteration: 38550 Train loss: 0.007965\n",
      "Epoch: 5508/10000 Iteration: 38557 Train loss: 0.007965\n",
      "Epoch: 5509/10000 Iteration: 38564 Train loss: 0.007965\n",
      "Epoch: 5510/10000 Iteration: 38571 Train loss: 0.007964\n",
      "Epoch: 5511/10000 Iteration: 38578 Train loss: 0.007964\n",
      "Epoch: 5512/10000 Iteration: 38585 Train loss: 0.007964\n",
      "Epoch: 5513/10000 Iteration: 38592 Train loss: 0.007964\n",
      "Epoch: 5514/10000 Iteration: 38599 Train loss: 0.007964\n",
      "Epoch: 5515/10000 Iteration: 38606 Train loss: 0.007963\n",
      "Epoch: 5516/10000 Iteration: 38613 Train loss: 0.007963\n",
      "Epoch: 5517/10000 Iteration: 38620 Train loss: 0.007963\n",
      "Epoch: 5518/10000 Iteration: 38627 Train loss: 0.007963\n",
      "Epoch: 5519/10000 Iteration: 38634 Train loss: 0.007963\n",
      "Epoch: 5520/10000 Iteration: 38641 Train loss: 0.007962\n",
      "Epoch: 5521/10000 Iteration: 38648 Train loss: 0.007962\n",
      "Epoch: 5522/10000 Iteration: 38655 Train loss: 0.007962\n",
      "Epoch: 5523/10000 Iteration: 38662 Train loss: 0.007962\n",
      "Epoch: 5524/10000 Iteration: 38669 Train loss: 0.007962\n",
      "Epoch: 5525/10000 Iteration: 38676 Train loss: 0.007961\n",
      "Epoch: 5526/10000 Iteration: 38683 Train loss: 0.007961\n",
      "Epoch: 5527/10000 Iteration: 38690 Train loss: 0.007961\n",
      "Epoch: 5528/10000 Iteration: 38697 Train loss: 0.007961\n",
      "Epoch: 5529/10000 Iteration: 38704 Train loss: 0.007961\n",
      "Epoch: 5530/10000 Iteration: 38711 Train loss: 0.007960\n",
      "Epoch: 5531/10000 Iteration: 38718 Train loss: 0.007960\n",
      "Epoch: 5532/10000 Iteration: 38725 Train loss: 0.007960\n",
      "Epoch: 5533/10000 Iteration: 38732 Train loss: 0.007960\n",
      "Epoch: 5534/10000 Iteration: 38739 Train loss: 0.007960\n",
      "Epoch: 5535/10000 Iteration: 38746 Train loss: 0.007959\n",
      "Epoch: 5536/10000 Iteration: 38753 Train loss: 0.007959\n",
      "Epoch: 5537/10000 Iteration: 38760 Train loss: 0.007959\n",
      "Epoch: 5538/10000 Iteration: 38767 Train loss: 0.007959\n",
      "Epoch: 5539/10000 Iteration: 38774 Train loss: 0.007959\n",
      "Epoch: 5540/10000 Iteration: 38781 Train loss: 0.007958\n",
      "Epoch: 5541/10000 Iteration: 38788 Train loss: 0.007958\n",
      "Epoch: 5542/10000 Iteration: 38795 Train loss: 0.007958\n",
      "Epoch: 5543/10000 Iteration: 38802 Train loss: 0.007958\n",
      "Epoch: 5544/10000 Iteration: 38809 Train loss: 0.007958\n",
      "Epoch: 5545/10000 Iteration: 38816 Train loss: 0.007957\n",
      "Epoch: 5546/10000 Iteration: 38823 Train loss: 0.007957\n",
      "Epoch: 5547/10000 Iteration: 38830 Train loss: 0.007957\n",
      "Epoch: 5548/10000 Iteration: 38837 Train loss: 0.007957\n",
      "Epoch: 5549/10000 Iteration: 38844 Train loss: 0.007957\n",
      "Epoch: 5550/10000 Iteration: 38851 Train loss: 0.007957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5551/10000 Iteration: 38858 Train loss: 0.007956\n",
      "Epoch: 5552/10000 Iteration: 38865 Train loss: 0.007956\n",
      "Epoch: 5553/10000 Iteration: 38872 Train loss: 0.007956\n",
      "Epoch: 5554/10000 Iteration: 38879 Train loss: 0.007956\n",
      "Epoch: 5555/10000 Iteration: 38886 Train loss: 0.007956\n",
      "Epoch: 5556/10000 Iteration: 38893 Train loss: 0.007955\n",
      "Epoch: 5557/10000 Iteration: 38900 Train loss: 0.007955\n",
      "Epoch: 5558/10000 Iteration: 38907 Train loss: 0.007955\n",
      "Epoch: 5559/10000 Iteration: 38914 Train loss: 0.007955\n",
      "Epoch: 5560/10000 Iteration: 38921 Train loss: 0.007955\n",
      "Epoch: 5561/10000 Iteration: 38928 Train loss: 0.007954\n",
      "Epoch: 5562/10000 Iteration: 38935 Train loss: 0.007954\n",
      "Epoch: 5563/10000 Iteration: 38942 Train loss: 0.007954\n",
      "Epoch: 5564/10000 Iteration: 38949 Train loss: 0.007954\n",
      "Epoch: 5565/10000 Iteration: 38956 Train loss: 0.007954\n",
      "Epoch: 5566/10000 Iteration: 38963 Train loss: 0.007953\n",
      "Epoch: 5567/10000 Iteration: 38970 Train loss: 0.007953\n",
      "Epoch: 5568/10000 Iteration: 38977 Train loss: 0.007953\n",
      "Epoch: 5569/10000 Iteration: 38984 Train loss: 0.007953\n",
      "Epoch: 5570/10000 Iteration: 38991 Train loss: 0.007953\n",
      "Epoch: 5571/10000 Iteration: 38998 Train loss: 0.007952\n",
      "Epoch: 5572/10000 Iteration: 39005 Train loss: 0.007952\n",
      "Epoch: 5573/10000 Iteration: 39012 Train loss: 0.007952\n",
      "Epoch: 5574/10000 Iteration: 39019 Train loss: 0.007952\n",
      "Epoch: 5575/10000 Iteration: 39026 Train loss: 0.007952\n",
      "Epoch: 5576/10000 Iteration: 39033 Train loss: 0.007951\n",
      "Epoch: 5577/10000 Iteration: 39040 Train loss: 0.007951\n",
      "Epoch: 5578/10000 Iteration: 39047 Train loss: 0.007951\n",
      "Epoch: 5579/10000 Iteration: 39054 Train loss: 0.007951\n",
      "Epoch: 5580/10000 Iteration: 39061 Train loss: 0.007951\n",
      "Epoch: 5581/10000 Iteration: 39068 Train loss: 0.007950\n",
      "Epoch: 5582/10000 Iteration: 39075 Train loss: 0.007950\n",
      "Epoch: 5583/10000 Iteration: 39082 Train loss: 0.007950\n",
      "Epoch: 5584/10000 Iteration: 39089 Train loss: 0.007950\n",
      "Epoch: 5585/10000 Iteration: 39096 Train loss: 0.007950\n",
      "Epoch: 5586/10000 Iteration: 39103 Train loss: 0.007949\n",
      "Epoch: 5587/10000 Iteration: 39110 Train loss: 0.007949\n",
      "Epoch: 5588/10000 Iteration: 39117 Train loss: 0.007949\n",
      "Epoch: 5589/10000 Iteration: 39124 Train loss: 0.007949\n",
      "Epoch: 5590/10000 Iteration: 39131 Train loss: 0.007949\n",
      "Epoch: 5591/10000 Iteration: 39138 Train loss: 0.007948\n",
      "Epoch: 5592/10000 Iteration: 39145 Train loss: 0.007948\n",
      "Epoch: 5593/10000 Iteration: 39152 Train loss: 0.007948\n",
      "Epoch: 5594/10000 Iteration: 39159 Train loss: 0.007948\n",
      "Epoch: 5595/10000 Iteration: 39166 Train loss: 0.007948\n",
      "Epoch: 5596/10000 Iteration: 39173 Train loss: 0.007947\n",
      "Epoch: 5597/10000 Iteration: 39180 Train loss: 0.007947\n",
      "Epoch: 5598/10000 Iteration: 39187 Train loss: 0.007947\n",
      "Epoch: 5599/10000 Iteration: 39194 Train loss: 0.007947\n",
      "Epoch: 5600/10000 Iteration: 39201 Train loss: 0.007947\n",
      "Epoch: 5601/10000 Iteration: 39208 Train loss: 0.007946\n",
      "Epoch: 5602/10000 Iteration: 39215 Train loss: 0.007946\n",
      "Epoch: 5603/10000 Iteration: 39222 Train loss: 0.007946\n",
      "Epoch: 5604/10000 Iteration: 39229 Train loss: 0.007946\n",
      "Epoch: 5605/10000 Iteration: 39236 Train loss: 0.007946\n",
      "Epoch: 5606/10000 Iteration: 39243 Train loss: 0.007945\n",
      "Epoch: 5607/10000 Iteration: 39250 Train loss: 0.007945\n",
      "Epoch: 5608/10000 Iteration: 39257 Train loss: 0.007945\n",
      "Epoch: 5609/10000 Iteration: 39264 Train loss: 0.007945\n",
      "Epoch: 5610/10000 Iteration: 39271 Train loss: 0.007944\n",
      "Epoch: 5611/10000 Iteration: 39278 Train loss: 0.007944\n",
      "Epoch: 5612/10000 Iteration: 39285 Train loss: 0.007944\n",
      "Epoch: 5613/10000 Iteration: 39292 Train loss: 0.007944\n",
      "Epoch: 5614/10000 Iteration: 39299 Train loss: 0.007944\n",
      "Epoch: 5615/10000 Iteration: 39306 Train loss: 0.007943\n",
      "Epoch: 5616/10000 Iteration: 39313 Train loss: 0.007943\n",
      "Epoch: 5617/10000 Iteration: 39320 Train loss: 0.007943\n",
      "Epoch: 5618/10000 Iteration: 39327 Train loss: 0.007943\n",
      "Epoch: 5619/10000 Iteration: 39334 Train loss: 0.007943\n",
      "Epoch: 5620/10000 Iteration: 39341 Train loss: 0.007942\n",
      "Epoch: 5621/10000 Iteration: 39348 Train loss: 0.007942\n",
      "Epoch: 5622/10000 Iteration: 39355 Train loss: 0.007942\n",
      "Epoch: 5623/10000 Iteration: 39362 Train loss: 0.007942\n",
      "Epoch: 5624/10000 Iteration: 39369 Train loss: 0.007942\n",
      "Epoch: 5625/10000 Iteration: 39376 Train loss: 0.007941\n",
      "Epoch: 5626/10000 Iteration: 39383 Train loss: 0.007941\n",
      "Epoch: 5627/10000 Iteration: 39390 Train loss: 0.007941\n",
      "Epoch: 5628/10000 Iteration: 39397 Train loss: 0.007941\n",
      "Epoch: 5629/10000 Iteration: 39404 Train loss: 0.007941\n",
      "Epoch: 5630/10000 Iteration: 39411 Train loss: 0.007940\n",
      "Epoch: 5631/10000 Iteration: 39418 Train loss: 0.007940\n",
      "Epoch: 5632/10000 Iteration: 39425 Train loss: 0.007940\n",
      "Epoch: 5633/10000 Iteration: 39432 Train loss: 0.007940\n",
      "Epoch: 5634/10000 Iteration: 39439 Train loss: 0.007940\n",
      "Epoch: 5635/10000 Iteration: 39446 Train loss: 0.007939\n",
      "Epoch: 5636/10000 Iteration: 39453 Train loss: 0.007939\n",
      "Epoch: 5637/10000 Iteration: 39460 Train loss: 0.007939\n",
      "Epoch: 5638/10000 Iteration: 39467 Train loss: 0.007939\n",
      "Epoch: 5639/10000 Iteration: 39474 Train loss: 0.007939\n",
      "Epoch: 5640/10000 Iteration: 39481 Train loss: 0.007938\n",
      "Epoch: 5641/10000 Iteration: 39488 Train loss: 0.007938\n",
      "Epoch: 5642/10000 Iteration: 39495 Train loss: 0.007938\n",
      "Epoch: 5643/10000 Iteration: 39502 Train loss: 0.007938\n",
      "Epoch: 5644/10000 Iteration: 39509 Train loss: 0.007938\n",
      "Epoch: 5645/10000 Iteration: 39516 Train loss: 0.007937\n",
      "Epoch: 5646/10000 Iteration: 39523 Train loss: 0.007937\n",
      "Epoch: 5647/10000 Iteration: 39530 Train loss: 0.007937\n",
      "Epoch: 5648/10000 Iteration: 39537 Train loss: 0.007937\n",
      "Epoch: 5649/10000 Iteration: 39544 Train loss: 0.007937\n",
      "Epoch: 5650/10000 Iteration: 39551 Train loss: 0.007936\n",
      "Epoch: 5651/10000 Iteration: 39558 Train loss: 0.007936\n",
      "Epoch: 5652/10000 Iteration: 39565 Train loss: 0.007936\n",
      "Epoch: 5653/10000 Iteration: 39572 Train loss: 0.007936\n",
      "Epoch: 5654/10000 Iteration: 39579 Train loss: 0.007936\n",
      "Epoch: 5655/10000 Iteration: 39586 Train loss: 0.007935\n",
      "Epoch: 5656/10000 Iteration: 39593 Train loss: 0.007935\n",
      "Epoch: 5657/10000 Iteration: 39600 Train loss: 0.007935\n",
      "Epoch: 5658/10000 Iteration: 39607 Train loss: 0.007935\n",
      "Epoch: 5659/10000 Iteration: 39614 Train loss: 0.007935\n",
      "Epoch: 5660/10000 Iteration: 39621 Train loss: 0.007934\n",
      "Epoch: 5661/10000 Iteration: 39628 Train loss: 0.007934\n",
      "Epoch: 5662/10000 Iteration: 39635 Train loss: 0.007934\n",
      "Epoch: 5663/10000 Iteration: 39642 Train loss: 0.007934\n",
      "Epoch: 5664/10000 Iteration: 39649 Train loss: 0.007934\n",
      "Epoch: 5665/10000 Iteration: 39656 Train loss: 0.007933\n",
      "Epoch: 5666/10000 Iteration: 39663 Train loss: 0.007933\n",
      "Epoch: 5667/10000 Iteration: 39670 Train loss: 0.007933\n",
      "Epoch: 5668/10000 Iteration: 39677 Train loss: 0.007933\n",
      "Epoch: 5669/10000 Iteration: 39684 Train loss: 0.007932\n",
      "Epoch: 5670/10000 Iteration: 39691 Train loss: 0.007932\n",
      "Epoch: 5671/10000 Iteration: 39698 Train loss: 0.007932\n",
      "Epoch: 5672/10000 Iteration: 39705 Train loss: 0.007932\n",
      "Epoch: 5673/10000 Iteration: 39712 Train loss: 0.007932\n",
      "Epoch: 5674/10000 Iteration: 39719 Train loss: 0.007931\n",
      "Epoch: 5675/10000 Iteration: 39726 Train loss: 0.007931\n",
      "Epoch: 5676/10000 Iteration: 39733 Train loss: 0.007931\n",
      "Epoch: 5677/10000 Iteration: 39740 Train loss: 0.007931\n",
      "Epoch: 5678/10000 Iteration: 39747 Train loss: 0.007931\n",
      "Epoch: 5679/10000 Iteration: 39754 Train loss: 0.007930\n",
      "Epoch: 5680/10000 Iteration: 39761 Train loss: 0.007930\n",
      "Epoch: 5681/10000 Iteration: 39768 Train loss: 0.007930\n",
      "Epoch: 5682/10000 Iteration: 39775 Train loss: 0.007930\n",
      "Epoch: 5683/10000 Iteration: 39782 Train loss: 0.007930\n",
      "Epoch: 5684/10000 Iteration: 39789 Train loss: 0.007929\n",
      "Epoch: 5685/10000 Iteration: 39796 Train loss: 0.007929\n",
      "Epoch: 5686/10000 Iteration: 39803 Train loss: 0.007929\n",
      "Epoch: 5687/10000 Iteration: 39810 Train loss: 0.007929\n",
      "Epoch: 5688/10000 Iteration: 39817 Train loss: 0.007929\n",
      "Epoch: 5689/10000 Iteration: 39824 Train loss: 0.007928\n",
      "Epoch: 5690/10000 Iteration: 39831 Train loss: 0.007928\n",
      "Epoch: 5691/10000 Iteration: 39838 Train loss: 0.007928\n",
      "Epoch: 5692/10000 Iteration: 39845 Train loss: 0.007928\n",
      "Epoch: 5693/10000 Iteration: 39852 Train loss: 0.007928\n",
      "Epoch: 5694/10000 Iteration: 39859 Train loss: 0.007927\n",
      "Epoch: 5695/10000 Iteration: 39866 Train loss: 0.007927\n",
      "Epoch: 5696/10000 Iteration: 39873 Train loss: 0.007927\n",
      "Epoch: 5697/10000 Iteration: 39880 Train loss: 0.007927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5698/10000 Iteration: 39887 Train loss: 0.007927\n",
      "Epoch: 5699/10000 Iteration: 39894 Train loss: 0.007926\n",
      "Epoch: 5700/10000 Iteration: 39901 Train loss: 0.007926\n",
      "Epoch: 5701/10000 Iteration: 39908 Train loss: 0.007926\n",
      "Epoch: 5702/10000 Iteration: 39915 Train loss: 0.007926\n",
      "Epoch: 5703/10000 Iteration: 39922 Train loss: 0.007925\n",
      "Epoch: 5704/10000 Iteration: 39929 Train loss: 0.007925\n",
      "Epoch: 5705/10000 Iteration: 39936 Train loss: 0.007925\n",
      "Epoch: 5706/10000 Iteration: 39943 Train loss: 0.007925\n",
      "Epoch: 5707/10000 Iteration: 39950 Train loss: 0.007925\n",
      "Epoch: 5708/10000 Iteration: 39957 Train loss: 0.007924\n",
      "Epoch: 5709/10000 Iteration: 39964 Train loss: 0.007924\n",
      "Epoch: 5710/10000 Iteration: 39971 Train loss: 0.007924\n",
      "Epoch: 5711/10000 Iteration: 39978 Train loss: 0.007924\n",
      "Epoch: 5712/10000 Iteration: 39985 Train loss: 0.007924\n",
      "Epoch: 5713/10000 Iteration: 39992 Train loss: 0.007923\n",
      "Epoch: 5714/10000 Iteration: 39999 Train loss: 0.007923\n",
      "Epoch: 5715/10000 Iteration: 40006 Train loss: 0.007923\n",
      "Epoch: 5716/10000 Iteration: 40013 Train loss: 0.007923\n",
      "Epoch: 5717/10000 Iteration: 40020 Train loss: 0.007923\n",
      "Epoch: 5718/10000 Iteration: 40027 Train loss: 0.007922\n",
      "Epoch: 5719/10000 Iteration: 40034 Train loss: 0.007922\n",
      "Epoch: 5720/10000 Iteration: 40041 Train loss: 0.007922\n",
      "Epoch: 5721/10000 Iteration: 40048 Train loss: 0.007922\n",
      "Epoch: 5722/10000 Iteration: 40055 Train loss: 0.007922\n",
      "Epoch: 5723/10000 Iteration: 40062 Train loss: 0.007921\n",
      "Epoch: 5724/10000 Iteration: 40069 Train loss: 0.007921\n",
      "Epoch: 5725/10000 Iteration: 40076 Train loss: 0.007921\n",
      "Epoch: 5726/10000 Iteration: 40083 Train loss: 0.007921\n",
      "Epoch: 5727/10000 Iteration: 40090 Train loss: 0.007920\n",
      "Epoch: 5728/10000 Iteration: 40097 Train loss: 0.007920\n",
      "Epoch: 5729/10000 Iteration: 40104 Train loss: 0.007920\n",
      "Epoch: 5730/10000 Iteration: 40111 Train loss: 0.007920\n",
      "Epoch: 5731/10000 Iteration: 40118 Train loss: 0.007920\n",
      "Epoch: 5732/10000 Iteration: 40125 Train loss: 0.007919\n",
      "Epoch: 5733/10000 Iteration: 40132 Train loss: 0.007919\n",
      "Epoch: 5734/10000 Iteration: 40139 Train loss: 0.007919\n",
      "Epoch: 5735/10000 Iteration: 40146 Train loss: 0.007919\n",
      "Epoch: 5736/10000 Iteration: 40153 Train loss: 0.007919\n",
      "Epoch: 5737/10000 Iteration: 40160 Train loss: 0.007918\n",
      "Epoch: 5738/10000 Iteration: 40167 Train loss: 0.007918\n",
      "Epoch: 5739/10000 Iteration: 40174 Train loss: 0.007918\n",
      "Epoch: 5740/10000 Iteration: 40181 Train loss: 0.007918\n",
      "Epoch: 5741/10000 Iteration: 40188 Train loss: 0.007918\n",
      "Epoch: 5742/10000 Iteration: 40195 Train loss: 0.007917\n",
      "Epoch: 5743/10000 Iteration: 40202 Train loss: 0.007917\n",
      "Epoch: 5744/10000 Iteration: 40209 Train loss: 0.007917\n",
      "Epoch: 5745/10000 Iteration: 40216 Train loss: 0.007917\n",
      "Epoch: 5746/10000 Iteration: 40223 Train loss: 0.007917\n",
      "Epoch: 5747/10000 Iteration: 40230 Train loss: 0.007916\n",
      "Epoch: 5748/10000 Iteration: 40237 Train loss: 0.007916\n",
      "Epoch: 5749/10000 Iteration: 40244 Train loss: 0.007916\n",
      "Epoch: 5750/10000 Iteration: 40251 Train loss: 0.007916\n",
      "Epoch: 5751/10000 Iteration: 40258 Train loss: 0.007915\n",
      "Epoch: 5752/10000 Iteration: 40265 Train loss: 0.007915\n",
      "Epoch: 5753/10000 Iteration: 40272 Train loss: 0.007915\n",
      "Epoch: 5754/10000 Iteration: 40279 Train loss: 0.007915\n",
      "Epoch: 5755/10000 Iteration: 40286 Train loss: 0.007915\n",
      "Epoch: 5756/10000 Iteration: 40293 Train loss: 0.007914\n",
      "Epoch: 5757/10000 Iteration: 40300 Train loss: 0.007914\n",
      "Epoch: 5758/10000 Iteration: 40307 Train loss: 0.007914\n",
      "Epoch: 5759/10000 Iteration: 40314 Train loss: 0.007914\n",
      "Epoch: 5760/10000 Iteration: 40321 Train loss: 0.007914\n",
      "Epoch: 5761/10000 Iteration: 40328 Train loss: 0.007913\n",
      "Epoch: 5762/10000 Iteration: 40335 Train loss: 0.007913\n",
      "Epoch: 5763/10000 Iteration: 40342 Train loss: 0.007913\n",
      "Epoch: 5764/10000 Iteration: 40349 Train loss: 0.007913\n",
      "Epoch: 5765/10000 Iteration: 40356 Train loss: 0.007913\n",
      "Epoch: 5766/10000 Iteration: 40363 Train loss: 0.007912\n",
      "Epoch: 5767/10000 Iteration: 40370 Train loss: 0.007912\n",
      "Epoch: 5768/10000 Iteration: 40377 Train loss: 0.007912\n",
      "Epoch: 5769/10000 Iteration: 40384 Train loss: 0.007912\n",
      "Epoch: 5770/10000 Iteration: 40391 Train loss: 0.007912\n",
      "Epoch: 5771/10000 Iteration: 40398 Train loss: 0.007911\n",
      "Epoch: 5772/10000 Iteration: 40405 Train loss: 0.007911\n",
      "Epoch: 5773/10000 Iteration: 40412 Train loss: 0.007911\n",
      "Epoch: 5774/10000 Iteration: 40419 Train loss: 0.007911\n",
      "Epoch: 5775/10000 Iteration: 40426 Train loss: 0.007911\n",
      "Epoch: 5776/10000 Iteration: 40433 Train loss: 0.007910\n",
      "Epoch: 5777/10000 Iteration: 40440 Train loss: 0.007910\n",
      "Epoch: 5778/10000 Iteration: 40447 Train loss: 0.007910\n",
      "Epoch: 5779/10000 Iteration: 40454 Train loss: 0.007910\n",
      "Epoch: 5780/10000 Iteration: 40461 Train loss: 0.007909\n",
      "Epoch: 5781/10000 Iteration: 40468 Train loss: 0.007909\n",
      "Epoch: 5782/10000 Iteration: 40475 Train loss: 0.007909\n",
      "Epoch: 5783/10000 Iteration: 40482 Train loss: 0.007909\n",
      "Epoch: 5784/10000 Iteration: 40489 Train loss: 0.007909\n",
      "Epoch: 5785/10000 Iteration: 40496 Train loss: 0.007908\n",
      "Epoch: 5786/10000 Iteration: 40503 Train loss: 0.007908\n",
      "Epoch: 5787/10000 Iteration: 40510 Train loss: 0.007908\n",
      "Epoch: 5788/10000 Iteration: 40517 Train loss: 0.007908\n",
      "Epoch: 5789/10000 Iteration: 40524 Train loss: 0.007908\n",
      "Epoch: 5790/10000 Iteration: 40531 Train loss: 0.007907\n",
      "Epoch: 5791/10000 Iteration: 40538 Train loss: 0.007907\n",
      "Epoch: 5792/10000 Iteration: 40545 Train loss: 0.007907\n",
      "Epoch: 5793/10000 Iteration: 40552 Train loss: 0.007907\n",
      "Epoch: 5794/10000 Iteration: 40559 Train loss: 0.007907\n",
      "Epoch: 5795/10000 Iteration: 40566 Train loss: 0.007906\n",
      "Epoch: 5796/10000 Iteration: 40573 Train loss: 0.007906\n",
      "Epoch: 5797/10000 Iteration: 40580 Train loss: 0.007906\n",
      "Epoch: 5798/10000 Iteration: 40587 Train loss: 0.007906\n",
      "Epoch: 5799/10000 Iteration: 40594 Train loss: 0.007905\n",
      "Epoch: 5800/10000 Iteration: 40601 Train loss: 0.007905\n",
      "Epoch: 5801/10000 Iteration: 40608 Train loss: 0.007905\n",
      "Epoch: 5802/10000 Iteration: 40615 Train loss: 0.007905\n",
      "Epoch: 5803/10000 Iteration: 40622 Train loss: 0.007905\n",
      "Epoch: 5804/10000 Iteration: 40629 Train loss: 0.007904\n",
      "Epoch: 5805/10000 Iteration: 40636 Train loss: 0.007904\n",
      "Epoch: 5806/10000 Iteration: 40643 Train loss: 0.007904\n",
      "Epoch: 5807/10000 Iteration: 40650 Train loss: 0.007904\n",
      "Epoch: 5808/10000 Iteration: 40657 Train loss: 0.007904\n",
      "Epoch: 5809/10000 Iteration: 40664 Train loss: 0.007903\n",
      "Epoch: 5810/10000 Iteration: 40671 Train loss: 0.007903\n",
      "Epoch: 5811/10000 Iteration: 40678 Train loss: 0.007903\n",
      "Epoch: 5812/10000 Iteration: 40685 Train loss: 0.007903\n",
      "Epoch: 5813/10000 Iteration: 40692 Train loss: 0.007903\n",
      "Epoch: 5814/10000 Iteration: 40699 Train loss: 0.007902\n",
      "Epoch: 5815/10000 Iteration: 40706 Train loss: 0.007902\n",
      "Epoch: 5816/10000 Iteration: 40713 Train loss: 0.007902\n",
      "Epoch: 5817/10000 Iteration: 40720 Train loss: 0.007902\n",
      "Epoch: 5818/10000 Iteration: 40727 Train loss: 0.007902\n",
      "Epoch: 5819/10000 Iteration: 40734 Train loss: 0.007901\n",
      "Epoch: 5820/10000 Iteration: 40741 Train loss: 0.007901\n",
      "Epoch: 5821/10000 Iteration: 40748 Train loss: 0.007901\n",
      "Epoch: 5822/10000 Iteration: 40755 Train loss: 0.007901\n",
      "Epoch: 5823/10000 Iteration: 40762 Train loss: 0.007900\n",
      "Epoch: 5824/10000 Iteration: 40769 Train loss: 0.007900\n",
      "Epoch: 5825/10000 Iteration: 40776 Train loss: 0.007900\n",
      "Epoch: 5826/10000 Iteration: 40783 Train loss: 0.007900\n",
      "Epoch: 5827/10000 Iteration: 40790 Train loss: 0.007900\n",
      "Epoch: 5828/10000 Iteration: 40797 Train loss: 0.007899\n",
      "Epoch: 5829/10000 Iteration: 40804 Train loss: 0.007899\n",
      "Epoch: 5830/10000 Iteration: 40811 Train loss: 0.007899\n",
      "Epoch: 5831/10000 Iteration: 40818 Train loss: 0.007899\n",
      "Epoch: 5832/10000 Iteration: 40825 Train loss: 0.007899\n",
      "Epoch: 5833/10000 Iteration: 40832 Train loss: 0.007898\n",
      "Epoch: 5834/10000 Iteration: 40839 Train loss: 0.007898\n",
      "Epoch: 5835/10000 Iteration: 40846 Train loss: 0.007898\n",
      "Epoch: 5836/10000 Iteration: 40853 Train loss: 0.007898\n",
      "Epoch: 5837/10000 Iteration: 40860 Train loss: 0.007898\n",
      "Epoch: 5838/10000 Iteration: 40867 Train loss: 0.007897\n",
      "Epoch: 5839/10000 Iteration: 40874 Train loss: 0.007897\n",
      "Epoch: 5840/10000 Iteration: 40881 Train loss: 0.007897\n",
      "Epoch: 5841/10000 Iteration: 40888 Train loss: 0.007897\n",
      "Epoch: 5842/10000 Iteration: 40895 Train loss: 0.007896\n",
      "Epoch: 5843/10000 Iteration: 40902 Train loss: 0.007896\n",
      "Epoch: 5844/10000 Iteration: 40909 Train loss: 0.007896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5845/10000 Iteration: 40916 Train loss: 0.007896\n",
      "Epoch: 5846/10000 Iteration: 40923 Train loss: 0.007896\n",
      "Epoch: 5847/10000 Iteration: 40930 Train loss: 0.007895\n",
      "Epoch: 5848/10000 Iteration: 40937 Train loss: 0.007895\n",
      "Epoch: 5849/10000 Iteration: 40944 Train loss: 0.007895\n",
      "Epoch: 5850/10000 Iteration: 40951 Train loss: 0.007895\n",
      "Epoch: 5851/10000 Iteration: 40958 Train loss: 0.007895\n",
      "Epoch: 5852/10000 Iteration: 40965 Train loss: 0.007894\n",
      "Epoch: 5853/10000 Iteration: 40972 Train loss: 0.007894\n",
      "Epoch: 5854/10000 Iteration: 40979 Train loss: 0.007894\n",
      "Epoch: 5855/10000 Iteration: 40986 Train loss: 0.007894\n",
      "Epoch: 5856/10000 Iteration: 40993 Train loss: 0.007894\n",
      "Epoch: 5857/10000 Iteration: 41000 Train loss: 0.007893\n",
      "Epoch: 5858/10000 Iteration: 41007 Train loss: 0.007893\n",
      "Epoch: 5859/10000 Iteration: 41014 Train loss: 0.007893\n",
      "Epoch: 5860/10000 Iteration: 41021 Train loss: 0.007893\n",
      "Epoch: 5861/10000 Iteration: 41028 Train loss: 0.007892\n",
      "Epoch: 5862/10000 Iteration: 41035 Train loss: 0.007892\n",
      "Epoch: 5863/10000 Iteration: 41042 Train loss: 0.007892\n",
      "Epoch: 5864/10000 Iteration: 41049 Train loss: 0.007892\n",
      "Epoch: 5865/10000 Iteration: 41056 Train loss: 0.007892\n",
      "Epoch: 5866/10000 Iteration: 41063 Train loss: 0.007891\n",
      "Epoch: 5867/10000 Iteration: 41070 Train loss: 0.007891\n",
      "Epoch: 5868/10000 Iteration: 41077 Train loss: 0.007891\n",
      "Epoch: 5869/10000 Iteration: 41084 Train loss: 0.007891\n",
      "Epoch: 5870/10000 Iteration: 41091 Train loss: 0.007891\n",
      "Epoch: 5871/10000 Iteration: 41098 Train loss: 0.007890\n",
      "Epoch: 5872/10000 Iteration: 41105 Train loss: 0.007890\n",
      "Epoch: 5873/10000 Iteration: 41112 Train loss: 0.007890\n",
      "Epoch: 5874/10000 Iteration: 41119 Train loss: 0.007890\n",
      "Epoch: 5875/10000 Iteration: 41126 Train loss: 0.007890\n",
      "Epoch: 5876/10000 Iteration: 41133 Train loss: 0.007889\n",
      "Epoch: 5877/10000 Iteration: 41140 Train loss: 0.007889\n",
      "Epoch: 5878/10000 Iteration: 41147 Train loss: 0.007889\n",
      "Epoch: 5879/10000 Iteration: 41154 Train loss: 0.007889\n",
      "Epoch: 5880/10000 Iteration: 41161 Train loss: 0.007888\n",
      "Epoch: 5881/10000 Iteration: 41168 Train loss: 0.007888\n",
      "Epoch: 5882/10000 Iteration: 41175 Train loss: 0.007888\n",
      "Epoch: 5883/10000 Iteration: 41182 Train loss: 0.007888\n",
      "Epoch: 5884/10000 Iteration: 41189 Train loss: 0.007888\n",
      "Epoch: 5885/10000 Iteration: 41196 Train loss: 0.007887\n",
      "Epoch: 5886/10000 Iteration: 41203 Train loss: 0.007887\n",
      "Epoch: 5887/10000 Iteration: 41210 Train loss: 0.007887\n",
      "Epoch: 5888/10000 Iteration: 41217 Train loss: 0.007887\n",
      "Epoch: 5889/10000 Iteration: 41224 Train loss: 0.007887\n",
      "Epoch: 5890/10000 Iteration: 41231 Train loss: 0.007886\n",
      "Epoch: 5891/10000 Iteration: 41238 Train loss: 0.007886\n",
      "Epoch: 5892/10000 Iteration: 41245 Train loss: 0.007886\n",
      "Epoch: 5893/10000 Iteration: 41252 Train loss: 0.007886\n",
      "Epoch: 5894/10000 Iteration: 41259 Train loss: 0.007886\n",
      "Epoch: 5895/10000 Iteration: 41266 Train loss: 0.007885\n",
      "Epoch: 5896/10000 Iteration: 41273 Train loss: 0.007885\n",
      "Epoch: 5897/10000 Iteration: 41280 Train loss: 0.007885\n",
      "Epoch: 5898/10000 Iteration: 41287 Train loss: 0.007885\n",
      "Epoch: 5899/10000 Iteration: 41294 Train loss: 0.007885\n",
      "Epoch: 5900/10000 Iteration: 41301 Train loss: 0.007884\n",
      "Epoch: 5901/10000 Iteration: 41308 Train loss: 0.007884\n",
      "Epoch: 5902/10000 Iteration: 41315 Train loss: 0.007884\n",
      "Epoch: 5903/10000 Iteration: 41322 Train loss: 0.007884\n",
      "Epoch: 5904/10000 Iteration: 41329 Train loss: 0.007883\n",
      "Epoch: 5905/10000 Iteration: 41336 Train loss: 0.007883\n",
      "Epoch: 5906/10000 Iteration: 41343 Train loss: 0.007883\n",
      "Epoch: 5907/10000 Iteration: 41350 Train loss: 0.007883\n",
      "Epoch: 5908/10000 Iteration: 41357 Train loss: 0.007883\n",
      "Epoch: 5909/10000 Iteration: 41364 Train loss: 0.007882\n",
      "Epoch: 5910/10000 Iteration: 41371 Train loss: 0.007882\n",
      "Epoch: 5911/10000 Iteration: 41378 Train loss: 0.007882\n",
      "Epoch: 5912/10000 Iteration: 41385 Train loss: 0.007882\n",
      "Epoch: 5913/10000 Iteration: 41392 Train loss: 0.007882\n",
      "Epoch: 5914/10000 Iteration: 41399 Train loss: 0.007881\n",
      "Epoch: 5915/10000 Iteration: 41406 Train loss: 0.007881\n",
      "Epoch: 5916/10000 Iteration: 41413 Train loss: 0.007881\n",
      "Epoch: 5917/10000 Iteration: 41420 Train loss: 0.007881\n",
      "Epoch: 5918/10000 Iteration: 41427 Train loss: 0.007881\n",
      "Epoch: 5919/10000 Iteration: 41434 Train loss: 0.007880\n",
      "Epoch: 5920/10000 Iteration: 41441 Train loss: 0.007880\n",
      "Epoch: 5921/10000 Iteration: 41448 Train loss: 0.007880\n",
      "Epoch: 5922/10000 Iteration: 41455 Train loss: 0.007880\n",
      "Epoch: 5923/10000 Iteration: 41462 Train loss: 0.007879\n",
      "Epoch: 5924/10000 Iteration: 41469 Train loss: 0.007879\n",
      "Epoch: 5925/10000 Iteration: 41476 Train loss: 0.007879\n",
      "Epoch: 5926/10000 Iteration: 41483 Train loss: 0.007879\n",
      "Epoch: 5927/10000 Iteration: 41490 Train loss: 0.007879\n",
      "Epoch: 5928/10000 Iteration: 41497 Train loss: 0.007878\n",
      "Epoch: 5929/10000 Iteration: 41504 Train loss: 0.007878\n",
      "Epoch: 5930/10000 Iteration: 41511 Train loss: 0.007878\n",
      "Epoch: 5931/10000 Iteration: 41518 Train loss: 0.007878\n",
      "Epoch: 5932/10000 Iteration: 41525 Train loss: 0.007878\n",
      "Epoch: 5933/10000 Iteration: 41532 Train loss: 0.007877\n",
      "Epoch: 5934/10000 Iteration: 41539 Train loss: 0.007877\n",
      "Epoch: 5935/10000 Iteration: 41546 Train loss: 0.007877\n",
      "Epoch: 5936/10000 Iteration: 41553 Train loss: 0.007877\n",
      "Epoch: 5937/10000 Iteration: 41560 Train loss: 0.007877\n",
      "Epoch: 5938/10000 Iteration: 41567 Train loss: 0.007876\n",
      "Epoch: 5939/10000 Iteration: 41574 Train loss: 0.007876\n",
      "Epoch: 5940/10000 Iteration: 41581 Train loss: 0.007876\n",
      "Epoch: 5941/10000 Iteration: 41588 Train loss: 0.007876\n",
      "Epoch: 5942/10000 Iteration: 41595 Train loss: 0.007875\n",
      "Epoch: 5943/10000 Iteration: 41602 Train loss: 0.007875\n",
      "Epoch: 5944/10000 Iteration: 41609 Train loss: 0.007875\n",
      "Epoch: 5945/10000 Iteration: 41616 Train loss: 0.007875\n",
      "Epoch: 5946/10000 Iteration: 41623 Train loss: 0.007875\n",
      "Epoch: 5947/10000 Iteration: 41630 Train loss: 0.007874\n",
      "Epoch: 5948/10000 Iteration: 41637 Train loss: 0.007874\n",
      "Epoch: 5949/10000 Iteration: 41644 Train loss: 0.007874\n",
      "Epoch: 5950/10000 Iteration: 41651 Train loss: 0.007874\n",
      "Epoch: 5951/10000 Iteration: 41658 Train loss: 0.007874\n",
      "Epoch: 5952/10000 Iteration: 41665 Train loss: 0.007873\n",
      "Epoch: 5953/10000 Iteration: 41672 Train loss: 0.007873\n",
      "Epoch: 5954/10000 Iteration: 41679 Train loss: 0.007873\n",
      "Epoch: 5955/10000 Iteration: 41686 Train loss: 0.007873\n",
      "Epoch: 5956/10000 Iteration: 41693 Train loss: 0.007873\n",
      "Epoch: 5957/10000 Iteration: 41700 Train loss: 0.007872\n",
      "Epoch: 5958/10000 Iteration: 41707 Train loss: 0.007872\n",
      "Epoch: 5959/10000 Iteration: 41714 Train loss: 0.007872\n",
      "Epoch: 5960/10000 Iteration: 41721 Train loss: 0.007872\n",
      "Epoch: 5961/10000 Iteration: 41728 Train loss: 0.007871\n",
      "Epoch: 5962/10000 Iteration: 41735 Train loss: 0.007871\n",
      "Epoch: 5963/10000 Iteration: 41742 Train loss: 0.007871\n",
      "Epoch: 5964/10000 Iteration: 41749 Train loss: 0.007871\n",
      "Epoch: 5965/10000 Iteration: 41756 Train loss: 0.007871\n",
      "Epoch: 5966/10000 Iteration: 41763 Train loss: 0.007870\n",
      "Epoch: 5967/10000 Iteration: 41770 Train loss: 0.007870\n",
      "Epoch: 5968/10000 Iteration: 41777 Train loss: 0.007870\n",
      "Epoch: 5969/10000 Iteration: 41784 Train loss: 0.007870\n",
      "Epoch: 5970/10000 Iteration: 41791 Train loss: 0.007870\n",
      "Epoch: 5971/10000 Iteration: 41798 Train loss: 0.007869\n",
      "Epoch: 5972/10000 Iteration: 41805 Train loss: 0.007869\n",
      "Epoch: 5973/10000 Iteration: 41812 Train loss: 0.007869\n",
      "Epoch: 5974/10000 Iteration: 41819 Train loss: 0.007869\n",
      "Epoch: 5975/10000 Iteration: 41826 Train loss: 0.007869\n",
      "Epoch: 5976/10000 Iteration: 41833 Train loss: 0.007868\n",
      "Epoch: 5977/10000 Iteration: 41840 Train loss: 0.007868\n",
      "Epoch: 5978/10000 Iteration: 41847 Train loss: 0.007868\n",
      "Epoch: 5979/10000 Iteration: 41854 Train loss: 0.007868\n",
      "Epoch: 5980/10000 Iteration: 41861 Train loss: 0.007867\n",
      "Epoch: 5981/10000 Iteration: 41868 Train loss: 0.007867\n",
      "Epoch: 5982/10000 Iteration: 41875 Train loss: 0.007867\n",
      "Epoch: 5983/10000 Iteration: 41882 Train loss: 0.007867\n",
      "Epoch: 5984/10000 Iteration: 41889 Train loss: 0.007867\n",
      "Epoch: 5985/10000 Iteration: 41896 Train loss: 0.007866\n",
      "Epoch: 5986/10000 Iteration: 41903 Train loss: 0.007866\n",
      "Epoch: 5987/10000 Iteration: 41910 Train loss: 0.007866\n",
      "Epoch: 5988/10000 Iteration: 41917 Train loss: 0.007866\n",
      "Epoch: 5989/10000 Iteration: 41924 Train loss: 0.007866\n",
      "Epoch: 5990/10000 Iteration: 41931 Train loss: 0.007865\n",
      "Epoch: 5991/10000 Iteration: 41938 Train loss: 0.007865\n",
      "Epoch: 5992/10000 Iteration: 41945 Train loss: 0.007865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5993/10000 Iteration: 41952 Train loss: 0.007865\n",
      "Epoch: 5994/10000 Iteration: 41959 Train loss: 0.007865\n",
      "Epoch: 5995/10000 Iteration: 41966 Train loss: 0.007864\n",
      "Epoch: 5996/10000 Iteration: 41973 Train loss: 0.007864\n",
      "Epoch: 5997/10000 Iteration: 41980 Train loss: 0.007864\n",
      "Epoch: 5998/10000 Iteration: 41987 Train loss: 0.007864\n",
      "Epoch: 5999/10000 Iteration: 41994 Train loss: 0.007863\n",
      "Epoch: 6000/10000 Iteration: 42001 Train loss: 0.007863\n",
      "Epoch: 6001/10000 Iteration: 42008 Train loss: 0.007863\n",
      "Epoch: 6002/10000 Iteration: 42015 Train loss: 0.007863\n",
      "Epoch: 6003/10000 Iteration: 42022 Train loss: 0.007863\n",
      "Epoch: 6004/10000 Iteration: 42029 Train loss: 0.007862\n",
      "Epoch: 6005/10000 Iteration: 42036 Train loss: 0.007862\n",
      "Epoch: 6006/10000 Iteration: 42043 Train loss: 0.007862\n",
      "Epoch: 6007/10000 Iteration: 42050 Train loss: 0.007862\n",
      "Epoch: 6008/10000 Iteration: 42057 Train loss: 0.007862\n",
      "Epoch: 6009/10000 Iteration: 42064 Train loss: 0.007861\n",
      "Epoch: 6010/10000 Iteration: 42071 Train loss: 0.007861\n",
      "Epoch: 6011/10000 Iteration: 42078 Train loss: 0.007861\n",
      "Epoch: 6012/10000 Iteration: 42085 Train loss: 0.007861\n",
      "Epoch: 6013/10000 Iteration: 42092 Train loss: 0.007861\n",
      "Epoch: 6014/10000 Iteration: 42099 Train loss: 0.007860\n",
      "Epoch: 6015/10000 Iteration: 42106 Train loss: 0.007860\n",
      "Epoch: 6016/10000 Iteration: 42113 Train loss: 0.007860\n",
      "Epoch: 6017/10000 Iteration: 42120 Train loss: 0.007860\n",
      "Epoch: 6018/10000 Iteration: 42127 Train loss: 0.007859\n",
      "Epoch: 6019/10000 Iteration: 42134 Train loss: 0.007859\n",
      "Epoch: 6020/10000 Iteration: 42141 Train loss: 0.007859\n",
      "Epoch: 6021/10000 Iteration: 42148 Train loss: 0.007859\n",
      "Epoch: 6022/10000 Iteration: 42155 Train loss: 0.007859\n",
      "Epoch: 6023/10000 Iteration: 42162 Train loss: 0.007858\n",
      "Epoch: 6024/10000 Iteration: 42169 Train loss: 0.007858\n",
      "Epoch: 6025/10000 Iteration: 42176 Train loss: 0.007858\n",
      "Epoch: 6026/10000 Iteration: 42183 Train loss: 0.007858\n",
      "Epoch: 6027/10000 Iteration: 42190 Train loss: 0.007858\n",
      "Epoch: 6028/10000 Iteration: 42197 Train loss: 0.007857\n",
      "Epoch: 6029/10000 Iteration: 42204 Train loss: 0.007857\n",
      "Epoch: 6030/10000 Iteration: 42211 Train loss: 0.007857\n",
      "Epoch: 6031/10000 Iteration: 42218 Train loss: 0.007857\n",
      "Epoch: 6032/10000 Iteration: 42225 Train loss: 0.007856\n",
      "Epoch: 6033/10000 Iteration: 42232 Train loss: 0.007856\n",
      "Epoch: 6034/10000 Iteration: 42239 Train loss: 0.007856\n",
      "Epoch: 6035/10000 Iteration: 42246 Train loss: 0.007856\n",
      "Epoch: 6036/10000 Iteration: 42253 Train loss: 0.007856\n",
      "Epoch: 6037/10000 Iteration: 42260 Train loss: 0.007855\n",
      "Epoch: 6038/10000 Iteration: 42267 Train loss: 0.007855\n",
      "Epoch: 6039/10000 Iteration: 42274 Train loss: 0.007855\n",
      "Epoch: 6040/10000 Iteration: 42281 Train loss: 0.007855\n",
      "Epoch: 6041/10000 Iteration: 42288 Train loss: 0.007855\n",
      "Epoch: 6042/10000 Iteration: 42295 Train loss: 0.007854\n",
      "Epoch: 6043/10000 Iteration: 42302 Train loss: 0.007854\n",
      "Epoch: 6044/10000 Iteration: 42309 Train loss: 0.007854\n",
      "Epoch: 6045/10000 Iteration: 42316 Train loss: 0.007854\n",
      "Epoch: 6046/10000 Iteration: 42323 Train loss: 0.007854\n",
      "Epoch: 6047/10000 Iteration: 42330 Train loss: 0.007853\n",
      "Epoch: 6048/10000 Iteration: 42337 Train loss: 0.007853\n",
      "Epoch: 6049/10000 Iteration: 42344 Train loss: 0.007853\n",
      "Epoch: 6050/10000 Iteration: 42351 Train loss: 0.007853\n",
      "Epoch: 6051/10000 Iteration: 42358 Train loss: 0.007852\n",
      "Epoch: 6052/10000 Iteration: 42365 Train loss: 0.007852\n",
      "Epoch: 6053/10000 Iteration: 42372 Train loss: 0.007852\n",
      "Epoch: 6054/10000 Iteration: 42379 Train loss: 0.007852\n",
      "Epoch: 6055/10000 Iteration: 42386 Train loss: 0.007852\n",
      "Epoch: 6056/10000 Iteration: 42393 Train loss: 0.007851\n",
      "Epoch: 6057/10000 Iteration: 42400 Train loss: 0.007851\n",
      "Epoch: 6058/10000 Iteration: 42407 Train loss: 0.007851\n",
      "Epoch: 6059/10000 Iteration: 42414 Train loss: 0.007851\n",
      "Epoch: 6060/10000 Iteration: 42421 Train loss: 0.007851\n",
      "Epoch: 6061/10000 Iteration: 42428 Train loss: 0.007850\n",
      "Epoch: 6062/10000 Iteration: 42435 Train loss: 0.007850\n",
      "Epoch: 6063/10000 Iteration: 42442 Train loss: 0.007850\n",
      "Epoch: 6064/10000 Iteration: 42449 Train loss: 0.007850\n",
      "Epoch: 6065/10000 Iteration: 42456 Train loss: 0.007850\n",
      "Epoch: 6066/10000 Iteration: 42463 Train loss: 0.007849\n",
      "Epoch: 6067/10000 Iteration: 42470 Train loss: 0.007849\n",
      "Epoch: 6068/10000 Iteration: 42477 Train loss: 0.007849\n",
      "Epoch: 6069/10000 Iteration: 42484 Train loss: 0.007849\n",
      "Epoch: 6070/10000 Iteration: 42491 Train loss: 0.007849\n",
      "Epoch: 6071/10000 Iteration: 42498 Train loss: 0.007848\n",
      "Epoch: 6072/10000 Iteration: 42505 Train loss: 0.007848\n",
      "Epoch: 6073/10000 Iteration: 42512 Train loss: 0.007848\n",
      "Epoch: 6074/10000 Iteration: 42519 Train loss: 0.007848\n",
      "Epoch: 6075/10000 Iteration: 42526 Train loss: 0.007847\n",
      "Epoch: 6076/10000 Iteration: 42533 Train loss: 0.007847\n",
      "Epoch: 6077/10000 Iteration: 42540 Train loss: 0.007847\n",
      "Epoch: 6078/10000 Iteration: 42547 Train loss: 0.007847\n",
      "Epoch: 6079/10000 Iteration: 42554 Train loss: 0.007847\n",
      "Epoch: 6080/10000 Iteration: 42561 Train loss: 0.007846\n",
      "Epoch: 6081/10000 Iteration: 42568 Train loss: 0.007846\n",
      "Epoch: 6082/10000 Iteration: 42575 Train loss: 0.007846\n",
      "Epoch: 6083/10000 Iteration: 42582 Train loss: 0.007846\n",
      "Epoch: 6084/10000 Iteration: 42589 Train loss: 0.007846\n",
      "Epoch: 6085/10000 Iteration: 42596 Train loss: 0.007845\n",
      "Epoch: 6086/10000 Iteration: 42603 Train loss: 0.007845\n",
      "Epoch: 6087/10000 Iteration: 42610 Train loss: 0.007845\n",
      "Epoch: 6088/10000 Iteration: 42617 Train loss: 0.007845\n",
      "Epoch: 6089/10000 Iteration: 42624 Train loss: 0.007845\n",
      "Epoch: 6090/10000 Iteration: 42631 Train loss: 0.007844\n",
      "Epoch: 6091/10000 Iteration: 42638 Train loss: 0.007844\n",
      "Epoch: 6092/10000 Iteration: 42645 Train loss: 0.007844\n",
      "Epoch: 6093/10000 Iteration: 42652 Train loss: 0.007844\n",
      "Epoch: 6094/10000 Iteration: 42659 Train loss: 0.007843\n",
      "Epoch: 6095/10000 Iteration: 42666 Train loss: 0.007843\n",
      "Epoch: 6096/10000 Iteration: 42673 Train loss: 0.007843\n",
      "Epoch: 6097/10000 Iteration: 42680 Train loss: 0.007843\n",
      "Epoch: 6098/10000 Iteration: 42687 Train loss: 0.007843\n",
      "Epoch: 6099/10000 Iteration: 42694 Train loss: 0.007842\n",
      "Epoch: 6100/10000 Iteration: 42701 Train loss: 0.007842\n",
      "Epoch: 6101/10000 Iteration: 42708 Train loss: 0.007842\n",
      "Epoch: 6102/10000 Iteration: 42715 Train loss: 0.007842\n",
      "Epoch: 6103/10000 Iteration: 42722 Train loss: 0.007842\n",
      "Epoch: 6104/10000 Iteration: 42729 Train loss: 0.007841\n",
      "Epoch: 6105/10000 Iteration: 42736 Train loss: 0.007841\n",
      "Epoch: 6106/10000 Iteration: 42743 Train loss: 0.007841\n",
      "Epoch: 6107/10000 Iteration: 42750 Train loss: 0.007841\n",
      "Epoch: 6108/10000 Iteration: 42757 Train loss: 0.007841\n",
      "Epoch: 6109/10000 Iteration: 42764 Train loss: 0.007840\n",
      "Epoch: 6110/10000 Iteration: 42771 Train loss: 0.007840\n",
      "Epoch: 6111/10000 Iteration: 42778 Train loss: 0.007840\n",
      "Epoch: 6112/10000 Iteration: 42785 Train loss: 0.007840\n",
      "Epoch: 6113/10000 Iteration: 42792 Train loss: 0.007839\n",
      "Epoch: 6114/10000 Iteration: 42799 Train loss: 0.007839\n",
      "Epoch: 6115/10000 Iteration: 42806 Train loss: 0.007839\n",
      "Epoch: 6116/10000 Iteration: 42813 Train loss: 0.007839\n",
      "Epoch: 6117/10000 Iteration: 42820 Train loss: 0.007839\n",
      "Epoch: 6118/10000 Iteration: 42827 Train loss: 0.007838\n",
      "Epoch: 6119/10000 Iteration: 42834 Train loss: 0.007838\n",
      "Epoch: 6120/10000 Iteration: 42841 Train loss: 0.007838\n",
      "Epoch: 6121/10000 Iteration: 42848 Train loss: 0.007838\n",
      "Epoch: 6122/10000 Iteration: 42855 Train loss: 0.007838\n",
      "Epoch: 6123/10000 Iteration: 42862 Train loss: 0.007837\n",
      "Epoch: 6124/10000 Iteration: 42869 Train loss: 0.007837\n",
      "Epoch: 6125/10000 Iteration: 42876 Train loss: 0.007837\n",
      "Epoch: 6126/10000 Iteration: 42883 Train loss: 0.007837\n",
      "Epoch: 6127/10000 Iteration: 42890 Train loss: 0.007837\n",
      "Epoch: 6128/10000 Iteration: 42897 Train loss: 0.007836\n",
      "Epoch: 6129/10000 Iteration: 42904 Train loss: 0.007836\n",
      "Epoch: 6130/10000 Iteration: 42911 Train loss: 0.007836\n",
      "Epoch: 6131/10000 Iteration: 42918 Train loss: 0.007836\n",
      "Epoch: 6132/10000 Iteration: 42925 Train loss: 0.007836\n",
      "Epoch: 6133/10000 Iteration: 42932 Train loss: 0.007835\n",
      "Epoch: 6134/10000 Iteration: 42939 Train loss: 0.007835\n",
      "Epoch: 6135/10000 Iteration: 42946 Train loss: 0.007835\n",
      "Epoch: 6136/10000 Iteration: 42953 Train loss: 0.007835\n",
      "Epoch: 6137/10000 Iteration: 42960 Train loss: 0.007834\n",
      "Epoch: 6138/10000 Iteration: 42967 Train loss: 0.007834\n",
      "Epoch: 6139/10000 Iteration: 42974 Train loss: 0.007834\n",
      "Epoch: 6140/10000 Iteration: 42981 Train loss: 0.007834\n",
      "Epoch: 6141/10000 Iteration: 42988 Train loss: 0.007834\n",
      "Epoch: 6142/10000 Iteration: 42995 Train loss: 0.007833\n",
      "Epoch: 6143/10000 Iteration: 43002 Train loss: 0.007833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6144/10000 Iteration: 43009 Train loss: 0.007833\n",
      "Epoch: 6145/10000 Iteration: 43016 Train loss: 0.007833\n",
      "Epoch: 6146/10000 Iteration: 43023 Train loss: 0.007833\n",
      "Epoch: 6147/10000 Iteration: 43030 Train loss: 0.007832\n",
      "Epoch: 6148/10000 Iteration: 43037 Train loss: 0.007832\n",
      "Epoch: 6149/10000 Iteration: 43044 Train loss: 0.007832\n",
      "Epoch: 6150/10000 Iteration: 43051 Train loss: 0.007832\n",
      "Epoch: 6151/10000 Iteration: 43058 Train loss: 0.007832\n",
      "Epoch: 6152/10000 Iteration: 43065 Train loss: 0.007831\n",
      "Epoch: 6153/10000 Iteration: 43072 Train loss: 0.007831\n",
      "Epoch: 6154/10000 Iteration: 43079 Train loss: 0.007831\n",
      "Epoch: 6155/10000 Iteration: 43086 Train loss: 0.007831\n",
      "Epoch: 6156/10000 Iteration: 43093 Train loss: 0.007831\n",
      "Epoch: 6157/10000 Iteration: 43100 Train loss: 0.007830\n",
      "Epoch: 6158/10000 Iteration: 43107 Train loss: 0.007830\n",
      "Epoch: 6159/10000 Iteration: 43114 Train loss: 0.007830\n",
      "Epoch: 6160/10000 Iteration: 43121 Train loss: 0.007830\n",
      "Epoch: 6161/10000 Iteration: 43128 Train loss: 0.007829\n",
      "Epoch: 6162/10000 Iteration: 43135 Train loss: 0.007829\n",
      "Epoch: 6163/10000 Iteration: 43142 Train loss: 0.007829\n",
      "Epoch: 6164/10000 Iteration: 43149 Train loss: 0.007829\n",
      "Epoch: 6165/10000 Iteration: 43156 Train loss: 0.007829\n",
      "Epoch: 6166/10000 Iteration: 43163 Train loss: 0.007828\n",
      "Epoch: 6167/10000 Iteration: 43170 Train loss: 0.007828\n",
      "Epoch: 6168/10000 Iteration: 43177 Train loss: 0.007828\n",
      "Epoch: 6169/10000 Iteration: 43184 Train loss: 0.007828\n",
      "Epoch: 6170/10000 Iteration: 43191 Train loss: 0.007828\n",
      "Epoch: 6171/10000 Iteration: 43198 Train loss: 0.007827\n",
      "Epoch: 6172/10000 Iteration: 43205 Train loss: 0.007827\n",
      "Epoch: 6173/10000 Iteration: 43212 Train loss: 0.007827\n",
      "Epoch: 6174/10000 Iteration: 43219 Train loss: 0.007827\n",
      "Epoch: 6175/10000 Iteration: 43226 Train loss: 0.007827\n",
      "Epoch: 6176/10000 Iteration: 43233 Train loss: 0.007826\n",
      "Epoch: 6177/10000 Iteration: 43240 Train loss: 0.007826\n",
      "Epoch: 6178/10000 Iteration: 43247 Train loss: 0.007826\n",
      "Epoch: 6179/10000 Iteration: 43254 Train loss: 0.007826\n",
      "Epoch: 6180/10000 Iteration: 43261 Train loss: 0.007826\n",
      "Epoch: 6181/10000 Iteration: 43268 Train loss: 0.007825\n",
      "Epoch: 6182/10000 Iteration: 43275 Train loss: 0.007825\n",
      "Epoch: 6183/10000 Iteration: 43282 Train loss: 0.007825\n",
      "Epoch: 6184/10000 Iteration: 43289 Train loss: 0.007825\n",
      "Epoch: 6185/10000 Iteration: 43296 Train loss: 0.007824\n",
      "Epoch: 6186/10000 Iteration: 43303 Train loss: 0.007824\n",
      "Epoch: 6187/10000 Iteration: 43310 Train loss: 0.007824\n",
      "Epoch: 6188/10000 Iteration: 43317 Train loss: 0.007824\n",
      "Epoch: 6189/10000 Iteration: 43324 Train loss: 0.007824\n",
      "Epoch: 6190/10000 Iteration: 43331 Train loss: 0.007823\n",
      "Epoch: 6191/10000 Iteration: 43338 Train loss: 0.007823\n",
      "Epoch: 6192/10000 Iteration: 43345 Train loss: 0.007823\n",
      "Epoch: 6193/10000 Iteration: 43352 Train loss: 0.007823\n",
      "Epoch: 6194/10000 Iteration: 43359 Train loss: 0.007823\n",
      "Epoch: 6195/10000 Iteration: 43366 Train loss: 0.007822\n",
      "Epoch: 6196/10000 Iteration: 43373 Train loss: 0.007822\n",
      "Epoch: 6197/10000 Iteration: 43380 Train loss: 0.007822\n",
      "Epoch: 6198/10000 Iteration: 43387 Train loss: 0.007822\n",
      "Epoch: 6199/10000 Iteration: 43394 Train loss: 0.007822\n",
      "Epoch: 6200/10000 Iteration: 43401 Train loss: 0.007821\n",
      "Epoch: 6201/10000 Iteration: 43408 Train loss: 0.007821\n",
      "Epoch: 6202/10000 Iteration: 43415 Train loss: 0.007821\n",
      "Epoch: 6203/10000 Iteration: 43422 Train loss: 0.007821\n",
      "Epoch: 6204/10000 Iteration: 43429 Train loss: 0.007821\n",
      "Epoch: 6205/10000 Iteration: 43436 Train loss: 0.007820\n",
      "Epoch: 6206/10000 Iteration: 43443 Train loss: 0.007820\n",
      "Epoch: 6207/10000 Iteration: 43450 Train loss: 0.007820\n",
      "Epoch: 6208/10000 Iteration: 43457 Train loss: 0.007820\n",
      "Epoch: 6209/10000 Iteration: 43464 Train loss: 0.007820\n",
      "Epoch: 6210/10000 Iteration: 43471 Train loss: 0.007819\n",
      "Epoch: 6211/10000 Iteration: 43478 Train loss: 0.007819\n",
      "Epoch: 6212/10000 Iteration: 43485 Train loss: 0.007819\n",
      "Epoch: 6213/10000 Iteration: 43492 Train loss: 0.007819\n",
      "Epoch: 6214/10000 Iteration: 43499 Train loss: 0.007818\n",
      "Epoch: 6215/10000 Iteration: 43506 Train loss: 0.007818\n",
      "Epoch: 6216/10000 Iteration: 43513 Train loss: 0.007818\n",
      "Epoch: 6217/10000 Iteration: 43520 Train loss: 0.007818\n",
      "Epoch: 6218/10000 Iteration: 43527 Train loss: 0.007818\n",
      "Epoch: 6219/10000 Iteration: 43534 Train loss: 0.007817\n",
      "Epoch: 6220/10000 Iteration: 43541 Train loss: 0.007817\n",
      "Epoch: 6221/10000 Iteration: 43548 Train loss: 0.007817\n",
      "Epoch: 6222/10000 Iteration: 43555 Train loss: 0.007817\n",
      "Epoch: 6223/10000 Iteration: 43562 Train loss: 0.007817\n",
      "Epoch: 6224/10000 Iteration: 43569 Train loss: 0.007816\n",
      "Epoch: 6225/10000 Iteration: 43576 Train loss: 0.007816\n",
      "Epoch: 6226/10000 Iteration: 43583 Train loss: 0.007816\n",
      "Epoch: 6227/10000 Iteration: 43590 Train loss: 0.007816\n",
      "Epoch: 6228/10000 Iteration: 43597 Train loss: 0.007816\n",
      "Epoch: 6229/10000 Iteration: 43604 Train loss: 0.007815\n",
      "Epoch: 6230/10000 Iteration: 43611 Train loss: 0.007815\n",
      "Epoch: 6231/10000 Iteration: 43618 Train loss: 0.007815\n",
      "Epoch: 6232/10000 Iteration: 43625 Train loss: 0.007815\n",
      "Epoch: 6233/10000 Iteration: 43632 Train loss: 0.007815\n",
      "Epoch: 6234/10000 Iteration: 43639 Train loss: 0.007814\n",
      "Epoch: 6235/10000 Iteration: 43646 Train loss: 0.007814\n",
      "Epoch: 6236/10000 Iteration: 43653 Train loss: 0.007814\n",
      "Epoch: 6237/10000 Iteration: 43660 Train loss: 0.007814\n",
      "Epoch: 6238/10000 Iteration: 43667 Train loss: 0.007814\n",
      "Epoch: 6239/10000 Iteration: 43674 Train loss: 0.007813\n",
      "Epoch: 6240/10000 Iteration: 43681 Train loss: 0.007813\n",
      "Epoch: 6241/10000 Iteration: 43688 Train loss: 0.007813\n",
      "Epoch: 6242/10000 Iteration: 43695 Train loss: 0.007813\n",
      "Epoch: 6243/10000 Iteration: 43702 Train loss: 0.007812\n",
      "Epoch: 6244/10000 Iteration: 43709 Train loss: 0.007812\n",
      "Epoch: 6245/10000 Iteration: 43716 Train loss: 0.007812\n",
      "Epoch: 6246/10000 Iteration: 43723 Train loss: 0.007812\n",
      "Epoch: 6247/10000 Iteration: 43730 Train loss: 0.007812\n",
      "Epoch: 6248/10000 Iteration: 43737 Train loss: 0.007811\n",
      "Epoch: 6249/10000 Iteration: 43744 Train loss: 0.007811\n",
      "Epoch: 6250/10000 Iteration: 43751 Train loss: 0.007811\n",
      "Epoch: 6251/10000 Iteration: 43758 Train loss: 0.007811\n",
      "Epoch: 6252/10000 Iteration: 43765 Train loss: 0.007811\n",
      "Epoch: 6253/10000 Iteration: 43772 Train loss: 0.007810\n",
      "Epoch: 6254/10000 Iteration: 43779 Train loss: 0.007810\n",
      "Epoch: 6255/10000 Iteration: 43786 Train loss: 0.007810\n",
      "Epoch: 6256/10000 Iteration: 43793 Train loss: 0.007810\n",
      "Epoch: 6257/10000 Iteration: 43800 Train loss: 0.007810\n",
      "Epoch: 6258/10000 Iteration: 43807 Train loss: 0.007809\n",
      "Epoch: 6259/10000 Iteration: 43814 Train loss: 0.007809\n",
      "Epoch: 6260/10000 Iteration: 43821 Train loss: 0.007809\n",
      "Epoch: 6261/10000 Iteration: 43828 Train loss: 0.007809\n",
      "Epoch: 6262/10000 Iteration: 43835 Train loss: 0.007809\n",
      "Epoch: 6263/10000 Iteration: 43842 Train loss: 0.007808\n",
      "Epoch: 6264/10000 Iteration: 43849 Train loss: 0.007808\n",
      "Epoch: 6265/10000 Iteration: 43856 Train loss: 0.007808\n",
      "Epoch: 6266/10000 Iteration: 43863 Train loss: 0.007808\n",
      "Epoch: 6267/10000 Iteration: 43870 Train loss: 0.007808\n",
      "Epoch: 6268/10000 Iteration: 43877 Train loss: 0.007807\n",
      "Epoch: 6269/10000 Iteration: 43884 Train loss: 0.007807\n",
      "Epoch: 6270/10000 Iteration: 43891 Train loss: 0.007807\n",
      "Epoch: 6271/10000 Iteration: 43898 Train loss: 0.007807\n",
      "Epoch: 6272/10000 Iteration: 43905 Train loss: 0.007807\n",
      "Epoch: 6273/10000 Iteration: 43912 Train loss: 0.007806\n",
      "Epoch: 6274/10000 Iteration: 43919 Train loss: 0.007806\n",
      "Epoch: 6275/10000 Iteration: 43926 Train loss: 0.007806\n",
      "Epoch: 6276/10000 Iteration: 43933 Train loss: 0.007806\n",
      "Epoch: 6277/10000 Iteration: 43940 Train loss: 0.007806\n",
      "Epoch: 6278/10000 Iteration: 43947 Train loss: 0.007805\n",
      "Epoch: 6279/10000 Iteration: 43954 Train loss: 0.007805\n",
      "Epoch: 6280/10000 Iteration: 43961 Train loss: 0.007805\n",
      "Epoch: 6281/10000 Iteration: 43968 Train loss: 0.007805\n",
      "Epoch: 6282/10000 Iteration: 43975 Train loss: 0.007805\n",
      "Epoch: 6283/10000 Iteration: 43982 Train loss: 0.007804\n",
      "Epoch: 6284/10000 Iteration: 43989 Train loss: 0.007804\n",
      "Epoch: 6285/10000 Iteration: 43996 Train loss: 0.007804\n",
      "Epoch: 6286/10000 Iteration: 44003 Train loss: 0.007804\n",
      "Epoch: 6287/10000 Iteration: 44010 Train loss: 0.007804\n",
      "Epoch: 6288/10000 Iteration: 44017 Train loss: 0.007803\n",
      "Epoch: 6289/10000 Iteration: 44024 Train loss: 0.007803\n",
      "Epoch: 6290/10000 Iteration: 44031 Train loss: 0.007803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6291/10000 Iteration: 44038 Train loss: 0.007803\n",
      "Epoch: 6292/10000 Iteration: 44045 Train loss: 0.007802\n",
      "Epoch: 6293/10000 Iteration: 44052 Train loss: 0.007802\n",
      "Epoch: 6294/10000 Iteration: 44059 Train loss: 0.007802\n",
      "Epoch: 6295/10000 Iteration: 44066 Train loss: 0.007802\n",
      "Epoch: 6296/10000 Iteration: 44073 Train loss: 0.007802\n",
      "Epoch: 6297/10000 Iteration: 44080 Train loss: 0.007801\n",
      "Epoch: 6298/10000 Iteration: 44087 Train loss: 0.007801\n",
      "Epoch: 6299/10000 Iteration: 44094 Train loss: 0.007801\n",
      "Epoch: 6300/10000 Iteration: 44101 Train loss: 0.007801\n",
      "Epoch: 6301/10000 Iteration: 44108 Train loss: 0.007801\n",
      "Epoch: 6302/10000 Iteration: 44115 Train loss: 0.007800\n",
      "Epoch: 6303/10000 Iteration: 44122 Train loss: 0.007800\n",
      "Epoch: 6304/10000 Iteration: 44129 Train loss: 0.007800\n",
      "Epoch: 6305/10000 Iteration: 44136 Train loss: 0.007800\n",
      "Epoch: 6306/10000 Iteration: 44143 Train loss: 0.007800\n",
      "Epoch: 6307/10000 Iteration: 44150 Train loss: 0.007799\n",
      "Epoch: 6308/10000 Iteration: 44157 Train loss: 0.007799\n",
      "Epoch: 6309/10000 Iteration: 44164 Train loss: 0.007799\n",
      "Epoch: 6310/10000 Iteration: 44171 Train loss: 0.007799\n",
      "Epoch: 6311/10000 Iteration: 44178 Train loss: 0.007799\n",
      "Epoch: 6312/10000 Iteration: 44185 Train loss: 0.007798\n",
      "Epoch: 6313/10000 Iteration: 44192 Train loss: 0.007798\n",
      "Epoch: 6314/10000 Iteration: 44199 Train loss: 0.007798\n",
      "Epoch: 6315/10000 Iteration: 44206 Train loss: 0.007798\n",
      "Epoch: 6316/10000 Iteration: 44213 Train loss: 0.007798\n",
      "Epoch: 6317/10000 Iteration: 44220 Train loss: 0.007797\n",
      "Epoch: 6318/10000 Iteration: 44227 Train loss: 0.007797\n",
      "Epoch: 6319/10000 Iteration: 44234 Train loss: 0.007797\n",
      "Epoch: 6320/10000 Iteration: 44241 Train loss: 0.007797\n",
      "Epoch: 6321/10000 Iteration: 44248 Train loss: 0.007797\n",
      "Epoch: 6322/10000 Iteration: 44255 Train loss: 0.007796\n",
      "Epoch: 6323/10000 Iteration: 44262 Train loss: 0.007796\n",
      "Epoch: 6324/10000 Iteration: 44269 Train loss: 0.007796\n",
      "Epoch: 6325/10000 Iteration: 44276 Train loss: 0.007796\n",
      "Epoch: 6326/10000 Iteration: 44283 Train loss: 0.007796\n",
      "Epoch: 6327/10000 Iteration: 44290 Train loss: 0.007795\n",
      "Epoch: 6328/10000 Iteration: 44297 Train loss: 0.007795\n",
      "Epoch: 6329/10000 Iteration: 44304 Train loss: 0.007795\n",
      "Epoch: 6330/10000 Iteration: 44311 Train loss: 0.007795\n",
      "Epoch: 6331/10000 Iteration: 44318 Train loss: 0.007795\n",
      "Epoch: 6332/10000 Iteration: 44325 Train loss: 0.007794\n",
      "Epoch: 6333/10000 Iteration: 44332 Train loss: 0.007794\n",
      "Epoch: 6334/10000 Iteration: 44339 Train loss: 0.007794\n",
      "Epoch: 6335/10000 Iteration: 44346 Train loss: 0.007794\n",
      "Epoch: 6336/10000 Iteration: 44353 Train loss: 0.007794\n",
      "Epoch: 6337/10000 Iteration: 44360 Train loss: 0.007793\n",
      "Epoch: 6338/10000 Iteration: 44367 Train loss: 0.007793\n",
      "Epoch: 6339/10000 Iteration: 44374 Train loss: 0.007793\n",
      "Epoch: 6340/10000 Iteration: 44381 Train loss: 0.007793\n",
      "Epoch: 6341/10000 Iteration: 44388 Train loss: 0.007793\n",
      "Epoch: 6342/10000 Iteration: 44395 Train loss: 0.007792\n",
      "Epoch: 6343/10000 Iteration: 44402 Train loss: 0.007792\n",
      "Epoch: 6344/10000 Iteration: 44409 Train loss: 0.007792\n",
      "Epoch: 6345/10000 Iteration: 44416 Train loss: 0.007792\n",
      "Epoch: 6346/10000 Iteration: 44423 Train loss: 0.007792\n",
      "Epoch: 6347/10000 Iteration: 44430 Train loss: 0.007791\n",
      "Epoch: 6348/10000 Iteration: 44437 Train loss: 0.007791\n",
      "Epoch: 6349/10000 Iteration: 44444 Train loss: 0.007791\n",
      "Epoch: 6350/10000 Iteration: 44451 Train loss: 0.007791\n",
      "Epoch: 6351/10000 Iteration: 44458 Train loss: 0.007791\n",
      "Epoch: 6352/10000 Iteration: 44465 Train loss: 0.007790\n",
      "Epoch: 6353/10000 Iteration: 44472 Train loss: 0.007790\n",
      "Epoch: 6354/10000 Iteration: 44479 Train loss: 0.007790\n",
      "Epoch: 6355/10000 Iteration: 44486 Train loss: 0.007790\n",
      "Epoch: 6356/10000 Iteration: 44493 Train loss: 0.007789\n",
      "Epoch: 6357/10000 Iteration: 44500 Train loss: 0.007789\n",
      "Epoch: 6358/10000 Iteration: 44507 Train loss: 0.007789\n",
      "Epoch: 6359/10000 Iteration: 44514 Train loss: 0.007789\n",
      "Epoch: 6360/10000 Iteration: 44521 Train loss: 0.007789\n",
      "Epoch: 6361/10000 Iteration: 44528 Train loss: 0.007788\n",
      "Epoch: 6362/10000 Iteration: 44535 Train loss: 0.007788\n",
      "Epoch: 6363/10000 Iteration: 44542 Train loss: 0.007788\n",
      "Epoch: 6364/10000 Iteration: 44549 Train loss: 0.007788\n",
      "Epoch: 6365/10000 Iteration: 44556 Train loss: 0.007788\n",
      "Epoch: 6366/10000 Iteration: 44563 Train loss: 0.007787\n",
      "Epoch: 6367/10000 Iteration: 44570 Train loss: 0.007787\n",
      "Epoch: 6368/10000 Iteration: 44577 Train loss: 0.007787\n",
      "Epoch: 6369/10000 Iteration: 44584 Train loss: 0.007787\n",
      "Epoch: 6370/10000 Iteration: 44591 Train loss: 0.007787\n",
      "Epoch: 6371/10000 Iteration: 44598 Train loss: 0.007786\n",
      "Epoch: 6372/10000 Iteration: 44605 Train loss: 0.007786\n",
      "Epoch: 6373/10000 Iteration: 44612 Train loss: 0.007786\n",
      "Epoch: 6374/10000 Iteration: 44619 Train loss: 0.007786\n",
      "Epoch: 6375/10000 Iteration: 44626 Train loss: 0.007786\n",
      "Epoch: 6376/10000 Iteration: 44633 Train loss: 0.007785\n",
      "Epoch: 6377/10000 Iteration: 44640 Train loss: 0.007785\n",
      "Epoch: 6378/10000 Iteration: 44647 Train loss: 0.007785\n",
      "Epoch: 6379/10000 Iteration: 44654 Train loss: 0.007785\n",
      "Epoch: 6380/10000 Iteration: 44661 Train loss: 0.007785\n",
      "Epoch: 6381/10000 Iteration: 44668 Train loss: 0.007784\n",
      "Epoch: 6382/10000 Iteration: 44675 Train loss: 0.007784\n",
      "Epoch: 6383/10000 Iteration: 44682 Train loss: 0.007784\n",
      "Epoch: 6384/10000 Iteration: 44689 Train loss: 0.007784\n",
      "Epoch: 6385/10000 Iteration: 44696 Train loss: 0.007784\n",
      "Epoch: 6386/10000 Iteration: 44703 Train loss: 0.007783\n",
      "Epoch: 6387/10000 Iteration: 44710 Train loss: 0.007783\n",
      "Epoch: 6388/10000 Iteration: 44717 Train loss: 0.007783\n",
      "Epoch: 6389/10000 Iteration: 44724 Train loss: 0.007783\n",
      "Epoch: 6390/10000 Iteration: 44731 Train loss: 0.007783\n",
      "Epoch: 6391/10000 Iteration: 44738 Train loss: 0.007782\n",
      "Epoch: 6392/10000 Iteration: 44745 Train loss: 0.007782\n",
      "Epoch: 6393/10000 Iteration: 44752 Train loss: 0.007782\n",
      "Epoch: 6394/10000 Iteration: 44759 Train loss: 0.007782\n",
      "Epoch: 6395/10000 Iteration: 44766 Train loss: 0.007782\n",
      "Epoch: 6396/10000 Iteration: 44773 Train loss: 0.007781\n",
      "Epoch: 6397/10000 Iteration: 44780 Train loss: 0.007781\n",
      "Epoch: 6398/10000 Iteration: 44787 Train loss: 0.007781\n",
      "Epoch: 6399/10000 Iteration: 44794 Train loss: 0.007781\n",
      "Epoch: 6400/10000 Iteration: 44801 Train loss: 0.007781\n",
      "Epoch: 6401/10000 Iteration: 44808 Train loss: 0.007780\n",
      "Epoch: 6402/10000 Iteration: 44815 Train loss: 0.007780\n",
      "Epoch: 6403/10000 Iteration: 44822 Train loss: 0.007780\n",
      "Epoch: 6404/10000 Iteration: 44829 Train loss: 0.007780\n",
      "Epoch: 6405/10000 Iteration: 44836 Train loss: 0.007780\n",
      "Epoch: 6406/10000 Iteration: 44843 Train loss: 0.007779\n",
      "Epoch: 6407/10000 Iteration: 44850 Train loss: 0.007779\n",
      "Epoch: 6408/10000 Iteration: 44857 Train loss: 0.007779\n",
      "Epoch: 6409/10000 Iteration: 44864 Train loss: 0.007779\n",
      "Epoch: 6410/10000 Iteration: 44871 Train loss: 0.007779\n",
      "Epoch: 6411/10000 Iteration: 44878 Train loss: 0.007778\n",
      "Epoch: 6412/10000 Iteration: 44885 Train loss: 0.007778\n",
      "Epoch: 6413/10000 Iteration: 44892 Train loss: 0.007778\n",
      "Epoch: 6414/10000 Iteration: 44899 Train loss: 0.007778\n",
      "Epoch: 6415/10000 Iteration: 44906 Train loss: 0.007778\n",
      "Epoch: 6416/10000 Iteration: 44913 Train loss: 0.007777\n",
      "Epoch: 6417/10000 Iteration: 44920 Train loss: 0.007777\n",
      "Epoch: 6418/10000 Iteration: 44927 Train loss: 0.007777\n",
      "Epoch: 6419/10000 Iteration: 44934 Train loss: 0.007777\n",
      "Epoch: 6420/10000 Iteration: 44941 Train loss: 0.007777\n",
      "Epoch: 6421/10000 Iteration: 44948 Train loss: 0.007776\n",
      "Epoch: 6422/10000 Iteration: 44955 Train loss: 0.007776\n",
      "Epoch: 6423/10000 Iteration: 44962 Train loss: 0.007776\n",
      "Epoch: 6424/10000 Iteration: 44969 Train loss: 0.007776\n",
      "Epoch: 6425/10000 Iteration: 44976 Train loss: 0.007776\n",
      "Epoch: 6426/10000 Iteration: 44983 Train loss: 0.007775\n",
      "Epoch: 6427/10000 Iteration: 44990 Train loss: 0.007775\n",
      "Epoch: 6428/10000 Iteration: 44997 Train loss: 0.007775\n",
      "Epoch: 6429/10000 Iteration: 45004 Train loss: 0.007775\n",
      "Epoch: 6430/10000 Iteration: 45011 Train loss: 0.007775\n",
      "Epoch: 6431/10000 Iteration: 45018 Train loss: 0.007774\n",
      "Epoch: 6432/10000 Iteration: 45025 Train loss: 0.007774\n",
      "Epoch: 6433/10000 Iteration: 45032 Train loss: 0.007774\n",
      "Epoch: 6434/10000 Iteration: 45039 Train loss: 0.007774\n",
      "Epoch: 6435/10000 Iteration: 45046 Train loss: 0.007774\n",
      "Epoch: 6436/10000 Iteration: 45053 Train loss: 0.007773\n",
      "Epoch: 6437/10000 Iteration: 45060 Train loss: 0.007773\n",
      "Epoch: 6438/10000 Iteration: 45067 Train loss: 0.007773\n",
      "Epoch: 6439/10000 Iteration: 45074 Train loss: 0.007773\n",
      "Epoch: 6440/10000 Iteration: 45081 Train loss: 0.007773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6441/10000 Iteration: 45088 Train loss: 0.007772\n",
      "Epoch: 6442/10000 Iteration: 45095 Train loss: 0.007772\n",
      "Epoch: 6443/10000 Iteration: 45102 Train loss: 0.007772\n",
      "Epoch: 6444/10000 Iteration: 45109 Train loss: 0.007772\n",
      "Epoch: 6445/10000 Iteration: 45116 Train loss: 0.007772\n",
      "Epoch: 6446/10000 Iteration: 45123 Train loss: 0.007771\n",
      "Epoch: 6447/10000 Iteration: 45130 Train loss: 0.007771\n",
      "Epoch: 6448/10000 Iteration: 45137 Train loss: 0.007771\n",
      "Epoch: 6449/10000 Iteration: 45144 Train loss: 0.007771\n",
      "Epoch: 6450/10000 Iteration: 45151 Train loss: 0.007771\n",
      "Epoch: 6451/10000 Iteration: 45158 Train loss: 0.007770\n",
      "Epoch: 6452/10000 Iteration: 45165 Train loss: 0.007770\n",
      "Epoch: 6453/10000 Iteration: 45172 Train loss: 0.007770\n",
      "Epoch: 6454/10000 Iteration: 45179 Train loss: 0.007770\n",
      "Epoch: 6455/10000 Iteration: 45186 Train loss: 0.007770\n",
      "Epoch: 6456/10000 Iteration: 45193 Train loss: 0.007770\n",
      "Epoch: 6457/10000 Iteration: 45200 Train loss: 0.007769\n",
      "Epoch: 6458/10000 Iteration: 45207 Train loss: 0.007769\n",
      "Epoch: 6459/10000 Iteration: 45214 Train loss: 0.007769\n",
      "Epoch: 6460/10000 Iteration: 45221 Train loss: 0.007769\n",
      "Epoch: 6461/10000 Iteration: 45228 Train loss: 0.007769\n",
      "Epoch: 6462/10000 Iteration: 45235 Train loss: 0.007768\n",
      "Epoch: 6463/10000 Iteration: 45242 Train loss: 0.007768\n",
      "Epoch: 6464/10000 Iteration: 45249 Train loss: 0.007768\n",
      "Epoch: 6465/10000 Iteration: 45256 Train loss: 0.007768\n",
      "Epoch: 6466/10000 Iteration: 45263 Train loss: 0.007768\n",
      "Epoch: 6467/10000 Iteration: 45270 Train loss: 0.007767\n",
      "Epoch: 6468/10000 Iteration: 45277 Train loss: 0.007767\n",
      "Epoch: 6469/10000 Iteration: 45284 Train loss: 0.007767\n",
      "Epoch: 6470/10000 Iteration: 45291 Train loss: 0.007767\n",
      "Epoch: 6471/10000 Iteration: 45298 Train loss: 0.007767\n",
      "Epoch: 6472/10000 Iteration: 45305 Train loss: 0.007766\n",
      "Epoch: 6473/10000 Iteration: 45312 Train loss: 0.007766\n",
      "Epoch: 6474/10000 Iteration: 45319 Train loss: 0.007766\n",
      "Epoch: 6475/10000 Iteration: 45326 Train loss: 0.007766\n",
      "Epoch: 6476/10000 Iteration: 45333 Train loss: 0.007766\n",
      "Epoch: 6477/10000 Iteration: 45340 Train loss: 0.007765\n",
      "Epoch: 6478/10000 Iteration: 45347 Train loss: 0.007765\n",
      "Epoch: 6479/10000 Iteration: 45354 Train loss: 0.007765\n",
      "Epoch: 6480/10000 Iteration: 45361 Train loss: 0.007765\n",
      "Epoch: 6481/10000 Iteration: 45368 Train loss: 0.007765\n",
      "Epoch: 6482/10000 Iteration: 45375 Train loss: 0.007764\n",
      "Epoch: 6483/10000 Iteration: 45382 Train loss: 0.007764\n",
      "Epoch: 6484/10000 Iteration: 45389 Train loss: 0.007764\n",
      "Epoch: 6485/10000 Iteration: 45396 Train loss: 0.007764\n",
      "Epoch: 6486/10000 Iteration: 45403 Train loss: 0.007764\n",
      "Epoch: 6487/10000 Iteration: 45410 Train loss: 0.007763\n",
      "Epoch: 6488/10000 Iteration: 45417 Train loss: 0.007763\n",
      "Epoch: 6489/10000 Iteration: 45424 Train loss: 0.007763\n",
      "Epoch: 6490/10000 Iteration: 45431 Train loss: 0.007763\n",
      "Epoch: 6491/10000 Iteration: 45438 Train loss: 0.007763\n",
      "Epoch: 6492/10000 Iteration: 45445 Train loss: 0.007762\n",
      "Epoch: 6493/10000 Iteration: 45452 Train loss: 0.007762\n",
      "Epoch: 6494/10000 Iteration: 45459 Train loss: 0.007762\n",
      "Epoch: 6495/10000 Iteration: 45466 Train loss: 0.007762\n",
      "Epoch: 6496/10000 Iteration: 45473 Train loss: 0.007762\n",
      "Epoch: 6497/10000 Iteration: 45480 Train loss: 0.007761\n",
      "Epoch: 6498/10000 Iteration: 45487 Train loss: 0.007761\n",
      "Epoch: 6499/10000 Iteration: 45494 Train loss: 0.007761\n",
      "Epoch: 6500/10000 Iteration: 45501 Train loss: 0.007761\n",
      "Epoch: 6501/10000 Iteration: 45508 Train loss: 0.007761\n",
      "Epoch: 6502/10000 Iteration: 45515 Train loss: 0.007760\n",
      "Epoch: 6503/10000 Iteration: 45522 Train loss: 0.007760\n",
      "Epoch: 6504/10000 Iteration: 45529 Train loss: 0.007760\n",
      "Epoch: 6505/10000 Iteration: 45536 Train loss: 0.007760\n",
      "Epoch: 6506/10000 Iteration: 45543 Train loss: 0.007760\n",
      "Epoch: 6507/10000 Iteration: 45550 Train loss: 0.007759\n",
      "Epoch: 6508/10000 Iteration: 45557 Train loss: 0.007759\n",
      "Epoch: 6509/10000 Iteration: 45564 Train loss: 0.007759\n",
      "Epoch: 6510/10000 Iteration: 45571 Train loss: 0.007759\n",
      "Epoch: 6511/10000 Iteration: 45578 Train loss: 0.007759\n",
      "Epoch: 6512/10000 Iteration: 45585 Train loss: 0.007758\n",
      "Epoch: 6513/10000 Iteration: 45592 Train loss: 0.007758\n",
      "Epoch: 6514/10000 Iteration: 45599 Train loss: 0.007758\n",
      "Epoch: 6515/10000 Iteration: 45606 Train loss: 0.007758\n",
      "Epoch: 6516/10000 Iteration: 45613 Train loss: 0.007758\n",
      "Epoch: 6517/10000 Iteration: 45620 Train loss: 0.007757\n",
      "Epoch: 6518/10000 Iteration: 45627 Train loss: 0.007757\n",
      "Epoch: 6519/10000 Iteration: 45634 Train loss: 0.007757\n",
      "Epoch: 6520/10000 Iteration: 45641 Train loss: 0.007757\n",
      "Epoch: 6521/10000 Iteration: 45648 Train loss: 0.007757\n",
      "Epoch: 6522/10000 Iteration: 45655 Train loss: 0.007757\n",
      "Epoch: 6523/10000 Iteration: 45662 Train loss: 0.007756\n",
      "Epoch: 6524/10000 Iteration: 45669 Train loss: 0.007756\n",
      "Epoch: 6525/10000 Iteration: 45676 Train loss: 0.007756\n",
      "Epoch: 6526/10000 Iteration: 45683 Train loss: 0.007756\n",
      "Epoch: 6527/10000 Iteration: 45690 Train loss: 0.007756\n",
      "Epoch: 6528/10000 Iteration: 45697 Train loss: 0.007755\n",
      "Epoch: 6529/10000 Iteration: 45704 Train loss: 0.007755\n",
      "Epoch: 6530/10000 Iteration: 45711 Train loss: 0.007755\n",
      "Epoch: 6531/10000 Iteration: 45718 Train loss: 0.007755\n",
      "Epoch: 6532/10000 Iteration: 45725 Train loss: 0.007755\n",
      "Epoch: 6533/10000 Iteration: 45732 Train loss: 0.007754\n",
      "Epoch: 6534/10000 Iteration: 45739 Train loss: 0.007754\n",
      "Epoch: 6535/10000 Iteration: 45746 Train loss: 0.007754\n",
      "Epoch: 6536/10000 Iteration: 45753 Train loss: 0.007754\n",
      "Epoch: 6537/10000 Iteration: 45760 Train loss: 0.007754\n",
      "Epoch: 6538/10000 Iteration: 45767 Train loss: 0.007753\n",
      "Epoch: 6539/10000 Iteration: 45774 Train loss: 0.007753\n",
      "Epoch: 6540/10000 Iteration: 45781 Train loss: 0.007753\n",
      "Epoch: 6541/10000 Iteration: 45788 Train loss: 0.007753\n",
      "Epoch: 6542/10000 Iteration: 45795 Train loss: 0.007753\n",
      "Epoch: 6543/10000 Iteration: 45802 Train loss: 0.007752\n",
      "Epoch: 6544/10000 Iteration: 45809 Train loss: 0.007752\n",
      "Epoch: 6545/10000 Iteration: 45816 Train loss: 0.007752\n",
      "Epoch: 6546/10000 Iteration: 45823 Train loss: 0.007752\n",
      "Epoch: 6547/10000 Iteration: 45830 Train loss: 0.007752\n",
      "Epoch: 6548/10000 Iteration: 45837 Train loss: 0.007751\n",
      "Epoch: 6549/10000 Iteration: 45844 Train loss: 0.007751\n",
      "Epoch: 6550/10000 Iteration: 45851 Train loss: 0.007751\n",
      "Epoch: 6551/10000 Iteration: 45858 Train loss: 0.007751\n",
      "Epoch: 6552/10000 Iteration: 45865 Train loss: 0.007751\n",
      "Epoch: 6553/10000 Iteration: 45872 Train loss: 0.007750\n",
      "Epoch: 6554/10000 Iteration: 45879 Train loss: 0.007750\n",
      "Epoch: 6555/10000 Iteration: 45886 Train loss: 0.007750\n",
      "Epoch: 6556/10000 Iteration: 45893 Train loss: 0.007750\n",
      "Epoch: 6557/10000 Iteration: 45900 Train loss: 0.007750\n",
      "Epoch: 6558/10000 Iteration: 45907 Train loss: 0.007750\n",
      "Epoch: 6559/10000 Iteration: 45914 Train loss: 0.007749\n",
      "Epoch: 6560/10000 Iteration: 45921 Train loss: 0.007749\n",
      "Epoch: 6561/10000 Iteration: 45928 Train loss: 0.007749\n",
      "Epoch: 6562/10000 Iteration: 45935 Train loss: 0.007749\n",
      "Epoch: 6563/10000 Iteration: 45942 Train loss: 0.007749\n",
      "Epoch: 6564/10000 Iteration: 45949 Train loss: 0.007748\n",
      "Epoch: 6565/10000 Iteration: 45956 Train loss: 0.007748\n",
      "Epoch: 6566/10000 Iteration: 45963 Train loss: 0.007748\n",
      "Epoch: 6567/10000 Iteration: 45970 Train loss: 0.007748\n",
      "Epoch: 6568/10000 Iteration: 45977 Train loss: 0.007748\n",
      "Epoch: 6569/10000 Iteration: 45984 Train loss: 0.007747\n",
      "Epoch: 6570/10000 Iteration: 45991 Train loss: 0.007747\n",
      "Epoch: 6571/10000 Iteration: 45998 Train loss: 0.007747\n",
      "Epoch: 6572/10000 Iteration: 46005 Train loss: 0.007747\n",
      "Epoch: 6573/10000 Iteration: 46012 Train loss: 0.007747\n",
      "Epoch: 6574/10000 Iteration: 46019 Train loss: 0.007746\n",
      "Epoch: 6575/10000 Iteration: 46026 Train loss: 0.007746\n",
      "Epoch: 6576/10000 Iteration: 46033 Train loss: 0.007746\n",
      "Epoch: 6577/10000 Iteration: 46040 Train loss: 0.007746\n",
      "Epoch: 6578/10000 Iteration: 46047 Train loss: 0.007746\n",
      "Epoch: 6579/10000 Iteration: 46054 Train loss: 0.007745\n",
      "Epoch: 6580/10000 Iteration: 46061 Train loss: 0.007745\n",
      "Epoch: 6581/10000 Iteration: 46068 Train loss: 0.007745\n",
      "Epoch: 6582/10000 Iteration: 46075 Train loss: 0.007745\n",
      "Epoch: 6583/10000 Iteration: 46082 Train loss: 0.007745\n",
      "Epoch: 6584/10000 Iteration: 46089 Train loss: 0.007744\n",
      "Epoch: 6585/10000 Iteration: 46096 Train loss: 0.007744\n",
      "Epoch: 6586/10000 Iteration: 46103 Train loss: 0.007744\n",
      "Epoch: 6587/10000 Iteration: 46110 Train loss: 0.007744\n",
      "Epoch: 6588/10000 Iteration: 46117 Train loss: 0.007744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6589/10000 Iteration: 46124 Train loss: 0.007743\n",
      "Epoch: 6590/10000 Iteration: 46131 Train loss: 0.007743\n",
      "Epoch: 6591/10000 Iteration: 46138 Train loss: 0.007743\n",
      "Epoch: 6592/10000 Iteration: 46145 Train loss: 0.007743\n",
      "Epoch: 6593/10000 Iteration: 46152 Train loss: 0.007743\n",
      "Epoch: 6594/10000 Iteration: 46159 Train loss: 0.007743\n",
      "Epoch: 6595/10000 Iteration: 46166 Train loss: 0.007742\n",
      "Epoch: 6596/10000 Iteration: 46173 Train loss: 0.007742\n",
      "Epoch: 6597/10000 Iteration: 46180 Train loss: 0.007742\n",
      "Epoch: 6598/10000 Iteration: 46187 Train loss: 0.007742\n",
      "Epoch: 6599/10000 Iteration: 46194 Train loss: 0.007742\n",
      "Epoch: 6600/10000 Iteration: 46201 Train loss: 0.007741\n",
      "Epoch: 6601/10000 Iteration: 46208 Train loss: 0.007741\n",
      "Epoch: 6602/10000 Iteration: 46215 Train loss: 0.007741\n",
      "Epoch: 6603/10000 Iteration: 46222 Train loss: 0.007741\n",
      "Epoch: 6604/10000 Iteration: 46229 Train loss: 0.007741\n",
      "Epoch: 6605/10000 Iteration: 46236 Train loss: 0.007740\n",
      "Epoch: 6606/10000 Iteration: 46243 Train loss: 0.007740\n",
      "Epoch: 6607/10000 Iteration: 46250 Train loss: 0.007740\n",
      "Epoch: 6608/10000 Iteration: 46257 Train loss: 0.007740\n",
      "Epoch: 6609/10000 Iteration: 46264 Train loss: 0.007740\n",
      "Epoch: 6610/10000 Iteration: 46271 Train loss: 0.007739\n",
      "Epoch: 6611/10000 Iteration: 46278 Train loss: 0.007739\n",
      "Epoch: 6612/10000 Iteration: 46285 Train loss: 0.007739\n",
      "Epoch: 6613/10000 Iteration: 46292 Train loss: 0.007739\n",
      "Epoch: 6614/10000 Iteration: 46299 Train loss: 0.007739\n",
      "Epoch: 6615/10000 Iteration: 46306 Train loss: 0.007738\n",
      "Epoch: 6616/10000 Iteration: 46313 Train loss: 0.007738\n",
      "Epoch: 6617/10000 Iteration: 46320 Train loss: 0.007738\n",
      "Epoch: 6618/10000 Iteration: 46327 Train loss: 0.007738\n",
      "Epoch: 6619/10000 Iteration: 46334 Train loss: 0.007738\n",
      "Epoch: 6620/10000 Iteration: 46341 Train loss: 0.007738\n",
      "Epoch: 6621/10000 Iteration: 46348 Train loss: 0.007737\n",
      "Epoch: 6622/10000 Iteration: 46355 Train loss: 0.007737\n",
      "Epoch: 6623/10000 Iteration: 46362 Train loss: 0.007737\n",
      "Epoch: 6624/10000 Iteration: 46369 Train loss: 0.007737\n",
      "Epoch: 6625/10000 Iteration: 46376 Train loss: 0.007737\n",
      "Epoch: 6626/10000 Iteration: 46383 Train loss: 0.007736\n",
      "Epoch: 6627/10000 Iteration: 46390 Train loss: 0.007736\n",
      "Epoch: 6628/10000 Iteration: 46397 Train loss: 0.007736\n",
      "Epoch: 6629/10000 Iteration: 46404 Train loss: 0.007736\n",
      "Epoch: 6630/10000 Iteration: 46411 Train loss: 0.007736\n",
      "Epoch: 6631/10000 Iteration: 46418 Train loss: 0.007735\n",
      "Epoch: 6632/10000 Iteration: 46425 Train loss: 0.007735\n",
      "Epoch: 6633/10000 Iteration: 46432 Train loss: 0.007735\n",
      "Epoch: 6634/10000 Iteration: 46439 Train loss: 0.007735\n",
      "Epoch: 6635/10000 Iteration: 46446 Train loss: 0.007735\n",
      "Epoch: 6636/10000 Iteration: 46453 Train loss: 0.007735\n",
      "Epoch: 6637/10000 Iteration: 46460 Train loss: 0.007734\n",
      "Epoch: 6638/10000 Iteration: 46467 Train loss: 0.007734\n",
      "Epoch: 6639/10000 Iteration: 46474 Train loss: 0.007734\n",
      "Epoch: 6640/10000 Iteration: 46481 Train loss: 0.007734\n",
      "Epoch: 6641/10000 Iteration: 46488 Train loss: 0.007734\n",
      "Epoch: 6642/10000 Iteration: 46495 Train loss: 0.007733\n",
      "Epoch: 6643/10000 Iteration: 46502 Train loss: 0.007733\n",
      "Epoch: 6644/10000 Iteration: 46509 Train loss: 0.007733\n",
      "Epoch: 6645/10000 Iteration: 46516 Train loss: 0.007733\n",
      "Epoch: 6646/10000 Iteration: 46523 Train loss: 0.007733\n",
      "Epoch: 6647/10000 Iteration: 46530 Train loss: 0.007732\n",
      "Epoch: 6648/10000 Iteration: 46537 Train loss: 0.007732\n",
      "Epoch: 6649/10000 Iteration: 46544 Train loss: 0.007732\n",
      "Epoch: 6650/10000 Iteration: 46551 Train loss: 0.007732\n",
      "Epoch: 6651/10000 Iteration: 46558 Train loss: 0.007732\n",
      "Epoch: 6652/10000 Iteration: 46565 Train loss: 0.007731\n",
      "Epoch: 6653/10000 Iteration: 46572 Train loss: 0.007731\n",
      "Epoch: 6654/10000 Iteration: 46579 Train loss: 0.007731\n",
      "Epoch: 6655/10000 Iteration: 46586 Train loss: 0.007731\n",
      "Epoch: 6656/10000 Iteration: 46593 Train loss: 0.007731\n",
      "Epoch: 6657/10000 Iteration: 46600 Train loss: 0.007731\n",
      "Epoch: 6658/10000 Iteration: 46607 Train loss: 0.007730\n",
      "Epoch: 6659/10000 Iteration: 46614 Train loss: 0.007730\n",
      "Epoch: 6660/10000 Iteration: 46621 Train loss: 0.007730\n",
      "Epoch: 6661/10000 Iteration: 46628 Train loss: 0.007730\n",
      "Epoch: 6662/10000 Iteration: 46635 Train loss: 0.007730\n",
      "Epoch: 6663/10000 Iteration: 46642 Train loss: 0.007729\n",
      "Epoch: 6664/10000 Iteration: 46649 Train loss: 0.007729\n",
      "Epoch: 6665/10000 Iteration: 46656 Train loss: 0.007729\n",
      "Epoch: 6666/10000 Iteration: 46663 Train loss: 0.007729\n",
      "Epoch: 6667/10000 Iteration: 46670 Train loss: 0.007729\n",
      "Epoch: 6668/10000 Iteration: 46677 Train loss: 0.007728\n",
      "Epoch: 6669/10000 Iteration: 46684 Train loss: 0.007728\n",
      "Epoch: 6670/10000 Iteration: 46691 Train loss: 0.007728\n",
      "Epoch: 6671/10000 Iteration: 46698 Train loss: 0.007728\n",
      "Epoch: 6672/10000 Iteration: 46705 Train loss: 0.007728\n",
      "Epoch: 6673/10000 Iteration: 46712 Train loss: 0.007727\n",
      "Epoch: 6674/10000 Iteration: 46719 Train loss: 0.007727\n",
      "Epoch: 6675/10000 Iteration: 46726 Train loss: 0.007727\n",
      "Epoch: 6676/10000 Iteration: 46733 Train loss: 0.007727\n",
      "Epoch: 6677/10000 Iteration: 46740 Train loss: 0.007727\n",
      "Epoch: 6678/10000 Iteration: 46747 Train loss: 0.007727\n",
      "Epoch: 6679/10000 Iteration: 46754 Train loss: 0.007726\n",
      "Epoch: 6680/10000 Iteration: 46761 Train loss: 0.007726\n",
      "Epoch: 6681/10000 Iteration: 46768 Train loss: 0.007726\n",
      "Epoch: 6682/10000 Iteration: 46775 Train loss: 0.007726\n",
      "Epoch: 6683/10000 Iteration: 46782 Train loss: 0.007726\n",
      "Epoch: 6684/10000 Iteration: 46789 Train loss: 0.007725\n",
      "Epoch: 6685/10000 Iteration: 46796 Train loss: 0.007725\n",
      "Epoch: 6686/10000 Iteration: 46803 Train loss: 0.007725\n",
      "Epoch: 6687/10000 Iteration: 46810 Train loss: 0.007725\n",
      "Epoch: 6688/10000 Iteration: 46817 Train loss: 0.007725\n",
      "Epoch: 6689/10000 Iteration: 46824 Train loss: 0.007724\n",
      "Epoch: 6690/10000 Iteration: 46831 Train loss: 0.007724\n",
      "Epoch: 6691/10000 Iteration: 46838 Train loss: 0.007724\n",
      "Epoch: 6692/10000 Iteration: 46845 Train loss: 0.007724\n",
      "Epoch: 6693/10000 Iteration: 46852 Train loss: 0.007724\n",
      "Epoch: 6694/10000 Iteration: 46859 Train loss: 0.007724\n",
      "Epoch: 6695/10000 Iteration: 46866 Train loss: 0.007723\n",
      "Epoch: 6696/10000 Iteration: 46873 Train loss: 0.007723\n",
      "Epoch: 6697/10000 Iteration: 46880 Train loss: 0.007723\n",
      "Epoch: 6698/10000 Iteration: 46887 Train loss: 0.007723\n",
      "Epoch: 6699/10000 Iteration: 46894 Train loss: 0.007723\n",
      "Epoch: 6700/10000 Iteration: 46901 Train loss: 0.007722\n",
      "Epoch: 6701/10000 Iteration: 46908 Train loss: 0.007722\n",
      "Epoch: 6702/10000 Iteration: 46915 Train loss: 0.007722\n",
      "Epoch: 6703/10000 Iteration: 46922 Train loss: 0.007722\n",
      "Epoch: 6704/10000 Iteration: 46929 Train loss: 0.007722\n",
      "Epoch: 6705/10000 Iteration: 46936 Train loss: 0.007721\n",
      "Epoch: 6706/10000 Iteration: 46943 Train loss: 0.007721\n",
      "Epoch: 6707/10000 Iteration: 46950 Train loss: 0.007721\n",
      "Epoch: 6708/10000 Iteration: 46957 Train loss: 0.007721\n",
      "Epoch: 6709/10000 Iteration: 46964 Train loss: 0.007721\n",
      "Epoch: 6710/10000 Iteration: 46971 Train loss: 0.007721\n",
      "Epoch: 6711/10000 Iteration: 46978 Train loss: 0.007720\n",
      "Epoch: 6712/10000 Iteration: 46985 Train loss: 0.007720\n",
      "Epoch: 6713/10000 Iteration: 46992 Train loss: 0.007720\n",
      "Epoch: 6714/10000 Iteration: 46999 Train loss: 0.007720\n",
      "Epoch: 6715/10000 Iteration: 47006 Train loss: 0.007720\n",
      "Epoch: 6716/10000 Iteration: 47013 Train loss: 0.007719\n",
      "Epoch: 6717/10000 Iteration: 47020 Train loss: 0.007719\n",
      "Epoch: 6718/10000 Iteration: 47027 Train loss: 0.007719\n",
      "Epoch: 6719/10000 Iteration: 47034 Train loss: 0.007719\n",
      "Epoch: 6720/10000 Iteration: 47041 Train loss: 0.007719\n",
      "Epoch: 6721/10000 Iteration: 47048 Train loss: 0.007718\n",
      "Epoch: 6722/10000 Iteration: 47055 Train loss: 0.007718\n",
      "Epoch: 6723/10000 Iteration: 47062 Train loss: 0.007718\n",
      "Epoch: 6724/10000 Iteration: 47069 Train loss: 0.007718\n",
      "Epoch: 6725/10000 Iteration: 47076 Train loss: 0.007718\n",
      "Epoch: 6726/10000 Iteration: 47083 Train loss: 0.007718\n",
      "Epoch: 6727/10000 Iteration: 47090 Train loss: 0.007717\n",
      "Epoch: 6728/10000 Iteration: 47097 Train loss: 0.007717\n",
      "Epoch: 6729/10000 Iteration: 47104 Train loss: 0.007717\n",
      "Epoch: 6730/10000 Iteration: 47111 Train loss: 0.007717\n",
      "Epoch: 6731/10000 Iteration: 47118 Train loss: 0.007717\n",
      "Epoch: 6732/10000 Iteration: 47125 Train loss: 0.007716\n",
      "Epoch: 6733/10000 Iteration: 47132 Train loss: 0.007716\n",
      "Epoch: 6734/10000 Iteration: 47139 Train loss: 0.007716\n",
      "Epoch: 6735/10000 Iteration: 47146 Train loss: 0.007716\n",
      "Epoch: 6736/10000 Iteration: 47153 Train loss: 0.007716\n",
      "Epoch: 6737/10000 Iteration: 47160 Train loss: 0.007715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6738/10000 Iteration: 47167 Train loss: 0.007715\n",
      "Epoch: 6739/10000 Iteration: 47174 Train loss: 0.007715\n",
      "Epoch: 6740/10000 Iteration: 47181 Train loss: 0.007715\n",
      "Epoch: 6741/10000 Iteration: 47188 Train loss: 0.007715\n",
      "Epoch: 6742/10000 Iteration: 47195 Train loss: 0.007715\n",
      "Epoch: 6743/10000 Iteration: 47202 Train loss: 0.007714\n",
      "Epoch: 6744/10000 Iteration: 47209 Train loss: 0.007714\n",
      "Epoch: 6745/10000 Iteration: 47216 Train loss: 0.007714\n",
      "Epoch: 6746/10000 Iteration: 47223 Train loss: 0.007714\n",
      "Epoch: 6747/10000 Iteration: 47230 Train loss: 0.007714\n",
      "Epoch: 6748/10000 Iteration: 47237 Train loss: 0.007713\n",
      "Epoch: 6749/10000 Iteration: 47244 Train loss: 0.007713\n",
      "Epoch: 6750/10000 Iteration: 47251 Train loss: 0.007713\n",
      "Epoch: 6751/10000 Iteration: 47258 Train loss: 0.007713\n",
      "Epoch: 6752/10000 Iteration: 47265 Train loss: 0.007713\n",
      "Epoch: 6753/10000 Iteration: 47272 Train loss: 0.007713\n",
      "Epoch: 6754/10000 Iteration: 47279 Train loss: 0.007712\n",
      "Epoch: 6755/10000 Iteration: 47286 Train loss: 0.007712\n",
      "Epoch: 6756/10000 Iteration: 47293 Train loss: 0.007712\n",
      "Epoch: 6757/10000 Iteration: 47300 Train loss: 0.007712\n",
      "Epoch: 6758/10000 Iteration: 47307 Train loss: 0.007712\n",
      "Epoch: 6759/10000 Iteration: 47314 Train loss: 0.007711\n",
      "Epoch: 6760/10000 Iteration: 47321 Train loss: 0.007711\n",
      "Epoch: 6761/10000 Iteration: 47328 Train loss: 0.007711\n",
      "Epoch: 6762/10000 Iteration: 47335 Train loss: 0.007711\n",
      "Epoch: 6763/10000 Iteration: 47342 Train loss: 0.007711\n",
      "Epoch: 6764/10000 Iteration: 47349 Train loss: 0.007710\n",
      "Epoch: 6765/10000 Iteration: 47356 Train loss: 0.007710\n",
      "Epoch: 6766/10000 Iteration: 47363 Train loss: 0.007710\n",
      "Epoch: 6767/10000 Iteration: 47370 Train loss: 0.007710\n",
      "Epoch: 6768/10000 Iteration: 47377 Train loss: 0.007710\n",
      "Epoch: 6769/10000 Iteration: 47384 Train loss: 0.007710\n",
      "Epoch: 6770/10000 Iteration: 47391 Train loss: 0.007709\n",
      "Epoch: 6771/10000 Iteration: 47398 Train loss: 0.007709\n",
      "Epoch: 6772/10000 Iteration: 47405 Train loss: 0.007709\n",
      "Epoch: 6773/10000 Iteration: 47412 Train loss: 0.007709\n",
      "Epoch: 6774/10000 Iteration: 47419 Train loss: 0.007709\n",
      "Epoch: 6775/10000 Iteration: 47426 Train loss: 0.007708\n",
      "Epoch: 6776/10000 Iteration: 47433 Train loss: 0.007708\n",
      "Epoch: 6777/10000 Iteration: 47440 Train loss: 0.007708\n",
      "Epoch: 6778/10000 Iteration: 47447 Train loss: 0.007708\n",
      "Epoch: 6779/10000 Iteration: 47454 Train loss: 0.007708\n",
      "Epoch: 6780/10000 Iteration: 47461 Train loss: 0.007708\n",
      "Epoch: 6781/10000 Iteration: 47468 Train loss: 0.007707\n",
      "Epoch: 6782/10000 Iteration: 47475 Train loss: 0.007707\n",
      "Epoch: 6783/10000 Iteration: 47482 Train loss: 0.007707\n",
      "Epoch: 6784/10000 Iteration: 47489 Train loss: 0.007707\n",
      "Epoch: 6785/10000 Iteration: 47496 Train loss: 0.007707\n",
      "Epoch: 6786/10000 Iteration: 47503 Train loss: 0.007706\n",
      "Epoch: 6787/10000 Iteration: 47510 Train loss: 0.007706\n",
      "Epoch: 6788/10000 Iteration: 47517 Train loss: 0.007706\n",
      "Epoch: 6789/10000 Iteration: 47524 Train loss: 0.007706\n",
      "Epoch: 6790/10000 Iteration: 47531 Train loss: 0.007706\n",
      "Epoch: 6791/10000 Iteration: 47538 Train loss: 0.007706\n",
      "Epoch: 6792/10000 Iteration: 47545 Train loss: 0.007705\n",
      "Epoch: 6793/10000 Iteration: 47552 Train loss: 0.007705\n",
      "Epoch: 6794/10000 Iteration: 47559 Train loss: 0.007705\n",
      "Epoch: 6795/10000 Iteration: 47566 Train loss: 0.007705\n",
      "Epoch: 6796/10000 Iteration: 47573 Train loss: 0.007705\n",
      "Epoch: 6797/10000 Iteration: 47580 Train loss: 0.007704\n",
      "Epoch: 6798/10000 Iteration: 47587 Train loss: 0.007704\n",
      "Epoch: 6799/10000 Iteration: 47594 Train loss: 0.007704\n",
      "Epoch: 6800/10000 Iteration: 47601 Train loss: 0.007704\n",
      "Epoch: 6801/10000 Iteration: 47608 Train loss: 0.007704\n",
      "Epoch: 6802/10000 Iteration: 47615 Train loss: 0.007704\n",
      "Epoch: 6803/10000 Iteration: 47622 Train loss: 0.007703\n",
      "Epoch: 6804/10000 Iteration: 47629 Train loss: 0.007703\n",
      "Epoch: 6805/10000 Iteration: 47636 Train loss: 0.007703\n",
      "Epoch: 6806/10000 Iteration: 47643 Train loss: 0.007703\n",
      "Epoch: 6807/10000 Iteration: 47650 Train loss: 0.007703\n",
      "Epoch: 6808/10000 Iteration: 47657 Train loss: 0.007702\n",
      "Epoch: 6809/10000 Iteration: 47664 Train loss: 0.007702\n",
      "Epoch: 6810/10000 Iteration: 47671 Train loss: 0.007702\n",
      "Epoch: 6811/10000 Iteration: 47678 Train loss: 0.007702\n",
      "Epoch: 6812/10000 Iteration: 47685 Train loss: 0.007702\n",
      "Epoch: 6813/10000 Iteration: 47692 Train loss: 0.007702\n",
      "Epoch: 6814/10000 Iteration: 47699 Train loss: 0.007701\n",
      "Epoch: 6815/10000 Iteration: 47706 Train loss: 0.007701\n",
      "Epoch: 6816/10000 Iteration: 47713 Train loss: 0.007701\n",
      "Epoch: 6817/10000 Iteration: 47720 Train loss: 0.007701\n",
      "Epoch: 6818/10000 Iteration: 47727 Train loss: 0.007701\n",
      "Epoch: 6819/10000 Iteration: 47734 Train loss: 0.007700\n",
      "Epoch: 6820/10000 Iteration: 47741 Train loss: 0.007700\n",
      "Epoch: 6821/10000 Iteration: 47748 Train loss: 0.007700\n",
      "Epoch: 6822/10000 Iteration: 47755 Train loss: 0.007700\n",
      "Epoch: 6823/10000 Iteration: 47762 Train loss: 0.007700\n",
      "Epoch: 6824/10000 Iteration: 47769 Train loss: 0.007700\n",
      "Epoch: 6825/10000 Iteration: 47776 Train loss: 0.007699\n",
      "Epoch: 6826/10000 Iteration: 47783 Train loss: 0.007699\n",
      "Epoch: 6827/10000 Iteration: 47790 Train loss: 0.007699\n",
      "Epoch: 6828/10000 Iteration: 47797 Train loss: 0.007699\n",
      "Epoch: 6829/10000 Iteration: 47804 Train loss: 0.007699\n",
      "Epoch: 6830/10000 Iteration: 47811 Train loss: 0.007698\n",
      "Epoch: 6831/10000 Iteration: 47818 Train loss: 0.007698\n",
      "Epoch: 6832/10000 Iteration: 47825 Train loss: 0.007698\n",
      "Epoch: 6833/10000 Iteration: 47832 Train loss: 0.007698\n",
      "Epoch: 6834/10000 Iteration: 47839 Train loss: 0.007698\n",
      "Epoch: 6835/10000 Iteration: 47846 Train loss: 0.007697\n",
      "Epoch: 6836/10000 Iteration: 47853 Train loss: 0.007697\n",
      "Epoch: 6837/10000 Iteration: 47860 Train loss: 0.007697\n",
      "Epoch: 6838/10000 Iteration: 47867 Train loss: 0.007697\n",
      "Epoch: 6839/10000 Iteration: 47874 Train loss: 0.007697\n",
      "Epoch: 6840/10000 Iteration: 47881 Train loss: 0.007697\n",
      "Epoch: 6841/10000 Iteration: 47888 Train loss: 0.007696\n",
      "Epoch: 6842/10000 Iteration: 47895 Train loss: 0.007696\n",
      "Epoch: 6843/10000 Iteration: 47902 Train loss: 0.007696\n",
      "Epoch: 6844/10000 Iteration: 47909 Train loss: 0.007696\n",
      "Epoch: 6845/10000 Iteration: 47916 Train loss: 0.007696\n",
      "Epoch: 6846/10000 Iteration: 47923 Train loss: 0.007696\n",
      "Epoch: 6847/10000 Iteration: 47930 Train loss: 0.007695\n",
      "Epoch: 6848/10000 Iteration: 47937 Train loss: 0.007695\n",
      "Epoch: 6849/10000 Iteration: 47944 Train loss: 0.007695\n",
      "Epoch: 6850/10000 Iteration: 47951 Train loss: 0.007695\n",
      "Epoch: 6851/10000 Iteration: 47958 Train loss: 0.007695\n",
      "Epoch: 6852/10000 Iteration: 47965 Train loss: 0.007694\n",
      "Epoch: 6853/10000 Iteration: 47972 Train loss: 0.007694\n",
      "Epoch: 6854/10000 Iteration: 47979 Train loss: 0.007694\n",
      "Epoch: 6855/10000 Iteration: 47986 Train loss: 0.007694\n",
      "Epoch: 6856/10000 Iteration: 47993 Train loss: 0.007694\n",
      "Epoch: 6857/10000 Iteration: 48000 Train loss: 0.007694\n",
      "Epoch: 6858/10000 Iteration: 48007 Train loss: 0.007693\n",
      "Epoch: 6859/10000 Iteration: 48014 Train loss: 0.007693\n",
      "Epoch: 6860/10000 Iteration: 48021 Train loss: 0.007693\n",
      "Epoch: 6861/10000 Iteration: 48028 Train loss: 0.007693\n",
      "Epoch: 6862/10000 Iteration: 48035 Train loss: 0.007693\n",
      "Epoch: 6863/10000 Iteration: 48042 Train loss: 0.007692\n",
      "Epoch: 6864/10000 Iteration: 48049 Train loss: 0.007692\n",
      "Epoch: 6865/10000 Iteration: 48056 Train loss: 0.007692\n",
      "Epoch: 6866/10000 Iteration: 48063 Train loss: 0.007692\n",
      "Epoch: 6867/10000 Iteration: 48070 Train loss: 0.007692\n",
      "Epoch: 6868/10000 Iteration: 48077 Train loss: 0.007692\n",
      "Epoch: 6869/10000 Iteration: 48084 Train loss: 0.007691\n",
      "Epoch: 6870/10000 Iteration: 48091 Train loss: 0.007691\n",
      "Epoch: 6871/10000 Iteration: 48098 Train loss: 0.007691\n",
      "Epoch: 6872/10000 Iteration: 48105 Train loss: 0.007691\n",
      "Epoch: 6873/10000 Iteration: 48112 Train loss: 0.007691\n",
      "Epoch: 6874/10000 Iteration: 48119 Train loss: 0.007690\n",
      "Epoch: 6875/10000 Iteration: 48126 Train loss: 0.007690\n",
      "Epoch: 6876/10000 Iteration: 48133 Train loss: 0.007690\n",
      "Epoch: 6877/10000 Iteration: 48140 Train loss: 0.007690\n",
      "Epoch: 6878/10000 Iteration: 48147 Train loss: 0.007690\n",
      "Epoch: 6879/10000 Iteration: 48154 Train loss: 0.007690\n",
      "Epoch: 6880/10000 Iteration: 48161 Train loss: 0.007689\n",
      "Epoch: 6881/10000 Iteration: 48168 Train loss: 0.007689\n",
      "Epoch: 6882/10000 Iteration: 48175 Train loss: 0.007689\n",
      "Epoch: 6883/10000 Iteration: 48182 Train loss: 0.007689\n",
      "Epoch: 6884/10000 Iteration: 48189 Train loss: 0.007689\n",
      "Epoch: 6885/10000 Iteration: 48196 Train loss: 0.007689\n",
      "Epoch: 6886/10000 Iteration: 48203 Train loss: 0.007688\n",
      "Epoch: 6887/10000 Iteration: 48210 Train loss: 0.007688\n",
      "Epoch: 6888/10000 Iteration: 48217 Train loss: 0.007688\n",
      "Epoch: 6889/10000 Iteration: 48224 Train loss: 0.007688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6890/10000 Iteration: 48231 Train loss: 0.007688\n",
      "Epoch: 6891/10000 Iteration: 48238 Train loss: 0.007687\n",
      "Epoch: 6892/10000 Iteration: 48245 Train loss: 0.007687\n",
      "Epoch: 6893/10000 Iteration: 48252 Train loss: 0.007687\n",
      "Epoch: 6894/10000 Iteration: 48259 Train loss: 0.007687\n",
      "Epoch: 6895/10000 Iteration: 48266 Train loss: 0.007687\n",
      "Epoch: 6896/10000 Iteration: 48273 Train loss: 0.007687\n",
      "Epoch: 6897/10000 Iteration: 48280 Train loss: 0.007686\n",
      "Epoch: 6898/10000 Iteration: 48287 Train loss: 0.007686\n",
      "Epoch: 6899/10000 Iteration: 48294 Train loss: 0.007686\n",
      "Epoch: 6900/10000 Iteration: 48301 Train loss: 0.007686\n",
      "Epoch: 6901/10000 Iteration: 48308 Train loss: 0.007686\n",
      "Epoch: 6902/10000 Iteration: 48315 Train loss: 0.007686\n",
      "Epoch: 6903/10000 Iteration: 48322 Train loss: 0.007685\n",
      "Epoch: 6904/10000 Iteration: 48329 Train loss: 0.007685\n",
      "Epoch: 6905/10000 Iteration: 48336 Train loss: 0.007685\n",
      "Epoch: 6906/10000 Iteration: 48343 Train loss: 0.007685\n",
      "Epoch: 6907/10000 Iteration: 48350 Train loss: 0.007685\n",
      "Epoch: 6908/10000 Iteration: 48357 Train loss: 0.007684\n",
      "Epoch: 6909/10000 Iteration: 48364 Train loss: 0.007684\n",
      "Epoch: 6910/10000 Iteration: 48371 Train loss: 0.007684\n",
      "Epoch: 6911/10000 Iteration: 48378 Train loss: 0.007684\n",
      "Epoch: 6912/10000 Iteration: 48385 Train loss: 0.007684\n",
      "Epoch: 6913/10000 Iteration: 48392 Train loss: 0.007684\n",
      "Epoch: 6914/10000 Iteration: 48399 Train loss: 0.007683\n",
      "Epoch: 6915/10000 Iteration: 48406 Train loss: 0.007683\n",
      "Epoch: 6916/10000 Iteration: 48413 Train loss: 0.007683\n",
      "Epoch: 6917/10000 Iteration: 48420 Train loss: 0.007683\n",
      "Epoch: 6918/10000 Iteration: 48427 Train loss: 0.007683\n",
      "Epoch: 6919/10000 Iteration: 48434 Train loss: 0.007682\n",
      "Epoch: 6920/10000 Iteration: 48441 Train loss: 0.007682\n",
      "Epoch: 6921/10000 Iteration: 48448 Train loss: 0.007682\n",
      "Epoch: 6922/10000 Iteration: 48455 Train loss: 0.007682\n",
      "Epoch: 6923/10000 Iteration: 48462 Train loss: 0.007682\n",
      "Epoch: 6924/10000 Iteration: 48469 Train loss: 0.007682\n",
      "Epoch: 6925/10000 Iteration: 48476 Train loss: 0.007681\n",
      "Epoch: 6926/10000 Iteration: 48483 Train loss: 0.007681\n",
      "Epoch: 6927/10000 Iteration: 48490 Train loss: 0.007681\n",
      "Epoch: 6928/10000 Iteration: 48497 Train loss: 0.007681\n",
      "Epoch: 6929/10000 Iteration: 48504 Train loss: 0.007681\n",
      "Epoch: 6930/10000 Iteration: 48511 Train loss: 0.007681\n",
      "Epoch: 6931/10000 Iteration: 48518 Train loss: 0.007680\n",
      "Epoch: 6932/10000 Iteration: 48525 Train loss: 0.007680\n",
      "Epoch: 6933/10000 Iteration: 48532 Train loss: 0.007680\n",
      "Epoch: 6934/10000 Iteration: 48539 Train loss: 0.007680\n",
      "Epoch: 6935/10000 Iteration: 48546 Train loss: 0.007680\n",
      "Epoch: 6936/10000 Iteration: 48553 Train loss: 0.007680\n",
      "Epoch: 6937/10000 Iteration: 48560 Train loss: 0.007679\n",
      "Epoch: 6938/10000 Iteration: 48567 Train loss: 0.007679\n",
      "Epoch: 6939/10000 Iteration: 48574 Train loss: 0.007679\n",
      "Epoch: 6940/10000 Iteration: 48581 Train loss: 0.007679\n",
      "Epoch: 6941/10000 Iteration: 48588 Train loss: 0.007679\n",
      "Epoch: 6942/10000 Iteration: 48595 Train loss: 0.007678\n",
      "Epoch: 6943/10000 Iteration: 48602 Train loss: 0.007678\n",
      "Epoch: 6944/10000 Iteration: 48609 Train loss: 0.007678\n",
      "Epoch: 6945/10000 Iteration: 48616 Train loss: 0.007678\n",
      "Epoch: 6946/10000 Iteration: 48623 Train loss: 0.007678\n",
      "Epoch: 6947/10000 Iteration: 48630 Train loss: 0.007678\n",
      "Epoch: 6948/10000 Iteration: 48637 Train loss: 0.007677\n",
      "Epoch: 6949/10000 Iteration: 48644 Train loss: 0.007677\n",
      "Epoch: 6950/10000 Iteration: 48651 Train loss: 0.007677\n",
      "Epoch: 6951/10000 Iteration: 48658 Train loss: 0.007677\n",
      "Epoch: 6952/10000 Iteration: 48665 Train loss: 0.007677\n",
      "Epoch: 6953/10000 Iteration: 48672 Train loss: 0.007677\n",
      "Epoch: 6954/10000 Iteration: 48679 Train loss: 0.007676\n",
      "Epoch: 6955/10000 Iteration: 48686 Train loss: 0.007676\n",
      "Epoch: 6956/10000 Iteration: 48693 Train loss: 0.007676\n",
      "Epoch: 6957/10000 Iteration: 48700 Train loss: 0.007676\n",
      "Epoch: 6958/10000 Iteration: 48707 Train loss: 0.007676\n",
      "Epoch: 6959/10000 Iteration: 48714 Train loss: 0.007675\n",
      "Epoch: 6960/10000 Iteration: 48721 Train loss: 0.007675\n",
      "Epoch: 6961/10000 Iteration: 48728 Train loss: 0.007675\n",
      "Epoch: 6962/10000 Iteration: 48735 Train loss: 0.007675\n",
      "Epoch: 6963/10000 Iteration: 48742 Train loss: 0.007675\n",
      "Epoch: 6964/10000 Iteration: 48749 Train loss: 0.007675\n",
      "Epoch: 6965/10000 Iteration: 48756 Train loss: 0.007674\n",
      "Epoch: 6966/10000 Iteration: 48763 Train loss: 0.007674\n",
      "Epoch: 6967/10000 Iteration: 48770 Train loss: 0.007674\n",
      "Epoch: 6968/10000 Iteration: 48777 Train loss: 0.007674\n",
      "Epoch: 6969/10000 Iteration: 48784 Train loss: 0.007674\n",
      "Epoch: 6970/10000 Iteration: 48791 Train loss: 0.007674\n",
      "Epoch: 6971/10000 Iteration: 48798 Train loss: 0.007673\n",
      "Epoch: 6972/10000 Iteration: 48805 Train loss: 0.007673\n",
      "Epoch: 6973/10000 Iteration: 48812 Train loss: 0.007673\n",
      "Epoch: 6974/10000 Iteration: 48819 Train loss: 0.007673\n",
      "Epoch: 6975/10000 Iteration: 48826 Train loss: 0.007673\n",
      "Epoch: 6976/10000 Iteration: 48833 Train loss: 0.007673\n",
      "Epoch: 6977/10000 Iteration: 48840 Train loss: 0.007672\n",
      "Epoch: 6978/10000 Iteration: 48847 Train loss: 0.007672\n",
      "Epoch: 6979/10000 Iteration: 48854 Train loss: 0.007672\n",
      "Epoch: 6980/10000 Iteration: 48861 Train loss: 0.007672\n",
      "Epoch: 6981/10000 Iteration: 48868 Train loss: 0.007672\n",
      "Epoch: 6982/10000 Iteration: 48875 Train loss: 0.007671\n",
      "Epoch: 6983/10000 Iteration: 48882 Train loss: 0.007671\n",
      "Epoch: 6984/10000 Iteration: 48889 Train loss: 0.007671\n",
      "Epoch: 6985/10000 Iteration: 48896 Train loss: 0.007671\n",
      "Epoch: 6986/10000 Iteration: 48903 Train loss: 0.007671\n",
      "Epoch: 6987/10000 Iteration: 48910 Train loss: 0.007671\n",
      "Epoch: 6988/10000 Iteration: 48917 Train loss: 0.007670\n",
      "Epoch: 6989/10000 Iteration: 48924 Train loss: 0.007670\n",
      "Epoch: 6990/10000 Iteration: 48931 Train loss: 0.007670\n",
      "Epoch: 6991/10000 Iteration: 48938 Train loss: 0.007670\n",
      "Epoch: 6992/10000 Iteration: 48945 Train loss: 0.007670\n",
      "Epoch: 6993/10000 Iteration: 48952 Train loss: 0.007670\n",
      "Epoch: 6994/10000 Iteration: 48959 Train loss: 0.007669\n",
      "Epoch: 6995/10000 Iteration: 48966 Train loss: 0.007669\n",
      "Epoch: 6996/10000 Iteration: 48973 Train loss: 0.007669\n",
      "Epoch: 6997/10000 Iteration: 48980 Train loss: 0.007669\n",
      "Epoch: 6998/10000 Iteration: 48987 Train loss: 0.007669\n",
      "Epoch: 6999/10000 Iteration: 48994 Train loss: 0.007669\n",
      "Epoch: 7000/10000 Iteration: 49001 Train loss: 0.007668\n",
      "Epoch: 7001/10000 Iteration: 49008 Train loss: 0.007668\n",
      "Epoch: 7002/10000 Iteration: 49015 Train loss: 0.007668\n",
      "Epoch: 7003/10000 Iteration: 49022 Train loss: 0.007668\n",
      "Epoch: 7004/10000 Iteration: 49029 Train loss: 0.007668\n",
      "Epoch: 7005/10000 Iteration: 49036 Train loss: 0.007668\n",
      "Epoch: 7006/10000 Iteration: 49043 Train loss: 0.007667\n",
      "Epoch: 7007/10000 Iteration: 49050 Train loss: 0.007667\n",
      "Epoch: 7008/10000 Iteration: 49057 Train loss: 0.007667\n",
      "Epoch: 7009/10000 Iteration: 49064 Train loss: 0.007667\n",
      "Epoch: 7010/10000 Iteration: 49071 Train loss: 0.007667\n",
      "Epoch: 7011/10000 Iteration: 49078 Train loss: 0.007666\n",
      "Epoch: 7012/10000 Iteration: 49085 Train loss: 0.007666\n",
      "Epoch: 7013/10000 Iteration: 49092 Train loss: 0.007666\n",
      "Epoch: 7014/10000 Iteration: 49099 Train loss: 0.007666\n",
      "Epoch: 7015/10000 Iteration: 49106 Train loss: 0.007666\n",
      "Epoch: 7016/10000 Iteration: 49113 Train loss: 0.007666\n",
      "Epoch: 7017/10000 Iteration: 49120 Train loss: 0.007665\n",
      "Epoch: 7018/10000 Iteration: 49127 Train loss: 0.007665\n",
      "Epoch: 7019/10000 Iteration: 49134 Train loss: 0.007665\n",
      "Epoch: 7020/10000 Iteration: 49141 Train loss: 0.007665\n",
      "Epoch: 7021/10000 Iteration: 49148 Train loss: 0.007665\n",
      "Epoch: 7022/10000 Iteration: 49155 Train loss: 0.007665\n",
      "Epoch: 7023/10000 Iteration: 49162 Train loss: 0.007664\n",
      "Epoch: 7024/10000 Iteration: 49169 Train loss: 0.007664\n",
      "Epoch: 7025/10000 Iteration: 49176 Train loss: 0.007664\n",
      "Epoch: 7026/10000 Iteration: 49183 Train loss: 0.007664\n",
      "Epoch: 7027/10000 Iteration: 49190 Train loss: 0.007664\n",
      "Epoch: 7028/10000 Iteration: 49197 Train loss: 0.007664\n",
      "Epoch: 7029/10000 Iteration: 49204 Train loss: 0.007663\n",
      "Epoch: 7030/10000 Iteration: 49211 Train loss: 0.007663\n",
      "Epoch: 7031/10000 Iteration: 49218 Train loss: 0.007663\n",
      "Epoch: 7032/10000 Iteration: 49225 Train loss: 0.007663\n",
      "Epoch: 7033/10000 Iteration: 49232 Train loss: 0.007663\n",
      "Epoch: 7034/10000 Iteration: 49239 Train loss: 0.007663\n",
      "Epoch: 7035/10000 Iteration: 49246 Train loss: 0.007662\n",
      "Epoch: 7036/10000 Iteration: 49253 Train loss: 0.007662\n",
      "Epoch: 7037/10000 Iteration: 49260 Train loss: 0.007662\n",
      "Epoch: 7038/10000 Iteration: 49267 Train loss: 0.007662\n",
      "Epoch: 7039/10000 Iteration: 49274 Train loss: 0.007662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7040/10000 Iteration: 49281 Train loss: 0.007662\n",
      "Epoch: 7041/10000 Iteration: 49288 Train loss: 0.007661\n",
      "Epoch: 7042/10000 Iteration: 49295 Train loss: 0.007661\n",
      "Epoch: 7043/10000 Iteration: 49302 Train loss: 0.007661\n",
      "Epoch: 7044/10000 Iteration: 49309 Train loss: 0.007661\n",
      "Epoch: 7045/10000 Iteration: 49316 Train loss: 0.007661\n",
      "Epoch: 7046/10000 Iteration: 49323 Train loss: 0.007661\n",
      "Epoch: 7047/10000 Iteration: 49330 Train loss: 0.007660\n",
      "Epoch: 7048/10000 Iteration: 49337 Train loss: 0.007660\n",
      "Epoch: 7049/10000 Iteration: 49344 Train loss: 0.007660\n",
      "Epoch: 7050/10000 Iteration: 49351 Train loss: 0.007660\n",
      "Epoch: 7051/10000 Iteration: 49358 Train loss: 0.007660\n",
      "Epoch: 7052/10000 Iteration: 49365 Train loss: 0.007659\n",
      "Epoch: 7053/10000 Iteration: 49372 Train loss: 0.007659\n",
      "Epoch: 7054/10000 Iteration: 49379 Train loss: 0.007659\n",
      "Epoch: 7055/10000 Iteration: 49386 Train loss: 0.007659\n",
      "Epoch: 7056/10000 Iteration: 49393 Train loss: 0.007659\n",
      "Epoch: 7057/10000 Iteration: 49400 Train loss: 0.007659\n",
      "Epoch: 7058/10000 Iteration: 49407 Train loss: 0.007658\n",
      "Epoch: 7059/10000 Iteration: 49414 Train loss: 0.007658\n",
      "Epoch: 7060/10000 Iteration: 49421 Train loss: 0.007658\n",
      "Epoch: 7061/10000 Iteration: 49428 Train loss: 0.007658\n",
      "Epoch: 7062/10000 Iteration: 49435 Train loss: 0.007658\n",
      "Epoch: 7063/10000 Iteration: 49442 Train loss: 0.007658\n",
      "Epoch: 7064/10000 Iteration: 49449 Train loss: 0.007657\n",
      "Epoch: 7065/10000 Iteration: 49456 Train loss: 0.007657\n",
      "Epoch: 7066/10000 Iteration: 49463 Train loss: 0.007657\n",
      "Epoch: 7067/10000 Iteration: 49470 Train loss: 0.007657\n",
      "Epoch: 7068/10000 Iteration: 49477 Train loss: 0.007657\n",
      "Epoch: 7069/10000 Iteration: 49484 Train loss: 0.007657\n",
      "Epoch: 7070/10000 Iteration: 49491 Train loss: 0.007656\n",
      "Epoch: 7071/10000 Iteration: 49498 Train loss: 0.007656\n",
      "Epoch: 7072/10000 Iteration: 49505 Train loss: 0.007656\n",
      "Epoch: 7073/10000 Iteration: 49512 Train loss: 0.007656\n",
      "Epoch: 7074/10000 Iteration: 49519 Train loss: 0.007656\n",
      "Epoch: 7075/10000 Iteration: 49526 Train loss: 0.007656\n",
      "Epoch: 7076/10000 Iteration: 49533 Train loss: 0.007655\n",
      "Epoch: 7077/10000 Iteration: 49540 Train loss: 0.007655\n",
      "Epoch: 7078/10000 Iteration: 49547 Train loss: 0.007655\n",
      "Epoch: 7079/10000 Iteration: 49554 Train loss: 0.007655\n",
      "Epoch: 7080/10000 Iteration: 49561 Train loss: 0.007655\n",
      "Epoch: 7081/10000 Iteration: 49568 Train loss: 0.007655\n",
      "Epoch: 7082/10000 Iteration: 49575 Train loss: 0.007654\n",
      "Epoch: 7083/10000 Iteration: 49582 Train loss: 0.007654\n",
      "Epoch: 7084/10000 Iteration: 49589 Train loss: 0.007654\n",
      "Epoch: 7085/10000 Iteration: 49596 Train loss: 0.007654\n",
      "Epoch: 7086/10000 Iteration: 49603 Train loss: 0.007654\n",
      "Epoch: 7087/10000 Iteration: 49610 Train loss: 0.007654\n",
      "Epoch: 7088/10000 Iteration: 49617 Train loss: 0.007653\n",
      "Epoch: 7089/10000 Iteration: 49624 Train loss: 0.007653\n",
      "Epoch: 7090/10000 Iteration: 49631 Train loss: 0.007653\n",
      "Epoch: 7091/10000 Iteration: 49638 Train loss: 0.007653\n",
      "Epoch: 7092/10000 Iteration: 49645 Train loss: 0.007653\n",
      "Epoch: 7093/10000 Iteration: 49652 Train loss: 0.007653\n",
      "Epoch: 7094/10000 Iteration: 49659 Train loss: 0.007652\n",
      "Epoch: 7095/10000 Iteration: 49666 Train loss: 0.007652\n",
      "Epoch: 7096/10000 Iteration: 49673 Train loss: 0.007652\n",
      "Epoch: 7097/10000 Iteration: 49680 Train loss: 0.007652\n",
      "Epoch: 7098/10000 Iteration: 49687 Train loss: 0.007652\n",
      "Epoch: 7099/10000 Iteration: 49694 Train loss: 0.007652\n",
      "Epoch: 7100/10000 Iteration: 49701 Train loss: 0.007651\n",
      "Epoch: 7101/10000 Iteration: 49708 Train loss: 0.007651\n",
      "Epoch: 7102/10000 Iteration: 49715 Train loss: 0.007651\n",
      "Epoch: 7103/10000 Iteration: 49722 Train loss: 0.007651\n",
      "Epoch: 7104/10000 Iteration: 49729 Train loss: 0.007651\n",
      "Epoch: 7105/10000 Iteration: 49736 Train loss: 0.007651\n",
      "Epoch: 7106/10000 Iteration: 49743 Train loss: 0.007650\n",
      "Epoch: 7107/10000 Iteration: 49750 Train loss: 0.007650\n",
      "Epoch: 7108/10000 Iteration: 49757 Train loss: 0.007650\n",
      "Epoch: 7109/10000 Iteration: 49764 Train loss: 0.007650\n",
      "Epoch: 7110/10000 Iteration: 49771 Train loss: 0.007650\n",
      "Epoch: 7111/10000 Iteration: 49778 Train loss: 0.007650\n",
      "Epoch: 7112/10000 Iteration: 49785 Train loss: 0.007649\n",
      "Epoch: 7113/10000 Iteration: 49792 Train loss: 0.007649\n",
      "Epoch: 7114/10000 Iteration: 49799 Train loss: 0.007649\n",
      "Epoch: 7115/10000 Iteration: 49806 Train loss: 0.007649\n",
      "Epoch: 7116/10000 Iteration: 49813 Train loss: 0.007649\n",
      "Epoch: 7117/10000 Iteration: 49820 Train loss: 0.007649\n",
      "Epoch: 7118/10000 Iteration: 49827 Train loss: 0.007648\n",
      "Epoch: 7119/10000 Iteration: 49834 Train loss: 0.007648\n",
      "Epoch: 7120/10000 Iteration: 49841 Train loss: 0.007648\n",
      "Epoch: 7121/10000 Iteration: 49848 Train loss: 0.007648\n",
      "Epoch: 7122/10000 Iteration: 49855 Train loss: 0.007648\n",
      "Epoch: 7123/10000 Iteration: 49862 Train loss: 0.007648\n",
      "Epoch: 7124/10000 Iteration: 49869 Train loss: 0.007647\n",
      "Epoch: 7125/10000 Iteration: 49876 Train loss: 0.007647\n",
      "Epoch: 7126/10000 Iteration: 49883 Train loss: 0.007647\n",
      "Epoch: 7127/10000 Iteration: 49890 Train loss: 0.007647\n",
      "Epoch: 7128/10000 Iteration: 49897 Train loss: 0.007647\n",
      "Epoch: 7129/10000 Iteration: 49904 Train loss: 0.007647\n",
      "Epoch: 7130/10000 Iteration: 49911 Train loss: 0.007646\n",
      "Epoch: 7131/10000 Iteration: 49918 Train loss: 0.007646\n",
      "Epoch: 7132/10000 Iteration: 49925 Train loss: 0.007646\n",
      "Epoch: 7133/10000 Iteration: 49932 Train loss: 0.007646\n",
      "Epoch: 7134/10000 Iteration: 49939 Train loss: 0.007646\n",
      "Epoch: 7135/10000 Iteration: 49946 Train loss: 0.007646\n",
      "Epoch: 7136/10000 Iteration: 49953 Train loss: 0.007645\n",
      "Epoch: 7137/10000 Iteration: 49960 Train loss: 0.007645\n",
      "Epoch: 7138/10000 Iteration: 49967 Train loss: 0.007645\n",
      "Epoch: 7139/10000 Iteration: 49974 Train loss: 0.007645\n",
      "Epoch: 7140/10000 Iteration: 49981 Train loss: 0.007645\n",
      "Epoch: 7141/10000 Iteration: 49988 Train loss: 0.007645\n",
      "Epoch: 7142/10000 Iteration: 49995 Train loss: 0.007644\n",
      "Epoch: 7143/10000 Iteration: 50002 Train loss: 0.007644\n",
      "Epoch: 7144/10000 Iteration: 50009 Train loss: 0.007644\n",
      "Epoch: 7145/10000 Iteration: 50016 Train loss: 0.007644\n",
      "Epoch: 7146/10000 Iteration: 50023 Train loss: 0.007644\n",
      "Epoch: 7147/10000 Iteration: 50030 Train loss: 0.007644\n",
      "Epoch: 7148/10000 Iteration: 50037 Train loss: 0.007643\n",
      "Epoch: 7149/10000 Iteration: 50044 Train loss: 0.007643\n",
      "Epoch: 7150/10000 Iteration: 50051 Train loss: 0.007643\n",
      "Epoch: 7151/10000 Iteration: 50058 Train loss: 0.007643\n",
      "Epoch: 7152/10000 Iteration: 50065 Train loss: 0.007643\n",
      "Epoch: 7153/10000 Iteration: 50072 Train loss: 0.007643\n",
      "Epoch: 7154/10000 Iteration: 50079 Train loss: 0.007642\n",
      "Epoch: 7155/10000 Iteration: 50086 Train loss: 0.007642\n",
      "Epoch: 7156/10000 Iteration: 50093 Train loss: 0.007642\n",
      "Epoch: 7157/10000 Iteration: 50100 Train loss: 0.007642\n",
      "Epoch: 7158/10000 Iteration: 50107 Train loss: 0.007642\n",
      "Epoch: 7159/10000 Iteration: 50114 Train loss: 0.007642\n",
      "Epoch: 7160/10000 Iteration: 50121 Train loss: 0.007641\n",
      "Epoch: 7161/10000 Iteration: 50128 Train loss: 0.007641\n",
      "Epoch: 7162/10000 Iteration: 50135 Train loss: 0.007641\n",
      "Epoch: 7163/10000 Iteration: 50142 Train loss: 0.007641\n",
      "Epoch: 7164/10000 Iteration: 50149 Train loss: 0.007641\n",
      "Epoch: 7165/10000 Iteration: 50156 Train loss: 0.007641\n",
      "Epoch: 7166/10000 Iteration: 50163 Train loss: 0.007641\n",
      "Epoch: 7167/10000 Iteration: 50170 Train loss: 0.007640\n",
      "Epoch: 7168/10000 Iteration: 50177 Train loss: 0.007640\n",
      "Epoch: 7169/10000 Iteration: 50184 Train loss: 0.007640\n",
      "Epoch: 7170/10000 Iteration: 50191 Train loss: 0.007640\n",
      "Epoch: 7171/10000 Iteration: 50198 Train loss: 0.007640\n",
      "Epoch: 7172/10000 Iteration: 50205 Train loss: 0.007640\n",
      "Epoch: 7173/10000 Iteration: 50212 Train loss: 0.007639\n",
      "Epoch: 7174/10000 Iteration: 50219 Train loss: 0.007639\n",
      "Epoch: 7175/10000 Iteration: 50226 Train loss: 0.007639\n",
      "Epoch: 7176/10000 Iteration: 50233 Train loss: 0.007639\n",
      "Epoch: 7177/10000 Iteration: 50240 Train loss: 0.007639\n",
      "Epoch: 7178/10000 Iteration: 50247 Train loss: 0.007639\n",
      "Epoch: 7179/10000 Iteration: 50254 Train loss: 0.007638\n",
      "Epoch: 7180/10000 Iteration: 50261 Train loss: 0.007638\n",
      "Epoch: 7181/10000 Iteration: 50268 Train loss: 0.007638\n",
      "Epoch: 7182/10000 Iteration: 50275 Train loss: 0.007638\n",
      "Epoch: 7183/10000 Iteration: 50282 Train loss: 0.007638\n",
      "Epoch: 7184/10000 Iteration: 50289 Train loss: 0.007638\n",
      "Epoch: 7185/10000 Iteration: 50296 Train loss: 0.007637\n",
      "Epoch: 7186/10000 Iteration: 50303 Train loss: 0.007637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7187/10000 Iteration: 50310 Train loss: 0.007637\n",
      "Epoch: 7188/10000 Iteration: 50317 Train loss: 0.007637\n",
      "Epoch: 7189/10000 Iteration: 50324 Train loss: 0.007637\n",
      "Epoch: 7190/10000 Iteration: 50331 Train loss: 0.007637\n",
      "Epoch: 7191/10000 Iteration: 50338 Train loss: 0.007636\n",
      "Epoch: 7192/10000 Iteration: 50345 Train loss: 0.007636\n",
      "Epoch: 7193/10000 Iteration: 50352 Train loss: 0.007636\n",
      "Epoch: 7194/10000 Iteration: 50359 Train loss: 0.007636\n",
      "Epoch: 7195/10000 Iteration: 50366 Train loss: 0.007636\n",
      "Epoch: 7196/10000 Iteration: 50373 Train loss: 0.007636\n",
      "Epoch: 7197/10000 Iteration: 50380 Train loss: 0.007636\n",
      "Epoch: 7198/10000 Iteration: 50387 Train loss: 0.007635\n",
      "Epoch: 7199/10000 Iteration: 50394 Train loss: 0.007635\n",
      "Epoch: 7200/10000 Iteration: 50401 Train loss: 0.007635\n",
      "Epoch: 7201/10000 Iteration: 50408 Train loss: 0.007635\n",
      "Epoch: 7202/10000 Iteration: 50415 Train loss: 0.007635\n",
      "Epoch: 7203/10000 Iteration: 50422 Train loss: 0.007635\n",
      "Epoch: 7204/10000 Iteration: 50429 Train loss: 0.007634\n",
      "Epoch: 7205/10000 Iteration: 50436 Train loss: 0.007634\n",
      "Epoch: 7206/10000 Iteration: 50443 Train loss: 0.007634\n",
      "Epoch: 7207/10000 Iteration: 50450 Train loss: 0.007634\n",
      "Epoch: 7208/10000 Iteration: 50457 Train loss: 0.007634\n",
      "Epoch: 7209/10000 Iteration: 50464 Train loss: 0.007634\n",
      "Epoch: 7210/10000 Iteration: 50471 Train loss: 0.007633\n",
      "Epoch: 7211/10000 Iteration: 50478 Train loss: 0.007633\n",
      "Epoch: 7212/10000 Iteration: 50485 Train loss: 0.007633\n",
      "Epoch: 7213/10000 Iteration: 50492 Train loss: 0.007633\n",
      "Epoch: 7214/10000 Iteration: 50499 Train loss: 0.007633\n",
      "Epoch: 7215/10000 Iteration: 50506 Train loss: 0.007633\n",
      "Epoch: 7216/10000 Iteration: 50513 Train loss: 0.007632\n",
      "Epoch: 7217/10000 Iteration: 50520 Train loss: 0.007632\n",
      "Epoch: 7218/10000 Iteration: 50527 Train loss: 0.007632\n",
      "Epoch: 7219/10000 Iteration: 50534 Train loss: 0.007632\n",
      "Epoch: 7220/10000 Iteration: 50541 Train loss: 0.007632\n",
      "Epoch: 7221/10000 Iteration: 50548 Train loss: 0.007632\n",
      "Epoch: 7222/10000 Iteration: 50555 Train loss: 0.007631\n",
      "Epoch: 7223/10000 Iteration: 50562 Train loss: 0.007631\n",
      "Epoch: 7224/10000 Iteration: 50569 Train loss: 0.007631\n",
      "Epoch: 7225/10000 Iteration: 50576 Train loss: 0.007631\n",
      "Epoch: 7226/10000 Iteration: 50583 Train loss: 0.007631\n",
      "Epoch: 7227/10000 Iteration: 50590 Train loss: 0.007631\n",
      "Epoch: 7228/10000 Iteration: 50597 Train loss: 0.007631\n",
      "Epoch: 7229/10000 Iteration: 50604 Train loss: 0.007630\n",
      "Epoch: 7230/10000 Iteration: 50611 Train loss: 0.007630\n",
      "Epoch: 7231/10000 Iteration: 50618 Train loss: 0.007630\n",
      "Epoch: 7232/10000 Iteration: 50625 Train loss: 0.007630\n",
      "Epoch: 7233/10000 Iteration: 50632 Train loss: 0.007630\n",
      "Epoch: 7234/10000 Iteration: 50639 Train loss: 0.007630\n",
      "Epoch: 7235/10000 Iteration: 50646 Train loss: 0.007629\n",
      "Epoch: 7236/10000 Iteration: 50653 Train loss: 0.007629\n",
      "Epoch: 7237/10000 Iteration: 50660 Train loss: 0.007629\n",
      "Epoch: 7238/10000 Iteration: 50667 Train loss: 0.007629\n",
      "Epoch: 7239/10000 Iteration: 50674 Train loss: 0.007629\n",
      "Epoch: 7240/10000 Iteration: 50681 Train loss: 0.007629\n",
      "Epoch: 7241/10000 Iteration: 50688 Train loss: 0.007628\n",
      "Epoch: 7242/10000 Iteration: 50695 Train loss: 0.007628\n",
      "Epoch: 7243/10000 Iteration: 50702 Train loss: 0.007628\n",
      "Epoch: 7244/10000 Iteration: 50709 Train loss: 0.007628\n",
      "Epoch: 7245/10000 Iteration: 50716 Train loss: 0.007628\n",
      "Epoch: 7246/10000 Iteration: 50723 Train loss: 0.007628\n",
      "Epoch: 7247/10000 Iteration: 50730 Train loss: 0.007627\n",
      "Epoch: 7248/10000 Iteration: 50737 Train loss: 0.007627\n",
      "Epoch: 7249/10000 Iteration: 50744 Train loss: 0.007627\n",
      "Epoch: 7250/10000 Iteration: 50751 Train loss: 0.007627\n",
      "Epoch: 7251/10000 Iteration: 50758 Train loss: 0.007627\n",
      "Epoch: 7252/10000 Iteration: 50765 Train loss: 0.007627\n",
      "Epoch: 7253/10000 Iteration: 50772 Train loss: 0.007627\n",
      "Epoch: 7254/10000 Iteration: 50779 Train loss: 0.007626\n",
      "Epoch: 7255/10000 Iteration: 50786 Train loss: 0.007626\n",
      "Epoch: 7256/10000 Iteration: 50793 Train loss: 0.007626\n",
      "Epoch: 7257/10000 Iteration: 50800 Train loss: 0.007626\n",
      "Epoch: 7258/10000 Iteration: 50807 Train loss: 0.007626\n",
      "Epoch: 7259/10000 Iteration: 50814 Train loss: 0.007626\n",
      "Epoch: 7260/10000 Iteration: 50821 Train loss: 0.007625\n",
      "Epoch: 7261/10000 Iteration: 50828 Train loss: 0.007625\n",
      "Epoch: 7262/10000 Iteration: 50835 Train loss: 0.007625\n",
      "Epoch: 7263/10000 Iteration: 50842 Train loss: 0.007625\n",
      "Epoch: 7264/10000 Iteration: 50849 Train loss: 0.007625\n",
      "Epoch: 7265/10000 Iteration: 50856 Train loss: 0.007625\n",
      "Epoch: 7266/10000 Iteration: 50863 Train loss: 0.007624\n",
      "Epoch: 7267/10000 Iteration: 50870 Train loss: 0.007624\n",
      "Epoch: 7268/10000 Iteration: 50877 Train loss: 0.007624\n",
      "Epoch: 7269/10000 Iteration: 50884 Train loss: 0.007624\n",
      "Epoch: 7270/10000 Iteration: 50891 Train loss: 0.007624\n",
      "Epoch: 7271/10000 Iteration: 50898 Train loss: 0.007624\n",
      "Epoch: 7272/10000 Iteration: 50905 Train loss: 0.007624\n",
      "Epoch: 7273/10000 Iteration: 50912 Train loss: 0.007623\n",
      "Epoch: 7274/10000 Iteration: 50919 Train loss: 0.007623\n",
      "Epoch: 7275/10000 Iteration: 50926 Train loss: 0.007623\n",
      "Epoch: 7276/10000 Iteration: 50933 Train loss: 0.007623\n",
      "Epoch: 7277/10000 Iteration: 50940 Train loss: 0.007623\n",
      "Epoch: 7278/10000 Iteration: 50947 Train loss: 0.007623\n",
      "Epoch: 7279/10000 Iteration: 50954 Train loss: 0.007622\n",
      "Epoch: 7280/10000 Iteration: 50961 Train loss: 0.007622\n",
      "Epoch: 7281/10000 Iteration: 50968 Train loss: 0.007622\n",
      "Epoch: 7282/10000 Iteration: 50975 Train loss: 0.007622\n",
      "Epoch: 7283/10000 Iteration: 50982 Train loss: 0.007622\n",
      "Epoch: 7284/10000 Iteration: 50989 Train loss: 0.007622\n",
      "Epoch: 7285/10000 Iteration: 50996 Train loss: 0.007621\n",
      "Epoch: 7286/10000 Iteration: 51003 Train loss: 0.007621\n",
      "Epoch: 7287/10000 Iteration: 51010 Train loss: 0.007621\n",
      "Epoch: 7288/10000 Iteration: 51017 Train loss: 0.007621\n",
      "Epoch: 7289/10000 Iteration: 51024 Train loss: 0.007621\n",
      "Epoch: 7290/10000 Iteration: 51031 Train loss: 0.007621\n",
      "Epoch: 7291/10000 Iteration: 51038 Train loss: 0.007621\n",
      "Epoch: 7292/10000 Iteration: 51045 Train loss: 0.007620\n",
      "Epoch: 7293/10000 Iteration: 51052 Train loss: 0.007620\n",
      "Epoch: 7294/10000 Iteration: 51059 Train loss: 0.007620\n",
      "Epoch: 7295/10000 Iteration: 51066 Train loss: 0.007620\n",
      "Epoch: 7296/10000 Iteration: 51073 Train loss: 0.007620\n",
      "Epoch: 7297/10000 Iteration: 51080 Train loss: 0.007620\n",
      "Epoch: 7298/10000 Iteration: 51087 Train loss: 0.007619\n",
      "Epoch: 7299/10000 Iteration: 51094 Train loss: 0.007619\n",
      "Epoch: 7300/10000 Iteration: 51101 Train loss: 0.007619\n",
      "Epoch: 7301/10000 Iteration: 51108 Train loss: 0.007619\n",
      "Epoch: 7302/10000 Iteration: 51115 Train loss: 0.007619\n",
      "Epoch: 7303/10000 Iteration: 51122 Train loss: 0.007619\n",
      "Epoch: 7304/10000 Iteration: 51129 Train loss: 0.007619\n",
      "Epoch: 7305/10000 Iteration: 51136 Train loss: 0.007618\n",
      "Epoch: 7306/10000 Iteration: 51143 Train loss: 0.007618\n",
      "Epoch: 7307/10000 Iteration: 51150 Train loss: 0.007618\n",
      "Epoch: 7308/10000 Iteration: 51157 Train loss: 0.007618\n",
      "Epoch: 7309/10000 Iteration: 51164 Train loss: 0.007618\n",
      "Epoch: 7310/10000 Iteration: 51171 Train loss: 0.007618\n",
      "Epoch: 7311/10000 Iteration: 51178 Train loss: 0.007617\n",
      "Epoch: 7312/10000 Iteration: 51185 Train loss: 0.007617\n",
      "Epoch: 7313/10000 Iteration: 51192 Train loss: 0.007617\n",
      "Epoch: 7314/10000 Iteration: 51199 Train loss: 0.007617\n",
      "Epoch: 7315/10000 Iteration: 51206 Train loss: 0.007617\n",
      "Epoch: 7316/10000 Iteration: 51213 Train loss: 0.007617\n",
      "Epoch: 7317/10000 Iteration: 51220 Train loss: 0.007617\n",
      "Epoch: 7318/10000 Iteration: 51227 Train loss: 0.007616\n",
      "Epoch: 7319/10000 Iteration: 51234 Train loss: 0.007616\n",
      "Epoch: 7320/10000 Iteration: 51241 Train loss: 0.007616\n",
      "Epoch: 7321/10000 Iteration: 51248 Train loss: 0.007616\n",
      "Epoch: 7322/10000 Iteration: 51255 Train loss: 0.007616\n",
      "Epoch: 7323/10000 Iteration: 51262 Train loss: 0.007616\n",
      "Epoch: 7324/10000 Iteration: 51269 Train loss: 0.007615\n",
      "Epoch: 7325/10000 Iteration: 51276 Train loss: 0.007615\n",
      "Epoch: 7326/10000 Iteration: 51283 Train loss: 0.007615\n",
      "Epoch: 7327/10000 Iteration: 51290 Train loss: 0.007615\n",
      "Epoch: 7328/10000 Iteration: 51297 Train loss: 0.007615\n",
      "Epoch: 7329/10000 Iteration: 51304 Train loss: 0.007615\n",
      "Epoch: 7330/10000 Iteration: 51311 Train loss: 0.007615\n",
      "Epoch: 7331/10000 Iteration: 51318 Train loss: 0.007614\n",
      "Epoch: 7332/10000 Iteration: 51325 Train loss: 0.007614\n",
      "Epoch: 7333/10000 Iteration: 51332 Train loss: 0.007614\n",
      "Epoch: 7334/10000 Iteration: 51339 Train loss: 0.007614\n",
      "Epoch: 7335/10000 Iteration: 51346 Train loss: 0.007614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7336/10000 Iteration: 51353 Train loss: 0.007614\n",
      "Epoch: 7337/10000 Iteration: 51360 Train loss: 0.007613\n",
      "Epoch: 7338/10000 Iteration: 51367 Train loss: 0.007613\n",
      "Epoch: 7339/10000 Iteration: 51374 Train loss: 0.007613\n",
      "Epoch: 7340/10000 Iteration: 51381 Train loss: 0.007613\n",
      "Epoch: 7341/10000 Iteration: 51388 Train loss: 0.007613\n",
      "Epoch: 7342/10000 Iteration: 51395 Train loss: 0.007613\n",
      "Epoch: 7343/10000 Iteration: 51402 Train loss: 0.007613\n",
      "Epoch: 7344/10000 Iteration: 51409 Train loss: 0.007612\n",
      "Epoch: 7345/10000 Iteration: 51416 Train loss: 0.007612\n",
      "Epoch: 7346/10000 Iteration: 51423 Train loss: 0.007612\n",
      "Epoch: 7347/10000 Iteration: 51430 Train loss: 0.007612\n",
      "Epoch: 7348/10000 Iteration: 51437 Train loss: 0.007612\n",
      "Epoch: 7349/10000 Iteration: 51444 Train loss: 0.007612\n",
      "Epoch: 7350/10000 Iteration: 51451 Train loss: 0.007611\n",
      "Epoch: 7351/10000 Iteration: 51458 Train loss: 0.007611\n",
      "Epoch: 7352/10000 Iteration: 51465 Train loss: 0.007611\n",
      "Epoch: 7353/10000 Iteration: 51472 Train loss: 0.007611\n",
      "Epoch: 7354/10000 Iteration: 51479 Train loss: 0.007611\n",
      "Epoch: 7355/10000 Iteration: 51486 Train loss: 0.007611\n",
      "Epoch: 7356/10000 Iteration: 51493 Train loss: 0.007611\n",
      "Epoch: 7357/10000 Iteration: 51500 Train loss: 0.007610\n",
      "Epoch: 7358/10000 Iteration: 51507 Train loss: 0.007610\n",
      "Epoch: 7359/10000 Iteration: 51514 Train loss: 0.007610\n",
      "Epoch: 7360/10000 Iteration: 51521 Train loss: 0.007610\n",
      "Epoch: 7361/10000 Iteration: 51528 Train loss: 0.007610\n",
      "Epoch: 7362/10000 Iteration: 51535 Train loss: 0.007610\n",
      "Epoch: 7363/10000 Iteration: 51542 Train loss: 0.007609\n",
      "Epoch: 7364/10000 Iteration: 51549 Train loss: 0.007609\n",
      "Epoch: 7365/10000 Iteration: 51556 Train loss: 0.007609\n",
      "Epoch: 7366/10000 Iteration: 51563 Train loss: 0.007609\n",
      "Epoch: 7367/10000 Iteration: 51570 Train loss: 0.007609\n",
      "Epoch: 7368/10000 Iteration: 51577 Train loss: 0.007609\n",
      "Epoch: 7369/10000 Iteration: 51584 Train loss: 0.007609\n",
      "Epoch: 7370/10000 Iteration: 51591 Train loss: 0.007608\n",
      "Epoch: 7371/10000 Iteration: 51598 Train loss: 0.007608\n",
      "Epoch: 7372/10000 Iteration: 51605 Train loss: 0.007608\n",
      "Epoch: 7373/10000 Iteration: 51612 Train loss: 0.007608\n",
      "Epoch: 7374/10000 Iteration: 51619 Train loss: 0.007608\n",
      "Epoch: 7375/10000 Iteration: 51626 Train loss: 0.007608\n",
      "Epoch: 7376/10000 Iteration: 51633 Train loss: 0.007607\n",
      "Epoch: 7377/10000 Iteration: 51640 Train loss: 0.007607\n",
      "Epoch: 7378/10000 Iteration: 51647 Train loss: 0.007607\n",
      "Epoch: 7379/10000 Iteration: 51654 Train loss: 0.007607\n",
      "Epoch: 7380/10000 Iteration: 51661 Train loss: 0.007607\n",
      "Epoch: 7381/10000 Iteration: 51668 Train loss: 0.007607\n",
      "Epoch: 7382/10000 Iteration: 51675 Train loss: 0.007607\n",
      "Epoch: 7383/10000 Iteration: 51682 Train loss: 0.007606\n",
      "Epoch: 7384/10000 Iteration: 51689 Train loss: 0.007606\n",
      "Epoch: 7385/10000 Iteration: 51696 Train loss: 0.007606\n",
      "Epoch: 7386/10000 Iteration: 51703 Train loss: 0.007606\n",
      "Epoch: 7387/10000 Iteration: 51710 Train loss: 0.007606\n",
      "Epoch: 7388/10000 Iteration: 51717 Train loss: 0.007606\n",
      "Epoch: 7389/10000 Iteration: 51724 Train loss: 0.007605\n",
      "Epoch: 7390/10000 Iteration: 51731 Train loss: 0.007605\n",
      "Epoch: 7391/10000 Iteration: 51738 Train loss: 0.007605\n",
      "Epoch: 7392/10000 Iteration: 51745 Train loss: 0.007605\n",
      "Epoch: 7393/10000 Iteration: 51752 Train loss: 0.007605\n",
      "Epoch: 7394/10000 Iteration: 51759 Train loss: 0.007605\n",
      "Epoch: 7395/10000 Iteration: 51766 Train loss: 0.007605\n",
      "Epoch: 7396/10000 Iteration: 51773 Train loss: 0.007604\n",
      "Epoch: 7397/10000 Iteration: 51780 Train loss: 0.007604\n",
      "Epoch: 7398/10000 Iteration: 51787 Train loss: 0.007604\n",
      "Epoch: 7399/10000 Iteration: 51794 Train loss: 0.007604\n",
      "Epoch: 7400/10000 Iteration: 51801 Train loss: 0.007604\n",
      "Epoch: 7401/10000 Iteration: 51808 Train loss: 0.007604\n",
      "Epoch: 7402/10000 Iteration: 51815 Train loss: 0.007604\n",
      "Epoch: 7403/10000 Iteration: 51822 Train loss: 0.007603\n",
      "Epoch: 7404/10000 Iteration: 51829 Train loss: 0.007603\n",
      "Epoch: 7405/10000 Iteration: 51836 Train loss: 0.007603\n",
      "Epoch: 7406/10000 Iteration: 51843 Train loss: 0.007603\n",
      "Epoch: 7407/10000 Iteration: 51850 Train loss: 0.007603\n",
      "Epoch: 7408/10000 Iteration: 51857 Train loss: 0.007603\n",
      "Epoch: 7409/10000 Iteration: 51864 Train loss: 0.007602\n",
      "Epoch: 7410/10000 Iteration: 51871 Train loss: 0.007602\n",
      "Epoch: 7411/10000 Iteration: 51878 Train loss: 0.007602\n",
      "Epoch: 7412/10000 Iteration: 51885 Train loss: 0.007602\n",
      "Epoch: 7413/10000 Iteration: 51892 Train loss: 0.007602\n",
      "Epoch: 7414/10000 Iteration: 51899 Train loss: 0.007602\n",
      "Epoch: 7415/10000 Iteration: 51906 Train loss: 0.007602\n",
      "Epoch: 7416/10000 Iteration: 51913 Train loss: 0.007601\n",
      "Epoch: 7417/10000 Iteration: 51920 Train loss: 0.007601\n",
      "Epoch: 7418/10000 Iteration: 51927 Train loss: 0.007601\n",
      "Epoch: 7419/10000 Iteration: 51934 Train loss: 0.007601\n",
      "Epoch: 7420/10000 Iteration: 51941 Train loss: 0.007601\n",
      "Epoch: 7421/10000 Iteration: 51948 Train loss: 0.007601\n",
      "Epoch: 7422/10000 Iteration: 51955 Train loss: 0.007601\n",
      "Epoch: 7423/10000 Iteration: 51962 Train loss: 0.007600\n",
      "Epoch: 7424/10000 Iteration: 51969 Train loss: 0.007600\n",
      "Epoch: 7425/10000 Iteration: 51976 Train loss: 0.007600\n",
      "Epoch: 7426/10000 Iteration: 51983 Train loss: 0.007600\n",
      "Epoch: 7427/10000 Iteration: 51990 Train loss: 0.007600\n",
      "Epoch: 7428/10000 Iteration: 51997 Train loss: 0.007600\n",
      "Epoch: 7429/10000 Iteration: 52004 Train loss: 0.007600\n",
      "Epoch: 7430/10000 Iteration: 52011 Train loss: 0.007599\n",
      "Epoch: 7431/10000 Iteration: 52018 Train loss: 0.007599\n",
      "Epoch: 7432/10000 Iteration: 52025 Train loss: 0.007599\n",
      "Epoch: 7433/10000 Iteration: 52032 Train loss: 0.007599\n",
      "Epoch: 7434/10000 Iteration: 52039 Train loss: 0.007599\n",
      "Epoch: 7435/10000 Iteration: 52046 Train loss: 0.007599\n",
      "Epoch: 7436/10000 Iteration: 52053 Train loss: 0.007598\n",
      "Epoch: 7437/10000 Iteration: 52060 Train loss: 0.007598\n",
      "Epoch: 7438/10000 Iteration: 52067 Train loss: 0.007598\n",
      "Epoch: 7439/10000 Iteration: 52074 Train loss: 0.007598\n",
      "Epoch: 7440/10000 Iteration: 52081 Train loss: 0.007598\n",
      "Epoch: 7441/10000 Iteration: 52088 Train loss: 0.007598\n",
      "Epoch: 7442/10000 Iteration: 52095 Train loss: 0.007598\n",
      "Epoch: 7443/10000 Iteration: 52102 Train loss: 0.007597\n",
      "Epoch: 7444/10000 Iteration: 52109 Train loss: 0.007597\n",
      "Epoch: 7445/10000 Iteration: 52116 Train loss: 0.007597\n",
      "Epoch: 7446/10000 Iteration: 52123 Train loss: 0.007597\n",
      "Epoch: 7447/10000 Iteration: 52130 Train loss: 0.007597\n",
      "Epoch: 7448/10000 Iteration: 52137 Train loss: 0.007597\n",
      "Epoch: 7449/10000 Iteration: 52144 Train loss: 0.007597\n",
      "Epoch: 7450/10000 Iteration: 52151 Train loss: 0.007596\n",
      "Epoch: 7451/10000 Iteration: 52158 Train loss: 0.007596\n",
      "Epoch: 7452/10000 Iteration: 52165 Train loss: 0.007596\n",
      "Epoch: 7453/10000 Iteration: 52172 Train loss: 0.007596\n",
      "Epoch: 7454/10000 Iteration: 52179 Train loss: 0.007596\n",
      "Epoch: 7455/10000 Iteration: 52186 Train loss: 0.007596\n",
      "Epoch: 7456/10000 Iteration: 52193 Train loss: 0.007596\n",
      "Epoch: 7457/10000 Iteration: 52200 Train loss: 0.007595\n",
      "Epoch: 7458/10000 Iteration: 52207 Train loss: 0.007595\n",
      "Epoch: 7459/10000 Iteration: 52214 Train loss: 0.007595\n",
      "Epoch: 7460/10000 Iteration: 52221 Train loss: 0.007595\n",
      "Epoch: 7461/10000 Iteration: 52228 Train loss: 0.007595\n",
      "Epoch: 7462/10000 Iteration: 52235 Train loss: 0.007595\n",
      "Epoch: 7463/10000 Iteration: 52242 Train loss: 0.007594\n",
      "Epoch: 7464/10000 Iteration: 52249 Train loss: 0.007594\n",
      "Epoch: 7465/10000 Iteration: 52256 Train loss: 0.007594\n",
      "Epoch: 7466/10000 Iteration: 52263 Train loss: 0.007594\n",
      "Epoch: 7467/10000 Iteration: 52270 Train loss: 0.007594\n",
      "Epoch: 7468/10000 Iteration: 52277 Train loss: 0.007594\n",
      "Epoch: 7469/10000 Iteration: 52284 Train loss: 0.007594\n",
      "Epoch: 7470/10000 Iteration: 52291 Train loss: 0.007593\n",
      "Epoch: 7471/10000 Iteration: 52298 Train loss: 0.007593\n",
      "Epoch: 7472/10000 Iteration: 52305 Train loss: 0.007593\n",
      "Epoch: 7473/10000 Iteration: 52312 Train loss: 0.007593\n",
      "Epoch: 7474/10000 Iteration: 52319 Train loss: 0.007593\n",
      "Epoch: 7475/10000 Iteration: 52326 Train loss: 0.007593\n",
      "Epoch: 7476/10000 Iteration: 52333 Train loss: 0.007593\n",
      "Epoch: 7477/10000 Iteration: 52340 Train loss: 0.007592\n",
      "Epoch: 7478/10000 Iteration: 52347 Train loss: 0.007592\n",
      "Epoch: 7479/10000 Iteration: 52354 Train loss: 0.007592\n",
      "Epoch: 7480/10000 Iteration: 52361 Train loss: 0.007592\n",
      "Epoch: 7481/10000 Iteration: 52368 Train loss: 0.007592\n",
      "Epoch: 7482/10000 Iteration: 52375 Train loss: 0.007592\n",
      "Epoch: 7483/10000 Iteration: 52382 Train loss: 0.007592\n",
      "Epoch: 7484/10000 Iteration: 52389 Train loss: 0.007591\n",
      "Epoch: 7485/10000 Iteration: 52396 Train loss: 0.007591\n",
      "Epoch: 7486/10000 Iteration: 52403 Train loss: 0.007591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7487/10000 Iteration: 52410 Train loss: 0.007591\n",
      "Epoch: 7488/10000 Iteration: 52417 Train loss: 0.007591\n",
      "Epoch: 7489/10000 Iteration: 52424 Train loss: 0.007591\n",
      "Epoch: 7490/10000 Iteration: 52431 Train loss: 0.007591\n",
      "Epoch: 7491/10000 Iteration: 52438 Train loss: 0.007590\n",
      "Epoch: 7492/10000 Iteration: 52445 Train loss: 0.007590\n",
      "Epoch: 7493/10000 Iteration: 52452 Train loss: 0.007590\n",
      "Epoch: 7494/10000 Iteration: 52459 Train loss: 0.007590\n",
      "Epoch: 7495/10000 Iteration: 52466 Train loss: 0.007590\n",
      "Epoch: 7496/10000 Iteration: 52473 Train loss: 0.007590\n",
      "Epoch: 7497/10000 Iteration: 52480 Train loss: 0.007590\n",
      "Epoch: 7498/10000 Iteration: 52487 Train loss: 0.007589\n",
      "Epoch: 7499/10000 Iteration: 52494 Train loss: 0.007589\n",
      "Epoch: 7500/10000 Iteration: 52501 Train loss: 0.007589\n",
      "Epoch: 7501/10000 Iteration: 52508 Train loss: 0.007589\n",
      "Epoch: 7502/10000 Iteration: 52515 Train loss: 0.007589\n",
      "Epoch: 7503/10000 Iteration: 52522 Train loss: 0.007589\n",
      "Epoch: 7504/10000 Iteration: 52529 Train loss: 0.007589\n",
      "Epoch: 7505/10000 Iteration: 52536 Train loss: 0.007588\n",
      "Epoch: 7506/10000 Iteration: 52543 Train loss: 0.007588\n",
      "Epoch: 7507/10000 Iteration: 52550 Train loss: 0.007588\n",
      "Epoch: 7508/10000 Iteration: 52557 Train loss: 0.007588\n",
      "Epoch: 7509/10000 Iteration: 52564 Train loss: 0.007588\n",
      "Epoch: 7510/10000 Iteration: 52571 Train loss: 0.007588\n",
      "Epoch: 7511/10000 Iteration: 52578 Train loss: 0.007588\n",
      "Epoch: 7512/10000 Iteration: 52585 Train loss: 0.007587\n",
      "Epoch: 7513/10000 Iteration: 52592 Train loss: 0.007587\n",
      "Epoch: 7514/10000 Iteration: 52599 Train loss: 0.007587\n",
      "Epoch: 7515/10000 Iteration: 52606 Train loss: 0.007587\n",
      "Epoch: 7516/10000 Iteration: 52613 Train loss: 0.007587\n",
      "Epoch: 7517/10000 Iteration: 52620 Train loss: 0.007587\n",
      "Epoch: 7518/10000 Iteration: 52627 Train loss: 0.007587\n",
      "Epoch: 7519/10000 Iteration: 52634 Train loss: 0.007586\n",
      "Epoch: 7520/10000 Iteration: 52641 Train loss: 0.007586\n",
      "Epoch: 7521/10000 Iteration: 52648 Train loss: 0.007586\n",
      "Epoch: 7522/10000 Iteration: 52655 Train loss: 0.007586\n",
      "Epoch: 7523/10000 Iteration: 52662 Train loss: 0.007586\n",
      "Epoch: 7524/10000 Iteration: 52669 Train loss: 0.007586\n",
      "Epoch: 7525/10000 Iteration: 52676 Train loss: 0.007586\n",
      "Epoch: 7526/10000 Iteration: 52683 Train loss: 0.007585\n",
      "Epoch: 7527/10000 Iteration: 52690 Train loss: 0.007585\n",
      "Epoch: 7528/10000 Iteration: 52697 Train loss: 0.007585\n",
      "Epoch: 7529/10000 Iteration: 52704 Train loss: 0.007585\n",
      "Epoch: 7530/10000 Iteration: 52711 Train loss: 0.007585\n",
      "Epoch: 7531/10000 Iteration: 52718 Train loss: 0.007585\n",
      "Epoch: 7532/10000 Iteration: 52725 Train loss: 0.007585\n",
      "Epoch: 7533/10000 Iteration: 52732 Train loss: 0.007584\n",
      "Epoch: 7534/10000 Iteration: 52739 Train loss: 0.007584\n",
      "Epoch: 7535/10000 Iteration: 52746 Train loss: 0.007584\n",
      "Epoch: 7536/10000 Iteration: 52753 Train loss: 0.007584\n",
      "Epoch: 7537/10000 Iteration: 52760 Train loss: 0.007584\n",
      "Epoch: 7538/10000 Iteration: 52767 Train loss: 0.007584\n",
      "Epoch: 7539/10000 Iteration: 52774 Train loss: 0.007584\n",
      "Epoch: 7540/10000 Iteration: 52781 Train loss: 0.007583\n",
      "Epoch: 7541/10000 Iteration: 52788 Train loss: 0.007583\n",
      "Epoch: 7542/10000 Iteration: 52795 Train loss: 0.007583\n",
      "Epoch: 7543/10000 Iteration: 52802 Train loss: 0.007583\n",
      "Epoch: 7544/10000 Iteration: 52809 Train loss: 0.007583\n",
      "Epoch: 7545/10000 Iteration: 52816 Train loss: 0.007583\n",
      "Epoch: 7546/10000 Iteration: 52823 Train loss: 0.007583\n",
      "Epoch: 7547/10000 Iteration: 52830 Train loss: 0.007582\n",
      "Epoch: 7548/10000 Iteration: 52837 Train loss: 0.007582\n",
      "Epoch: 7549/10000 Iteration: 52844 Train loss: 0.007582\n",
      "Epoch: 7550/10000 Iteration: 52851 Train loss: 0.007582\n",
      "Epoch: 7551/10000 Iteration: 52858 Train loss: 0.007582\n",
      "Epoch: 7552/10000 Iteration: 52865 Train loss: 0.007582\n",
      "Epoch: 7553/10000 Iteration: 52872 Train loss: 0.007582\n",
      "Epoch: 7554/10000 Iteration: 52879 Train loss: 0.007581\n",
      "Epoch: 7555/10000 Iteration: 52886 Train loss: 0.007581\n",
      "Epoch: 7556/10000 Iteration: 52893 Train loss: 0.007581\n",
      "Epoch: 7557/10000 Iteration: 52900 Train loss: 0.007581\n",
      "Epoch: 7558/10000 Iteration: 52907 Train loss: 0.007581\n",
      "Epoch: 7559/10000 Iteration: 52914 Train loss: 0.007581\n",
      "Epoch: 7560/10000 Iteration: 52921 Train loss: 0.007581\n",
      "Epoch: 7561/10000 Iteration: 52928 Train loss: 0.007580\n",
      "Epoch: 7562/10000 Iteration: 52935 Train loss: 0.007580\n",
      "Epoch: 7563/10000 Iteration: 52942 Train loss: 0.007580\n",
      "Epoch: 7564/10000 Iteration: 52949 Train loss: 0.007580\n",
      "Epoch: 7565/10000 Iteration: 52956 Train loss: 0.007580\n",
      "Epoch: 7566/10000 Iteration: 52963 Train loss: 0.007580\n",
      "Epoch: 7567/10000 Iteration: 52970 Train loss: 0.007580\n",
      "Epoch: 7568/10000 Iteration: 52977 Train loss: 0.007579\n",
      "Epoch: 7569/10000 Iteration: 52984 Train loss: 0.007579\n",
      "Epoch: 7570/10000 Iteration: 52991 Train loss: 0.007579\n",
      "Epoch: 7571/10000 Iteration: 52998 Train loss: 0.007579\n",
      "Epoch: 7572/10000 Iteration: 53005 Train loss: 0.007579\n",
      "Epoch: 7573/10000 Iteration: 53012 Train loss: 0.007579\n",
      "Epoch: 7574/10000 Iteration: 53019 Train loss: 0.007579\n",
      "Epoch: 7575/10000 Iteration: 53026 Train loss: 0.007578\n",
      "Epoch: 7576/10000 Iteration: 53033 Train loss: 0.007578\n",
      "Epoch: 7577/10000 Iteration: 53040 Train loss: 0.007578\n",
      "Epoch: 7578/10000 Iteration: 53047 Train loss: 0.007578\n",
      "Epoch: 7579/10000 Iteration: 53054 Train loss: 0.007578\n",
      "Epoch: 7580/10000 Iteration: 53061 Train loss: 0.007578\n",
      "Epoch: 7581/10000 Iteration: 53068 Train loss: 0.007578\n",
      "Epoch: 7582/10000 Iteration: 53075 Train loss: 0.007577\n",
      "Epoch: 7583/10000 Iteration: 53082 Train loss: 0.007577\n",
      "Epoch: 7584/10000 Iteration: 53089 Train loss: 0.007577\n",
      "Epoch: 7585/10000 Iteration: 53096 Train loss: 0.007577\n",
      "Epoch: 7586/10000 Iteration: 53103 Train loss: 0.007577\n",
      "Epoch: 7587/10000 Iteration: 53110 Train loss: 0.007577\n",
      "Epoch: 7588/10000 Iteration: 53117 Train loss: 0.007577\n",
      "Epoch: 7589/10000 Iteration: 53124 Train loss: 0.007577\n",
      "Epoch: 7590/10000 Iteration: 53131 Train loss: 0.007576\n",
      "Epoch: 7591/10000 Iteration: 53138 Train loss: 0.007576\n",
      "Epoch: 7592/10000 Iteration: 53145 Train loss: 0.007576\n",
      "Epoch: 7593/10000 Iteration: 53152 Train loss: 0.007576\n",
      "Epoch: 7594/10000 Iteration: 53159 Train loss: 0.007576\n",
      "Epoch: 7595/10000 Iteration: 53166 Train loss: 0.007576\n",
      "Epoch: 7596/10000 Iteration: 53173 Train loss: 0.007576\n",
      "Epoch: 7597/10000 Iteration: 53180 Train loss: 0.007575\n",
      "Epoch: 7598/10000 Iteration: 53187 Train loss: 0.007575\n",
      "Epoch: 7599/10000 Iteration: 53194 Train loss: 0.007575\n",
      "Epoch: 7600/10000 Iteration: 53201 Train loss: 0.007575\n",
      "Epoch: 7601/10000 Iteration: 53208 Train loss: 0.007575\n",
      "Epoch: 7602/10000 Iteration: 53215 Train loss: 0.007575\n",
      "Epoch: 7603/10000 Iteration: 53222 Train loss: 0.007575\n",
      "Epoch: 7604/10000 Iteration: 53229 Train loss: 0.007574\n",
      "Epoch: 7605/10000 Iteration: 53236 Train loss: 0.007574\n",
      "Epoch: 7606/10000 Iteration: 53243 Train loss: 0.007574\n",
      "Epoch: 7607/10000 Iteration: 53250 Train loss: 0.007574\n",
      "Epoch: 7608/10000 Iteration: 53257 Train loss: 0.007574\n",
      "Epoch: 7609/10000 Iteration: 53264 Train loss: 0.007574\n",
      "Epoch: 7610/10000 Iteration: 53271 Train loss: 0.007574\n",
      "Epoch: 7611/10000 Iteration: 53278 Train loss: 0.007573\n",
      "Epoch: 7612/10000 Iteration: 53285 Train loss: 0.007573\n",
      "Epoch: 7613/10000 Iteration: 53292 Train loss: 0.007573\n",
      "Epoch: 7614/10000 Iteration: 53299 Train loss: 0.007573\n",
      "Epoch: 7615/10000 Iteration: 53306 Train loss: 0.007573\n",
      "Epoch: 7616/10000 Iteration: 53313 Train loss: 0.007573\n",
      "Epoch: 7617/10000 Iteration: 53320 Train loss: 0.007573\n",
      "Epoch: 7618/10000 Iteration: 53327 Train loss: 0.007572\n",
      "Epoch: 7619/10000 Iteration: 53334 Train loss: 0.007572\n",
      "Epoch: 7620/10000 Iteration: 53341 Train loss: 0.007572\n",
      "Epoch: 7621/10000 Iteration: 53348 Train loss: 0.007572\n",
      "Epoch: 7622/10000 Iteration: 53355 Train loss: 0.007572\n",
      "Epoch: 7623/10000 Iteration: 53362 Train loss: 0.007572\n",
      "Epoch: 7624/10000 Iteration: 53369 Train loss: 0.007572\n",
      "Epoch: 7625/10000 Iteration: 53376 Train loss: 0.007572\n",
      "Epoch: 7626/10000 Iteration: 53383 Train loss: 0.007571\n",
      "Epoch: 7627/10000 Iteration: 53390 Train loss: 0.007571\n",
      "Epoch: 7628/10000 Iteration: 53397 Train loss: 0.007571\n",
      "Epoch: 7629/10000 Iteration: 53404 Train loss: 0.007571\n",
      "Epoch: 7630/10000 Iteration: 53411 Train loss: 0.007571\n",
      "Epoch: 7631/10000 Iteration: 53418 Train loss: 0.007571\n",
      "Epoch: 7632/10000 Iteration: 53425 Train loss: 0.007571\n",
      "Epoch: 7633/10000 Iteration: 53432 Train loss: 0.007570\n",
      "Epoch: 7634/10000 Iteration: 53439 Train loss: 0.007570\n",
      "Epoch: 7635/10000 Iteration: 53446 Train loss: 0.007570\n",
      "Epoch: 7636/10000 Iteration: 53453 Train loss: 0.007570\n",
      "Epoch: 7637/10000 Iteration: 53460 Train loss: 0.007570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7638/10000 Iteration: 53467 Train loss: 0.007570\n",
      "Epoch: 7639/10000 Iteration: 53474 Train loss: 0.007570\n",
      "Epoch: 7640/10000 Iteration: 53481 Train loss: 0.007569\n",
      "Epoch: 7641/10000 Iteration: 53488 Train loss: 0.007569\n",
      "Epoch: 7642/10000 Iteration: 53495 Train loss: 0.007569\n",
      "Epoch: 7643/10000 Iteration: 53502 Train loss: 0.007569\n",
      "Epoch: 7644/10000 Iteration: 53509 Train loss: 0.007569\n",
      "Epoch: 7645/10000 Iteration: 53516 Train loss: 0.007569\n",
      "Epoch: 7646/10000 Iteration: 53523 Train loss: 0.007569\n",
      "Epoch: 7647/10000 Iteration: 53530 Train loss: 0.007568\n",
      "Epoch: 7648/10000 Iteration: 53537 Train loss: 0.007568\n",
      "Epoch: 7649/10000 Iteration: 53544 Train loss: 0.007568\n",
      "Epoch: 7650/10000 Iteration: 53551 Train loss: 0.007568\n",
      "Epoch: 7651/10000 Iteration: 53558 Train loss: 0.007568\n",
      "Epoch: 7652/10000 Iteration: 53565 Train loss: 0.007568\n",
      "Epoch: 7653/10000 Iteration: 53572 Train loss: 0.007568\n",
      "Epoch: 7654/10000 Iteration: 53579 Train loss: 0.007568\n",
      "Epoch: 7655/10000 Iteration: 53586 Train loss: 0.007567\n",
      "Epoch: 7656/10000 Iteration: 53593 Train loss: 0.007567\n",
      "Epoch: 7657/10000 Iteration: 53600 Train loss: 0.007567\n",
      "Epoch: 7658/10000 Iteration: 53607 Train loss: 0.007567\n",
      "Epoch: 7659/10000 Iteration: 53614 Train loss: 0.007567\n",
      "Epoch: 7660/10000 Iteration: 53621 Train loss: 0.007567\n",
      "Epoch: 7661/10000 Iteration: 53628 Train loss: 0.007567\n",
      "Epoch: 7662/10000 Iteration: 53635 Train loss: 0.007566\n",
      "Epoch: 7663/10000 Iteration: 53642 Train loss: 0.007566\n",
      "Epoch: 7664/10000 Iteration: 53649 Train loss: 0.007566\n",
      "Epoch: 7665/10000 Iteration: 53656 Train loss: 0.007566\n",
      "Epoch: 7666/10000 Iteration: 53663 Train loss: 0.007566\n",
      "Epoch: 7667/10000 Iteration: 53670 Train loss: 0.007566\n",
      "Epoch: 7668/10000 Iteration: 53677 Train loss: 0.007566\n",
      "Epoch: 7669/10000 Iteration: 53684 Train loss: 0.007565\n",
      "Epoch: 7670/10000 Iteration: 53691 Train loss: 0.007565\n",
      "Epoch: 7671/10000 Iteration: 53698 Train loss: 0.007565\n",
      "Epoch: 7672/10000 Iteration: 53705 Train loss: 0.007565\n",
      "Epoch: 7673/10000 Iteration: 53712 Train loss: 0.007565\n",
      "Epoch: 7674/10000 Iteration: 53719 Train loss: 0.007565\n",
      "Epoch: 7675/10000 Iteration: 53726 Train loss: 0.007565\n",
      "Epoch: 7676/10000 Iteration: 53733 Train loss: 0.007565\n",
      "Epoch: 7677/10000 Iteration: 53740 Train loss: 0.007564\n",
      "Epoch: 7678/10000 Iteration: 53747 Train loss: 0.007564\n",
      "Epoch: 7679/10000 Iteration: 53754 Train loss: 0.007564\n",
      "Epoch: 7680/10000 Iteration: 53761 Train loss: 0.007564\n",
      "Epoch: 7681/10000 Iteration: 53768 Train loss: 0.007564\n",
      "Epoch: 7682/10000 Iteration: 53775 Train loss: 0.007564\n",
      "Epoch: 7683/10000 Iteration: 53782 Train loss: 0.007564\n",
      "Epoch: 7684/10000 Iteration: 53789 Train loss: 0.007563\n",
      "Epoch: 7685/10000 Iteration: 53796 Train loss: 0.007563\n",
      "Epoch: 7686/10000 Iteration: 53803 Train loss: 0.007563\n",
      "Epoch: 7687/10000 Iteration: 53810 Train loss: 0.007563\n",
      "Epoch: 7688/10000 Iteration: 53817 Train loss: 0.007563\n",
      "Epoch: 7689/10000 Iteration: 53824 Train loss: 0.007563\n",
      "Epoch: 7690/10000 Iteration: 53831 Train loss: 0.007563\n",
      "Epoch: 7691/10000 Iteration: 53838 Train loss: 0.007563\n",
      "Epoch: 7692/10000 Iteration: 53845 Train loss: 0.007562\n",
      "Epoch: 7693/10000 Iteration: 53852 Train loss: 0.007562\n",
      "Epoch: 7694/10000 Iteration: 53859 Train loss: 0.007562\n",
      "Epoch: 7695/10000 Iteration: 53866 Train loss: 0.007562\n",
      "Epoch: 7696/10000 Iteration: 53873 Train loss: 0.007562\n",
      "Epoch: 7697/10000 Iteration: 53880 Train loss: 0.007562\n",
      "Epoch: 7698/10000 Iteration: 53887 Train loss: 0.007562\n",
      "Epoch: 7699/10000 Iteration: 53894 Train loss: 0.007561\n",
      "Epoch: 7700/10000 Iteration: 53901 Train loss: 0.007561\n",
      "Epoch: 7701/10000 Iteration: 53908 Train loss: 0.007561\n",
      "Epoch: 7702/10000 Iteration: 53915 Train loss: 0.007561\n",
      "Epoch: 7703/10000 Iteration: 53922 Train loss: 0.007561\n",
      "Epoch: 7704/10000 Iteration: 53929 Train loss: 0.007561\n",
      "Epoch: 7705/10000 Iteration: 53936 Train loss: 0.007561\n",
      "Epoch: 7706/10000 Iteration: 53943 Train loss: 0.007560\n",
      "Epoch: 7707/10000 Iteration: 53950 Train loss: 0.007560\n",
      "Epoch: 7708/10000 Iteration: 53957 Train loss: 0.007560\n",
      "Epoch: 7709/10000 Iteration: 53964 Train loss: 0.007560\n",
      "Epoch: 7710/10000 Iteration: 53971 Train loss: 0.007560\n",
      "Epoch: 7711/10000 Iteration: 53978 Train loss: 0.007560\n",
      "Epoch: 7712/10000 Iteration: 53985 Train loss: 0.007560\n",
      "Epoch: 7713/10000 Iteration: 53992 Train loss: 0.007560\n",
      "Epoch: 7714/10000 Iteration: 53999 Train loss: 0.007559\n",
      "Epoch: 7715/10000 Iteration: 54006 Train loss: 0.007559\n",
      "Epoch: 7716/10000 Iteration: 54013 Train loss: 0.007559\n",
      "Epoch: 7717/10000 Iteration: 54020 Train loss: 0.007559\n",
      "Epoch: 7718/10000 Iteration: 54027 Train loss: 0.007559\n",
      "Epoch: 7719/10000 Iteration: 54034 Train loss: 0.007559\n",
      "Epoch: 7720/10000 Iteration: 54041 Train loss: 0.007559\n",
      "Epoch: 7721/10000 Iteration: 54048 Train loss: 0.007558\n",
      "Epoch: 7722/10000 Iteration: 54055 Train loss: 0.007558\n",
      "Epoch: 7723/10000 Iteration: 54062 Train loss: 0.007558\n",
      "Epoch: 7724/10000 Iteration: 54069 Train loss: 0.007558\n",
      "Epoch: 7725/10000 Iteration: 54076 Train loss: 0.007558\n",
      "Epoch: 7726/10000 Iteration: 54083 Train loss: 0.007558\n",
      "Epoch: 7727/10000 Iteration: 54090 Train loss: 0.007558\n",
      "Epoch: 7728/10000 Iteration: 54097 Train loss: 0.007558\n",
      "Epoch: 7729/10000 Iteration: 54104 Train loss: 0.007557\n",
      "Epoch: 7730/10000 Iteration: 54111 Train loss: 0.007557\n",
      "Epoch: 7731/10000 Iteration: 54118 Train loss: 0.007557\n",
      "Epoch: 7732/10000 Iteration: 54125 Train loss: 0.007557\n",
      "Epoch: 7733/10000 Iteration: 54132 Train loss: 0.007557\n",
      "Epoch: 7734/10000 Iteration: 54139 Train loss: 0.007557\n",
      "Epoch: 7735/10000 Iteration: 54146 Train loss: 0.007557\n",
      "Epoch: 7736/10000 Iteration: 54153 Train loss: 0.007557\n",
      "Epoch: 7737/10000 Iteration: 54160 Train loss: 0.007556\n",
      "Epoch: 7738/10000 Iteration: 54167 Train loss: 0.007556\n",
      "Epoch: 7739/10000 Iteration: 54174 Train loss: 0.007556\n",
      "Epoch: 7740/10000 Iteration: 54181 Train loss: 0.007556\n",
      "Epoch: 7741/10000 Iteration: 54188 Train loss: 0.007556\n",
      "Epoch: 7742/10000 Iteration: 54195 Train loss: 0.007556\n",
      "Epoch: 7743/10000 Iteration: 54202 Train loss: 0.007556\n",
      "Epoch: 7744/10000 Iteration: 54209 Train loss: 0.007555\n",
      "Epoch: 7745/10000 Iteration: 54216 Train loss: 0.007555\n",
      "Epoch: 7746/10000 Iteration: 54223 Train loss: 0.007555\n",
      "Epoch: 7747/10000 Iteration: 54230 Train loss: 0.007555\n",
      "Epoch: 7748/10000 Iteration: 54237 Train loss: 0.007555\n",
      "Epoch: 7749/10000 Iteration: 54244 Train loss: 0.007555\n",
      "Epoch: 7750/10000 Iteration: 54251 Train loss: 0.007555\n",
      "Epoch: 7751/10000 Iteration: 54258 Train loss: 0.007555\n",
      "Epoch: 7752/10000 Iteration: 54265 Train loss: 0.007554\n",
      "Epoch: 7753/10000 Iteration: 54272 Train loss: 0.007554\n",
      "Epoch: 7754/10000 Iteration: 54279 Train loss: 0.007554\n",
      "Epoch: 7755/10000 Iteration: 54286 Train loss: 0.007554\n",
      "Epoch: 7756/10000 Iteration: 54293 Train loss: 0.007554\n",
      "Epoch: 7757/10000 Iteration: 54300 Train loss: 0.007554\n",
      "Epoch: 7758/10000 Iteration: 54307 Train loss: 0.007554\n",
      "Epoch: 7759/10000 Iteration: 54314 Train loss: 0.007553\n",
      "Epoch: 7760/10000 Iteration: 54321 Train loss: 0.007553\n",
      "Epoch: 7761/10000 Iteration: 54328 Train loss: 0.007553\n",
      "Epoch: 7762/10000 Iteration: 54335 Train loss: 0.007553\n",
      "Epoch: 7763/10000 Iteration: 54342 Train loss: 0.007553\n",
      "Epoch: 7764/10000 Iteration: 54349 Train loss: 0.007553\n",
      "Epoch: 7765/10000 Iteration: 54356 Train loss: 0.007553\n",
      "Epoch: 7766/10000 Iteration: 54363 Train loss: 0.007553\n",
      "Epoch: 7767/10000 Iteration: 54370 Train loss: 0.007552\n",
      "Epoch: 7768/10000 Iteration: 54377 Train loss: 0.007552\n",
      "Epoch: 7769/10000 Iteration: 54384 Train loss: 0.007552\n",
      "Epoch: 7770/10000 Iteration: 54391 Train loss: 0.007552\n",
      "Epoch: 7771/10000 Iteration: 54398 Train loss: 0.007552\n",
      "Epoch: 7772/10000 Iteration: 54405 Train loss: 0.007552\n",
      "Epoch: 7773/10000 Iteration: 54412 Train loss: 0.007552\n",
      "Epoch: 7774/10000 Iteration: 54419 Train loss: 0.007552\n",
      "Epoch: 7775/10000 Iteration: 54426 Train loss: 0.007551\n",
      "Epoch: 7776/10000 Iteration: 54433 Train loss: 0.007551\n",
      "Epoch: 7777/10000 Iteration: 54440 Train loss: 0.007551\n",
      "Epoch: 7778/10000 Iteration: 54447 Train loss: 0.007551\n",
      "Epoch: 7779/10000 Iteration: 54454 Train loss: 0.007551\n",
      "Epoch: 7780/10000 Iteration: 54461 Train loss: 0.007551\n",
      "Epoch: 7781/10000 Iteration: 54468 Train loss: 0.007551\n",
      "Epoch: 7782/10000 Iteration: 54475 Train loss: 0.007551\n",
      "Epoch: 7783/10000 Iteration: 54482 Train loss: 0.007550\n",
      "Epoch: 7784/10000 Iteration: 54489 Train loss: 0.007550\n",
      "Epoch: 7785/10000 Iteration: 54496 Train loss: 0.007550\n",
      "Epoch: 7786/10000 Iteration: 54503 Train loss: 0.007550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7787/10000 Iteration: 54510 Train loss: 0.007550\n",
      "Epoch: 7788/10000 Iteration: 54517 Train loss: 0.007550\n",
      "Epoch: 7789/10000 Iteration: 54524 Train loss: 0.007550\n",
      "Epoch: 7790/10000 Iteration: 54531 Train loss: 0.007549\n",
      "Epoch: 7791/10000 Iteration: 54538 Train loss: 0.007549\n",
      "Epoch: 7792/10000 Iteration: 54545 Train loss: 0.007549\n",
      "Epoch: 7793/10000 Iteration: 54552 Train loss: 0.007549\n",
      "Epoch: 7794/10000 Iteration: 54559 Train loss: 0.007549\n",
      "Epoch: 7795/10000 Iteration: 54566 Train loss: 0.007549\n",
      "Epoch: 7796/10000 Iteration: 54573 Train loss: 0.007549\n",
      "Epoch: 7797/10000 Iteration: 54580 Train loss: 0.007549\n",
      "Epoch: 7798/10000 Iteration: 54587 Train loss: 0.007548\n",
      "Epoch: 7799/10000 Iteration: 54594 Train loss: 0.007548\n",
      "Epoch: 7800/10000 Iteration: 54601 Train loss: 0.007548\n",
      "Epoch: 7801/10000 Iteration: 54608 Train loss: 0.007548\n",
      "Epoch: 7802/10000 Iteration: 54615 Train loss: 0.007548\n",
      "Epoch: 7803/10000 Iteration: 54622 Train loss: 0.007548\n",
      "Epoch: 7804/10000 Iteration: 54629 Train loss: 0.007548\n",
      "Epoch: 7805/10000 Iteration: 54636 Train loss: 0.007548\n",
      "Epoch: 7806/10000 Iteration: 54643 Train loss: 0.007547\n",
      "Epoch: 7807/10000 Iteration: 54650 Train loss: 0.007547\n",
      "Epoch: 7808/10000 Iteration: 54657 Train loss: 0.007547\n",
      "Epoch: 7809/10000 Iteration: 54664 Train loss: 0.007547\n",
      "Epoch: 7810/10000 Iteration: 54671 Train loss: 0.007547\n",
      "Epoch: 7811/10000 Iteration: 54678 Train loss: 0.007547\n",
      "Epoch: 7812/10000 Iteration: 54685 Train loss: 0.007547\n",
      "Epoch: 7813/10000 Iteration: 54692 Train loss: 0.007547\n",
      "Epoch: 7814/10000 Iteration: 54699 Train loss: 0.007546\n",
      "Epoch: 7815/10000 Iteration: 54706 Train loss: 0.007546\n",
      "Epoch: 7816/10000 Iteration: 54713 Train loss: 0.007546\n",
      "Epoch: 7817/10000 Iteration: 54720 Train loss: 0.007546\n",
      "Epoch: 7818/10000 Iteration: 54727 Train loss: 0.007546\n",
      "Epoch: 7819/10000 Iteration: 54734 Train loss: 0.007546\n",
      "Epoch: 7820/10000 Iteration: 54741 Train loss: 0.007546\n",
      "Epoch: 7821/10000 Iteration: 54748 Train loss: 0.007546\n",
      "Epoch: 7822/10000 Iteration: 54755 Train loss: 0.007545\n",
      "Epoch: 7823/10000 Iteration: 54762 Train loss: 0.007545\n",
      "Epoch: 7824/10000 Iteration: 54769 Train loss: 0.007545\n",
      "Epoch: 7825/10000 Iteration: 54776 Train loss: 0.007545\n",
      "Epoch: 7826/10000 Iteration: 54783 Train loss: 0.007545\n",
      "Epoch: 7827/10000 Iteration: 54790 Train loss: 0.007545\n",
      "Epoch: 7828/10000 Iteration: 54797 Train loss: 0.007545\n",
      "Epoch: 7829/10000 Iteration: 54804 Train loss: 0.007545\n",
      "Epoch: 7830/10000 Iteration: 54811 Train loss: 0.007544\n",
      "Epoch: 7831/10000 Iteration: 54818 Train loss: 0.007544\n",
      "Epoch: 7832/10000 Iteration: 54825 Train loss: 0.007544\n",
      "Epoch: 7833/10000 Iteration: 54832 Train loss: 0.007544\n",
      "Epoch: 7834/10000 Iteration: 54839 Train loss: 0.007544\n",
      "Epoch: 7835/10000 Iteration: 54846 Train loss: 0.007544\n",
      "Epoch: 7836/10000 Iteration: 54853 Train loss: 0.007544\n",
      "Epoch: 7837/10000 Iteration: 54860 Train loss: 0.007544\n",
      "Epoch: 7838/10000 Iteration: 54867 Train loss: 0.007543\n",
      "Epoch: 7839/10000 Iteration: 54874 Train loss: 0.007543\n",
      "Epoch: 7840/10000 Iteration: 54881 Train loss: 0.007543\n",
      "Epoch: 7841/10000 Iteration: 54888 Train loss: 0.007543\n",
      "Epoch: 7842/10000 Iteration: 54895 Train loss: 0.007543\n",
      "Epoch: 7843/10000 Iteration: 54902 Train loss: 0.007543\n",
      "Epoch: 7844/10000 Iteration: 54909 Train loss: 0.007543\n",
      "Epoch: 7845/10000 Iteration: 54916 Train loss: 0.007542\n",
      "Epoch: 7846/10000 Iteration: 54923 Train loss: 0.007542\n",
      "Epoch: 7847/10000 Iteration: 54930 Train loss: 0.007542\n",
      "Epoch: 7848/10000 Iteration: 54937 Train loss: 0.007542\n",
      "Epoch: 7849/10000 Iteration: 54944 Train loss: 0.007542\n",
      "Epoch: 7850/10000 Iteration: 54951 Train loss: 0.007542\n",
      "Epoch: 7851/10000 Iteration: 54958 Train loss: 0.007542\n",
      "Epoch: 7852/10000 Iteration: 54965 Train loss: 0.007542\n",
      "Epoch: 7853/10000 Iteration: 54972 Train loss: 0.007542\n",
      "Epoch: 7854/10000 Iteration: 54979 Train loss: 0.007541\n",
      "Epoch: 7855/10000 Iteration: 54986 Train loss: 0.007541\n",
      "Epoch: 7856/10000 Iteration: 54993 Train loss: 0.007541\n",
      "Epoch: 7857/10000 Iteration: 55000 Train loss: 0.007541\n",
      "Epoch: 7858/10000 Iteration: 55007 Train loss: 0.007541\n",
      "Epoch: 7859/10000 Iteration: 55014 Train loss: 0.007541\n",
      "Epoch: 7860/10000 Iteration: 55021 Train loss: 0.007541\n",
      "Epoch: 7861/10000 Iteration: 55028 Train loss: 0.007540\n",
      "Epoch: 7862/10000 Iteration: 55035 Train loss: 0.007540\n",
      "Epoch: 7863/10000 Iteration: 55042 Train loss: 0.007540\n",
      "Epoch: 7864/10000 Iteration: 55049 Train loss: 0.007540\n",
      "Epoch: 7865/10000 Iteration: 55056 Train loss: 0.007540\n",
      "Epoch: 7866/10000 Iteration: 55063 Train loss: 0.007540\n",
      "Epoch: 7867/10000 Iteration: 55070 Train loss: 0.007540\n",
      "Epoch: 7868/10000 Iteration: 55077 Train loss: 0.007540\n",
      "Epoch: 7869/10000 Iteration: 55084 Train loss: 0.007540\n",
      "Epoch: 7870/10000 Iteration: 55091 Train loss: 0.007539\n",
      "Epoch: 7871/10000 Iteration: 55098 Train loss: 0.007539\n",
      "Epoch: 7872/10000 Iteration: 55105 Train loss: 0.007539\n",
      "Epoch: 7873/10000 Iteration: 55112 Train loss: 0.007539\n",
      "Epoch: 7874/10000 Iteration: 55119 Train loss: 0.007539\n",
      "Epoch: 7875/10000 Iteration: 55126 Train loss: 0.007539\n",
      "Epoch: 7876/10000 Iteration: 55133 Train loss: 0.007539\n",
      "Epoch: 7877/10000 Iteration: 55140 Train loss: 0.007539\n",
      "Epoch: 7878/10000 Iteration: 55147 Train loss: 0.007538\n",
      "Epoch: 7879/10000 Iteration: 55154 Train loss: 0.007538\n",
      "Epoch: 7880/10000 Iteration: 55161 Train loss: 0.007538\n",
      "Epoch: 7881/10000 Iteration: 55168 Train loss: 0.007538\n",
      "Epoch: 7882/10000 Iteration: 55175 Train loss: 0.007538\n",
      "Epoch: 7883/10000 Iteration: 55182 Train loss: 0.007538\n",
      "Epoch: 7884/10000 Iteration: 55189 Train loss: 0.007538\n",
      "Epoch: 7885/10000 Iteration: 55196 Train loss: 0.007538\n",
      "Epoch: 7886/10000 Iteration: 55203 Train loss: 0.007537\n",
      "Epoch: 7887/10000 Iteration: 55210 Train loss: 0.007537\n",
      "Epoch: 7888/10000 Iteration: 55217 Train loss: 0.007537\n",
      "Epoch: 7889/10000 Iteration: 55224 Train loss: 0.007537\n",
      "Epoch: 7890/10000 Iteration: 55231 Train loss: 0.007537\n",
      "Epoch: 7891/10000 Iteration: 55238 Train loss: 0.007537\n",
      "Epoch: 7892/10000 Iteration: 55245 Train loss: 0.007537\n",
      "Epoch: 7893/10000 Iteration: 55252 Train loss: 0.007537\n",
      "Epoch: 7894/10000 Iteration: 55259 Train loss: 0.007536\n",
      "Epoch: 7895/10000 Iteration: 55266 Train loss: 0.007536\n",
      "Epoch: 7896/10000 Iteration: 55273 Train loss: 0.007536\n",
      "Epoch: 7897/10000 Iteration: 55280 Train loss: 0.007536\n",
      "Epoch: 7898/10000 Iteration: 55287 Train loss: 0.007536\n",
      "Epoch: 7899/10000 Iteration: 55294 Train loss: 0.007536\n",
      "Epoch: 7900/10000 Iteration: 55301 Train loss: 0.007536\n",
      "Epoch: 7901/10000 Iteration: 55308 Train loss: 0.007536\n",
      "Epoch: 7902/10000 Iteration: 55315 Train loss: 0.007535\n",
      "Epoch: 7903/10000 Iteration: 55322 Train loss: 0.007535\n",
      "Epoch: 7904/10000 Iteration: 55329 Train loss: 0.007535\n",
      "Epoch: 7905/10000 Iteration: 55336 Train loss: 0.007535\n",
      "Epoch: 7906/10000 Iteration: 55343 Train loss: 0.007535\n",
      "Epoch: 7907/10000 Iteration: 55350 Train loss: 0.007535\n",
      "Epoch: 7908/10000 Iteration: 55357 Train loss: 0.007535\n",
      "Epoch: 7909/10000 Iteration: 55364 Train loss: 0.007535\n",
      "Epoch: 7910/10000 Iteration: 55371 Train loss: 0.007534\n",
      "Epoch: 7911/10000 Iteration: 55378 Train loss: 0.007534\n",
      "Epoch: 7912/10000 Iteration: 55385 Train loss: 0.007534\n",
      "Epoch: 7913/10000 Iteration: 55392 Train loss: 0.007534\n",
      "Epoch: 7914/10000 Iteration: 55399 Train loss: 0.007534\n",
      "Epoch: 7915/10000 Iteration: 55406 Train loss: 0.007534\n",
      "Epoch: 7916/10000 Iteration: 55413 Train loss: 0.007534\n",
      "Epoch: 7917/10000 Iteration: 55420 Train loss: 0.007534\n",
      "Epoch: 7918/10000 Iteration: 55427 Train loss: 0.007533\n",
      "Epoch: 7919/10000 Iteration: 55434 Train loss: 0.007533\n",
      "Epoch: 7920/10000 Iteration: 55441 Train loss: 0.007533\n",
      "Epoch: 7921/10000 Iteration: 55448 Train loss: 0.007533\n",
      "Epoch: 7922/10000 Iteration: 55455 Train loss: 0.007533\n",
      "Epoch: 7923/10000 Iteration: 55462 Train loss: 0.007533\n",
      "Epoch: 7924/10000 Iteration: 55469 Train loss: 0.007533\n",
      "Epoch: 7925/10000 Iteration: 55476 Train loss: 0.007533\n",
      "Epoch: 7926/10000 Iteration: 55483 Train loss: 0.007533\n",
      "Epoch: 7927/10000 Iteration: 55490 Train loss: 0.007532\n",
      "Epoch: 7928/10000 Iteration: 55497 Train loss: 0.007532\n",
      "Epoch: 7929/10000 Iteration: 55504 Train loss: 0.007532\n",
      "Epoch: 7930/10000 Iteration: 55511 Train loss: 0.007532\n",
      "Epoch: 7931/10000 Iteration: 55518 Train loss: 0.007532\n",
      "Epoch: 7932/10000 Iteration: 55525 Train loss: 0.007532\n",
      "Epoch: 7933/10000 Iteration: 55532 Train loss: 0.007532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7934/10000 Iteration: 55539 Train loss: 0.007532\n",
      "Epoch: 7935/10000 Iteration: 55546 Train loss: 0.007531\n",
      "Epoch: 7936/10000 Iteration: 55553 Train loss: 0.007531\n",
      "Epoch: 7937/10000 Iteration: 55560 Train loss: 0.007531\n",
      "Epoch: 7938/10000 Iteration: 55567 Train loss: 0.007531\n",
      "Epoch: 7939/10000 Iteration: 55574 Train loss: 0.007531\n",
      "Epoch: 7940/10000 Iteration: 55581 Train loss: 0.007531\n",
      "Epoch: 7941/10000 Iteration: 55588 Train loss: 0.007531\n",
      "Epoch: 7942/10000 Iteration: 55595 Train loss: 0.007531\n",
      "Epoch: 7943/10000 Iteration: 55602 Train loss: 0.007530\n",
      "Epoch: 7944/10000 Iteration: 55609 Train loss: 0.007530\n",
      "Epoch: 7945/10000 Iteration: 55616 Train loss: 0.007530\n",
      "Epoch: 7946/10000 Iteration: 55623 Train loss: 0.007530\n",
      "Epoch: 7947/10000 Iteration: 55630 Train loss: 0.007530\n",
      "Epoch: 7948/10000 Iteration: 55637 Train loss: 0.007530\n",
      "Epoch: 7949/10000 Iteration: 55644 Train loss: 0.007530\n",
      "Epoch: 7950/10000 Iteration: 55651 Train loss: 0.007530\n",
      "Epoch: 7951/10000 Iteration: 55658 Train loss: 0.007529\n",
      "Epoch: 7952/10000 Iteration: 55665 Train loss: 0.007529\n",
      "Epoch: 7953/10000 Iteration: 55672 Train loss: 0.007529\n",
      "Epoch: 7954/10000 Iteration: 55679 Train loss: 0.007529\n",
      "Epoch: 7955/10000 Iteration: 55686 Train loss: 0.007529\n",
      "Epoch: 7956/10000 Iteration: 55693 Train loss: 0.007529\n",
      "Epoch: 7957/10000 Iteration: 55700 Train loss: 0.007529\n",
      "Epoch: 7958/10000 Iteration: 55707 Train loss: 0.007529\n",
      "Epoch: 7959/10000 Iteration: 55714 Train loss: 0.007529\n",
      "Epoch: 7960/10000 Iteration: 55721 Train loss: 0.007528\n",
      "Epoch: 7961/10000 Iteration: 55728 Train loss: 0.007528\n",
      "Epoch: 7962/10000 Iteration: 55735 Train loss: 0.007528\n",
      "Epoch: 7963/10000 Iteration: 55742 Train loss: 0.007528\n",
      "Epoch: 7964/10000 Iteration: 55749 Train loss: 0.007528\n",
      "Epoch: 7965/10000 Iteration: 55756 Train loss: 0.007528\n",
      "Epoch: 7966/10000 Iteration: 55763 Train loss: 0.007528\n",
      "Epoch: 7967/10000 Iteration: 55770 Train loss: 0.007528\n",
      "Epoch: 7968/10000 Iteration: 55777 Train loss: 0.007527\n",
      "Epoch: 7969/10000 Iteration: 55784 Train loss: 0.007527\n",
      "Epoch: 7970/10000 Iteration: 55791 Train loss: 0.007527\n",
      "Epoch: 7971/10000 Iteration: 55798 Train loss: 0.007527\n",
      "Epoch: 7972/10000 Iteration: 55805 Train loss: 0.007527\n",
      "Epoch: 7973/10000 Iteration: 55812 Train loss: 0.007527\n",
      "Epoch: 7974/10000 Iteration: 55819 Train loss: 0.007527\n",
      "Epoch: 7975/10000 Iteration: 55826 Train loss: 0.007527\n",
      "Epoch: 7976/10000 Iteration: 55833 Train loss: 0.007527\n",
      "Epoch: 7977/10000 Iteration: 55840 Train loss: 0.007526\n",
      "Epoch: 7978/10000 Iteration: 55847 Train loss: 0.007526\n",
      "Epoch: 7979/10000 Iteration: 55854 Train loss: 0.007526\n",
      "Epoch: 7980/10000 Iteration: 55861 Train loss: 0.007526\n",
      "Epoch: 7981/10000 Iteration: 55868 Train loss: 0.007526\n",
      "Epoch: 7982/10000 Iteration: 55875 Train loss: 0.007526\n",
      "Epoch: 7983/10000 Iteration: 55882 Train loss: 0.007526\n",
      "Epoch: 7984/10000 Iteration: 55889 Train loss: 0.007526\n",
      "Epoch: 7985/10000 Iteration: 55896 Train loss: 0.007526\n",
      "Epoch: 7986/10000 Iteration: 55903 Train loss: 0.007525\n",
      "Epoch: 7987/10000 Iteration: 55910 Train loss: 0.007525\n",
      "Epoch: 7988/10000 Iteration: 55917 Train loss: 0.007525\n",
      "Epoch: 7989/10000 Iteration: 55924 Train loss: 0.007525\n",
      "Epoch: 7990/10000 Iteration: 55931 Train loss: 0.007525\n",
      "Epoch: 7991/10000 Iteration: 55938 Train loss: 0.007525\n",
      "Epoch: 7992/10000 Iteration: 55945 Train loss: 0.007525\n",
      "Epoch: 7993/10000 Iteration: 55952 Train loss: 0.007525\n",
      "Epoch: 7994/10000 Iteration: 55959 Train loss: 0.007524\n",
      "Epoch: 7995/10000 Iteration: 55966 Train loss: 0.007524\n",
      "Epoch: 7996/10000 Iteration: 55973 Train loss: 0.007524\n",
      "Epoch: 7997/10000 Iteration: 55980 Train loss: 0.007524\n",
      "Epoch: 7998/10000 Iteration: 55987 Train loss: 0.007524\n",
      "Epoch: 7999/10000 Iteration: 55994 Train loss: 0.007524\n",
      "Epoch: 8000/10000 Iteration: 56001 Train loss: 0.007524\n",
      "Epoch: 8001/10000 Iteration: 56008 Train loss: 0.007524\n",
      "Epoch: 8002/10000 Iteration: 56015 Train loss: 0.007524\n",
      "Epoch: 8003/10000 Iteration: 56022 Train loss: 0.007523\n",
      "Epoch: 8004/10000 Iteration: 56029 Train loss: 0.007523\n",
      "Epoch: 8005/10000 Iteration: 56036 Train loss: 0.007523\n",
      "Epoch: 8006/10000 Iteration: 56043 Train loss: 0.007523\n",
      "Epoch: 8007/10000 Iteration: 56050 Train loss: 0.007523\n",
      "Epoch: 8008/10000 Iteration: 56057 Train loss: 0.007523\n",
      "Epoch: 8009/10000 Iteration: 56064 Train loss: 0.007523\n",
      "Epoch: 8010/10000 Iteration: 56071 Train loss: 0.007523\n",
      "Epoch: 8011/10000 Iteration: 56078 Train loss: 0.007523\n",
      "Epoch: 8012/10000 Iteration: 56085 Train loss: 0.007522\n",
      "Epoch: 8013/10000 Iteration: 56092 Train loss: 0.007522\n",
      "Epoch: 8014/10000 Iteration: 56099 Train loss: 0.007522\n",
      "Epoch: 8015/10000 Iteration: 56106 Train loss: 0.007522\n",
      "Epoch: 8016/10000 Iteration: 56113 Train loss: 0.007522\n",
      "Epoch: 8017/10000 Iteration: 56120 Train loss: 0.007522\n",
      "Epoch: 8018/10000 Iteration: 56127 Train loss: 0.007522\n",
      "Epoch: 8019/10000 Iteration: 56134 Train loss: 0.007522\n",
      "Epoch: 8020/10000 Iteration: 56141 Train loss: 0.007521\n",
      "Epoch: 8021/10000 Iteration: 56148 Train loss: 0.007521\n",
      "Epoch: 8022/10000 Iteration: 56155 Train loss: 0.007521\n",
      "Epoch: 8023/10000 Iteration: 56162 Train loss: 0.007521\n",
      "Epoch: 8024/10000 Iteration: 56169 Train loss: 0.007521\n",
      "Epoch: 8025/10000 Iteration: 56176 Train loss: 0.007521\n",
      "Epoch: 8026/10000 Iteration: 56183 Train loss: 0.007521\n",
      "Epoch: 8027/10000 Iteration: 56190 Train loss: 0.007521\n",
      "Epoch: 8028/10000 Iteration: 56197 Train loss: 0.007521\n",
      "Epoch: 8029/10000 Iteration: 56204 Train loss: 0.007520\n",
      "Epoch: 8030/10000 Iteration: 56211 Train loss: 0.007520\n",
      "Epoch: 8031/10000 Iteration: 56218 Train loss: 0.007520\n",
      "Epoch: 8032/10000 Iteration: 56225 Train loss: 0.007520\n",
      "Epoch: 8033/10000 Iteration: 56232 Train loss: 0.007520\n",
      "Epoch: 8034/10000 Iteration: 56239 Train loss: 0.007520\n",
      "Epoch: 8035/10000 Iteration: 56246 Train loss: 0.007520\n",
      "Epoch: 8036/10000 Iteration: 56253 Train loss: 0.007520\n",
      "Epoch: 8037/10000 Iteration: 56260 Train loss: 0.007520\n",
      "Epoch: 8038/10000 Iteration: 56267 Train loss: 0.007519\n",
      "Epoch: 8039/10000 Iteration: 56274 Train loss: 0.007519\n",
      "Epoch: 8040/10000 Iteration: 56281 Train loss: 0.007519\n",
      "Epoch: 8041/10000 Iteration: 56288 Train loss: 0.007519\n",
      "Epoch: 8042/10000 Iteration: 56295 Train loss: 0.007519\n",
      "Epoch: 8043/10000 Iteration: 56302 Train loss: 0.007519\n",
      "Epoch: 8044/10000 Iteration: 56309 Train loss: 0.007519\n",
      "Epoch: 8045/10000 Iteration: 56316 Train loss: 0.007519\n",
      "Epoch: 8046/10000 Iteration: 56323 Train loss: 0.007518\n",
      "Epoch: 8047/10000 Iteration: 56330 Train loss: 0.007518\n",
      "Epoch: 8048/10000 Iteration: 56337 Train loss: 0.007518\n",
      "Epoch: 8049/10000 Iteration: 56344 Train loss: 0.007518\n",
      "Epoch: 8050/10000 Iteration: 56351 Train loss: 0.007518\n",
      "Epoch: 8051/10000 Iteration: 56358 Train loss: 0.007518\n",
      "Epoch: 8052/10000 Iteration: 56365 Train loss: 0.007518\n",
      "Epoch: 8053/10000 Iteration: 56372 Train loss: 0.007518\n",
      "Epoch: 8054/10000 Iteration: 56379 Train loss: 0.007518\n",
      "Epoch: 8055/10000 Iteration: 56386 Train loss: 0.007517\n",
      "Epoch: 8056/10000 Iteration: 56393 Train loss: 0.007517\n",
      "Epoch: 8057/10000 Iteration: 56400 Train loss: 0.007517\n",
      "Epoch: 8058/10000 Iteration: 56407 Train loss: 0.007517\n",
      "Epoch: 8059/10000 Iteration: 56414 Train loss: 0.007517\n",
      "Epoch: 8060/10000 Iteration: 56421 Train loss: 0.007517\n",
      "Epoch: 8061/10000 Iteration: 56428 Train loss: 0.007517\n",
      "Epoch: 8062/10000 Iteration: 56435 Train loss: 0.007517\n",
      "Epoch: 8063/10000 Iteration: 56442 Train loss: 0.007517\n",
      "Epoch: 8064/10000 Iteration: 56449 Train loss: 0.007516\n",
      "Epoch: 8065/10000 Iteration: 56456 Train loss: 0.007516\n",
      "Epoch: 8066/10000 Iteration: 56463 Train loss: 0.007516\n",
      "Epoch: 8067/10000 Iteration: 56470 Train loss: 0.007516\n",
      "Epoch: 8068/10000 Iteration: 56477 Train loss: 0.007516\n",
      "Epoch: 8069/10000 Iteration: 56484 Train loss: 0.007516\n",
      "Epoch: 8070/10000 Iteration: 56491 Train loss: 0.007516\n",
      "Epoch: 8071/10000 Iteration: 56498 Train loss: 0.007516\n",
      "Epoch: 8072/10000 Iteration: 56505 Train loss: 0.007516\n",
      "Epoch: 8073/10000 Iteration: 56512 Train loss: 0.007515\n",
      "Epoch: 8074/10000 Iteration: 56519 Train loss: 0.007515\n",
      "Epoch: 8075/10000 Iteration: 56526 Train loss: 0.007515\n",
      "Epoch: 8076/10000 Iteration: 56533 Train loss: 0.007515\n",
      "Epoch: 8077/10000 Iteration: 56540 Train loss: 0.007515\n",
      "Epoch: 8078/10000 Iteration: 56547 Train loss: 0.007515\n",
      "Epoch: 8079/10000 Iteration: 56554 Train loss: 0.007515\n",
      "Epoch: 8080/10000 Iteration: 56561 Train loss: 0.007515\n",
      "Epoch: 8081/10000 Iteration: 56568 Train loss: 0.007515\n",
      "Epoch: 8082/10000 Iteration: 56575 Train loss: 0.007514\n",
      "Epoch: 8083/10000 Iteration: 56582 Train loss: 0.007514\n",
      "Epoch: 8084/10000 Iteration: 56589 Train loss: 0.007514\n",
      "Epoch: 8085/10000 Iteration: 56596 Train loss: 0.007514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8086/10000 Iteration: 56603 Train loss: 0.007514\n",
      "Epoch: 8087/10000 Iteration: 56610 Train loss: 0.007514\n",
      "Epoch: 8088/10000 Iteration: 56617 Train loss: 0.007514\n",
      "Epoch: 8089/10000 Iteration: 56624 Train loss: 0.007514\n",
      "Epoch: 8090/10000 Iteration: 56631 Train loss: 0.007514\n",
      "Epoch: 8091/10000 Iteration: 56638 Train loss: 0.007513\n",
      "Epoch: 8092/10000 Iteration: 56645 Train loss: 0.007513\n",
      "Epoch: 8093/10000 Iteration: 56652 Train loss: 0.007513\n",
      "Epoch: 8094/10000 Iteration: 56659 Train loss: 0.007513\n",
      "Epoch: 8095/10000 Iteration: 56666 Train loss: 0.007513\n",
      "Epoch: 8096/10000 Iteration: 56673 Train loss: 0.007513\n",
      "Epoch: 8097/10000 Iteration: 56680 Train loss: 0.007513\n",
      "Epoch: 8098/10000 Iteration: 56687 Train loss: 0.007513\n",
      "Epoch: 8099/10000 Iteration: 56694 Train loss: 0.007513\n",
      "Epoch: 8100/10000 Iteration: 56701 Train loss: 0.007512\n",
      "Epoch: 8101/10000 Iteration: 56708 Train loss: 0.007512\n",
      "Epoch: 8102/10000 Iteration: 56715 Train loss: 0.007512\n",
      "Epoch: 8103/10000 Iteration: 56722 Train loss: 0.007512\n",
      "Epoch: 8104/10000 Iteration: 56729 Train loss: 0.007512\n",
      "Epoch: 8105/10000 Iteration: 56736 Train loss: 0.007512\n",
      "Epoch: 8106/10000 Iteration: 56743 Train loss: 0.007512\n",
      "Epoch: 8107/10000 Iteration: 56750 Train loss: 0.007512\n",
      "Epoch: 8108/10000 Iteration: 56757 Train loss: 0.007512\n",
      "Epoch: 8109/10000 Iteration: 56764 Train loss: 0.007511\n",
      "Epoch: 8110/10000 Iteration: 56771 Train loss: 0.007511\n",
      "Epoch: 8111/10000 Iteration: 56778 Train loss: 0.007511\n",
      "Epoch: 8112/10000 Iteration: 56785 Train loss: 0.007511\n",
      "Epoch: 8113/10000 Iteration: 56792 Train loss: 0.007511\n",
      "Epoch: 8114/10000 Iteration: 56799 Train loss: 0.007511\n",
      "Epoch: 8115/10000 Iteration: 56806 Train loss: 0.007511\n",
      "Epoch: 8116/10000 Iteration: 56813 Train loss: 0.007511\n",
      "Epoch: 8117/10000 Iteration: 56820 Train loss: 0.007511\n",
      "Epoch: 8118/10000 Iteration: 56827 Train loss: 0.007510\n",
      "Epoch: 8119/10000 Iteration: 56834 Train loss: 0.007510\n",
      "Epoch: 8120/10000 Iteration: 56841 Train loss: 0.007510\n",
      "Epoch: 8121/10000 Iteration: 56848 Train loss: 0.007510\n",
      "Epoch: 8122/10000 Iteration: 56855 Train loss: 0.007510\n",
      "Epoch: 8123/10000 Iteration: 56862 Train loss: 0.007510\n",
      "Epoch: 8124/10000 Iteration: 56869 Train loss: 0.007510\n",
      "Epoch: 8125/10000 Iteration: 56876 Train loss: 0.007510\n",
      "Epoch: 8126/10000 Iteration: 56883 Train loss: 0.007510\n",
      "Epoch: 8127/10000 Iteration: 56890 Train loss: 0.007509\n",
      "Epoch: 8128/10000 Iteration: 56897 Train loss: 0.007509\n",
      "Epoch: 8129/10000 Iteration: 56904 Train loss: 0.007509\n",
      "Epoch: 8130/10000 Iteration: 56911 Train loss: 0.007509\n",
      "Epoch: 8131/10000 Iteration: 56918 Train loss: 0.007509\n",
      "Epoch: 8132/10000 Iteration: 56925 Train loss: 0.007509\n",
      "Epoch: 8133/10000 Iteration: 56932 Train loss: 0.007509\n",
      "Epoch: 8134/10000 Iteration: 56939 Train loss: 0.007509\n",
      "Epoch: 8135/10000 Iteration: 56946 Train loss: 0.007509\n",
      "Epoch: 8136/10000 Iteration: 56953 Train loss: 0.007508\n",
      "Epoch: 8137/10000 Iteration: 56960 Train loss: 0.007508\n",
      "Epoch: 8138/10000 Iteration: 56967 Train loss: 0.007508\n",
      "Epoch: 8139/10000 Iteration: 56974 Train loss: 0.007508\n",
      "Epoch: 8140/10000 Iteration: 56981 Train loss: 0.007508\n",
      "Epoch: 8141/10000 Iteration: 56988 Train loss: 0.007508\n",
      "Epoch: 8142/10000 Iteration: 56995 Train loss: 0.007508\n",
      "Epoch: 8143/10000 Iteration: 57002 Train loss: 0.007508\n",
      "Epoch: 8144/10000 Iteration: 57009 Train loss: 0.007508\n",
      "Epoch: 8145/10000 Iteration: 57016 Train loss: 0.007507\n",
      "Epoch: 8146/10000 Iteration: 57023 Train loss: 0.007507\n",
      "Epoch: 8147/10000 Iteration: 57030 Train loss: 0.007507\n",
      "Epoch: 8148/10000 Iteration: 57037 Train loss: 0.007507\n",
      "Epoch: 8149/10000 Iteration: 57044 Train loss: 0.007507\n",
      "Epoch: 8150/10000 Iteration: 57051 Train loss: 0.007507\n",
      "Epoch: 8151/10000 Iteration: 57058 Train loss: 0.007507\n",
      "Epoch: 8152/10000 Iteration: 57065 Train loss: 0.007507\n",
      "Epoch: 8153/10000 Iteration: 57072 Train loss: 0.007507\n",
      "Epoch: 8154/10000 Iteration: 57079 Train loss: 0.007506\n",
      "Epoch: 8155/10000 Iteration: 57086 Train loss: 0.007506\n",
      "Epoch: 8156/10000 Iteration: 57093 Train loss: 0.007506\n",
      "Epoch: 8157/10000 Iteration: 57100 Train loss: 0.007506\n",
      "Epoch: 8158/10000 Iteration: 57107 Train loss: 0.007506\n",
      "Epoch: 8159/10000 Iteration: 57114 Train loss: 0.007506\n",
      "Epoch: 8160/10000 Iteration: 57121 Train loss: 0.007506\n",
      "Epoch: 8161/10000 Iteration: 57128 Train loss: 0.007506\n",
      "Epoch: 8162/10000 Iteration: 57135 Train loss: 0.007506\n",
      "Epoch: 8163/10000 Iteration: 57142 Train loss: 0.007505\n",
      "Epoch: 8164/10000 Iteration: 57149 Train loss: 0.007505\n",
      "Epoch: 8165/10000 Iteration: 57156 Train loss: 0.007505\n",
      "Epoch: 8166/10000 Iteration: 57163 Train loss: 0.007505\n",
      "Epoch: 8167/10000 Iteration: 57170 Train loss: 0.007505\n",
      "Epoch: 8168/10000 Iteration: 57177 Train loss: 0.007505\n",
      "Epoch: 8169/10000 Iteration: 57184 Train loss: 0.007505\n",
      "Epoch: 8170/10000 Iteration: 57191 Train loss: 0.007505\n",
      "Epoch: 8171/10000 Iteration: 57198 Train loss: 0.007505\n",
      "Epoch: 8172/10000 Iteration: 57205 Train loss: 0.007505\n",
      "Epoch: 8173/10000 Iteration: 57212 Train loss: 0.007504\n",
      "Epoch: 8174/10000 Iteration: 57219 Train loss: 0.007504\n",
      "Epoch: 8175/10000 Iteration: 57226 Train loss: 0.007504\n",
      "Epoch: 8176/10000 Iteration: 57233 Train loss: 0.007504\n",
      "Epoch: 8177/10000 Iteration: 57240 Train loss: 0.007504\n",
      "Epoch: 8178/10000 Iteration: 57247 Train loss: 0.007504\n",
      "Epoch: 8179/10000 Iteration: 57254 Train loss: 0.007504\n",
      "Epoch: 8180/10000 Iteration: 57261 Train loss: 0.007504\n",
      "Epoch: 8181/10000 Iteration: 57268 Train loss: 0.007504\n",
      "Epoch: 8182/10000 Iteration: 57275 Train loss: 0.007503\n",
      "Epoch: 8183/10000 Iteration: 57282 Train loss: 0.007503\n",
      "Epoch: 8184/10000 Iteration: 57289 Train loss: 0.007503\n",
      "Epoch: 8185/10000 Iteration: 57296 Train loss: 0.007503\n",
      "Epoch: 8186/10000 Iteration: 57303 Train loss: 0.007503\n",
      "Epoch: 8187/10000 Iteration: 57310 Train loss: 0.007503\n",
      "Epoch: 8188/10000 Iteration: 57317 Train loss: 0.007503\n",
      "Epoch: 8189/10000 Iteration: 57324 Train loss: 0.007503\n",
      "Epoch: 8190/10000 Iteration: 57331 Train loss: 0.007503\n",
      "Epoch: 8191/10000 Iteration: 57338 Train loss: 0.007502\n",
      "Epoch: 8192/10000 Iteration: 57345 Train loss: 0.007502\n",
      "Epoch: 8193/10000 Iteration: 57352 Train loss: 0.007502\n",
      "Epoch: 8194/10000 Iteration: 57359 Train loss: 0.007502\n",
      "Epoch: 8195/10000 Iteration: 57366 Train loss: 0.007502\n",
      "Epoch: 8196/10000 Iteration: 57373 Train loss: 0.007502\n",
      "Epoch: 8197/10000 Iteration: 57380 Train loss: 0.007502\n",
      "Epoch: 8198/10000 Iteration: 57387 Train loss: 0.007502\n",
      "Epoch: 8199/10000 Iteration: 57394 Train loss: 0.007502\n",
      "Epoch: 8200/10000 Iteration: 57401 Train loss: 0.007502\n",
      "Epoch: 8201/10000 Iteration: 57408 Train loss: 0.007501\n",
      "Epoch: 8202/10000 Iteration: 57415 Train loss: 0.007501\n",
      "Epoch: 8203/10000 Iteration: 57422 Train loss: 0.007501\n",
      "Epoch: 8204/10000 Iteration: 57429 Train loss: 0.007501\n",
      "Epoch: 8205/10000 Iteration: 57436 Train loss: 0.007501\n",
      "Epoch: 8206/10000 Iteration: 57443 Train loss: 0.007501\n",
      "Epoch: 8207/10000 Iteration: 57450 Train loss: 0.007501\n",
      "Epoch: 8208/10000 Iteration: 57457 Train loss: 0.007501\n",
      "Epoch: 8209/10000 Iteration: 57464 Train loss: 0.007501\n",
      "Epoch: 8210/10000 Iteration: 57471 Train loss: 0.007500\n",
      "Epoch: 8211/10000 Iteration: 57478 Train loss: 0.007500\n",
      "Epoch: 8212/10000 Iteration: 57485 Train loss: 0.007500\n",
      "Epoch: 8213/10000 Iteration: 57492 Train loss: 0.007500\n",
      "Epoch: 8214/10000 Iteration: 57499 Train loss: 0.007500\n",
      "Epoch: 8215/10000 Iteration: 57506 Train loss: 0.007500\n",
      "Epoch: 8216/10000 Iteration: 57513 Train loss: 0.007500\n",
      "Epoch: 8217/10000 Iteration: 57520 Train loss: 0.007500\n",
      "Epoch: 8218/10000 Iteration: 57527 Train loss: 0.007500\n",
      "Epoch: 8219/10000 Iteration: 57534 Train loss: 0.007500\n",
      "Epoch: 8220/10000 Iteration: 57541 Train loss: 0.007499\n",
      "Epoch: 8221/10000 Iteration: 57548 Train loss: 0.007499\n",
      "Epoch: 8222/10000 Iteration: 57555 Train loss: 0.007499\n",
      "Epoch: 8223/10000 Iteration: 57562 Train loss: 0.007499\n",
      "Epoch: 8224/10000 Iteration: 57569 Train loss: 0.007499\n",
      "Epoch: 8225/10000 Iteration: 57576 Train loss: 0.007499\n",
      "Epoch: 8226/10000 Iteration: 57583 Train loss: 0.007499\n",
      "Epoch: 8227/10000 Iteration: 57590 Train loss: 0.007499\n",
      "Epoch: 8228/10000 Iteration: 57597 Train loss: 0.007499\n",
      "Epoch: 8229/10000 Iteration: 57604 Train loss: 0.007498\n",
      "Epoch: 8230/10000 Iteration: 57611 Train loss: 0.007498\n",
      "Epoch: 8231/10000 Iteration: 57618 Train loss: 0.007498\n",
      "Epoch: 8232/10000 Iteration: 57625 Train loss: 0.007498\n",
      "Epoch: 8233/10000 Iteration: 57632 Train loss: 0.007498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8234/10000 Iteration: 57639 Train loss: 0.007498\n",
      "Epoch: 8235/10000 Iteration: 57646 Train loss: 0.007498\n",
      "Epoch: 8236/10000 Iteration: 57653 Train loss: 0.007498\n",
      "Epoch: 8237/10000 Iteration: 57660 Train loss: 0.007498\n",
      "Epoch: 8238/10000 Iteration: 57667 Train loss: 0.007498\n",
      "Epoch: 8239/10000 Iteration: 57674 Train loss: 0.007497\n",
      "Epoch: 8240/10000 Iteration: 57681 Train loss: 0.007497\n",
      "Epoch: 8241/10000 Iteration: 57688 Train loss: 0.007497\n",
      "Epoch: 8242/10000 Iteration: 57695 Train loss: 0.007497\n",
      "Epoch: 8243/10000 Iteration: 57702 Train loss: 0.007497\n",
      "Epoch: 8244/10000 Iteration: 57709 Train loss: 0.007497\n",
      "Epoch: 8245/10000 Iteration: 57716 Train loss: 0.007497\n",
      "Epoch: 8246/10000 Iteration: 57723 Train loss: 0.007497\n",
      "Epoch: 8247/10000 Iteration: 57730 Train loss: 0.007497\n",
      "Epoch: 8248/10000 Iteration: 57737 Train loss: 0.007497\n",
      "Epoch: 8249/10000 Iteration: 57744 Train loss: 0.007496\n",
      "Epoch: 8250/10000 Iteration: 57751 Train loss: 0.007496\n",
      "Epoch: 8251/10000 Iteration: 57758 Train loss: 0.007496\n",
      "Epoch: 8252/10000 Iteration: 57765 Train loss: 0.007496\n",
      "Epoch: 8253/10000 Iteration: 57772 Train loss: 0.007496\n",
      "Epoch: 8254/10000 Iteration: 57779 Train loss: 0.007496\n",
      "Epoch: 8255/10000 Iteration: 57786 Train loss: 0.007496\n",
      "Epoch: 8256/10000 Iteration: 57793 Train loss: 0.007496\n",
      "Epoch: 8257/10000 Iteration: 57800 Train loss: 0.007496\n",
      "Epoch: 8258/10000 Iteration: 57807 Train loss: 0.007495\n",
      "Epoch: 8259/10000 Iteration: 57814 Train loss: 0.007495\n",
      "Epoch: 8260/10000 Iteration: 57821 Train loss: 0.007495\n",
      "Epoch: 8261/10000 Iteration: 57828 Train loss: 0.007495\n",
      "Epoch: 8262/10000 Iteration: 57835 Train loss: 0.007495\n",
      "Epoch: 8263/10000 Iteration: 57842 Train loss: 0.007495\n",
      "Epoch: 8264/10000 Iteration: 57849 Train loss: 0.007495\n",
      "Epoch: 8265/10000 Iteration: 57856 Train loss: 0.007495\n",
      "Epoch: 8266/10000 Iteration: 57863 Train loss: 0.007495\n",
      "Epoch: 8267/10000 Iteration: 57870 Train loss: 0.007495\n",
      "Epoch: 8268/10000 Iteration: 57877 Train loss: 0.007494\n",
      "Epoch: 8269/10000 Iteration: 57884 Train loss: 0.007494\n",
      "Epoch: 8270/10000 Iteration: 57891 Train loss: 0.007494\n",
      "Epoch: 8271/10000 Iteration: 57898 Train loss: 0.007494\n",
      "Epoch: 8272/10000 Iteration: 57905 Train loss: 0.007494\n",
      "Epoch: 8273/10000 Iteration: 57912 Train loss: 0.007494\n",
      "Epoch: 8274/10000 Iteration: 57919 Train loss: 0.007494\n",
      "Epoch: 8275/10000 Iteration: 57926 Train loss: 0.007494\n",
      "Epoch: 8276/10000 Iteration: 57933 Train loss: 0.007494\n",
      "Epoch: 8277/10000 Iteration: 57940 Train loss: 0.007494\n",
      "Epoch: 8278/10000 Iteration: 57947 Train loss: 0.007493\n",
      "Epoch: 8279/10000 Iteration: 57954 Train loss: 0.007493\n",
      "Epoch: 8280/10000 Iteration: 57961 Train loss: 0.007493\n",
      "Epoch: 8281/10000 Iteration: 57968 Train loss: 0.007493\n",
      "Epoch: 8282/10000 Iteration: 57975 Train loss: 0.007493\n",
      "Epoch: 8283/10000 Iteration: 57982 Train loss: 0.007493\n",
      "Epoch: 8284/10000 Iteration: 57989 Train loss: 0.007493\n",
      "Epoch: 8285/10000 Iteration: 57996 Train loss: 0.007493\n",
      "Epoch: 8286/10000 Iteration: 58003 Train loss: 0.007493\n",
      "Epoch: 8287/10000 Iteration: 58010 Train loss: 0.007493\n",
      "Epoch: 8288/10000 Iteration: 58017 Train loss: 0.007492\n",
      "Epoch: 8289/10000 Iteration: 58024 Train loss: 0.007492\n",
      "Epoch: 8290/10000 Iteration: 58031 Train loss: 0.007492\n",
      "Epoch: 8291/10000 Iteration: 58038 Train loss: 0.007492\n",
      "Epoch: 8292/10000 Iteration: 58045 Train loss: 0.007492\n",
      "Epoch: 8293/10000 Iteration: 58052 Train loss: 0.007492\n",
      "Epoch: 8294/10000 Iteration: 58059 Train loss: 0.007492\n",
      "Epoch: 8295/10000 Iteration: 58066 Train loss: 0.007492\n",
      "Epoch: 8296/10000 Iteration: 58073 Train loss: 0.007492\n",
      "Epoch: 8297/10000 Iteration: 58080 Train loss: 0.007492\n",
      "Epoch: 8298/10000 Iteration: 58087 Train loss: 0.007491\n",
      "Epoch: 8299/10000 Iteration: 58094 Train loss: 0.007491\n",
      "Epoch: 8300/10000 Iteration: 58101 Train loss: 0.007491\n",
      "Epoch: 8301/10000 Iteration: 58108 Train loss: 0.007491\n",
      "Epoch: 8302/10000 Iteration: 58115 Train loss: 0.007491\n",
      "Epoch: 8303/10000 Iteration: 58122 Train loss: 0.007491\n",
      "Epoch: 8304/10000 Iteration: 58129 Train loss: 0.007491\n",
      "Epoch: 8305/10000 Iteration: 58136 Train loss: 0.007491\n",
      "Epoch: 8306/10000 Iteration: 58143 Train loss: 0.007491\n",
      "Epoch: 8307/10000 Iteration: 58150 Train loss: 0.007491\n",
      "Epoch: 8308/10000 Iteration: 58157 Train loss: 0.007490\n",
      "Epoch: 8309/10000 Iteration: 58164 Train loss: 0.007490\n",
      "Epoch: 8310/10000 Iteration: 58171 Train loss: 0.007490\n",
      "Epoch: 8311/10000 Iteration: 58178 Train loss: 0.007490\n",
      "Epoch: 8312/10000 Iteration: 58185 Train loss: 0.007490\n",
      "Epoch: 8313/10000 Iteration: 58192 Train loss: 0.007490\n",
      "Epoch: 8314/10000 Iteration: 58199 Train loss: 0.007490\n",
      "Epoch: 8315/10000 Iteration: 58206 Train loss: 0.007490\n",
      "Epoch: 8316/10000 Iteration: 58213 Train loss: 0.007490\n",
      "Epoch: 8317/10000 Iteration: 58220 Train loss: 0.007490\n",
      "Epoch: 8318/10000 Iteration: 58227 Train loss: 0.007489\n",
      "Epoch: 8319/10000 Iteration: 58234 Train loss: 0.007489\n",
      "Epoch: 8320/10000 Iteration: 58241 Train loss: 0.007489\n",
      "Epoch: 8321/10000 Iteration: 58248 Train loss: 0.007489\n",
      "Epoch: 8322/10000 Iteration: 58255 Train loss: 0.007489\n",
      "Epoch: 8323/10000 Iteration: 58262 Train loss: 0.007489\n",
      "Epoch: 8324/10000 Iteration: 58269 Train loss: 0.007489\n",
      "Epoch: 8325/10000 Iteration: 58276 Train loss: 0.007489\n",
      "Epoch: 8326/10000 Iteration: 58283 Train loss: 0.007489\n",
      "Epoch: 8327/10000 Iteration: 58290 Train loss: 0.007489\n",
      "Epoch: 8328/10000 Iteration: 58297 Train loss: 0.007488\n",
      "Epoch: 8329/10000 Iteration: 58304 Train loss: 0.007488\n",
      "Epoch: 8330/10000 Iteration: 58311 Train loss: 0.007488\n",
      "Epoch: 8331/10000 Iteration: 58318 Train loss: 0.007488\n",
      "Epoch: 8332/10000 Iteration: 58325 Train loss: 0.007488\n",
      "Epoch: 8333/10000 Iteration: 58332 Train loss: 0.007488\n",
      "Epoch: 8334/10000 Iteration: 58339 Train loss: 0.007488\n",
      "Epoch: 8335/10000 Iteration: 58346 Train loss: 0.007488\n",
      "Epoch: 8336/10000 Iteration: 58353 Train loss: 0.007488\n",
      "Epoch: 8337/10000 Iteration: 58360 Train loss: 0.007488\n",
      "Epoch: 8338/10000 Iteration: 58367 Train loss: 0.007487\n",
      "Epoch: 8339/10000 Iteration: 58374 Train loss: 0.007487\n",
      "Epoch: 8340/10000 Iteration: 58381 Train loss: 0.007487\n",
      "Epoch: 8341/10000 Iteration: 58388 Train loss: 0.007487\n",
      "Epoch: 8342/10000 Iteration: 58395 Train loss: 0.007487\n",
      "Epoch: 8343/10000 Iteration: 58402 Train loss: 0.007487\n",
      "Epoch: 8344/10000 Iteration: 58409 Train loss: 0.007487\n",
      "Epoch: 8345/10000 Iteration: 58416 Train loss: 0.007487\n",
      "Epoch: 8346/10000 Iteration: 58423 Train loss: 0.007487\n",
      "Epoch: 8347/10000 Iteration: 58430 Train loss: 0.007487\n",
      "Epoch: 8348/10000 Iteration: 58437 Train loss: 0.007486\n",
      "Epoch: 8349/10000 Iteration: 58444 Train loss: 0.007486\n",
      "Epoch: 8350/10000 Iteration: 58451 Train loss: 0.007486\n",
      "Epoch: 8351/10000 Iteration: 58458 Train loss: 0.007486\n",
      "Epoch: 8352/10000 Iteration: 58465 Train loss: 0.007486\n",
      "Epoch: 8353/10000 Iteration: 58472 Train loss: 0.007486\n",
      "Epoch: 8354/10000 Iteration: 58479 Train loss: 0.007486\n",
      "Epoch: 8355/10000 Iteration: 58486 Train loss: 0.007486\n",
      "Epoch: 8356/10000 Iteration: 58493 Train loss: 0.007486\n",
      "Epoch: 8357/10000 Iteration: 58500 Train loss: 0.007486\n",
      "Epoch: 8358/10000 Iteration: 58507 Train loss: 0.007486\n",
      "Epoch: 8359/10000 Iteration: 58514 Train loss: 0.007485\n",
      "Epoch: 8360/10000 Iteration: 58521 Train loss: 0.007485\n",
      "Epoch: 8361/10000 Iteration: 58528 Train loss: 0.007485\n",
      "Epoch: 8362/10000 Iteration: 58535 Train loss: 0.007485\n",
      "Epoch: 8363/10000 Iteration: 58542 Train loss: 0.007485\n",
      "Epoch: 8364/10000 Iteration: 58549 Train loss: 0.007485\n",
      "Epoch: 8365/10000 Iteration: 58556 Train loss: 0.007485\n",
      "Epoch: 8366/10000 Iteration: 58563 Train loss: 0.007485\n",
      "Epoch: 8367/10000 Iteration: 58570 Train loss: 0.007485\n",
      "Epoch: 8368/10000 Iteration: 58577 Train loss: 0.007485\n",
      "Epoch: 8369/10000 Iteration: 58584 Train loss: 0.007484\n",
      "Epoch: 8370/10000 Iteration: 58591 Train loss: 0.007484\n",
      "Epoch: 8371/10000 Iteration: 58598 Train loss: 0.007484\n",
      "Epoch: 8372/10000 Iteration: 58605 Train loss: 0.007484\n",
      "Epoch: 8373/10000 Iteration: 58612 Train loss: 0.007484\n",
      "Epoch: 8374/10000 Iteration: 58619 Train loss: 0.007484\n",
      "Epoch: 8375/10000 Iteration: 58626 Train loss: 0.007484\n",
      "Epoch: 8376/10000 Iteration: 58633 Train loss: 0.007484\n",
      "Epoch: 8377/10000 Iteration: 58640 Train loss: 0.007484\n",
      "Epoch: 8378/10000 Iteration: 58647 Train loss: 0.007484\n",
      "Epoch: 8379/10000 Iteration: 58654 Train loss: 0.007484\n",
      "Epoch: 8380/10000 Iteration: 58661 Train loss: 0.007483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8381/10000 Iteration: 58668 Train loss: 0.007483\n",
      "Epoch: 8382/10000 Iteration: 58675 Train loss: 0.007483\n",
      "Epoch: 8383/10000 Iteration: 58682 Train loss: 0.007483\n",
      "Epoch: 8384/10000 Iteration: 58689 Train loss: 0.007483\n",
      "Epoch: 8385/10000 Iteration: 58696 Train loss: 0.007483\n",
      "Epoch: 8386/10000 Iteration: 58703 Train loss: 0.007483\n",
      "Epoch: 8387/10000 Iteration: 58710 Train loss: 0.007483\n",
      "Epoch: 8388/10000 Iteration: 58717 Train loss: 0.007483\n",
      "Epoch: 8389/10000 Iteration: 58724 Train loss: 0.007483\n",
      "Epoch: 8390/10000 Iteration: 58731 Train loss: 0.007482\n",
      "Epoch: 8391/10000 Iteration: 58738 Train loss: 0.007482\n",
      "Epoch: 8392/10000 Iteration: 58745 Train loss: 0.007482\n",
      "Epoch: 8393/10000 Iteration: 58752 Train loss: 0.007482\n",
      "Epoch: 8394/10000 Iteration: 58759 Train loss: 0.007482\n",
      "Epoch: 8395/10000 Iteration: 58766 Train loss: 0.007482\n",
      "Epoch: 8396/10000 Iteration: 58773 Train loss: 0.007482\n",
      "Epoch: 8397/10000 Iteration: 58780 Train loss: 0.007482\n",
      "Epoch: 8398/10000 Iteration: 58787 Train loss: 0.007482\n",
      "Epoch: 8399/10000 Iteration: 58794 Train loss: 0.007482\n",
      "Epoch: 8400/10000 Iteration: 58801 Train loss: 0.007482\n",
      "Epoch: 8401/10000 Iteration: 58808 Train loss: 0.007481\n",
      "Epoch: 8402/10000 Iteration: 58815 Train loss: 0.007481\n",
      "Epoch: 8403/10000 Iteration: 58822 Train loss: 0.007481\n",
      "Epoch: 8404/10000 Iteration: 58829 Train loss: 0.007481\n",
      "Epoch: 8405/10000 Iteration: 58836 Train loss: 0.007481\n",
      "Epoch: 8406/10000 Iteration: 58843 Train loss: 0.007481\n",
      "Epoch: 8407/10000 Iteration: 58850 Train loss: 0.007481\n",
      "Epoch: 8408/10000 Iteration: 58857 Train loss: 0.007481\n",
      "Epoch: 8409/10000 Iteration: 58864 Train loss: 0.007481\n",
      "Epoch: 8410/10000 Iteration: 58871 Train loss: 0.007481\n",
      "Epoch: 8411/10000 Iteration: 58878 Train loss: 0.007481\n",
      "Epoch: 8412/10000 Iteration: 58885 Train loss: 0.007480\n",
      "Epoch: 8413/10000 Iteration: 58892 Train loss: 0.007480\n",
      "Epoch: 8414/10000 Iteration: 58899 Train loss: 0.007480\n",
      "Epoch: 8415/10000 Iteration: 58906 Train loss: 0.007480\n",
      "Epoch: 8416/10000 Iteration: 58913 Train loss: 0.007480\n",
      "Epoch: 8417/10000 Iteration: 58920 Train loss: 0.007480\n",
      "Epoch: 8418/10000 Iteration: 58927 Train loss: 0.007480\n",
      "Epoch: 8419/10000 Iteration: 58934 Train loss: 0.007480\n",
      "Epoch: 8420/10000 Iteration: 58941 Train loss: 0.007480\n",
      "Epoch: 8421/10000 Iteration: 58948 Train loss: 0.007480\n",
      "Epoch: 8422/10000 Iteration: 58955 Train loss: 0.007480\n",
      "Epoch: 8423/10000 Iteration: 58962 Train loss: 0.007479\n",
      "Epoch: 8424/10000 Iteration: 58969 Train loss: 0.007479\n",
      "Epoch: 8425/10000 Iteration: 58976 Train loss: 0.007479\n",
      "Epoch: 8426/10000 Iteration: 58983 Train loss: 0.007479\n",
      "Epoch: 8427/10000 Iteration: 58990 Train loss: 0.007479\n",
      "Epoch: 8428/10000 Iteration: 58997 Train loss: 0.007479\n",
      "Epoch: 8429/10000 Iteration: 59004 Train loss: 0.007479\n",
      "Epoch: 8430/10000 Iteration: 59011 Train loss: 0.007479\n",
      "Epoch: 8431/10000 Iteration: 59018 Train loss: 0.007479\n",
      "Epoch: 8432/10000 Iteration: 59025 Train loss: 0.007479\n",
      "Epoch: 8433/10000 Iteration: 59032 Train loss: 0.007479\n",
      "Epoch: 8434/10000 Iteration: 59039 Train loss: 0.007478\n",
      "Epoch: 8435/10000 Iteration: 59046 Train loss: 0.007478\n",
      "Epoch: 8436/10000 Iteration: 59053 Train loss: 0.007478\n",
      "Epoch: 8437/10000 Iteration: 59060 Train loss: 0.007478\n",
      "Epoch: 8438/10000 Iteration: 59067 Train loss: 0.007478\n",
      "Epoch: 8439/10000 Iteration: 59074 Train loss: 0.007478\n",
      "Epoch: 8440/10000 Iteration: 59081 Train loss: 0.007478\n",
      "Epoch: 8441/10000 Iteration: 59088 Train loss: 0.007478\n",
      "Epoch: 8442/10000 Iteration: 59095 Train loss: 0.007478\n",
      "Epoch: 8443/10000 Iteration: 59102 Train loss: 0.007478\n",
      "Epoch: 8444/10000 Iteration: 59109 Train loss: 0.007478\n",
      "Epoch: 8445/10000 Iteration: 59116 Train loss: 0.007477\n",
      "Epoch: 8446/10000 Iteration: 59123 Train loss: 0.007477\n",
      "Epoch: 8447/10000 Iteration: 59130 Train loss: 0.007477\n",
      "Epoch: 8448/10000 Iteration: 59137 Train loss: 0.007477\n",
      "Epoch: 8449/10000 Iteration: 59144 Train loss: 0.007477\n",
      "Epoch: 8450/10000 Iteration: 59151 Train loss: 0.007477\n",
      "Epoch: 8451/10000 Iteration: 59158 Train loss: 0.007477\n",
      "Epoch: 8452/10000 Iteration: 59165 Train loss: 0.007477\n",
      "Epoch: 8453/10000 Iteration: 59172 Train loss: 0.007477\n",
      "Epoch: 8454/10000 Iteration: 59179 Train loss: 0.007477\n",
      "Epoch: 8455/10000 Iteration: 59186 Train loss: 0.007477\n",
      "Epoch: 8456/10000 Iteration: 59193 Train loss: 0.007476\n",
      "Epoch: 8457/10000 Iteration: 59200 Train loss: 0.007476\n",
      "Epoch: 8458/10000 Iteration: 59207 Train loss: 0.007476\n",
      "Epoch: 8459/10000 Iteration: 59214 Train loss: 0.007476\n",
      "Epoch: 8460/10000 Iteration: 59221 Train loss: 0.007476\n",
      "Epoch: 8461/10000 Iteration: 59228 Train loss: 0.007476\n",
      "Epoch: 8462/10000 Iteration: 59235 Train loss: 0.007476\n",
      "Epoch: 8463/10000 Iteration: 59242 Train loss: 0.007476\n",
      "Epoch: 8464/10000 Iteration: 59249 Train loss: 0.007476\n",
      "Epoch: 8465/10000 Iteration: 59256 Train loss: 0.007476\n",
      "Epoch: 8466/10000 Iteration: 59263 Train loss: 0.007476\n",
      "Epoch: 8467/10000 Iteration: 59270 Train loss: 0.007475\n",
      "Epoch: 8468/10000 Iteration: 59277 Train loss: 0.007475\n",
      "Epoch: 8469/10000 Iteration: 59284 Train loss: 0.007475\n",
      "Epoch: 8470/10000 Iteration: 59291 Train loss: 0.007475\n",
      "Epoch: 8471/10000 Iteration: 59298 Train loss: 0.007475\n",
      "Epoch: 8472/10000 Iteration: 59305 Train loss: 0.007475\n",
      "Epoch: 8473/10000 Iteration: 59312 Train loss: 0.007475\n",
      "Epoch: 8474/10000 Iteration: 59319 Train loss: 0.007475\n",
      "Epoch: 8475/10000 Iteration: 59326 Train loss: 0.007475\n",
      "Epoch: 8476/10000 Iteration: 59333 Train loss: 0.007475\n",
      "Epoch: 8477/10000 Iteration: 59340 Train loss: 0.007475\n",
      "Epoch: 8478/10000 Iteration: 59347 Train loss: 0.007474\n",
      "Epoch: 8479/10000 Iteration: 59354 Train loss: 0.007474\n",
      "Epoch: 8480/10000 Iteration: 59361 Train loss: 0.007474\n",
      "Epoch: 8481/10000 Iteration: 59368 Train loss: 0.007474\n",
      "Epoch: 8482/10000 Iteration: 59375 Train loss: 0.007474\n",
      "Epoch: 8483/10000 Iteration: 59382 Train loss: 0.007474\n",
      "Epoch: 8484/10000 Iteration: 59389 Train loss: 0.007474\n",
      "Epoch: 8485/10000 Iteration: 59396 Train loss: 0.007474\n",
      "Epoch: 8486/10000 Iteration: 59403 Train loss: 0.007474\n",
      "Epoch: 8487/10000 Iteration: 59410 Train loss: 0.007474\n",
      "Epoch: 8488/10000 Iteration: 59417 Train loss: 0.007474\n",
      "Epoch: 8489/10000 Iteration: 59424 Train loss: 0.007473\n",
      "Epoch: 8490/10000 Iteration: 59431 Train loss: 0.007473\n",
      "Epoch: 8491/10000 Iteration: 59438 Train loss: 0.007473\n",
      "Epoch: 8492/10000 Iteration: 59445 Train loss: 0.007473\n",
      "Epoch: 8493/10000 Iteration: 59452 Train loss: 0.007473\n",
      "Epoch: 8494/10000 Iteration: 59459 Train loss: 0.007473\n",
      "Epoch: 8495/10000 Iteration: 59466 Train loss: 0.007473\n",
      "Epoch: 8496/10000 Iteration: 59473 Train loss: 0.007473\n",
      "Epoch: 8497/10000 Iteration: 59480 Train loss: 0.007473\n",
      "Epoch: 8498/10000 Iteration: 59487 Train loss: 0.007473\n",
      "Epoch: 8499/10000 Iteration: 59494 Train loss: 0.007473\n",
      "Epoch: 8500/10000 Iteration: 59501 Train loss: 0.007473\n",
      "Epoch: 8501/10000 Iteration: 59508 Train loss: 0.007472\n",
      "Epoch: 8502/10000 Iteration: 59515 Train loss: 0.007472\n",
      "Epoch: 8503/10000 Iteration: 59522 Train loss: 0.007472\n",
      "Epoch: 8504/10000 Iteration: 59529 Train loss: 0.007472\n",
      "Epoch: 8505/10000 Iteration: 59536 Train loss: 0.007472\n",
      "Epoch: 8506/10000 Iteration: 59543 Train loss: 0.007472\n",
      "Epoch: 8507/10000 Iteration: 59550 Train loss: 0.007472\n",
      "Epoch: 8508/10000 Iteration: 59557 Train loss: 0.007472\n",
      "Epoch: 8509/10000 Iteration: 59564 Train loss: 0.007472\n",
      "Epoch: 8510/10000 Iteration: 59571 Train loss: 0.007472\n",
      "Epoch: 8511/10000 Iteration: 59578 Train loss: 0.007472\n",
      "Epoch: 8512/10000 Iteration: 59585 Train loss: 0.007471\n",
      "Epoch: 8513/10000 Iteration: 59592 Train loss: 0.007471\n",
      "Epoch: 8514/10000 Iteration: 59599 Train loss: 0.007471\n",
      "Epoch: 8515/10000 Iteration: 59606 Train loss: 0.007471\n",
      "Epoch: 8516/10000 Iteration: 59613 Train loss: 0.007471\n",
      "Epoch: 8517/10000 Iteration: 59620 Train loss: 0.007471\n",
      "Epoch: 8518/10000 Iteration: 59627 Train loss: 0.007471\n",
      "Epoch: 8519/10000 Iteration: 59634 Train loss: 0.007471\n",
      "Epoch: 8520/10000 Iteration: 59641 Train loss: 0.007471\n",
      "Epoch: 8521/10000 Iteration: 59648 Train loss: 0.007471\n",
      "Epoch: 8522/10000 Iteration: 59655 Train loss: 0.007471\n",
      "Epoch: 8523/10000 Iteration: 59662 Train loss: 0.007471\n",
      "Epoch: 8524/10000 Iteration: 59669 Train loss: 0.007470\n",
      "Epoch: 8525/10000 Iteration: 59676 Train loss: 0.007470\n",
      "Epoch: 8526/10000 Iteration: 59683 Train loss: 0.007470\n",
      "Epoch: 8527/10000 Iteration: 59690 Train loss: 0.007470\n",
      "Epoch: 8528/10000 Iteration: 59697 Train loss: 0.007470\n",
      "Epoch: 8529/10000 Iteration: 59704 Train loss: 0.007470\n",
      "Epoch: 8530/10000 Iteration: 59711 Train loss: 0.007470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8531/10000 Iteration: 59718 Train loss: 0.007470\n",
      "Epoch: 8532/10000 Iteration: 59725 Train loss: 0.007470\n",
      "Epoch: 8533/10000 Iteration: 59732 Train loss: 0.007470\n",
      "Epoch: 8534/10000 Iteration: 59739 Train loss: 0.007470\n",
      "Epoch: 8535/10000 Iteration: 59746 Train loss: 0.007469\n",
      "Epoch: 8536/10000 Iteration: 59753 Train loss: 0.007469\n",
      "Epoch: 8537/10000 Iteration: 59760 Train loss: 0.007469\n",
      "Epoch: 8538/10000 Iteration: 59767 Train loss: 0.007469\n",
      "Epoch: 8539/10000 Iteration: 59774 Train loss: 0.007469\n",
      "Epoch: 8540/10000 Iteration: 59781 Train loss: 0.007469\n",
      "Epoch: 8541/10000 Iteration: 59788 Train loss: 0.007469\n",
      "Epoch: 8542/10000 Iteration: 59795 Train loss: 0.007469\n",
      "Epoch: 8543/10000 Iteration: 59802 Train loss: 0.007469\n",
      "Epoch: 8544/10000 Iteration: 59809 Train loss: 0.007469\n",
      "Epoch: 8545/10000 Iteration: 59816 Train loss: 0.007469\n",
      "Epoch: 8546/10000 Iteration: 59823 Train loss: 0.007469\n",
      "Epoch: 8547/10000 Iteration: 59830 Train loss: 0.007468\n",
      "Epoch: 8548/10000 Iteration: 59837 Train loss: 0.007468\n",
      "Epoch: 8549/10000 Iteration: 59844 Train loss: 0.007468\n",
      "Epoch: 8550/10000 Iteration: 59851 Train loss: 0.007468\n",
      "Epoch: 8551/10000 Iteration: 59858 Train loss: 0.007468\n",
      "Epoch: 8552/10000 Iteration: 59865 Train loss: 0.007468\n",
      "Epoch: 8553/10000 Iteration: 59872 Train loss: 0.007468\n",
      "Epoch: 8554/10000 Iteration: 59879 Train loss: 0.007468\n",
      "Epoch: 8555/10000 Iteration: 59886 Train loss: 0.007468\n",
      "Epoch: 8556/10000 Iteration: 59893 Train loss: 0.007468\n",
      "Epoch: 8557/10000 Iteration: 59900 Train loss: 0.007468\n",
      "Epoch: 8558/10000 Iteration: 59907 Train loss: 0.007467\n",
      "Epoch: 8559/10000 Iteration: 59914 Train loss: 0.007467\n",
      "Epoch: 8560/10000 Iteration: 59921 Train loss: 0.007467\n",
      "Epoch: 8561/10000 Iteration: 59928 Train loss: 0.007467\n",
      "Epoch: 8562/10000 Iteration: 59935 Train loss: 0.007467\n",
      "Epoch: 8563/10000 Iteration: 59942 Train loss: 0.007467\n",
      "Epoch: 8564/10000 Iteration: 59949 Train loss: 0.007467\n",
      "Epoch: 8565/10000 Iteration: 59956 Train loss: 0.007467\n",
      "Epoch: 8566/10000 Iteration: 59963 Train loss: 0.007467\n",
      "Epoch: 8567/10000 Iteration: 59970 Train loss: 0.007467\n",
      "Epoch: 8568/10000 Iteration: 59977 Train loss: 0.007467\n",
      "Epoch: 8569/10000 Iteration: 59984 Train loss: 0.007467\n",
      "Epoch: 8570/10000 Iteration: 59991 Train loss: 0.007466\n",
      "Epoch: 8571/10000 Iteration: 59998 Train loss: 0.007466\n",
      "Epoch: 8572/10000 Iteration: 60005 Train loss: 0.007466\n",
      "Epoch: 8573/10000 Iteration: 60012 Train loss: 0.007466\n",
      "Epoch: 8574/10000 Iteration: 60019 Train loss: 0.007466\n",
      "Epoch: 8575/10000 Iteration: 60026 Train loss: 0.007466\n",
      "Epoch: 8576/10000 Iteration: 60033 Train loss: 0.007466\n",
      "Epoch: 8577/10000 Iteration: 60040 Train loss: 0.007466\n",
      "Epoch: 8578/10000 Iteration: 60047 Train loss: 0.007466\n",
      "Epoch: 8579/10000 Iteration: 60054 Train loss: 0.007466\n",
      "Epoch: 8580/10000 Iteration: 60061 Train loss: 0.007466\n",
      "Epoch: 8581/10000 Iteration: 60068 Train loss: 0.007466\n",
      "Epoch: 8582/10000 Iteration: 60075 Train loss: 0.007465\n",
      "Epoch: 8583/10000 Iteration: 60082 Train loss: 0.007465\n",
      "Epoch: 8584/10000 Iteration: 60089 Train loss: 0.007465\n",
      "Epoch: 8585/10000 Iteration: 60096 Train loss: 0.007465\n",
      "Epoch: 8586/10000 Iteration: 60103 Train loss: 0.007465\n",
      "Epoch: 8587/10000 Iteration: 60110 Train loss: 0.007465\n",
      "Epoch: 8588/10000 Iteration: 60117 Train loss: 0.007465\n",
      "Epoch: 8589/10000 Iteration: 60124 Train loss: 0.007465\n",
      "Epoch: 8590/10000 Iteration: 60131 Train loss: 0.007465\n",
      "Epoch: 8591/10000 Iteration: 60138 Train loss: 0.007465\n",
      "Epoch: 8592/10000 Iteration: 60145 Train loss: 0.007465\n",
      "Epoch: 8593/10000 Iteration: 60152 Train loss: 0.007465\n",
      "Epoch: 8594/10000 Iteration: 60159 Train loss: 0.007464\n",
      "Epoch: 8595/10000 Iteration: 60166 Train loss: 0.007464\n",
      "Epoch: 8596/10000 Iteration: 60173 Train loss: 0.007464\n",
      "Epoch: 8597/10000 Iteration: 60180 Train loss: 0.007464\n",
      "Epoch: 8598/10000 Iteration: 60187 Train loss: 0.007464\n",
      "Epoch: 8599/10000 Iteration: 60194 Train loss: 0.007464\n",
      "Epoch: 8600/10000 Iteration: 60201 Train loss: 0.007464\n",
      "Epoch: 8601/10000 Iteration: 60208 Train loss: 0.007464\n",
      "Epoch: 8602/10000 Iteration: 60215 Train loss: 0.007464\n",
      "Epoch: 8603/10000 Iteration: 60222 Train loss: 0.007464\n",
      "Epoch: 8604/10000 Iteration: 60229 Train loss: 0.007464\n",
      "Epoch: 8605/10000 Iteration: 60236 Train loss: 0.007464\n",
      "Epoch: 8606/10000 Iteration: 60243 Train loss: 0.007463\n",
      "Epoch: 8607/10000 Iteration: 60250 Train loss: 0.007463\n",
      "Epoch: 8608/10000 Iteration: 60257 Train loss: 0.007463\n",
      "Epoch: 8609/10000 Iteration: 60264 Train loss: 0.007463\n",
      "Epoch: 8610/10000 Iteration: 60271 Train loss: 0.007463\n",
      "Epoch: 8611/10000 Iteration: 60278 Train loss: 0.007463\n",
      "Epoch: 8612/10000 Iteration: 60285 Train loss: 0.007463\n",
      "Epoch: 8613/10000 Iteration: 60292 Train loss: 0.007463\n",
      "Epoch: 8614/10000 Iteration: 60299 Train loss: 0.007463\n",
      "Epoch: 8615/10000 Iteration: 60306 Train loss: 0.007463\n",
      "Epoch: 8616/10000 Iteration: 60313 Train loss: 0.007463\n",
      "Epoch: 8617/10000 Iteration: 60320 Train loss: 0.007463\n",
      "Epoch: 8618/10000 Iteration: 60327 Train loss: 0.007463\n",
      "Epoch: 8619/10000 Iteration: 60334 Train loss: 0.007462\n",
      "Epoch: 8620/10000 Iteration: 60341 Train loss: 0.007462\n",
      "Epoch: 8621/10000 Iteration: 60348 Train loss: 0.007462\n",
      "Epoch: 8622/10000 Iteration: 60355 Train loss: 0.007462\n",
      "Epoch: 8623/10000 Iteration: 60362 Train loss: 0.007462\n",
      "Epoch: 8624/10000 Iteration: 60369 Train loss: 0.007462\n",
      "Epoch: 8625/10000 Iteration: 60376 Train loss: 0.007462\n",
      "Epoch: 8626/10000 Iteration: 60383 Train loss: 0.007462\n",
      "Epoch: 8627/10000 Iteration: 60390 Train loss: 0.007462\n",
      "Epoch: 8628/10000 Iteration: 60397 Train loss: 0.007462\n",
      "Epoch: 8629/10000 Iteration: 60404 Train loss: 0.007462\n",
      "Epoch: 8630/10000 Iteration: 60411 Train loss: 0.007462\n",
      "Epoch: 8631/10000 Iteration: 60418 Train loss: 0.007462\n",
      "Epoch: 8632/10000 Iteration: 60425 Train loss: 0.007461\n",
      "Epoch: 8633/10000 Iteration: 60432 Train loss: 0.007461\n",
      "Epoch: 8634/10000 Iteration: 60439 Train loss: 0.007461\n",
      "Epoch: 8635/10000 Iteration: 60446 Train loss: 0.007461\n",
      "Epoch: 8636/10000 Iteration: 60453 Train loss: 0.007461\n",
      "Epoch: 8637/10000 Iteration: 60460 Train loss: 0.007461\n",
      "Epoch: 8638/10000 Iteration: 60467 Train loss: 0.007461\n",
      "Epoch: 8639/10000 Iteration: 60474 Train loss: 0.007461\n",
      "Epoch: 8640/10000 Iteration: 60481 Train loss: 0.007461\n",
      "Epoch: 8641/10000 Iteration: 60488 Train loss: 0.007461\n",
      "Epoch: 8642/10000 Iteration: 60495 Train loss: 0.007461\n",
      "Epoch: 8643/10000 Iteration: 60502 Train loss: 0.007461\n",
      "Epoch: 8644/10000 Iteration: 60509 Train loss: 0.007460\n",
      "Epoch: 8645/10000 Iteration: 60516 Train loss: 0.007460\n",
      "Epoch: 8646/10000 Iteration: 60523 Train loss: 0.007460\n",
      "Epoch: 8647/10000 Iteration: 60530 Train loss: 0.007460\n",
      "Epoch: 8648/10000 Iteration: 60537 Train loss: 0.007460\n",
      "Epoch: 8649/10000 Iteration: 60544 Train loss: 0.007460\n",
      "Epoch: 8650/10000 Iteration: 60551 Train loss: 0.007460\n",
      "Epoch: 8651/10000 Iteration: 60558 Train loss: 0.007460\n",
      "Epoch: 8652/10000 Iteration: 60565 Train loss: 0.007460\n",
      "Epoch: 8653/10000 Iteration: 60572 Train loss: 0.007460\n",
      "Epoch: 8654/10000 Iteration: 60579 Train loss: 0.007460\n",
      "Epoch: 8655/10000 Iteration: 60586 Train loss: 0.007460\n",
      "Epoch: 8656/10000 Iteration: 60593 Train loss: 0.007460\n",
      "Epoch: 8657/10000 Iteration: 60600 Train loss: 0.007459\n",
      "Epoch: 8658/10000 Iteration: 60607 Train loss: 0.007459\n",
      "Epoch: 8659/10000 Iteration: 60614 Train loss: 0.007459\n",
      "Epoch: 8660/10000 Iteration: 60621 Train loss: 0.007459\n",
      "Epoch: 8661/10000 Iteration: 60628 Train loss: 0.007459\n",
      "Epoch: 8662/10000 Iteration: 60635 Train loss: 0.007459\n",
      "Epoch: 8663/10000 Iteration: 60642 Train loss: 0.007459\n",
      "Epoch: 8664/10000 Iteration: 60649 Train loss: 0.007459\n",
      "Epoch: 8665/10000 Iteration: 60656 Train loss: 0.007459\n",
      "Epoch: 8666/10000 Iteration: 60663 Train loss: 0.007459\n",
      "Epoch: 8667/10000 Iteration: 60670 Train loss: 0.007459\n",
      "Epoch: 8668/10000 Iteration: 60677 Train loss: 0.007459\n",
      "Epoch: 8669/10000 Iteration: 60684 Train loss: 0.007459\n",
      "Epoch: 8670/10000 Iteration: 60691 Train loss: 0.007458\n",
      "Epoch: 8671/10000 Iteration: 60698 Train loss: 0.007458\n",
      "Epoch: 8672/10000 Iteration: 60705 Train loss: 0.007458\n",
      "Epoch: 8673/10000 Iteration: 60712 Train loss: 0.007458\n",
      "Epoch: 8674/10000 Iteration: 60719 Train loss: 0.007458\n",
      "Epoch: 8675/10000 Iteration: 60726 Train loss: 0.007458\n",
      "Epoch: 8676/10000 Iteration: 60733 Train loss: 0.007458\n",
      "Epoch: 8677/10000 Iteration: 60740 Train loss: 0.007458\n",
      "Epoch: 8678/10000 Iteration: 60747 Train loss: 0.007458\n",
      "Epoch: 8679/10000 Iteration: 60754 Train loss: 0.007458\n",
      "Epoch: 8680/10000 Iteration: 60761 Train loss: 0.007458\n",
      "Epoch: 8681/10000 Iteration: 60768 Train loss: 0.007458\n",
      "Epoch: 8682/10000 Iteration: 60775 Train loss: 0.007458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8683/10000 Iteration: 60782 Train loss: 0.007457\n",
      "Epoch: 8684/10000 Iteration: 60789 Train loss: 0.007457\n",
      "Epoch: 8685/10000 Iteration: 60796 Train loss: 0.007457\n",
      "Epoch: 8686/10000 Iteration: 60803 Train loss: 0.007457\n",
      "Epoch: 8687/10000 Iteration: 60810 Train loss: 0.007457\n",
      "Epoch: 8688/10000 Iteration: 60817 Train loss: 0.007457\n",
      "Epoch: 8689/10000 Iteration: 60824 Train loss: 0.007457\n",
      "Epoch: 8690/10000 Iteration: 60831 Train loss: 0.007457\n",
      "Epoch: 8691/10000 Iteration: 60838 Train loss: 0.007457\n",
      "Epoch: 8692/10000 Iteration: 60845 Train loss: 0.007457\n",
      "Epoch: 8693/10000 Iteration: 60852 Train loss: 0.007457\n",
      "Epoch: 8694/10000 Iteration: 60859 Train loss: 0.007457\n",
      "Epoch: 8695/10000 Iteration: 60866 Train loss: 0.007457\n",
      "Epoch: 8696/10000 Iteration: 60873 Train loss: 0.007457\n",
      "Epoch: 8697/10000 Iteration: 60880 Train loss: 0.007456\n",
      "Epoch: 8698/10000 Iteration: 60887 Train loss: 0.007456\n",
      "Epoch: 8699/10000 Iteration: 60894 Train loss: 0.007456\n",
      "Epoch: 8700/10000 Iteration: 60901 Train loss: 0.007456\n",
      "Epoch: 8701/10000 Iteration: 60908 Train loss: 0.007456\n",
      "Epoch: 8702/10000 Iteration: 60915 Train loss: 0.007456\n",
      "Epoch: 8703/10000 Iteration: 60922 Train loss: 0.007456\n",
      "Epoch: 8704/10000 Iteration: 60929 Train loss: 0.007456\n",
      "Epoch: 8705/10000 Iteration: 60936 Train loss: 0.007456\n",
      "Epoch: 8706/10000 Iteration: 60943 Train loss: 0.007456\n",
      "Epoch: 8707/10000 Iteration: 60950 Train loss: 0.007456\n",
      "Epoch: 8708/10000 Iteration: 60957 Train loss: 0.007456\n",
      "Epoch: 8709/10000 Iteration: 60964 Train loss: 0.007456\n",
      "Epoch: 8710/10000 Iteration: 60971 Train loss: 0.007455\n",
      "Epoch: 8711/10000 Iteration: 60978 Train loss: 0.007455\n",
      "Epoch: 8712/10000 Iteration: 60985 Train loss: 0.007455\n",
      "Epoch: 8713/10000 Iteration: 60992 Train loss: 0.007455\n",
      "Epoch: 8714/10000 Iteration: 60999 Train loss: 0.007455\n",
      "Epoch: 8715/10000 Iteration: 61006 Train loss: 0.007455\n",
      "Epoch: 8716/10000 Iteration: 61013 Train loss: 0.007455\n",
      "Epoch: 8717/10000 Iteration: 61020 Train loss: 0.007455\n",
      "Epoch: 8718/10000 Iteration: 61027 Train loss: 0.007455\n",
      "Epoch: 8719/10000 Iteration: 61034 Train loss: 0.007455\n",
      "Epoch: 8720/10000 Iteration: 61041 Train loss: 0.007455\n",
      "Epoch: 8721/10000 Iteration: 61048 Train loss: 0.007455\n",
      "Epoch: 8722/10000 Iteration: 61055 Train loss: 0.007455\n",
      "Epoch: 8723/10000 Iteration: 61062 Train loss: 0.007455\n",
      "Epoch: 8724/10000 Iteration: 61069 Train loss: 0.007454\n",
      "Epoch: 8725/10000 Iteration: 61076 Train loss: 0.007454\n",
      "Epoch: 8726/10000 Iteration: 61083 Train loss: 0.007454\n",
      "Epoch: 8727/10000 Iteration: 61090 Train loss: 0.007454\n",
      "Epoch: 8728/10000 Iteration: 61097 Train loss: 0.007454\n",
      "Epoch: 8729/10000 Iteration: 61104 Train loss: 0.007454\n",
      "Epoch: 8730/10000 Iteration: 61111 Train loss: 0.007454\n",
      "Epoch: 8731/10000 Iteration: 61118 Train loss: 0.007454\n",
      "Epoch: 8732/10000 Iteration: 61125 Train loss: 0.007454\n",
      "Epoch: 8733/10000 Iteration: 61132 Train loss: 0.007454\n",
      "Epoch: 8734/10000 Iteration: 61139 Train loss: 0.007454\n",
      "Epoch: 8735/10000 Iteration: 61146 Train loss: 0.007454\n",
      "Epoch: 8736/10000 Iteration: 61153 Train loss: 0.007454\n",
      "Epoch: 8737/10000 Iteration: 61160 Train loss: 0.007454\n",
      "Epoch: 8738/10000 Iteration: 61167 Train loss: 0.007453\n",
      "Epoch: 8739/10000 Iteration: 61174 Train loss: 0.007453\n",
      "Epoch: 8740/10000 Iteration: 61181 Train loss: 0.007453\n",
      "Epoch: 8741/10000 Iteration: 61188 Train loss: 0.007453\n",
      "Epoch: 8742/10000 Iteration: 61195 Train loss: 0.007453\n",
      "Epoch: 8743/10000 Iteration: 61202 Train loss: 0.007453\n",
      "Epoch: 8744/10000 Iteration: 61209 Train loss: 0.007453\n",
      "Epoch: 8745/10000 Iteration: 61216 Train loss: 0.007453\n",
      "Epoch: 8746/10000 Iteration: 61223 Train loss: 0.007453\n",
      "Epoch: 8747/10000 Iteration: 61230 Train loss: 0.007453\n",
      "Epoch: 8748/10000 Iteration: 61237 Train loss: 0.007453\n",
      "Epoch: 8749/10000 Iteration: 61244 Train loss: 0.007453\n",
      "Epoch: 8750/10000 Iteration: 61251 Train loss: 0.007453\n",
      "Epoch: 8751/10000 Iteration: 61258 Train loss: 0.007453\n",
      "Epoch: 8752/10000 Iteration: 61265 Train loss: 0.007452\n",
      "Epoch: 8753/10000 Iteration: 61272 Train loss: 0.007452\n",
      "Epoch: 8754/10000 Iteration: 61279 Train loss: 0.007452\n",
      "Epoch: 8755/10000 Iteration: 61286 Train loss: 0.007452\n",
      "Epoch: 8756/10000 Iteration: 61293 Train loss: 0.007452\n",
      "Epoch: 8757/10000 Iteration: 61300 Train loss: 0.007452\n",
      "Epoch: 8758/10000 Iteration: 61307 Train loss: 0.007452\n",
      "Epoch: 8759/10000 Iteration: 61314 Train loss: 0.007452\n",
      "Epoch: 8760/10000 Iteration: 61321 Train loss: 0.007452\n",
      "Epoch: 8761/10000 Iteration: 61328 Train loss: 0.007452\n",
      "Epoch: 8762/10000 Iteration: 61335 Train loss: 0.007452\n",
      "Epoch: 8763/10000 Iteration: 61342 Train loss: 0.007452\n",
      "Epoch: 8764/10000 Iteration: 61349 Train loss: 0.007452\n",
      "Epoch: 8765/10000 Iteration: 61356 Train loss: 0.007452\n",
      "Epoch: 8766/10000 Iteration: 61363 Train loss: 0.007451\n",
      "Epoch: 8767/10000 Iteration: 61370 Train loss: 0.007451\n",
      "Epoch: 8768/10000 Iteration: 61377 Train loss: 0.007451\n",
      "Epoch: 8769/10000 Iteration: 61384 Train loss: 0.007451\n",
      "Epoch: 8770/10000 Iteration: 61391 Train loss: 0.007451\n",
      "Epoch: 8771/10000 Iteration: 61398 Train loss: 0.007451\n",
      "Epoch: 8772/10000 Iteration: 61405 Train loss: 0.007451\n",
      "Epoch: 8773/10000 Iteration: 61412 Train loss: 0.007451\n",
      "Epoch: 8774/10000 Iteration: 61419 Train loss: 0.007451\n",
      "Epoch: 8775/10000 Iteration: 61426 Train loss: 0.007451\n",
      "Epoch: 8776/10000 Iteration: 61433 Train loss: 0.007451\n",
      "Epoch: 8777/10000 Iteration: 61440 Train loss: 0.007451\n",
      "Epoch: 8778/10000 Iteration: 61447 Train loss: 0.007451\n",
      "Epoch: 8779/10000 Iteration: 61454 Train loss: 0.007451\n",
      "Epoch: 8780/10000 Iteration: 61461 Train loss: 0.007450\n",
      "Epoch: 8781/10000 Iteration: 61468 Train loss: 0.007450\n",
      "Epoch: 8782/10000 Iteration: 61475 Train loss: 0.007450\n",
      "Epoch: 8783/10000 Iteration: 61482 Train loss: 0.007450\n",
      "Epoch: 8784/10000 Iteration: 61489 Train loss: 0.007450\n",
      "Epoch: 8785/10000 Iteration: 61496 Train loss: 0.007450\n",
      "Epoch: 8786/10000 Iteration: 61503 Train loss: 0.007450\n",
      "Epoch: 8787/10000 Iteration: 61510 Train loss: 0.007450\n",
      "Epoch: 8788/10000 Iteration: 61517 Train loss: 0.007450\n",
      "Epoch: 8789/10000 Iteration: 61524 Train loss: 0.007450\n",
      "Epoch: 8790/10000 Iteration: 61531 Train loss: 0.007450\n",
      "Epoch: 8791/10000 Iteration: 61538 Train loss: 0.007450\n",
      "Epoch: 8792/10000 Iteration: 61545 Train loss: 0.007450\n",
      "Epoch: 8793/10000 Iteration: 61552 Train loss: 0.007450\n",
      "Epoch: 8794/10000 Iteration: 61559 Train loss: 0.007449\n",
      "Epoch: 8795/10000 Iteration: 61566 Train loss: 0.007449\n",
      "Epoch: 8796/10000 Iteration: 61573 Train loss: 0.007449\n",
      "Epoch: 8797/10000 Iteration: 61580 Train loss: 0.007449\n",
      "Epoch: 8798/10000 Iteration: 61587 Train loss: 0.007449\n",
      "Epoch: 8799/10000 Iteration: 61594 Train loss: 0.007449\n",
      "Epoch: 8800/10000 Iteration: 61601 Train loss: 0.007449\n",
      "Epoch: 8801/10000 Iteration: 61608 Train loss: 0.007449\n",
      "Epoch: 8802/10000 Iteration: 61615 Train loss: 0.007449\n",
      "Epoch: 8803/10000 Iteration: 61622 Train loss: 0.007449\n",
      "Epoch: 8804/10000 Iteration: 61629 Train loss: 0.007449\n",
      "Epoch: 8805/10000 Iteration: 61636 Train loss: 0.007449\n",
      "Epoch: 8806/10000 Iteration: 61643 Train loss: 0.007449\n",
      "Epoch: 8807/10000 Iteration: 61650 Train loss: 0.007449\n",
      "Epoch: 8808/10000 Iteration: 61657 Train loss: 0.007449\n",
      "Epoch: 8809/10000 Iteration: 61664 Train loss: 0.007448\n",
      "Epoch: 8810/10000 Iteration: 61671 Train loss: 0.007448\n",
      "Epoch: 8811/10000 Iteration: 61678 Train loss: 0.007448\n",
      "Epoch: 8812/10000 Iteration: 61685 Train loss: 0.007448\n",
      "Epoch: 8813/10000 Iteration: 61692 Train loss: 0.007448\n",
      "Epoch: 8814/10000 Iteration: 61699 Train loss: 0.007448\n",
      "Epoch: 8815/10000 Iteration: 61706 Train loss: 0.007448\n",
      "Epoch: 8816/10000 Iteration: 61713 Train loss: 0.007448\n",
      "Epoch: 8817/10000 Iteration: 61720 Train loss: 0.007448\n",
      "Epoch: 8818/10000 Iteration: 61727 Train loss: 0.007448\n",
      "Epoch: 8819/10000 Iteration: 61734 Train loss: 0.007448\n",
      "Epoch: 8820/10000 Iteration: 61741 Train loss: 0.007448\n",
      "Epoch: 8821/10000 Iteration: 61748 Train loss: 0.007448\n",
      "Epoch: 8822/10000 Iteration: 61755 Train loss: 0.007448\n",
      "Epoch: 8823/10000 Iteration: 61762 Train loss: 0.007448\n",
      "Epoch: 8824/10000 Iteration: 61769 Train loss: 0.007447\n",
      "Epoch: 8825/10000 Iteration: 61776 Train loss: 0.007447\n",
      "Epoch: 8826/10000 Iteration: 61783 Train loss: 0.007447\n",
      "Epoch: 8827/10000 Iteration: 61790 Train loss: 0.007447\n",
      "Epoch: 8828/10000 Iteration: 61797 Train loss: 0.007447\n",
      "Epoch: 8829/10000 Iteration: 61804 Train loss: 0.007447\n",
      "Epoch: 8830/10000 Iteration: 61811 Train loss: 0.007447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8831/10000 Iteration: 61818 Train loss: 0.007447\n",
      "Epoch: 8832/10000 Iteration: 61825 Train loss: 0.007447\n",
      "Epoch: 8833/10000 Iteration: 61832 Train loss: 0.007447\n",
      "Epoch: 8834/10000 Iteration: 61839 Train loss: 0.007447\n",
      "Epoch: 8835/10000 Iteration: 61846 Train loss: 0.007447\n",
      "Epoch: 8836/10000 Iteration: 61853 Train loss: 0.007447\n",
      "Epoch: 8837/10000 Iteration: 61860 Train loss: 0.007447\n",
      "Epoch: 8838/10000 Iteration: 61867 Train loss: 0.007447\n",
      "Epoch: 8839/10000 Iteration: 61874 Train loss: 0.007446\n",
      "Epoch: 8840/10000 Iteration: 61881 Train loss: 0.007446\n",
      "Epoch: 8841/10000 Iteration: 61888 Train loss: 0.007446\n",
      "Epoch: 8842/10000 Iteration: 61895 Train loss: 0.007446\n",
      "Epoch: 8843/10000 Iteration: 61902 Train loss: 0.007446\n",
      "Epoch: 8844/10000 Iteration: 61909 Train loss: 0.007446\n",
      "Epoch: 8845/10000 Iteration: 61916 Train loss: 0.007446\n",
      "Epoch: 8846/10000 Iteration: 61923 Train loss: 0.007446\n",
      "Epoch: 8847/10000 Iteration: 61930 Train loss: 0.007446\n",
      "Epoch: 8848/10000 Iteration: 61937 Train loss: 0.007446\n",
      "Epoch: 8849/10000 Iteration: 61944 Train loss: 0.007446\n",
      "Epoch: 8850/10000 Iteration: 61951 Train loss: 0.007446\n",
      "Epoch: 8851/10000 Iteration: 61958 Train loss: 0.007446\n",
      "Epoch: 8852/10000 Iteration: 61965 Train loss: 0.007446\n",
      "Epoch: 8853/10000 Iteration: 61972 Train loss: 0.007446\n",
      "Epoch: 8854/10000 Iteration: 61979 Train loss: 0.007445\n",
      "Epoch: 8855/10000 Iteration: 61986 Train loss: 0.007445\n",
      "Epoch: 8856/10000 Iteration: 61993 Train loss: 0.007445\n",
      "Epoch: 8857/10000 Iteration: 62000 Train loss: 0.007445\n",
      "Epoch: 8858/10000 Iteration: 62007 Train loss: 0.007445\n",
      "Epoch: 8859/10000 Iteration: 62014 Train loss: 0.007445\n",
      "Epoch: 8860/10000 Iteration: 62021 Train loss: 0.007445\n",
      "Epoch: 8861/10000 Iteration: 62028 Train loss: 0.007445\n",
      "Epoch: 8862/10000 Iteration: 62035 Train loss: 0.007445\n",
      "Epoch: 8863/10000 Iteration: 62042 Train loss: 0.007445\n",
      "Epoch: 8864/10000 Iteration: 62049 Train loss: 0.007445\n",
      "Epoch: 8865/10000 Iteration: 62056 Train loss: 0.007445\n",
      "Epoch: 8866/10000 Iteration: 62063 Train loss: 0.007445\n",
      "Epoch: 8867/10000 Iteration: 62070 Train loss: 0.007445\n",
      "Epoch: 8868/10000 Iteration: 62077 Train loss: 0.007445\n",
      "Epoch: 8869/10000 Iteration: 62084 Train loss: 0.007444\n",
      "Epoch: 8870/10000 Iteration: 62091 Train loss: 0.007444\n",
      "Epoch: 8871/10000 Iteration: 62098 Train loss: 0.007444\n",
      "Epoch: 8872/10000 Iteration: 62105 Train loss: 0.007444\n",
      "Epoch: 8873/10000 Iteration: 62112 Train loss: 0.007444\n",
      "Epoch: 8874/10000 Iteration: 62119 Train loss: 0.007444\n",
      "Epoch: 8875/10000 Iteration: 62126 Train loss: 0.007444\n",
      "Epoch: 8876/10000 Iteration: 62133 Train loss: 0.007444\n",
      "Epoch: 8877/10000 Iteration: 62140 Train loss: 0.007444\n",
      "Epoch: 8878/10000 Iteration: 62147 Train loss: 0.007444\n",
      "Epoch: 8879/10000 Iteration: 62154 Train loss: 0.007444\n",
      "Epoch: 8880/10000 Iteration: 62161 Train loss: 0.007444\n",
      "Epoch: 8881/10000 Iteration: 62168 Train loss: 0.007444\n",
      "Epoch: 8882/10000 Iteration: 62175 Train loss: 0.007444\n",
      "Epoch: 8883/10000 Iteration: 62182 Train loss: 0.007444\n",
      "Epoch: 8884/10000 Iteration: 62189 Train loss: 0.007444\n",
      "Epoch: 8885/10000 Iteration: 62196 Train loss: 0.007443\n",
      "Epoch: 8886/10000 Iteration: 62203 Train loss: 0.007443\n",
      "Epoch: 8887/10000 Iteration: 62210 Train loss: 0.007443\n",
      "Epoch: 8888/10000 Iteration: 62217 Train loss: 0.007443\n",
      "Epoch: 8889/10000 Iteration: 62224 Train loss: 0.007443\n",
      "Epoch: 8890/10000 Iteration: 62231 Train loss: 0.007443\n",
      "Epoch: 8891/10000 Iteration: 62238 Train loss: 0.007443\n",
      "Epoch: 8892/10000 Iteration: 62245 Train loss: 0.007443\n",
      "Epoch: 8893/10000 Iteration: 62252 Train loss: 0.007443\n",
      "Epoch: 8894/10000 Iteration: 62259 Train loss: 0.007443\n",
      "Epoch: 8895/10000 Iteration: 62266 Train loss: 0.007443\n",
      "Epoch: 8896/10000 Iteration: 62273 Train loss: 0.007443\n",
      "Epoch: 8897/10000 Iteration: 62280 Train loss: 0.007443\n",
      "Epoch: 8898/10000 Iteration: 62287 Train loss: 0.007443\n",
      "Epoch: 8899/10000 Iteration: 62294 Train loss: 0.007443\n",
      "Epoch: 8900/10000 Iteration: 62301 Train loss: 0.007443\n",
      "Epoch: 8901/10000 Iteration: 62308 Train loss: 0.007442\n",
      "Epoch: 8902/10000 Iteration: 62315 Train loss: 0.007442\n",
      "Epoch: 8903/10000 Iteration: 62322 Train loss: 0.007442\n",
      "Epoch: 8904/10000 Iteration: 62329 Train loss: 0.007442\n",
      "Epoch: 8905/10000 Iteration: 62336 Train loss: 0.007442\n",
      "Epoch: 8906/10000 Iteration: 62343 Train loss: 0.007442\n",
      "Epoch: 8907/10000 Iteration: 62350 Train loss: 0.007442\n",
      "Epoch: 8908/10000 Iteration: 62357 Train loss: 0.007442\n",
      "Epoch: 8909/10000 Iteration: 62364 Train loss: 0.007442\n",
      "Epoch: 8910/10000 Iteration: 62371 Train loss: 0.007442\n",
      "Epoch: 8911/10000 Iteration: 62378 Train loss: 0.007442\n",
      "Epoch: 8912/10000 Iteration: 62385 Train loss: 0.007442\n",
      "Epoch: 8913/10000 Iteration: 62392 Train loss: 0.007442\n",
      "Epoch: 8914/10000 Iteration: 62399 Train loss: 0.007442\n",
      "Epoch: 8915/10000 Iteration: 62406 Train loss: 0.007442\n",
      "Epoch: 8916/10000 Iteration: 62413 Train loss: 0.007442\n",
      "Epoch: 8917/10000 Iteration: 62420 Train loss: 0.007441\n",
      "Epoch: 8918/10000 Iteration: 62427 Train loss: 0.007441\n",
      "Epoch: 8919/10000 Iteration: 62434 Train loss: 0.007441\n",
      "Epoch: 8920/10000 Iteration: 62441 Train loss: 0.007441\n",
      "Epoch: 8921/10000 Iteration: 62448 Train loss: 0.007441\n",
      "Epoch: 8922/10000 Iteration: 62455 Train loss: 0.007441\n",
      "Epoch: 8923/10000 Iteration: 62462 Train loss: 0.007441\n",
      "Epoch: 8924/10000 Iteration: 62469 Train loss: 0.007441\n",
      "Epoch: 8925/10000 Iteration: 62476 Train loss: 0.007441\n",
      "Epoch: 8926/10000 Iteration: 62483 Train loss: 0.007441\n",
      "Epoch: 8927/10000 Iteration: 62490 Train loss: 0.007441\n",
      "Epoch: 8928/10000 Iteration: 62497 Train loss: 0.007441\n",
      "Epoch: 8929/10000 Iteration: 62504 Train loss: 0.007441\n",
      "Epoch: 8930/10000 Iteration: 62511 Train loss: 0.007441\n",
      "Epoch: 8931/10000 Iteration: 62518 Train loss: 0.007441\n",
      "Epoch: 8932/10000 Iteration: 62525 Train loss: 0.007441\n",
      "Epoch: 8933/10000 Iteration: 62532 Train loss: 0.007440\n",
      "Epoch: 8934/10000 Iteration: 62539 Train loss: 0.007440\n",
      "Epoch: 8935/10000 Iteration: 62546 Train loss: 0.007440\n",
      "Epoch: 8936/10000 Iteration: 62553 Train loss: 0.007440\n",
      "Epoch: 8937/10000 Iteration: 62560 Train loss: 0.007440\n",
      "Epoch: 8938/10000 Iteration: 62567 Train loss: 0.007440\n",
      "Epoch: 8939/10000 Iteration: 62574 Train loss: 0.007440\n",
      "Epoch: 8940/10000 Iteration: 62581 Train loss: 0.007440\n",
      "Epoch: 8941/10000 Iteration: 62588 Train loss: 0.007440\n",
      "Epoch: 8942/10000 Iteration: 62595 Train loss: 0.007440\n",
      "Epoch: 8943/10000 Iteration: 62602 Train loss: 0.007440\n",
      "Epoch: 8944/10000 Iteration: 62609 Train loss: 0.007440\n",
      "Epoch: 8945/10000 Iteration: 62616 Train loss: 0.007440\n",
      "Epoch: 8946/10000 Iteration: 62623 Train loss: 0.007440\n",
      "Epoch: 8947/10000 Iteration: 62630 Train loss: 0.007440\n",
      "Epoch: 8948/10000 Iteration: 62637 Train loss: 0.007440\n",
      "Epoch: 8949/10000 Iteration: 62644 Train loss: 0.007440\n",
      "Epoch: 8950/10000 Iteration: 62651 Train loss: 0.007439\n",
      "Epoch: 8951/10000 Iteration: 62658 Train loss: 0.007439\n",
      "Epoch: 8952/10000 Iteration: 62665 Train loss: 0.007439\n",
      "Epoch: 8953/10000 Iteration: 62672 Train loss: 0.007439\n",
      "Epoch: 8954/10000 Iteration: 62679 Train loss: 0.007439\n",
      "Epoch: 8955/10000 Iteration: 62686 Train loss: 0.007439\n",
      "Epoch: 8956/10000 Iteration: 62693 Train loss: 0.007439\n",
      "Epoch: 8957/10000 Iteration: 62700 Train loss: 0.007439\n",
      "Epoch: 8958/10000 Iteration: 62707 Train loss: 0.007439\n",
      "Epoch: 8959/10000 Iteration: 62714 Train loss: 0.007439\n",
      "Epoch: 8960/10000 Iteration: 62721 Train loss: 0.007439\n",
      "Epoch: 8961/10000 Iteration: 62728 Train loss: 0.007439\n",
      "Epoch: 8962/10000 Iteration: 62735 Train loss: 0.007439\n",
      "Epoch: 8963/10000 Iteration: 62742 Train loss: 0.007439\n",
      "Epoch: 8964/10000 Iteration: 62749 Train loss: 0.007439\n",
      "Epoch: 8965/10000 Iteration: 62756 Train loss: 0.007439\n",
      "Epoch: 8966/10000 Iteration: 62763 Train loss: 0.007439\n",
      "Epoch: 8967/10000 Iteration: 62770 Train loss: 0.007438\n",
      "Epoch: 8968/10000 Iteration: 62777 Train loss: 0.007438\n",
      "Epoch: 8969/10000 Iteration: 62784 Train loss: 0.007438\n",
      "Epoch: 8970/10000 Iteration: 62791 Train loss: 0.007438\n",
      "Epoch: 8971/10000 Iteration: 62798 Train loss: 0.007438\n",
      "Epoch: 8972/10000 Iteration: 62805 Train loss: 0.007438\n",
      "Epoch: 8973/10000 Iteration: 62812 Train loss: 0.007438\n",
      "Epoch: 8974/10000 Iteration: 62819 Train loss: 0.007438\n",
      "Epoch: 8975/10000 Iteration: 62826 Train loss: 0.007438\n",
      "Epoch: 8976/10000 Iteration: 62833 Train loss: 0.007438\n",
      "Epoch: 8977/10000 Iteration: 62840 Train loss: 0.007438\n",
      "Epoch: 8978/10000 Iteration: 62847 Train loss: 0.007438\n",
      "Epoch: 8979/10000 Iteration: 62854 Train loss: 0.007438\n",
      "Epoch: 8980/10000 Iteration: 62861 Train loss: 0.007438\n",
      "Epoch: 8981/10000 Iteration: 62868 Train loss: 0.007438\n",
      "Epoch: 8982/10000 Iteration: 62875 Train loss: 0.007438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8983/10000 Iteration: 62882 Train loss: 0.007438\n",
      "Epoch: 8984/10000 Iteration: 62889 Train loss: 0.007438\n",
      "Epoch: 8985/10000 Iteration: 62896 Train loss: 0.007437\n",
      "Epoch: 8986/10000 Iteration: 62903 Train loss: 0.007437\n",
      "Epoch: 8987/10000 Iteration: 62910 Train loss: 0.007437\n",
      "Epoch: 8988/10000 Iteration: 62917 Train loss: 0.007437\n",
      "Epoch: 8989/10000 Iteration: 62924 Train loss: 0.007437\n",
      "Epoch: 8990/10000 Iteration: 62931 Train loss: 0.007437\n",
      "Epoch: 8991/10000 Iteration: 62938 Train loss: 0.007437\n",
      "Epoch: 8992/10000 Iteration: 62945 Train loss: 0.007437\n",
      "Epoch: 8993/10000 Iteration: 62952 Train loss: 0.007437\n",
      "Epoch: 8994/10000 Iteration: 62959 Train loss: 0.007437\n",
      "Epoch: 8995/10000 Iteration: 62966 Train loss: 0.007437\n",
      "Epoch: 8996/10000 Iteration: 62973 Train loss: 0.007437\n",
      "Epoch: 8997/10000 Iteration: 62980 Train loss: 0.007437\n",
      "Epoch: 8998/10000 Iteration: 62987 Train loss: 0.007437\n",
      "Epoch: 8999/10000 Iteration: 62994 Train loss: 0.007437\n",
      "Epoch: 9000/10000 Iteration: 63001 Train loss: 0.007437\n",
      "Epoch: 9001/10000 Iteration: 63008 Train loss: 0.007437\n",
      "Epoch: 9002/10000 Iteration: 63015 Train loss: 0.007436\n",
      "Epoch: 9003/10000 Iteration: 63022 Train loss: 0.007436\n",
      "Epoch: 9004/10000 Iteration: 63029 Train loss: 0.007436\n",
      "Epoch: 9005/10000 Iteration: 63036 Train loss: 0.007436\n",
      "Epoch: 9006/10000 Iteration: 63043 Train loss: 0.007436\n",
      "Epoch: 9007/10000 Iteration: 63050 Train loss: 0.007436\n",
      "Epoch: 9008/10000 Iteration: 63057 Train loss: 0.007436\n",
      "Epoch: 9009/10000 Iteration: 63064 Train loss: 0.007436\n",
      "Epoch: 9010/10000 Iteration: 63071 Train loss: 0.007436\n",
      "Epoch: 9011/10000 Iteration: 63078 Train loss: 0.007436\n",
      "Epoch: 9012/10000 Iteration: 63085 Train loss: 0.007436\n",
      "Epoch: 9013/10000 Iteration: 63092 Train loss: 0.007436\n",
      "Epoch: 9014/10000 Iteration: 63099 Train loss: 0.007436\n",
      "Epoch: 9015/10000 Iteration: 63106 Train loss: 0.007436\n",
      "Epoch: 9016/10000 Iteration: 63113 Train loss: 0.007436\n",
      "Epoch: 9017/10000 Iteration: 63120 Train loss: 0.007436\n",
      "Epoch: 9018/10000 Iteration: 63127 Train loss: 0.007436\n",
      "Epoch: 9019/10000 Iteration: 63134 Train loss: 0.007436\n",
      "Epoch: 9020/10000 Iteration: 63141 Train loss: 0.007436\n",
      "Epoch: 9021/10000 Iteration: 63148 Train loss: 0.007435\n",
      "Epoch: 9022/10000 Iteration: 63155 Train loss: 0.007435\n",
      "Epoch: 9023/10000 Iteration: 63162 Train loss: 0.007435\n",
      "Epoch: 9024/10000 Iteration: 63169 Train loss: 0.007435\n",
      "Epoch: 9025/10000 Iteration: 63176 Train loss: 0.007435\n",
      "Epoch: 9026/10000 Iteration: 63183 Train loss: 0.007435\n",
      "Epoch: 9027/10000 Iteration: 63190 Train loss: 0.007435\n",
      "Epoch: 9028/10000 Iteration: 63197 Train loss: 0.007435\n",
      "Epoch: 9029/10000 Iteration: 63204 Train loss: 0.007435\n",
      "Epoch: 9030/10000 Iteration: 63211 Train loss: 0.007435\n",
      "Epoch: 9031/10000 Iteration: 63218 Train loss: 0.007435\n",
      "Epoch: 9032/10000 Iteration: 63225 Train loss: 0.007435\n",
      "Epoch: 9033/10000 Iteration: 63232 Train loss: 0.007435\n",
      "Epoch: 9034/10000 Iteration: 63239 Train loss: 0.007435\n",
      "Epoch: 9035/10000 Iteration: 63246 Train loss: 0.007435\n",
      "Epoch: 9036/10000 Iteration: 63253 Train loss: 0.007435\n",
      "Epoch: 9037/10000 Iteration: 63260 Train loss: 0.007435\n",
      "Epoch: 9038/10000 Iteration: 63267 Train loss: 0.007435\n",
      "Epoch: 9039/10000 Iteration: 63274 Train loss: 0.007434\n",
      "Epoch: 9040/10000 Iteration: 63281 Train loss: 0.007434\n",
      "Epoch: 9041/10000 Iteration: 63288 Train loss: 0.007434\n",
      "Epoch: 9042/10000 Iteration: 63295 Train loss: 0.007434\n",
      "Epoch: 9043/10000 Iteration: 63302 Train loss: 0.007434\n",
      "Epoch: 9044/10000 Iteration: 63309 Train loss: 0.007434\n",
      "Epoch: 9045/10000 Iteration: 63316 Train loss: 0.007434\n",
      "Epoch: 9046/10000 Iteration: 63323 Train loss: 0.007434\n",
      "Epoch: 9047/10000 Iteration: 63330 Train loss: 0.007434\n",
      "Epoch: 9048/10000 Iteration: 63337 Train loss: 0.007434\n",
      "Epoch: 9049/10000 Iteration: 63344 Train loss: 0.007434\n",
      "Epoch: 9050/10000 Iteration: 63351 Train loss: 0.007434\n",
      "Epoch: 9051/10000 Iteration: 63358 Train loss: 0.007434\n",
      "Epoch: 9052/10000 Iteration: 63365 Train loss: 0.007434\n",
      "Epoch: 9053/10000 Iteration: 63372 Train loss: 0.007434\n",
      "Epoch: 9054/10000 Iteration: 63379 Train loss: 0.007434\n",
      "Epoch: 9055/10000 Iteration: 63386 Train loss: 0.007434\n",
      "Epoch: 9056/10000 Iteration: 63393 Train loss: 0.007434\n",
      "Epoch: 9057/10000 Iteration: 63400 Train loss: 0.007434\n",
      "Epoch: 9058/10000 Iteration: 63407 Train loss: 0.007433\n",
      "Epoch: 9059/10000 Iteration: 63414 Train loss: 0.007433\n",
      "Epoch: 9060/10000 Iteration: 63421 Train loss: 0.007433\n",
      "Epoch: 9061/10000 Iteration: 63428 Train loss: 0.007433\n",
      "Epoch: 9062/10000 Iteration: 63435 Train loss: 0.007433\n",
      "Epoch: 9063/10000 Iteration: 63442 Train loss: 0.007433\n",
      "Epoch: 9064/10000 Iteration: 63449 Train loss: 0.007433\n",
      "Epoch: 9065/10000 Iteration: 63456 Train loss: 0.007433\n",
      "Epoch: 9066/10000 Iteration: 63463 Train loss: 0.007433\n",
      "Epoch: 9067/10000 Iteration: 63470 Train loss: 0.007433\n",
      "Epoch: 9068/10000 Iteration: 63477 Train loss: 0.007433\n",
      "Epoch: 9069/10000 Iteration: 63484 Train loss: 0.007433\n",
      "Epoch: 9070/10000 Iteration: 63491 Train loss: 0.007433\n",
      "Epoch: 9071/10000 Iteration: 63498 Train loss: 0.007433\n",
      "Epoch: 9072/10000 Iteration: 63505 Train loss: 0.007433\n",
      "Epoch: 9073/10000 Iteration: 63512 Train loss: 0.007433\n",
      "Epoch: 9074/10000 Iteration: 63519 Train loss: 0.007433\n",
      "Epoch: 9075/10000 Iteration: 63526 Train loss: 0.007433\n",
      "Epoch: 9076/10000 Iteration: 63533 Train loss: 0.007433\n",
      "Epoch: 9077/10000 Iteration: 63540 Train loss: 0.007433\n",
      "Epoch: 9078/10000 Iteration: 63547 Train loss: 0.007432\n",
      "Epoch: 9079/10000 Iteration: 63554 Train loss: 0.007432\n",
      "Epoch: 9080/10000 Iteration: 63561 Train loss: 0.007432\n",
      "Epoch: 9081/10000 Iteration: 63568 Train loss: 0.007432\n",
      "Epoch: 9082/10000 Iteration: 63575 Train loss: 0.007432\n",
      "Epoch: 9083/10000 Iteration: 63582 Train loss: 0.007432\n",
      "Epoch: 9084/10000 Iteration: 63589 Train loss: 0.007432\n",
      "Epoch: 9085/10000 Iteration: 63596 Train loss: 0.007432\n",
      "Epoch: 9086/10000 Iteration: 63603 Train loss: 0.007432\n",
      "Epoch: 9087/10000 Iteration: 63610 Train loss: 0.007432\n",
      "Epoch: 9088/10000 Iteration: 63617 Train loss: 0.007432\n",
      "Epoch: 9089/10000 Iteration: 63624 Train loss: 0.007432\n",
      "Epoch: 9090/10000 Iteration: 63631 Train loss: 0.007432\n",
      "Epoch: 9091/10000 Iteration: 63638 Train loss: 0.007432\n",
      "Epoch: 9092/10000 Iteration: 63645 Train loss: 0.007432\n",
      "Epoch: 9093/10000 Iteration: 63652 Train loss: 0.007432\n",
      "Epoch: 9094/10000 Iteration: 63659 Train loss: 0.007432\n",
      "Epoch: 9095/10000 Iteration: 63666 Train loss: 0.007432\n",
      "Epoch: 9096/10000 Iteration: 63673 Train loss: 0.007432\n",
      "Epoch: 9097/10000 Iteration: 63680 Train loss: 0.007432\n",
      "Epoch: 9098/10000 Iteration: 63687 Train loss: 0.007431\n",
      "Epoch: 9099/10000 Iteration: 63694 Train loss: 0.007431\n",
      "Epoch: 9100/10000 Iteration: 63701 Train loss: 0.007431\n",
      "Epoch: 9101/10000 Iteration: 63708 Train loss: 0.007431\n",
      "Epoch: 9102/10000 Iteration: 63715 Train loss: 0.007431\n",
      "Epoch: 9103/10000 Iteration: 63722 Train loss: 0.007431\n",
      "Epoch: 9104/10000 Iteration: 63729 Train loss: 0.007431\n",
      "Epoch: 9105/10000 Iteration: 63736 Train loss: 0.007431\n",
      "Epoch: 9106/10000 Iteration: 63743 Train loss: 0.007431\n",
      "Epoch: 9107/10000 Iteration: 63750 Train loss: 0.007431\n",
      "Epoch: 9108/10000 Iteration: 63757 Train loss: 0.007431\n",
      "Epoch: 9109/10000 Iteration: 63764 Train loss: 0.007431\n",
      "Epoch: 9110/10000 Iteration: 63771 Train loss: 0.007431\n",
      "Epoch: 9111/10000 Iteration: 63778 Train loss: 0.007431\n",
      "Epoch: 9112/10000 Iteration: 63785 Train loss: 0.007431\n",
      "Epoch: 9113/10000 Iteration: 63792 Train loss: 0.007431\n",
      "Epoch: 9114/10000 Iteration: 63799 Train loss: 0.007431\n",
      "Epoch: 9115/10000 Iteration: 63806 Train loss: 0.007431\n",
      "Epoch: 9116/10000 Iteration: 63813 Train loss: 0.007431\n",
      "Epoch: 9117/10000 Iteration: 63820 Train loss: 0.007431\n",
      "Epoch: 9118/10000 Iteration: 63827 Train loss: 0.007430\n",
      "Epoch: 9119/10000 Iteration: 63834 Train loss: 0.007430\n",
      "Epoch: 9120/10000 Iteration: 63841 Train loss: 0.007430\n",
      "Epoch: 9121/10000 Iteration: 63848 Train loss: 0.007430\n",
      "Epoch: 9122/10000 Iteration: 63855 Train loss: 0.007430\n",
      "Epoch: 9123/10000 Iteration: 63862 Train loss: 0.007430\n",
      "Epoch: 9124/10000 Iteration: 63869 Train loss: 0.007430\n",
      "Epoch: 9125/10000 Iteration: 63876 Train loss: 0.007430\n",
      "Epoch: 9126/10000 Iteration: 63883 Train loss: 0.007430\n",
      "Epoch: 9127/10000 Iteration: 63890 Train loss: 0.007430\n",
      "Epoch: 9128/10000 Iteration: 63897 Train loss: 0.007430\n",
      "Epoch: 9129/10000 Iteration: 63904 Train loss: 0.007430\n",
      "Epoch: 9130/10000 Iteration: 63911 Train loss: 0.007430\n",
      "Epoch: 9131/10000 Iteration: 63918 Train loss: 0.007430\n",
      "Epoch: 9132/10000 Iteration: 63925 Train loss: 0.007430\n",
      "Epoch: 9133/10000 Iteration: 63932 Train loss: 0.007430\n",
      "Epoch: 9134/10000 Iteration: 63939 Train loss: 0.007430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9135/10000 Iteration: 63946 Train loss: 0.007430\n",
      "Epoch: 9136/10000 Iteration: 63953 Train loss: 0.007430\n",
      "Epoch: 9137/10000 Iteration: 63960 Train loss: 0.007430\n",
      "Epoch: 9138/10000 Iteration: 63967 Train loss: 0.007430\n",
      "Epoch: 9139/10000 Iteration: 63974 Train loss: 0.007430\n",
      "Epoch: 9140/10000 Iteration: 63981 Train loss: 0.007429\n",
      "Epoch: 9141/10000 Iteration: 63988 Train loss: 0.007429\n",
      "Epoch: 9142/10000 Iteration: 63995 Train loss: 0.007429\n",
      "Epoch: 9143/10000 Iteration: 64002 Train loss: 0.007429\n",
      "Epoch: 9144/10000 Iteration: 64009 Train loss: 0.007429\n",
      "Epoch: 9145/10000 Iteration: 64016 Train loss: 0.007429\n",
      "Epoch: 9146/10000 Iteration: 64023 Train loss: 0.007429\n",
      "Epoch: 9147/10000 Iteration: 64030 Train loss: 0.007429\n",
      "Epoch: 9148/10000 Iteration: 64037 Train loss: 0.007429\n",
      "Epoch: 9149/10000 Iteration: 64044 Train loss: 0.007429\n",
      "Epoch: 9150/10000 Iteration: 64051 Train loss: 0.007429\n",
      "Epoch: 9151/10000 Iteration: 64058 Train loss: 0.007429\n",
      "Epoch: 9152/10000 Iteration: 64065 Train loss: 0.007429\n",
      "Epoch: 9153/10000 Iteration: 64072 Train loss: 0.007429\n",
      "Epoch: 9154/10000 Iteration: 64079 Train loss: 0.007429\n",
      "Epoch: 9155/10000 Iteration: 64086 Train loss: 0.007429\n",
      "Epoch: 9156/10000 Iteration: 64093 Train loss: 0.007429\n",
      "Epoch: 9157/10000 Iteration: 64100 Train loss: 0.007429\n",
      "Epoch: 9158/10000 Iteration: 64107 Train loss: 0.007429\n",
      "Epoch: 9159/10000 Iteration: 64114 Train loss: 0.007429\n",
      "Epoch: 9160/10000 Iteration: 64121 Train loss: 0.007429\n",
      "Epoch: 9161/10000 Iteration: 64128 Train loss: 0.007429\n",
      "Epoch: 9162/10000 Iteration: 64135 Train loss: 0.007428\n",
      "Epoch: 9163/10000 Iteration: 64142 Train loss: 0.007428\n",
      "Epoch: 9164/10000 Iteration: 64149 Train loss: 0.007428\n",
      "Epoch: 9165/10000 Iteration: 64156 Train loss: 0.007428\n",
      "Epoch: 9166/10000 Iteration: 64163 Train loss: 0.007428\n",
      "Epoch: 9167/10000 Iteration: 64170 Train loss: 0.007428\n",
      "Epoch: 9168/10000 Iteration: 64177 Train loss: 0.007428\n",
      "Epoch: 9169/10000 Iteration: 64184 Train loss: 0.007428\n",
      "Epoch: 9170/10000 Iteration: 64191 Train loss: 0.007428\n",
      "Epoch: 9171/10000 Iteration: 64198 Train loss: 0.007428\n",
      "Epoch: 9172/10000 Iteration: 64205 Train loss: 0.007428\n",
      "Epoch: 9173/10000 Iteration: 64212 Train loss: 0.007428\n",
      "Epoch: 9174/10000 Iteration: 64219 Train loss: 0.007428\n",
      "Epoch: 9175/10000 Iteration: 64226 Train loss: 0.007428\n",
      "Epoch: 9176/10000 Iteration: 64233 Train loss: 0.007428\n",
      "Epoch: 9177/10000 Iteration: 64240 Train loss: 0.007428\n",
      "Epoch: 9178/10000 Iteration: 64247 Train loss: 0.007428\n",
      "Epoch: 9179/10000 Iteration: 64254 Train loss: 0.007428\n",
      "Epoch: 9180/10000 Iteration: 64261 Train loss: 0.007428\n",
      "Epoch: 9181/10000 Iteration: 64268 Train loss: 0.007428\n",
      "Epoch: 9182/10000 Iteration: 64275 Train loss: 0.007428\n",
      "Epoch: 9183/10000 Iteration: 64282 Train loss: 0.007428\n",
      "Epoch: 9184/10000 Iteration: 64289 Train loss: 0.007428\n",
      "Epoch: 9185/10000 Iteration: 64296 Train loss: 0.007427\n",
      "Epoch: 9186/10000 Iteration: 64303 Train loss: 0.007427\n",
      "Epoch: 9187/10000 Iteration: 64310 Train loss: 0.007427\n",
      "Epoch: 9188/10000 Iteration: 64317 Train loss: 0.007427\n",
      "Epoch: 9189/10000 Iteration: 64324 Train loss: 0.007427\n",
      "Epoch: 9190/10000 Iteration: 64331 Train loss: 0.007427\n",
      "Epoch: 9191/10000 Iteration: 64338 Train loss: 0.007427\n",
      "Epoch: 9192/10000 Iteration: 64345 Train loss: 0.007427\n",
      "Epoch: 9193/10000 Iteration: 64352 Train loss: 0.007427\n",
      "Epoch: 9194/10000 Iteration: 64359 Train loss: 0.007427\n",
      "Epoch: 9195/10000 Iteration: 64366 Train loss: 0.007427\n",
      "Epoch: 9196/10000 Iteration: 64373 Train loss: 0.007427\n",
      "Epoch: 9197/10000 Iteration: 64380 Train loss: 0.007427\n",
      "Epoch: 9198/10000 Iteration: 64387 Train loss: 0.007427\n",
      "Epoch: 9199/10000 Iteration: 64394 Train loss: 0.007427\n",
      "Epoch: 9200/10000 Iteration: 64401 Train loss: 0.007427\n",
      "Epoch: 9201/10000 Iteration: 64408 Train loss: 0.007427\n",
      "Epoch: 9202/10000 Iteration: 64415 Train loss: 0.007427\n",
      "Epoch: 9203/10000 Iteration: 64422 Train loss: 0.007427\n",
      "Epoch: 9204/10000 Iteration: 64429 Train loss: 0.007427\n",
      "Epoch: 9205/10000 Iteration: 64436 Train loss: 0.007427\n",
      "Epoch: 9206/10000 Iteration: 64443 Train loss: 0.007427\n",
      "Epoch: 9207/10000 Iteration: 64450 Train loss: 0.007427\n",
      "Epoch: 9208/10000 Iteration: 64457 Train loss: 0.007427\n",
      "Epoch: 9209/10000 Iteration: 64464 Train loss: 0.007426\n",
      "Epoch: 9210/10000 Iteration: 64471 Train loss: 0.007426\n",
      "Epoch: 9211/10000 Iteration: 64478 Train loss: 0.007426\n",
      "Epoch: 9212/10000 Iteration: 64485 Train loss: 0.007426\n",
      "Epoch: 9213/10000 Iteration: 64492 Train loss: 0.007426\n",
      "Epoch: 9214/10000 Iteration: 64499 Train loss: 0.007426\n",
      "Epoch: 9215/10000 Iteration: 64506 Train loss: 0.007426\n",
      "Epoch: 9216/10000 Iteration: 64513 Train loss: 0.007426\n",
      "Epoch: 9217/10000 Iteration: 64520 Train loss: 0.007426\n",
      "Epoch: 9218/10000 Iteration: 64527 Train loss: 0.007426\n",
      "Epoch: 9219/10000 Iteration: 64534 Train loss: 0.007426\n",
      "Epoch: 9220/10000 Iteration: 64541 Train loss: 0.007426\n",
      "Epoch: 9221/10000 Iteration: 64548 Train loss: 0.007426\n",
      "Epoch: 9222/10000 Iteration: 64555 Train loss: 0.007426\n",
      "Epoch: 9223/10000 Iteration: 64562 Train loss: 0.007426\n",
      "Epoch: 9224/10000 Iteration: 64569 Train loss: 0.007426\n",
      "Epoch: 9225/10000 Iteration: 64576 Train loss: 0.007426\n",
      "Epoch: 9226/10000 Iteration: 64583 Train loss: 0.007426\n",
      "Epoch: 9227/10000 Iteration: 64590 Train loss: 0.007426\n",
      "Epoch: 9228/10000 Iteration: 64597 Train loss: 0.007426\n",
      "Epoch: 9229/10000 Iteration: 64604 Train loss: 0.007426\n",
      "Epoch: 9230/10000 Iteration: 64611 Train loss: 0.007426\n",
      "Epoch: 9231/10000 Iteration: 64618 Train loss: 0.007426\n",
      "Epoch: 9232/10000 Iteration: 64625 Train loss: 0.007426\n",
      "Epoch: 9233/10000 Iteration: 64632 Train loss: 0.007426\n",
      "Epoch: 9234/10000 Iteration: 64639 Train loss: 0.007425\n",
      "Epoch: 9235/10000 Iteration: 64646 Train loss: 0.007425\n",
      "Epoch: 9236/10000 Iteration: 64653 Train loss: 0.007425\n",
      "Epoch: 9237/10000 Iteration: 64660 Train loss: 0.007425\n",
      "Epoch: 9238/10000 Iteration: 64667 Train loss: 0.007425\n",
      "Epoch: 9239/10000 Iteration: 64674 Train loss: 0.007425\n",
      "Epoch: 9240/10000 Iteration: 64681 Train loss: 0.007425\n",
      "Epoch: 9241/10000 Iteration: 64688 Train loss: 0.007425\n",
      "Epoch: 9242/10000 Iteration: 64695 Train loss: 0.007425\n",
      "Epoch: 9243/10000 Iteration: 64702 Train loss: 0.007425\n",
      "Epoch: 9244/10000 Iteration: 64709 Train loss: 0.007425\n",
      "Epoch: 9245/10000 Iteration: 64716 Train loss: 0.007425\n",
      "Epoch: 9246/10000 Iteration: 64723 Train loss: 0.007425\n",
      "Epoch: 9247/10000 Iteration: 64730 Train loss: 0.007425\n",
      "Epoch: 9248/10000 Iteration: 64737 Train loss: 0.007425\n",
      "Epoch: 9249/10000 Iteration: 64744 Train loss: 0.007425\n",
      "Epoch: 9250/10000 Iteration: 64751 Train loss: 0.007425\n",
      "Epoch: 9251/10000 Iteration: 64758 Train loss: 0.007425\n",
      "Epoch: 9252/10000 Iteration: 64765 Train loss: 0.007425\n",
      "Epoch: 9253/10000 Iteration: 64772 Train loss: 0.007425\n",
      "Epoch: 9254/10000 Iteration: 64779 Train loss: 0.007425\n",
      "Epoch: 9255/10000 Iteration: 64786 Train loss: 0.007425\n",
      "Epoch: 9256/10000 Iteration: 64793 Train loss: 0.007425\n",
      "Epoch: 9257/10000 Iteration: 64800 Train loss: 0.007425\n",
      "Epoch: 9258/10000 Iteration: 64807 Train loss: 0.007425\n",
      "Epoch: 9259/10000 Iteration: 64814 Train loss: 0.007425\n",
      "Epoch: 9260/10000 Iteration: 64821 Train loss: 0.007424\n",
      "Epoch: 9261/10000 Iteration: 64828 Train loss: 0.007424\n",
      "Epoch: 9262/10000 Iteration: 64835 Train loss: 0.007424\n",
      "Epoch: 9263/10000 Iteration: 64842 Train loss: 0.007424\n",
      "Epoch: 9264/10000 Iteration: 64849 Train loss: 0.007424\n",
      "Epoch: 9265/10000 Iteration: 64856 Train loss: 0.007424\n",
      "Epoch: 9266/10000 Iteration: 64863 Train loss: 0.007424\n",
      "Epoch: 9267/10000 Iteration: 64870 Train loss: 0.007424\n",
      "Epoch: 9268/10000 Iteration: 64877 Train loss: 0.007424\n",
      "Epoch: 9269/10000 Iteration: 64884 Train loss: 0.007424\n",
      "Epoch: 9270/10000 Iteration: 64891 Train loss: 0.007424\n",
      "Epoch: 9271/10000 Iteration: 64898 Train loss: 0.007424\n",
      "Epoch: 9272/10000 Iteration: 64905 Train loss: 0.007424\n",
      "Epoch: 9273/10000 Iteration: 64912 Train loss: 0.007424\n",
      "Epoch: 9274/10000 Iteration: 64919 Train loss: 0.007424\n",
      "Epoch: 9275/10000 Iteration: 64926 Train loss: 0.007424\n",
      "Epoch: 9276/10000 Iteration: 64933 Train loss: 0.007424\n",
      "Epoch: 9277/10000 Iteration: 64940 Train loss: 0.007424\n",
      "Epoch: 9278/10000 Iteration: 64947 Train loss: 0.007424\n",
      "Epoch: 9279/10000 Iteration: 64954 Train loss: 0.007424\n",
      "Epoch: 9280/10000 Iteration: 64961 Train loss: 0.007424\n",
      "Epoch: 9281/10000 Iteration: 64968 Train loss: 0.007424\n",
      "Epoch: 9282/10000 Iteration: 64975 Train loss: 0.007424\n",
      "Epoch: 9283/10000 Iteration: 64982 Train loss: 0.007424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9284/10000 Iteration: 64989 Train loss: 0.007424\n",
      "Epoch: 9285/10000 Iteration: 64996 Train loss: 0.007424\n",
      "Epoch: 9286/10000 Iteration: 65003 Train loss: 0.007424\n",
      "Epoch: 9287/10000 Iteration: 65010 Train loss: 0.007424\n",
      "Epoch: 9288/10000 Iteration: 65017 Train loss: 0.007423\n",
      "Epoch: 9289/10000 Iteration: 65024 Train loss: 0.007423\n",
      "Epoch: 9290/10000 Iteration: 65031 Train loss: 0.007423\n",
      "Epoch: 9291/10000 Iteration: 65038 Train loss: 0.007423\n",
      "Epoch: 9292/10000 Iteration: 65045 Train loss: 0.007423\n",
      "Epoch: 9293/10000 Iteration: 65052 Train loss: 0.007423\n",
      "Epoch: 9294/10000 Iteration: 65059 Train loss: 0.007423\n",
      "Epoch: 9295/10000 Iteration: 65066 Train loss: 0.007423\n",
      "Epoch: 9296/10000 Iteration: 65073 Train loss: 0.007423\n",
      "Epoch: 9297/10000 Iteration: 65080 Train loss: 0.007423\n",
      "Epoch: 9298/10000 Iteration: 65087 Train loss: 0.007423\n",
      "Epoch: 9299/10000 Iteration: 65094 Train loss: 0.007423\n",
      "Epoch: 9300/10000 Iteration: 65101 Train loss: 0.007423\n",
      "Epoch: 9301/10000 Iteration: 65108 Train loss: 0.007423\n",
      "Epoch: 9302/10000 Iteration: 65115 Train loss: 0.007423\n",
      "Epoch: 9303/10000 Iteration: 65122 Train loss: 0.007423\n",
      "Epoch: 9304/10000 Iteration: 65129 Train loss: 0.007423\n",
      "Epoch: 9305/10000 Iteration: 65136 Train loss: 0.007423\n",
      "Epoch: 9306/10000 Iteration: 65143 Train loss: 0.007423\n",
      "Epoch: 9307/10000 Iteration: 65150 Train loss: 0.007423\n",
      "Epoch: 9308/10000 Iteration: 65157 Train loss: 0.007423\n",
      "Epoch: 9309/10000 Iteration: 65164 Train loss: 0.007423\n",
      "Epoch: 9310/10000 Iteration: 65171 Train loss: 0.007423\n",
      "Epoch: 9311/10000 Iteration: 65178 Train loss: 0.007423\n",
      "Epoch: 9312/10000 Iteration: 65185 Train loss: 0.007423\n",
      "Epoch: 9313/10000 Iteration: 65192 Train loss: 0.007423\n",
      "Epoch: 9314/10000 Iteration: 65199 Train loss: 0.007423\n",
      "Epoch: 9315/10000 Iteration: 65206 Train loss: 0.007423\n",
      "Epoch: 9316/10000 Iteration: 65213 Train loss: 0.007423\n",
      "Epoch: 9317/10000 Iteration: 65220 Train loss: 0.007423\n",
      "Epoch: 9318/10000 Iteration: 65227 Train loss: 0.007422\n",
      "Epoch: 9319/10000 Iteration: 65234 Train loss: 0.007422\n",
      "Epoch: 9320/10000 Iteration: 65241 Train loss: 0.007422\n",
      "Epoch: 9321/10000 Iteration: 65248 Train loss: 0.007422\n",
      "Epoch: 9322/10000 Iteration: 65255 Train loss: 0.007422\n",
      "Epoch: 9323/10000 Iteration: 65262 Train loss: 0.007422\n",
      "Epoch: 9324/10000 Iteration: 65269 Train loss: 0.007422\n",
      "Epoch: 9325/10000 Iteration: 65276 Train loss: 0.007422\n",
      "Epoch: 9326/10000 Iteration: 65283 Train loss: 0.007422\n",
      "Epoch: 9327/10000 Iteration: 65290 Train loss: 0.007422\n",
      "Epoch: 9328/10000 Iteration: 65297 Train loss: 0.007422\n",
      "Epoch: 9329/10000 Iteration: 65304 Train loss: 0.007422\n",
      "Epoch: 9330/10000 Iteration: 65311 Train loss: 0.007422\n",
      "Epoch: 9331/10000 Iteration: 65318 Train loss: 0.007422\n",
      "Epoch: 9332/10000 Iteration: 65325 Train loss: 0.007422\n",
      "Epoch: 9333/10000 Iteration: 65332 Train loss: 0.007422\n",
      "Epoch: 9334/10000 Iteration: 65339 Train loss: 0.007422\n",
      "Epoch: 9335/10000 Iteration: 65346 Train loss: 0.007422\n",
      "Epoch: 9336/10000 Iteration: 65353 Train loss: 0.007422\n",
      "Epoch: 9337/10000 Iteration: 65360 Train loss: 0.007422\n",
      "Epoch: 9338/10000 Iteration: 65367 Train loss: 0.007422\n",
      "Epoch: 9339/10000 Iteration: 65374 Train loss: 0.007422\n",
      "Epoch: 9340/10000 Iteration: 65381 Train loss: 0.007422\n",
      "Epoch: 9341/10000 Iteration: 65388 Train loss: 0.007422\n",
      "Epoch: 9342/10000 Iteration: 65395 Train loss: 0.007422\n",
      "Epoch: 9343/10000 Iteration: 65402 Train loss: 0.007422\n",
      "Epoch: 9344/10000 Iteration: 65409 Train loss: 0.007422\n",
      "Epoch: 9345/10000 Iteration: 65416 Train loss: 0.007422\n",
      "Epoch: 9346/10000 Iteration: 65423 Train loss: 0.007422\n",
      "Epoch: 9347/10000 Iteration: 65430 Train loss: 0.007422\n",
      "Epoch: 9348/10000 Iteration: 65437 Train loss: 0.007422\n",
      "Epoch: 9349/10000 Iteration: 65444 Train loss: 0.007422\n",
      "Epoch: 9350/10000 Iteration: 65451 Train loss: 0.007422\n",
      "Epoch: 9351/10000 Iteration: 65458 Train loss: 0.007421\n",
      "Epoch: 9352/10000 Iteration: 65465 Train loss: 0.007421\n",
      "Epoch: 9353/10000 Iteration: 65472 Train loss: 0.007421\n",
      "Epoch: 9354/10000 Iteration: 65479 Train loss: 0.007421\n",
      "Epoch: 9355/10000 Iteration: 65486 Train loss: 0.007421\n",
      "Epoch: 9356/10000 Iteration: 65493 Train loss: 0.007421\n",
      "Epoch: 9357/10000 Iteration: 65500 Train loss: 0.007421\n",
      "Epoch: 9358/10000 Iteration: 65507 Train loss: 0.007421\n",
      "Epoch: 9359/10000 Iteration: 65514 Train loss: 0.007421\n",
      "Epoch: 9360/10000 Iteration: 65521 Train loss: 0.007421\n",
      "Epoch: 9361/10000 Iteration: 65528 Train loss: 0.007421\n",
      "Epoch: 9362/10000 Iteration: 65535 Train loss: 0.007421\n",
      "Epoch: 9363/10000 Iteration: 65542 Train loss: 0.007421\n",
      "Epoch: 9364/10000 Iteration: 65549 Train loss: 0.007421\n",
      "Epoch: 9365/10000 Iteration: 65556 Train loss: 0.007421\n",
      "Epoch: 9366/10000 Iteration: 65563 Train loss: 0.007421\n",
      "Epoch: 9367/10000 Iteration: 65570 Train loss: 0.007421\n",
      "Epoch: 9368/10000 Iteration: 65577 Train loss: 0.007421\n",
      "Epoch: 9369/10000 Iteration: 65584 Train loss: 0.007421\n",
      "Epoch: 9370/10000 Iteration: 65591 Train loss: 0.007421\n",
      "Epoch: 9371/10000 Iteration: 65598 Train loss: 0.007421\n",
      "Epoch: 9372/10000 Iteration: 65605 Train loss: 0.007421\n",
      "Epoch: 9373/10000 Iteration: 65612 Train loss: 0.007421\n",
      "Epoch: 9374/10000 Iteration: 65619 Train loss: 0.007421\n",
      "Epoch: 9375/10000 Iteration: 65626 Train loss: 0.007421\n",
      "Epoch: 9376/10000 Iteration: 65633 Train loss: 0.007421\n",
      "Epoch: 9377/10000 Iteration: 65640 Train loss: 0.007421\n",
      "Epoch: 9378/10000 Iteration: 65647 Train loss: 0.007421\n",
      "Epoch: 9379/10000 Iteration: 65654 Train loss: 0.007421\n",
      "Epoch: 9380/10000 Iteration: 65661 Train loss: 0.007421\n",
      "Epoch: 9381/10000 Iteration: 65668 Train loss: 0.007421\n",
      "Epoch: 9382/10000 Iteration: 65675 Train loss: 0.007421\n",
      "Epoch: 9383/10000 Iteration: 65682 Train loss: 0.007421\n",
      "Epoch: 9384/10000 Iteration: 65689 Train loss: 0.007421\n",
      "Epoch: 9385/10000 Iteration: 65696 Train loss: 0.007421\n",
      "Epoch: 9386/10000 Iteration: 65703 Train loss: 0.007421\n",
      "Epoch: 9387/10000 Iteration: 65710 Train loss: 0.007420\n",
      "Epoch: 9388/10000 Iteration: 65717 Train loss: 0.007420\n",
      "Epoch: 9389/10000 Iteration: 65724 Train loss: 0.007420\n",
      "Epoch: 9390/10000 Iteration: 65731 Train loss: 0.007420\n",
      "Epoch: 9391/10000 Iteration: 65738 Train loss: 0.007420\n",
      "Epoch: 9392/10000 Iteration: 65745 Train loss: 0.007420\n",
      "Epoch: 9393/10000 Iteration: 65752 Train loss: 0.007420\n",
      "Epoch: 9394/10000 Iteration: 65759 Train loss: 0.007420\n",
      "Epoch: 9395/10000 Iteration: 65766 Train loss: 0.007420\n",
      "Epoch: 9396/10000 Iteration: 65773 Train loss: 0.007420\n",
      "Epoch: 9397/10000 Iteration: 65780 Train loss: 0.007420\n",
      "Epoch: 9398/10000 Iteration: 65787 Train loss: 0.007420\n",
      "Epoch: 9399/10000 Iteration: 65794 Train loss: 0.007420\n",
      "Epoch: 9400/10000 Iteration: 65801 Train loss: 0.007420\n",
      "Epoch: 9401/10000 Iteration: 65808 Train loss: 0.007420\n",
      "Epoch: 9402/10000 Iteration: 65815 Train loss: 0.007420\n",
      "Epoch: 9403/10000 Iteration: 65822 Train loss: 0.007420\n",
      "Epoch: 9404/10000 Iteration: 65829 Train loss: 0.007420\n",
      "Epoch: 9405/10000 Iteration: 65836 Train loss: 0.007420\n",
      "Epoch: 9406/10000 Iteration: 65843 Train loss: 0.007420\n",
      "Epoch: 9407/10000 Iteration: 65850 Train loss: 0.007420\n",
      "Epoch: 9408/10000 Iteration: 65857 Train loss: 0.007420\n",
      "Epoch: 9409/10000 Iteration: 65864 Train loss: 0.007420\n",
      "Epoch: 9410/10000 Iteration: 65871 Train loss: 0.007420\n",
      "Epoch: 9411/10000 Iteration: 65878 Train loss: 0.007420\n",
      "Epoch: 9412/10000 Iteration: 65885 Train loss: 0.007420\n",
      "Epoch: 9413/10000 Iteration: 65892 Train loss: 0.007420\n",
      "Epoch: 9414/10000 Iteration: 65899 Train loss: 0.007420\n",
      "Epoch: 9415/10000 Iteration: 65906 Train loss: 0.007420\n",
      "Epoch: 9416/10000 Iteration: 65913 Train loss: 0.007420\n",
      "Epoch: 9417/10000 Iteration: 65920 Train loss: 0.007420\n",
      "Epoch: 9418/10000 Iteration: 65927 Train loss: 0.007420\n",
      "Epoch: 9419/10000 Iteration: 65934 Train loss: 0.007420\n",
      "Epoch: 9420/10000 Iteration: 65941 Train loss: 0.007420\n",
      "Epoch: 9421/10000 Iteration: 65948 Train loss: 0.007420\n",
      "Epoch: 9422/10000 Iteration: 65955 Train loss: 0.007420\n",
      "Epoch: 9423/10000 Iteration: 65962 Train loss: 0.007420\n",
      "Epoch: 9424/10000 Iteration: 65969 Train loss: 0.007420\n",
      "Epoch: 9425/10000 Iteration: 65976 Train loss: 0.007420\n",
      "Epoch: 9426/10000 Iteration: 65983 Train loss: 0.007420\n",
      "Epoch: 9427/10000 Iteration: 65990 Train loss: 0.007419\n",
      "Epoch: 9428/10000 Iteration: 65997 Train loss: 0.007419\n",
      "Epoch: 9429/10000 Iteration: 66004 Train loss: 0.007419\n",
      "Epoch: 9430/10000 Iteration: 66011 Train loss: 0.007419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9431/10000 Iteration: 66018 Train loss: 0.007419\n",
      "Epoch: 9432/10000 Iteration: 66025 Train loss: 0.007419\n",
      "Epoch: 9433/10000 Iteration: 66032 Train loss: 0.007419\n",
      "Epoch: 9434/10000 Iteration: 66039 Train loss: 0.007419\n",
      "Epoch: 9435/10000 Iteration: 66046 Train loss: 0.007419\n",
      "Epoch: 9436/10000 Iteration: 66053 Train loss: 0.007419\n",
      "Epoch: 9437/10000 Iteration: 66060 Train loss: 0.007419\n",
      "Epoch: 9438/10000 Iteration: 66067 Train loss: 0.007419\n",
      "Epoch: 9439/10000 Iteration: 66074 Train loss: 0.007419\n",
      "Epoch: 9440/10000 Iteration: 66081 Train loss: 0.007419\n",
      "Epoch: 9441/10000 Iteration: 66088 Train loss: 0.007419\n",
      "Epoch: 9442/10000 Iteration: 66095 Train loss: 0.007419\n",
      "Epoch: 9443/10000 Iteration: 66102 Train loss: 0.007419\n",
      "Epoch: 9444/10000 Iteration: 66109 Train loss: 0.007419\n",
      "Epoch: 9445/10000 Iteration: 66116 Train loss: 0.007419\n",
      "Epoch: 9446/10000 Iteration: 66123 Train loss: 0.007419\n",
      "Epoch: 9447/10000 Iteration: 66130 Train loss: 0.007419\n",
      "Epoch: 9448/10000 Iteration: 66137 Train loss: 0.007419\n",
      "Epoch: 9449/10000 Iteration: 66144 Train loss: 0.007419\n",
      "Epoch: 9450/10000 Iteration: 66151 Train loss: 0.007419\n",
      "Epoch: 9451/10000 Iteration: 66158 Train loss: 0.007419\n",
      "Epoch: 9452/10000 Iteration: 66165 Train loss: 0.007419\n",
      "Epoch: 9453/10000 Iteration: 66172 Train loss: 0.007419\n",
      "Epoch: 9454/10000 Iteration: 66179 Train loss: 0.007419\n",
      "Epoch: 9455/10000 Iteration: 66186 Train loss: 0.007419\n",
      "Epoch: 9456/10000 Iteration: 66193 Train loss: 0.007419\n",
      "Epoch: 9457/10000 Iteration: 66200 Train loss: 0.007419\n",
      "Epoch: 9458/10000 Iteration: 66207 Train loss: 0.007419\n",
      "Epoch: 9459/10000 Iteration: 66214 Train loss: 0.007419\n",
      "Epoch: 9460/10000 Iteration: 66221 Train loss: 0.007419\n",
      "Epoch: 9461/10000 Iteration: 66228 Train loss: 0.007419\n",
      "Epoch: 9462/10000 Iteration: 66235 Train loss: 0.007419\n",
      "Epoch: 9463/10000 Iteration: 66242 Train loss: 0.007419\n",
      "Epoch: 9464/10000 Iteration: 66249 Train loss: 0.007419\n",
      "Epoch: 9465/10000 Iteration: 66256 Train loss: 0.007419\n",
      "Epoch: 9466/10000 Iteration: 66263 Train loss: 0.007419\n",
      "Epoch: 9467/10000 Iteration: 66270 Train loss: 0.007419\n",
      "Epoch: 9468/10000 Iteration: 66277 Train loss: 0.007419\n",
      "Epoch: 9469/10000 Iteration: 66284 Train loss: 0.007419\n",
      "Epoch: 9470/10000 Iteration: 66291 Train loss: 0.007419\n",
      "Epoch: 9471/10000 Iteration: 66298 Train loss: 0.007418\n",
      "Epoch: 9472/10000 Iteration: 66305 Train loss: 0.007418\n",
      "Epoch: 9473/10000 Iteration: 66312 Train loss: 0.007418\n",
      "Epoch: 9474/10000 Iteration: 66319 Train loss: 0.007418\n",
      "Epoch: 9475/10000 Iteration: 66326 Train loss: 0.007418\n",
      "Epoch: 9476/10000 Iteration: 66333 Train loss: 0.007418\n",
      "Epoch: 9477/10000 Iteration: 66340 Train loss: 0.007418\n",
      "Epoch: 9478/10000 Iteration: 66347 Train loss: 0.007418\n",
      "Epoch: 9479/10000 Iteration: 66354 Train loss: 0.007418\n",
      "Epoch: 9480/10000 Iteration: 66361 Train loss: 0.007418\n",
      "Epoch: 9481/10000 Iteration: 66368 Train loss: 0.007418\n",
      "Epoch: 9482/10000 Iteration: 66375 Train loss: 0.007418\n",
      "Epoch: 9483/10000 Iteration: 66382 Train loss: 0.007418\n",
      "Epoch: 9484/10000 Iteration: 66389 Train loss: 0.007418\n",
      "Epoch: 9485/10000 Iteration: 66396 Train loss: 0.007418\n",
      "Epoch: 9486/10000 Iteration: 66403 Train loss: 0.007418\n",
      "Epoch: 9487/10000 Iteration: 66410 Train loss: 0.007418\n",
      "Epoch: 9488/10000 Iteration: 66417 Train loss: 0.007418\n",
      "Epoch: 9489/10000 Iteration: 66424 Train loss: 0.007418\n",
      "Epoch: 9490/10000 Iteration: 66431 Train loss: 0.007418\n",
      "Epoch: 9491/10000 Iteration: 66438 Train loss: 0.007418\n",
      "Epoch: 9492/10000 Iteration: 66445 Train loss: 0.007418\n",
      "Epoch: 9493/10000 Iteration: 66452 Train loss: 0.007418\n",
      "Epoch: 9494/10000 Iteration: 66459 Train loss: 0.007418\n",
      "Epoch: 9495/10000 Iteration: 66466 Train loss: 0.007418\n",
      "Epoch: 9496/10000 Iteration: 66473 Train loss: 0.007418\n",
      "Epoch: 9497/10000 Iteration: 66480 Train loss: 0.007418\n",
      "Epoch: 9498/10000 Iteration: 66487 Train loss: 0.007418\n",
      "Epoch: 9499/10000 Iteration: 66494 Train loss: 0.007418\n",
      "Epoch: 9500/10000 Iteration: 66501 Train loss: 0.007418\n",
      "Epoch: 9501/10000 Iteration: 66508 Train loss: 0.007418\n",
      "Epoch: 9502/10000 Iteration: 66515 Train loss: 0.007418\n",
      "Epoch: 9503/10000 Iteration: 66522 Train loss: 0.007418\n",
      "Epoch: 9504/10000 Iteration: 66529 Train loss: 0.007418\n",
      "Epoch: 9505/10000 Iteration: 66536 Train loss: 0.007418\n",
      "Epoch: 9506/10000 Iteration: 66543 Train loss: 0.007418\n",
      "Epoch: 9507/10000 Iteration: 66550 Train loss: 0.007418\n",
      "Epoch: 9508/10000 Iteration: 66557 Train loss: 0.007418\n",
      "Epoch: 9509/10000 Iteration: 66564 Train loss: 0.007418\n",
      "Epoch: 9510/10000 Iteration: 66571 Train loss: 0.007418\n",
      "Epoch: 9511/10000 Iteration: 66578 Train loss: 0.007418\n",
      "Epoch: 9512/10000 Iteration: 66585 Train loss: 0.007418\n",
      "Epoch: 9513/10000 Iteration: 66592 Train loss: 0.007418\n",
      "Epoch: 9514/10000 Iteration: 66599 Train loss: 0.007418\n",
      "Epoch: 9515/10000 Iteration: 66606 Train loss: 0.007418\n",
      "Epoch: 9516/10000 Iteration: 66613 Train loss: 0.007418\n",
      "Epoch: 9517/10000 Iteration: 66620 Train loss: 0.007418\n",
      "Epoch: 9518/10000 Iteration: 66627 Train loss: 0.007418\n",
      "Epoch: 9519/10000 Iteration: 66634 Train loss: 0.007418\n",
      "Epoch: 9520/10000 Iteration: 66641 Train loss: 0.007418\n",
      "Epoch: 9521/10000 Iteration: 66648 Train loss: 0.007418\n",
      "Epoch: 9522/10000 Iteration: 66655 Train loss: 0.007418\n",
      "Epoch: 9523/10000 Iteration: 66662 Train loss: 0.007418\n",
      "Epoch: 9524/10000 Iteration: 66669 Train loss: 0.007418\n",
      "Epoch: 9525/10000 Iteration: 66676 Train loss: 0.007418\n",
      "Epoch: 9526/10000 Iteration: 66683 Train loss: 0.007418\n",
      "Epoch: 9527/10000 Iteration: 66690 Train loss: 0.007417\n",
      "Epoch: 9528/10000 Iteration: 66697 Train loss: 0.007417\n",
      "Epoch: 9529/10000 Iteration: 66704 Train loss: 0.007417\n",
      "Epoch: 9530/10000 Iteration: 66711 Train loss: 0.007417\n",
      "Epoch: 9531/10000 Iteration: 66718 Train loss: 0.007417\n",
      "Epoch: 9532/10000 Iteration: 66725 Train loss: 0.007417\n",
      "Epoch: 9533/10000 Iteration: 66732 Train loss: 0.007417\n",
      "Epoch: 9534/10000 Iteration: 66739 Train loss: 0.007417\n",
      "Epoch: 9535/10000 Iteration: 66746 Train loss: 0.007417\n",
      "Epoch: 9536/10000 Iteration: 66753 Train loss: 0.007417\n",
      "Epoch: 9537/10000 Iteration: 66760 Train loss: 0.007417\n",
      "Epoch: 9538/10000 Iteration: 66767 Train loss: 0.007417\n",
      "Epoch: 9539/10000 Iteration: 66774 Train loss: 0.007417\n",
      "Epoch: 9540/10000 Iteration: 66781 Train loss: 0.007417\n",
      "Epoch: 9541/10000 Iteration: 66788 Train loss: 0.007417\n",
      "Epoch: 9542/10000 Iteration: 66795 Train loss: 0.007417\n",
      "Epoch: 9543/10000 Iteration: 66802 Train loss: 0.007417\n",
      "Epoch: 9544/10000 Iteration: 66809 Train loss: 0.007417\n",
      "Epoch: 9545/10000 Iteration: 66816 Train loss: 0.007417\n",
      "Epoch: 9546/10000 Iteration: 66823 Train loss: 0.007417\n",
      "Epoch: 9547/10000 Iteration: 66830 Train loss: 0.007417\n",
      "Epoch: 9548/10000 Iteration: 66837 Train loss: 0.007417\n",
      "Epoch: 9549/10000 Iteration: 66844 Train loss: 0.007417\n",
      "Epoch: 9550/10000 Iteration: 66851 Train loss: 0.007417\n",
      "Epoch: 9551/10000 Iteration: 66858 Train loss: 0.007417\n",
      "Epoch: 9552/10000 Iteration: 66865 Train loss: 0.007417\n",
      "Epoch: 9553/10000 Iteration: 66872 Train loss: 0.007417\n",
      "Epoch: 9554/10000 Iteration: 66879 Train loss: 0.007417\n",
      "Epoch: 9555/10000 Iteration: 66886 Train loss: 0.007417\n",
      "Epoch: 9556/10000 Iteration: 66893 Train loss: 0.007417\n",
      "Epoch: 9557/10000 Iteration: 66900 Train loss: 0.007417\n",
      "Epoch: 9558/10000 Iteration: 66907 Train loss: 0.007417\n",
      "Epoch: 9559/10000 Iteration: 66914 Train loss: 0.007417\n",
      "Epoch: 9560/10000 Iteration: 66921 Train loss: 0.007417\n",
      "Epoch: 9561/10000 Iteration: 66928 Train loss: 0.007417\n",
      "Epoch: 9562/10000 Iteration: 66935 Train loss: 0.007417\n",
      "Epoch: 9563/10000 Iteration: 66942 Train loss: 0.007417\n",
      "Epoch: 9564/10000 Iteration: 66949 Train loss: 0.007417\n",
      "Epoch: 9565/10000 Iteration: 66956 Train loss: 0.007417\n",
      "Epoch: 9566/10000 Iteration: 66963 Train loss: 0.007417\n",
      "Epoch: 9567/10000 Iteration: 66970 Train loss: 0.007417\n",
      "Epoch: 9568/10000 Iteration: 66977 Train loss: 0.007417\n",
      "Epoch: 9569/10000 Iteration: 66984 Train loss: 0.007417\n",
      "Epoch: 9570/10000 Iteration: 66991 Train loss: 0.007417\n",
      "Epoch: 9571/10000 Iteration: 66998 Train loss: 0.007417\n",
      "Epoch: 9572/10000 Iteration: 67005 Train loss: 0.007417\n",
      "Epoch: 9573/10000 Iteration: 67012 Train loss: 0.007417\n",
      "Epoch: 9574/10000 Iteration: 67019 Train loss: 0.007417\n",
      "Epoch: 9575/10000 Iteration: 67026 Train loss: 0.007417\n",
      "Epoch: 9576/10000 Iteration: 67033 Train loss: 0.007417\n",
      "Epoch: 9577/10000 Iteration: 67040 Train loss: 0.007417\n",
      "Epoch: 9578/10000 Iteration: 67047 Train loss: 0.007417\n",
      "Epoch: 9579/10000 Iteration: 67054 Train loss: 0.007417\n",
      "Epoch: 9580/10000 Iteration: 67061 Train loss: 0.007417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9581/10000 Iteration: 67068 Train loss: 0.007417\n",
      "Epoch: 9582/10000 Iteration: 67075 Train loss: 0.007417\n",
      "Epoch: 9583/10000 Iteration: 67082 Train loss: 0.007417\n",
      "Epoch: 9584/10000 Iteration: 67089 Train loss: 0.007417\n",
      "Epoch: 9585/10000 Iteration: 67096 Train loss: 0.007417\n",
      "Epoch: 9586/10000 Iteration: 67103 Train loss: 0.007417\n",
      "Epoch: 9587/10000 Iteration: 67110 Train loss: 0.007417\n",
      "Epoch: 9588/10000 Iteration: 67117 Train loss: 0.007417\n",
      "Epoch: 9589/10000 Iteration: 67124 Train loss: 0.007417\n",
      "Epoch: 9590/10000 Iteration: 67131 Train loss: 0.007417\n",
      "Epoch: 9591/10000 Iteration: 67138 Train loss: 0.007417\n",
      "Epoch: 9592/10000 Iteration: 67145 Train loss: 0.007417\n",
      "Epoch: 9593/10000 Iteration: 67152 Train loss: 0.007417\n",
      "Epoch: 9594/10000 Iteration: 67159 Train loss: 0.007417\n",
      "Epoch: 9595/10000 Iteration: 67166 Train loss: 0.007417\n",
      "Epoch: 9596/10000 Iteration: 67173 Train loss: 0.007417\n",
      "Epoch: 9597/10000 Iteration: 67180 Train loss: 0.007417\n",
      "Epoch: 9598/10000 Iteration: 67187 Train loss: 0.007417\n",
      "Epoch: 9599/10000 Iteration: 67194 Train loss: 0.007417\n",
      "Epoch: 9600/10000 Iteration: 67201 Train loss: 0.007417\n",
      "Epoch: 9601/10000 Iteration: 67208 Train loss: 0.007417\n",
      "Epoch: 9602/10000 Iteration: 67215 Train loss: 0.007417\n",
      "Epoch: 9603/10000 Iteration: 67222 Train loss: 0.007417\n",
      "Epoch: 9604/10000 Iteration: 67229 Train loss: 0.007416\n",
      "Epoch: 9605/10000 Iteration: 67236 Train loss: 0.007416\n",
      "Epoch: 9606/10000 Iteration: 67243 Train loss: 0.007416\n",
      "Epoch: 9607/10000 Iteration: 67250 Train loss: 0.007416\n",
      "Epoch: 9608/10000 Iteration: 67257 Train loss: 0.007416\n",
      "Epoch: 9609/10000 Iteration: 67264 Train loss: 0.007416\n",
      "Epoch: 9610/10000 Iteration: 67271 Train loss: 0.007416\n",
      "Epoch: 9611/10000 Iteration: 67278 Train loss: 0.007416\n",
      "Epoch: 9612/10000 Iteration: 67285 Train loss: 0.007416\n",
      "Epoch: 9613/10000 Iteration: 67292 Train loss: 0.007416\n",
      "Epoch: 9614/10000 Iteration: 67299 Train loss: 0.007416\n",
      "Epoch: 9615/10000 Iteration: 67306 Train loss: 0.007416\n",
      "Epoch: 9616/10000 Iteration: 67313 Train loss: 0.007416\n",
      "Epoch: 9617/10000 Iteration: 67320 Train loss: 0.007416\n",
      "Epoch: 9618/10000 Iteration: 67327 Train loss: 0.007416\n",
      "Epoch: 9619/10000 Iteration: 67334 Train loss: 0.007416\n",
      "Epoch: 9620/10000 Iteration: 67341 Train loss: 0.007416\n",
      "Epoch: 9621/10000 Iteration: 67348 Train loss: 0.007416\n",
      "Epoch: 9622/10000 Iteration: 67355 Train loss: 0.007416\n",
      "Epoch: 9623/10000 Iteration: 67362 Train loss: 0.007416\n",
      "Epoch: 9624/10000 Iteration: 67369 Train loss: 0.007416\n",
      "Epoch: 9625/10000 Iteration: 67376 Train loss: 0.007416\n",
      "Epoch: 9626/10000 Iteration: 67383 Train loss: 0.007416\n",
      "Epoch: 9627/10000 Iteration: 67390 Train loss: 0.007416\n",
      "Epoch: 9628/10000 Iteration: 67397 Train loss: 0.007416\n",
      "Epoch: 9629/10000 Iteration: 67404 Train loss: 0.007416\n",
      "Epoch: 9630/10000 Iteration: 67411 Train loss: 0.007416\n",
      "Epoch: 9631/10000 Iteration: 67418 Train loss: 0.007416\n",
      "Epoch: 9632/10000 Iteration: 67425 Train loss: 0.007416\n",
      "Epoch: 9633/10000 Iteration: 67432 Train loss: 0.007416\n",
      "Epoch: 9634/10000 Iteration: 67439 Train loss: 0.007416\n",
      "Epoch: 9635/10000 Iteration: 67446 Train loss: 0.007416\n",
      "Epoch: 9636/10000 Iteration: 67453 Train loss: 0.007416\n",
      "Epoch: 9637/10000 Iteration: 67460 Train loss: 0.007416\n",
      "Epoch: 9638/10000 Iteration: 67467 Train loss: 0.007416\n",
      "Epoch: 9639/10000 Iteration: 67474 Train loss: 0.007416\n",
      "Epoch: 9640/10000 Iteration: 67481 Train loss: 0.007416\n",
      "Epoch: 9641/10000 Iteration: 67488 Train loss: 0.007416\n",
      "Epoch: 9642/10000 Iteration: 67495 Train loss: 0.007416\n",
      "Epoch: 9643/10000 Iteration: 67502 Train loss: 0.007416\n",
      "Epoch: 9644/10000 Iteration: 67509 Train loss: 0.007416\n",
      "Epoch: 9645/10000 Iteration: 67516 Train loss: 0.007416\n",
      "Epoch: 9646/10000 Iteration: 67523 Train loss: 0.007416\n",
      "Epoch: 9647/10000 Iteration: 67530 Train loss: 0.007416\n",
      "Epoch: 9648/10000 Iteration: 67537 Train loss: 0.007416\n",
      "Epoch: 9649/10000 Iteration: 67544 Train loss: 0.007416\n",
      "Epoch: 9650/10000 Iteration: 67551 Train loss: 0.007416\n",
      "Epoch: 9651/10000 Iteration: 67558 Train loss: 0.007416\n",
      "Epoch: 9652/10000 Iteration: 67565 Train loss: 0.007416\n",
      "Epoch: 9653/10000 Iteration: 67572 Train loss: 0.007416\n",
      "Epoch: 9654/10000 Iteration: 67579 Train loss: 0.007416\n",
      "Epoch: 9655/10000 Iteration: 67586 Train loss: 0.007416\n",
      "Epoch: 9656/10000 Iteration: 67593 Train loss: 0.007416\n",
      "Epoch: 9657/10000 Iteration: 67600 Train loss: 0.007416\n",
      "Epoch: 9658/10000 Iteration: 67607 Train loss: 0.007416\n",
      "Epoch: 9659/10000 Iteration: 67614 Train loss: 0.007416\n",
      "Epoch: 9660/10000 Iteration: 67621 Train loss: 0.007416\n",
      "Epoch: 9661/10000 Iteration: 67628 Train loss: 0.007416\n",
      "Epoch: 9662/10000 Iteration: 67635 Train loss: 0.007416\n",
      "Epoch: 9663/10000 Iteration: 67642 Train loss: 0.007416\n",
      "Epoch: 9664/10000 Iteration: 67649 Train loss: 0.007416\n",
      "Epoch: 9665/10000 Iteration: 67656 Train loss: 0.007416\n",
      "Epoch: 9666/10000 Iteration: 67663 Train loss: 0.007416\n",
      "Epoch: 9667/10000 Iteration: 67670 Train loss: 0.007416\n",
      "Epoch: 9668/10000 Iteration: 67677 Train loss: 0.007416\n",
      "Epoch: 9669/10000 Iteration: 67684 Train loss: 0.007416\n",
      "Epoch: 9670/10000 Iteration: 67691 Train loss: 0.007416\n",
      "Epoch: 9671/10000 Iteration: 67698 Train loss: 0.007416\n",
      "Epoch: 9672/10000 Iteration: 67705 Train loss: 0.007416\n",
      "Epoch: 9673/10000 Iteration: 67712 Train loss: 0.007416\n",
      "Epoch: 9674/10000 Iteration: 67719 Train loss: 0.007416\n",
      "Epoch: 9675/10000 Iteration: 67726 Train loss: 0.007416\n",
      "Epoch: 9676/10000 Iteration: 67733 Train loss: 0.007416\n",
      "Epoch: 9677/10000 Iteration: 67740 Train loss: 0.007416\n",
      "Epoch: 9678/10000 Iteration: 67747 Train loss: 0.007416\n",
      "Epoch: 9679/10000 Iteration: 67754 Train loss: 0.007416\n",
      "Epoch: 9680/10000 Iteration: 67761 Train loss: 0.007416\n",
      "Epoch: 9681/10000 Iteration: 67768 Train loss: 0.007416\n",
      "Epoch: 9682/10000 Iteration: 67775 Train loss: 0.007416\n",
      "Epoch: 9683/10000 Iteration: 67782 Train loss: 0.007416\n",
      "Epoch: 9684/10000 Iteration: 67789 Train loss: 0.007416\n",
      "Epoch: 9685/10000 Iteration: 67796 Train loss: 0.007416\n",
      "Epoch: 9686/10000 Iteration: 67803 Train loss: 0.007416\n",
      "Epoch: 9687/10000 Iteration: 67810 Train loss: 0.007416\n",
      "Epoch: 9688/10000 Iteration: 67817 Train loss: 0.007416\n",
      "Epoch: 9689/10000 Iteration: 67824 Train loss: 0.007416\n",
      "Epoch: 9690/10000 Iteration: 67831 Train loss: 0.007416\n",
      "Epoch: 9691/10000 Iteration: 67838 Train loss: 0.007416\n",
      "Epoch: 9692/10000 Iteration: 67845 Train loss: 0.007416\n",
      "Epoch: 9693/10000 Iteration: 67852 Train loss: 0.007416\n",
      "Epoch: 9694/10000 Iteration: 67859 Train loss: 0.007416\n",
      "Epoch: 9695/10000 Iteration: 67866 Train loss: 0.007416\n",
      "Epoch: 9696/10000 Iteration: 67873 Train loss: 0.007416\n",
      "Epoch: 9697/10000 Iteration: 67880 Train loss: 0.007416\n",
      "Epoch: 9698/10000 Iteration: 67887 Train loss: 0.007416\n",
      "Epoch: 9699/10000 Iteration: 67894 Train loss: 0.007416\n",
      "Epoch: 9700/10000 Iteration: 67901 Train loss: 0.007416\n",
      "Epoch: 9701/10000 Iteration: 67908 Train loss: 0.007416\n",
      "Epoch: 9702/10000 Iteration: 67915 Train loss: 0.007416\n",
      "Epoch: 9703/10000 Iteration: 67922 Train loss: 0.007416\n",
      "Epoch: 9704/10000 Iteration: 67929 Train loss: 0.007416\n",
      "Epoch: 9705/10000 Iteration: 67936 Train loss: 0.007416\n",
      "Epoch: 9706/10000 Iteration: 67943 Train loss: 0.007416\n",
      "Epoch: 9707/10000 Iteration: 67950 Train loss: 0.007416\n",
      "Epoch: 9708/10000 Iteration: 67957 Train loss: 0.007416\n",
      "Epoch: 9709/10000 Iteration: 67964 Train loss: 0.007416\n",
      "Epoch: 9710/10000 Iteration: 67971 Train loss: 0.007416\n",
      "Epoch: 9711/10000 Iteration: 67978 Train loss: 0.007416\n",
      "Epoch: 9712/10000 Iteration: 67985 Train loss: 0.007416\n",
      "Epoch: 9713/10000 Iteration: 67992 Train loss: 0.007416\n",
      "Epoch: 9714/10000 Iteration: 67999 Train loss: 0.007416\n",
      "Epoch: 9715/10000 Iteration: 68006 Train loss: 0.007416\n",
      "Epoch: 9716/10000 Iteration: 68013 Train loss: 0.007416\n",
      "Epoch: 9717/10000 Iteration: 68020 Train loss: 0.007416\n",
      "Epoch: 9718/10000 Iteration: 68027 Train loss: 0.007416\n",
      "Epoch: 9719/10000 Iteration: 68034 Train loss: 0.007416\n",
      "Epoch: 9720/10000 Iteration: 68041 Train loss: 0.007416\n",
      "Epoch: 9721/10000 Iteration: 68048 Train loss: 0.007416\n",
      "Epoch: 9722/10000 Iteration: 68055 Train loss: 0.007416\n",
      "Epoch: 9723/10000 Iteration: 68062 Train loss: 0.007416\n",
      "Epoch: 9724/10000 Iteration: 68069 Train loss: 0.007416\n",
      "Epoch: 9725/10000 Iteration: 68076 Train loss: 0.007416\n",
      "Epoch: 9726/10000 Iteration: 68083 Train loss: 0.007416\n",
      "Epoch: 9727/10000 Iteration: 68090 Train loss: 0.007416\n",
      "Epoch: 9728/10000 Iteration: 68097 Train loss: 0.007416\n",
      "Epoch: 9729/10000 Iteration: 68104 Train loss: 0.007416\n",
      "Epoch: 9730/10000 Iteration: 68111 Train loss: 0.007416\n",
      "Epoch: 9731/10000 Iteration: 68118 Train loss: 0.007416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9732/10000 Iteration: 68125 Train loss: 0.007416\n",
      "Epoch: 9733/10000 Iteration: 68132 Train loss: 0.007416\n",
      "Epoch: 9734/10000 Iteration: 68139 Train loss: 0.007416\n",
      "Epoch: 9735/10000 Iteration: 68146 Train loss: 0.007416\n",
      "Epoch: 9736/10000 Iteration: 68153 Train loss: 0.007416\n",
      "Epoch: 9737/10000 Iteration: 68160 Train loss: 0.007416\n",
      "Epoch: 9738/10000 Iteration: 68167 Train loss: 0.007416\n",
      "Epoch: 9739/10000 Iteration: 68174 Train loss: 0.007416\n",
      "Epoch: 9740/10000 Iteration: 68181 Train loss: 0.007416\n",
      "Epoch: 9741/10000 Iteration: 68188 Train loss: 0.007416\n",
      "Epoch: 9742/10000 Iteration: 68195 Train loss: 0.007416\n",
      "Epoch: 9743/10000 Iteration: 68202 Train loss: 0.007416\n",
      "Epoch: 9744/10000 Iteration: 68209 Train loss: 0.007416\n",
      "Epoch: 9745/10000 Iteration: 68216 Train loss: 0.007416\n",
      "Epoch: 9746/10000 Iteration: 68223 Train loss: 0.007416\n",
      "Epoch: 9747/10000 Iteration: 68230 Train loss: 0.007416\n",
      "Epoch: 9748/10000 Iteration: 68237 Train loss: 0.007416\n",
      "Epoch: 9749/10000 Iteration: 68244 Train loss: 0.007416\n",
      "Epoch: 9750/10000 Iteration: 68251 Train loss: 0.007416\n",
      "Epoch: 9751/10000 Iteration: 68258 Train loss: 0.007416\n",
      "Epoch: 9752/10000 Iteration: 68265 Train loss: 0.007416\n",
      "Epoch: 9753/10000 Iteration: 68272 Train loss: 0.007416\n",
      "Epoch: 9754/10000 Iteration: 68279 Train loss: 0.007416\n",
      "Epoch: 9755/10000 Iteration: 68286 Train loss: 0.007416\n",
      "Epoch: 9756/10000 Iteration: 68293 Train loss: 0.007416\n",
      "Epoch: 9757/10000 Iteration: 68300 Train loss: 0.007416\n",
      "Epoch: 9758/10000 Iteration: 68307 Train loss: 0.007416\n",
      "Epoch: 9759/10000 Iteration: 68314 Train loss: 0.007416\n",
      "Epoch: 9760/10000 Iteration: 68321 Train loss: 0.007416\n",
      "Epoch: 9761/10000 Iteration: 68328 Train loss: 0.007416\n",
      "Epoch: 9762/10000 Iteration: 68335 Train loss: 0.007416\n",
      "Epoch: 9763/10000 Iteration: 68342 Train loss: 0.007416\n",
      "Epoch: 9764/10000 Iteration: 68349 Train loss: 0.007416\n",
      "Epoch: 9765/10000 Iteration: 68356 Train loss: 0.007416\n",
      "Epoch: 9766/10000 Iteration: 68363 Train loss: 0.007416\n",
      "Epoch: 9767/10000 Iteration: 68370 Train loss: 0.007416\n",
      "Epoch: 9768/10000 Iteration: 68377 Train loss: 0.007416\n",
      "Epoch: 9769/10000 Iteration: 68384 Train loss: 0.007416\n",
      "Epoch: 9770/10000 Iteration: 68391 Train loss: 0.007416\n",
      "Epoch: 9771/10000 Iteration: 68398 Train loss: 0.007416\n",
      "Epoch: 9772/10000 Iteration: 68405 Train loss: 0.007416\n",
      "Epoch: 9773/10000 Iteration: 68412 Train loss: 0.007416\n",
      "Epoch: 9774/10000 Iteration: 68419 Train loss: 0.007416\n",
      "Epoch: 9775/10000 Iteration: 68426 Train loss: 0.007416\n",
      "Epoch: 9776/10000 Iteration: 68433 Train loss: 0.007416\n",
      "Epoch: 9777/10000 Iteration: 68440 Train loss: 0.007416\n",
      "Epoch: 9778/10000 Iteration: 68447 Train loss: 0.007416\n",
      "Epoch: 9779/10000 Iteration: 68454 Train loss: 0.007416\n",
      "Epoch: 9780/10000 Iteration: 68461 Train loss: 0.007416\n",
      "Epoch: 9781/10000 Iteration: 68468 Train loss: 0.007416\n",
      "Epoch: 9782/10000 Iteration: 68475 Train loss: 0.007416\n",
      "Epoch: 9783/10000 Iteration: 68482 Train loss: 0.007416\n",
      "Epoch: 9784/10000 Iteration: 68489 Train loss: 0.007416\n",
      "Epoch: 9785/10000 Iteration: 68496 Train loss: 0.007416\n",
      "Epoch: 9786/10000 Iteration: 68503 Train loss: 0.007416\n",
      "Epoch: 9787/10000 Iteration: 68510 Train loss: 0.007416\n",
      "Epoch: 9788/10000 Iteration: 68517 Train loss: 0.007416\n",
      "Epoch: 9789/10000 Iteration: 68524 Train loss: 0.007416\n",
      "Epoch: 9790/10000 Iteration: 68531 Train loss: 0.007416\n",
      "Epoch: 9791/10000 Iteration: 68538 Train loss: 0.007416\n",
      "Epoch: 9792/10000 Iteration: 68545 Train loss: 0.007416\n",
      "Epoch: 9793/10000 Iteration: 68552 Train loss: 0.007416\n",
      "Epoch: 9794/10000 Iteration: 68559 Train loss: 0.007416\n",
      "Epoch: 9795/10000 Iteration: 68566 Train loss: 0.007416\n",
      "Epoch: 9796/10000 Iteration: 68573 Train loss: 0.007416\n",
      "Epoch: 9797/10000 Iteration: 68580 Train loss: 0.007416\n",
      "Epoch: 9798/10000 Iteration: 68587 Train loss: 0.007416\n",
      "Epoch: 9799/10000 Iteration: 68594 Train loss: 0.007416\n",
      "Epoch: 9800/10000 Iteration: 68601 Train loss: 0.007416\n",
      "Epoch: 9801/10000 Iteration: 68608 Train loss: 0.007416\n",
      "Epoch: 9802/10000 Iteration: 68615 Train loss: 0.007416\n",
      "Epoch: 9803/10000 Iteration: 68622 Train loss: 0.007416\n",
      "Epoch: 9804/10000 Iteration: 68629 Train loss: 0.007416\n",
      "Epoch: 9805/10000 Iteration: 68636 Train loss: 0.007416\n",
      "Epoch: 9806/10000 Iteration: 68643 Train loss: 0.007416\n",
      "Epoch: 9807/10000 Iteration: 68650 Train loss: 0.007416\n",
      "Epoch: 9808/10000 Iteration: 68657 Train loss: 0.007416\n",
      "Epoch: 9809/10000 Iteration: 68664 Train loss: 0.007416\n",
      "Epoch: 9810/10000 Iteration: 68671 Train loss: 0.007416\n",
      "Epoch: 9811/10000 Iteration: 68678 Train loss: 0.007416\n",
      "Epoch: 9812/10000 Iteration: 68685 Train loss: 0.007416\n",
      "Epoch: 9813/10000 Iteration: 68692 Train loss: 0.007416\n",
      "Epoch: 9814/10000 Iteration: 68699 Train loss: 0.007416\n",
      "Epoch: 9815/10000 Iteration: 68706 Train loss: 0.007416\n",
      "Epoch: 9816/10000 Iteration: 68713 Train loss: 0.007416\n",
      "Epoch: 9817/10000 Iteration: 68720 Train loss: 0.007416\n",
      "Epoch: 9818/10000 Iteration: 68727 Train loss: 0.007416\n",
      "Epoch: 9819/10000 Iteration: 68734 Train loss: 0.007416\n",
      "Epoch: 9820/10000 Iteration: 68741 Train loss: 0.007416\n",
      "Epoch: 9821/10000 Iteration: 68748 Train loss: 0.007416\n",
      "Epoch: 9822/10000 Iteration: 68755 Train loss: 0.007416\n",
      "Epoch: 9823/10000 Iteration: 68762 Train loss: 0.007416\n",
      "Epoch: 9824/10000 Iteration: 68769 Train loss: 0.007416\n",
      "Epoch: 9825/10000 Iteration: 68776 Train loss: 0.007416\n",
      "Epoch: 9826/10000 Iteration: 68783 Train loss: 0.007416\n",
      "Epoch: 9827/10000 Iteration: 68790 Train loss: 0.007416\n",
      "Epoch: 9828/10000 Iteration: 68797 Train loss: 0.007416\n",
      "Epoch: 9829/10000 Iteration: 68804 Train loss: 0.007416\n",
      "Epoch: 9830/10000 Iteration: 68811 Train loss: 0.007416\n",
      "Epoch: 9831/10000 Iteration: 68818 Train loss: 0.007416\n",
      "Epoch: 9832/10000 Iteration: 68825 Train loss: 0.007416\n",
      "Epoch: 9833/10000 Iteration: 68832 Train loss: 0.007416\n",
      "Epoch: 9834/10000 Iteration: 68839 Train loss: 0.007416\n",
      "Epoch: 9835/10000 Iteration: 68846 Train loss: 0.007416\n",
      "Epoch: 9836/10000 Iteration: 68853 Train loss: 0.007416\n",
      "Epoch: 9837/10000 Iteration: 68860 Train loss: 0.007416\n",
      "Epoch: 9838/10000 Iteration: 68867 Train loss: 0.007416\n",
      "Epoch: 9839/10000 Iteration: 68874 Train loss: 0.007416\n",
      "Epoch: 9840/10000 Iteration: 68881 Train loss: 0.007416\n",
      "Epoch: 9841/10000 Iteration: 68888 Train loss: 0.007416\n",
      "Epoch: 9842/10000 Iteration: 68895 Train loss: 0.007416\n",
      "Epoch: 9843/10000 Iteration: 68902 Train loss: 0.007416\n",
      "Epoch: 9844/10000 Iteration: 68909 Train loss: 0.007416\n",
      "Epoch: 9845/10000 Iteration: 68916 Train loss: 0.007416\n",
      "Epoch: 9846/10000 Iteration: 68923 Train loss: 0.007416\n",
      "Epoch: 9847/10000 Iteration: 68930 Train loss: 0.007416\n",
      "Epoch: 9848/10000 Iteration: 68937 Train loss: 0.007416\n",
      "Epoch: 9849/10000 Iteration: 68944 Train loss: 0.007417\n",
      "Epoch: 9850/10000 Iteration: 68951 Train loss: 0.007417\n",
      "Epoch: 9851/10000 Iteration: 68958 Train loss: 0.007417\n",
      "Epoch: 9852/10000 Iteration: 68965 Train loss: 0.007417\n",
      "Epoch: 9853/10000 Iteration: 68972 Train loss: 0.007417\n",
      "Epoch: 9854/10000 Iteration: 68979 Train loss: 0.007417\n",
      "Epoch: 9855/10000 Iteration: 68986 Train loss: 0.007417\n",
      "Epoch: 9856/10000 Iteration: 68993 Train loss: 0.007417\n",
      "Epoch: 9857/10000 Iteration: 69000 Train loss: 0.007417\n",
      "Epoch: 9858/10000 Iteration: 69007 Train loss: 0.007417\n",
      "Epoch: 9859/10000 Iteration: 69014 Train loss: 0.007417\n",
      "Epoch: 9860/10000 Iteration: 69021 Train loss: 0.007417\n",
      "Epoch: 9861/10000 Iteration: 69028 Train loss: 0.007417\n",
      "Epoch: 9862/10000 Iteration: 69035 Train loss: 0.007417\n",
      "Epoch: 9863/10000 Iteration: 69042 Train loss: 0.007417\n",
      "Epoch: 9864/10000 Iteration: 69049 Train loss: 0.007417\n",
      "Epoch: 9865/10000 Iteration: 69056 Train loss: 0.007417\n",
      "Epoch: 9866/10000 Iteration: 69063 Train loss: 0.007417\n",
      "Epoch: 9867/10000 Iteration: 69070 Train loss: 0.007417\n",
      "Epoch: 9868/10000 Iteration: 69077 Train loss: 0.007417\n",
      "Epoch: 9869/10000 Iteration: 69084 Train loss: 0.007417\n",
      "Epoch: 9870/10000 Iteration: 69091 Train loss: 0.007417\n",
      "Epoch: 9871/10000 Iteration: 69098 Train loss: 0.007417\n",
      "Epoch: 9872/10000 Iteration: 69105 Train loss: 0.007417\n",
      "Epoch: 9873/10000 Iteration: 69112 Train loss: 0.007417\n",
      "Epoch: 9874/10000 Iteration: 69119 Train loss: 0.007417\n",
      "Epoch: 9875/10000 Iteration: 69126 Train loss: 0.007417\n",
      "Epoch: 9876/10000 Iteration: 69133 Train loss: 0.007417\n",
      "Epoch: 9877/10000 Iteration: 69140 Train loss: 0.007417\n",
      "Epoch: 9878/10000 Iteration: 69147 Train loss: 0.007417\n",
      "Epoch: 9879/10000 Iteration: 69154 Train loss: 0.007417\n",
      "Epoch: 9880/10000 Iteration: 69161 Train loss: 0.007417\n",
      "Epoch: 9881/10000 Iteration: 69168 Train loss: 0.007417\n",
      "Epoch: 9882/10000 Iteration: 69175 Train loss: 0.007417\n",
      "Epoch: 9883/10000 Iteration: 69182 Train loss: 0.007417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9884/10000 Iteration: 69189 Train loss: 0.007417\n",
      "Epoch: 9885/10000 Iteration: 69196 Train loss: 0.007417\n",
      "Epoch: 9886/10000 Iteration: 69203 Train loss: 0.007417\n",
      "Epoch: 9887/10000 Iteration: 69210 Train loss: 0.007417\n",
      "Epoch: 9888/10000 Iteration: 69217 Train loss: 0.007417\n",
      "Epoch: 9889/10000 Iteration: 69224 Train loss: 0.007417\n",
      "Epoch: 9890/10000 Iteration: 69231 Train loss: 0.007417\n",
      "Epoch: 9891/10000 Iteration: 69238 Train loss: 0.007417\n",
      "Epoch: 9892/10000 Iteration: 69245 Train loss: 0.007417\n",
      "Epoch: 9893/10000 Iteration: 69252 Train loss: 0.007417\n",
      "Epoch: 9894/10000 Iteration: 69259 Train loss: 0.007417\n",
      "Epoch: 9895/10000 Iteration: 69266 Train loss: 0.007417\n",
      "Epoch: 9896/10000 Iteration: 69273 Train loss: 0.007417\n",
      "Epoch: 9897/10000 Iteration: 69280 Train loss: 0.007417\n",
      "Epoch: 9898/10000 Iteration: 69287 Train loss: 0.007417\n",
      "Epoch: 9899/10000 Iteration: 69294 Train loss: 0.007417\n",
      "Epoch: 9900/10000 Iteration: 69301 Train loss: 0.007417\n",
      "Epoch: 9901/10000 Iteration: 69308 Train loss: 0.007417\n",
      "Epoch: 9902/10000 Iteration: 69315 Train loss: 0.007417\n",
      "Epoch: 9903/10000 Iteration: 69322 Train loss: 0.007417\n",
      "Epoch: 9904/10000 Iteration: 69329 Train loss: 0.007417\n",
      "Epoch: 9905/10000 Iteration: 69336 Train loss: 0.007417\n",
      "Epoch: 9906/10000 Iteration: 69343 Train loss: 0.007417\n",
      "Epoch: 9907/10000 Iteration: 69350 Train loss: 0.007417\n",
      "Epoch: 9908/10000 Iteration: 69357 Train loss: 0.007417\n",
      "Epoch: 9909/10000 Iteration: 69364 Train loss: 0.007417\n",
      "Epoch: 9910/10000 Iteration: 69371 Train loss: 0.007417\n",
      "Epoch: 9911/10000 Iteration: 69378 Train loss: 0.007417\n",
      "Epoch: 9912/10000 Iteration: 69385 Train loss: 0.007417\n",
      "Epoch: 9913/10000 Iteration: 69392 Train loss: 0.007417\n",
      "Epoch: 9914/10000 Iteration: 69399 Train loss: 0.007417\n",
      "Epoch: 9915/10000 Iteration: 69406 Train loss: 0.007417\n",
      "Epoch: 9916/10000 Iteration: 69413 Train loss: 0.007417\n",
      "Epoch: 9917/10000 Iteration: 69420 Train loss: 0.007417\n",
      "Epoch: 9918/10000 Iteration: 69427 Train loss: 0.007417\n",
      "Epoch: 9919/10000 Iteration: 69434 Train loss: 0.007417\n",
      "Epoch: 9920/10000 Iteration: 69441 Train loss: 0.007417\n",
      "Epoch: 9921/10000 Iteration: 69448 Train loss: 0.007417\n",
      "Epoch: 9922/10000 Iteration: 69455 Train loss: 0.007418\n",
      "Epoch: 9923/10000 Iteration: 69462 Train loss: 0.007418\n",
      "Epoch: 9924/10000 Iteration: 69469 Train loss: 0.007418\n",
      "Epoch: 9925/10000 Iteration: 69476 Train loss: 0.007418\n",
      "Epoch: 9926/10000 Iteration: 69483 Train loss: 0.007418\n",
      "Epoch: 9927/10000 Iteration: 69490 Train loss: 0.007418\n",
      "Epoch: 9928/10000 Iteration: 69497 Train loss: 0.007418\n",
      "Epoch: 9929/10000 Iteration: 69504 Train loss: 0.007418\n",
      "Epoch: 9930/10000 Iteration: 69511 Train loss: 0.007418\n",
      "Epoch: 9931/10000 Iteration: 69518 Train loss: 0.007418\n",
      "Epoch: 9932/10000 Iteration: 69525 Train loss: 0.007418\n",
      "Epoch: 9933/10000 Iteration: 69532 Train loss: 0.007418\n",
      "Epoch: 9934/10000 Iteration: 69539 Train loss: 0.007418\n",
      "Epoch: 9935/10000 Iteration: 69546 Train loss: 0.007418\n",
      "Epoch: 9936/10000 Iteration: 69553 Train loss: 0.007418\n",
      "Epoch: 9937/10000 Iteration: 69560 Train loss: 0.007418\n",
      "Epoch: 9938/10000 Iteration: 69567 Train loss: 0.007418\n",
      "Epoch: 9939/10000 Iteration: 69574 Train loss: 0.007418\n",
      "Epoch: 9940/10000 Iteration: 69581 Train loss: 0.007418\n",
      "Epoch: 9941/10000 Iteration: 69588 Train loss: 0.007418\n",
      "Epoch: 9942/10000 Iteration: 69595 Train loss: 0.007418\n",
      "Epoch: 9943/10000 Iteration: 69602 Train loss: 0.007418\n",
      "Epoch: 9944/10000 Iteration: 69609 Train loss: 0.007418\n",
      "Epoch: 9945/10000 Iteration: 69616 Train loss: 0.007418\n",
      "Epoch: 9946/10000 Iteration: 69623 Train loss: 0.007418\n",
      "Epoch: 9947/10000 Iteration: 69630 Train loss: 0.007418\n",
      "Epoch: 9948/10000 Iteration: 69637 Train loss: 0.007418\n",
      "Epoch: 9949/10000 Iteration: 69644 Train loss: 0.007418\n",
      "Epoch: 9950/10000 Iteration: 69651 Train loss: 0.007418\n",
      "Epoch: 9951/10000 Iteration: 69658 Train loss: 0.007418\n",
      "Epoch: 9952/10000 Iteration: 69665 Train loss: 0.007418\n",
      "Epoch: 9953/10000 Iteration: 69672 Train loss: 0.007418\n",
      "Epoch: 9954/10000 Iteration: 69679 Train loss: 0.007418\n",
      "Epoch: 9955/10000 Iteration: 69686 Train loss: 0.007418\n",
      "Epoch: 9956/10000 Iteration: 69693 Train loss: 0.007418\n",
      "Epoch: 9957/10000 Iteration: 69700 Train loss: 0.007418\n",
      "Epoch: 9958/10000 Iteration: 69707 Train loss: 0.007418\n",
      "Epoch: 9959/10000 Iteration: 69714 Train loss: 0.007418\n",
      "Epoch: 9960/10000 Iteration: 69721 Train loss: 0.007418\n",
      "Epoch: 9961/10000 Iteration: 69728 Train loss: 0.007418\n",
      "Epoch: 9962/10000 Iteration: 69735 Train loss: 0.007418\n",
      "Epoch: 9963/10000 Iteration: 69742 Train loss: 0.007418\n",
      "Epoch: 9964/10000 Iteration: 69749 Train loss: 0.007418\n",
      "Epoch: 9965/10000 Iteration: 69756 Train loss: 0.007418\n",
      "Epoch: 9966/10000 Iteration: 69763 Train loss: 0.007418\n",
      "Epoch: 9967/10000 Iteration: 69770 Train loss: 0.007418\n",
      "Epoch: 9968/10000 Iteration: 69777 Train loss: 0.007418\n",
      "Epoch: 9969/10000 Iteration: 69784 Train loss: 0.007418\n",
      "Epoch: 9970/10000 Iteration: 69791 Train loss: 0.007418\n",
      "Epoch: 9971/10000 Iteration: 69798 Train loss: 0.007418\n",
      "Epoch: 9972/10000 Iteration: 69805 Train loss: 0.007418\n",
      "Epoch: 9973/10000 Iteration: 69812 Train loss: 0.007418\n",
      "Epoch: 9974/10000 Iteration: 69819 Train loss: 0.007418\n",
      "Epoch: 9975/10000 Iteration: 69826 Train loss: 0.007418\n",
      "Epoch: 9976/10000 Iteration: 69833 Train loss: 0.007419\n",
      "Epoch: 9977/10000 Iteration: 69840 Train loss: 0.007419\n",
      "Epoch: 9978/10000 Iteration: 69847 Train loss: 0.007419\n",
      "Epoch: 9979/10000 Iteration: 69854 Train loss: 0.007419\n",
      "Epoch: 9980/10000 Iteration: 69861 Train loss: 0.007419\n",
      "Epoch: 9981/10000 Iteration: 69868 Train loss: 0.007419\n",
      "Epoch: 9982/10000 Iteration: 69875 Train loss: 0.007419\n",
      "Epoch: 9983/10000 Iteration: 69882 Train loss: 0.007419\n",
      "Epoch: 9984/10000 Iteration: 69889 Train loss: 0.007419\n",
      "Epoch: 9985/10000 Iteration: 69896 Train loss: 0.007419\n",
      "Epoch: 9986/10000 Iteration: 69903 Train loss: 0.007419\n",
      "Epoch: 9987/10000 Iteration: 69910 Train loss: 0.007419\n",
      "Epoch: 9988/10000 Iteration: 69917 Train loss: 0.007419\n",
      "Epoch: 9989/10000 Iteration: 69924 Train loss: 0.007419\n",
      "Epoch: 9990/10000 Iteration: 69931 Train loss: 0.007419\n",
      "Epoch: 9991/10000 Iteration: 69938 Train loss: 0.007419\n",
      "Epoch: 9992/10000 Iteration: 69945 Train loss: 0.007419\n",
      "Epoch: 9993/10000 Iteration: 69952 Train loss: 0.007419\n",
      "Epoch: 9994/10000 Iteration: 69959 Train loss: 0.007419\n",
      "Epoch: 9995/10000 Iteration: 69966 Train loss: 0.007419\n",
      "Epoch: 9996/10000 Iteration: 69973 Train loss: 0.007419\n",
      "Epoch: 9997/10000 Iteration: 69980 Train loss: 0.007419\n",
      "Epoch: 9998/10000 Iteration: 69987 Train loss: 0.007419\n",
      "Epoch: 9999/10000 Iteration: 69994 Train loss: 0.007419\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi0AAAF3CAYAAABpFHt+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAHJdJREFUeJzt3X20XXV95/HPh5snQlISkqsyuaS51oyQIo14CQ8ig7XQJFie1VAZtOrK4BQfl3TiOMtVp6stjraLYUSZWAN0RqHVCEaESUWL7chTLhghQEICxJWbEQgBAsEQcsl3/jj7JuceTsJJ7tn3d37nvF9r7XX30zn57F9I8mHvfc52RAgAAKDVHZI6AAAAQCMoLQAAIAuUFgAAkAVKCwAAyAKlBQAAZIHSAgAAskBpAQAAWaC0AACALFBaAABAFigtAAAgC2NSBzhQ06dPj1mzZqWOAQAAmuC+++57JiK6G9k3u9Iya9Ys9ff3p44BAACawPavGt2Xy0MAACALlBYAAJAFSgsAAMhCdve0AADQTnbt2qWBgQG9/PLLqaOUasKECerp6dHYsWMP+j0oLQAAJDQwMKDJkydr1qxZsp06TikiQlu3btXAwIB6e3sP+n24PAQAQEIvv/yypk2b1raFRZJsa9q0aSM+m0RpAQAgsXYuLEOacYyUFgAAOtjzzz+vr3/96wf8uoULF+r5558vIdG+UVoAAOhg+yotg4OD+33drbfeqilTppQVqy5uxAUAoIMtWbJEjz32mObOnauxY8dqwoQJmjp1qtauXatHH31U5557rjZt2qSXX35Zn/rUp7R48WJJe7+hfvv27VqwYIFOPfVU3XnnnZoxY4Z+8IMf6NBDD216VkoLAACt4tOfllavbu57zp0rXXnlPjdfccUVWrNmjVavXq077rhDZ511ltasWbPnUz7Lli3TEUccoR07duiEE07QBRdcoGnTpg17j/Xr1+uGG27QN7/5Tb3//e/X8uXLdfHFFzf3OERp2WvrVunVV6U3vCF1EgAAkpk3b96wjyVfddVVuummmyRJmzZt0vr1619TWnp7ezV37lxJ0jve8Q5t3LixlGyUliHTp1d+RqTNAQDoXPs5IzJaDjvssD3zd9xxh26//Xbdddddmjhxok4//fS6H1seP378nvmuri7t2LGjlGzciAsAQAebPHmyXnzxxbrbtm3bpqlTp2rixIlau3at7r777lFON1yppcX2fNvrbG+wvaTO9tNtb7O9upi+WGYeAAAw3LRp0/TOd75Txx57rC6//PJh2+bPn6/BwUEdc8wxWrJkiU466aREKSscJV0Osd0l6VFJZ0gakLRK0kUR8XDVPqdL+lxEvLfR9+3r64v+/v4mp5U09KU3XB4CAIyiRx55RMccc0zqGKOi3rHavi8i+hp5fZlnWuZJ2hARj0fEK5JulHROib8eAABoY2WWlhmSNlUtDxTrap1i+wHbt9n+3RLzAACAjKX+9ND9kmZGxHbbCyXdLGl27U62F0taLEkzZ84c3YQAAKAllHmmZbOko6qWe4p1e0TECxGxvZi/VdJY29Nr3ygilkZEX0T0dXd3lxgZAIDRV9b9pa2kGcdYZmlZJWm27V7b4yQtkrSiegfbb3Lx2Efb84o8W0vMBABAS5kwYYK2bt3a1sUlIrR161ZNmDBhRO9T2uWhiBi0fZmklZK6JC2LiIdsX1psv0bShZI+bntQ0g5Ji6Kdf9cAAKjR09OjgYEBbdmyJXWUUk2YMEE9PT0jeo/SPvJcFj7yDABA+2iVjzwDAAA0DaUFAABkgdICAACyQGkBAABZoLQAAIAsUFoAAEAWKC0AACALlBYAAJAFSgsAAMgCpQUAAGSB0gIAALJAaQEAAFmgtNTauTN1AgAAUAelpdbu3akTAACAOigtAAAgC5QWAACQBUpLrZdeSp0AAADUQWmp9cwzqRMAAIA6KC0AACALlBYAAJAFSkutXbtSJwAAAHVQWmrdf3/qBAAAoA5KCwAAyAKlBQAAZIHSUouv8QcAoCVRWmqtXJk6AQAAqIPSUuuVV1InAAAAdVBaAABAFigttSJSJwAAAHVQWmrdfHPqBAAAoA5KCwAAyAKlBQAAZIHSAgAAskBpAQAAWaC0AACALFBaAABAFigtAAAgC5QWAACQBUoLAADIAqUFAABkgdICAACyQGkBAABZoLQAAIAsUFoAAEAWKC0AACALlBYAAJAFSgsAAMgCpQUAAGSB0gIAALJQammxPd/2OtsbbC/Zz34n2B60fWGZeQAAQL5KKy22uyRdLWmBpDmSLrI9Zx/7fVnSP5WVBQAA5K/MMy3zJG2IiMcj4hVJN0o6p85+n5C0XNLTJWYBAACZK7O0zJC0qWp5oFi3h+0Zks6T9I0ScwAAgDaQ+kbcKyX9p4jYvb+dbC+23W+7f8uWLaMUDQAAtJIxJb73ZklHVS33FOuq9Um60bYkTZe00PZgRNxcvVNELJW0VJL6+vqitMQAAKBllVlaVkmabbtXlbKySNIfV+8QEb1D87avk3RLbWEBAACQSiwtETFo+zJJKyV1SVoWEQ/ZvrTYfk1ZvzYAAGg/ZZ5pUUTcKunWmnV1y0pEfLjMLAAAIG+pb8QFAABoCKUFAABkgdICAACyQGkBAABZoLQAAIAsUFoAAEAWKC0AACALlBYAAJAFSgsAAMgCpQUAAGSB0gIAALJAaQEAAFmgtAAAgCxQWgAAQBYoLQAAIAuUFgAAkAVKCwAAyAKlBQAAZIHSAgAAskBpAQAAWaC0AACALFBaAABAFigtAAAgC5QWAACQBUoLAADIAqUFAABkgdICAACyQGkBAABZoLQAAIAsUFoAAEAWKC0AACALlJZ6IlInAAAANSgt9fzmN6kTAACAGpQWAACQBUpLPS+8kDoBAACoQWmpZ8uW1AkAAEANSgsAAMgCpaWeNWtSJwAAADUoLfW8+GLqBAAAoAalpZ5t21InAAAANSgt9fz0p6kTAACAGpQWAACQBUpLPStXpk4AAABqUFoAAEAWKC0AACALlBYAAJAFSgsAAMgCpQUAAGSB0gIAALJAaQEAAFkotbTYnm97ne0NtpfU2X6O7Qdsr7bdb/vUMvMAAIB8jSnrjW13Sbpa0hmSBiStsr0iIh6u2u0nklZERNg+TtI/Sjq6rEwAACBfZZ5pmSdpQ0Q8HhGvSLpR0jnVO0TE9oiIYvEwSSEAAIA6yiwtMyRtqloeKNYNY/s822sl/UjSR0rMAwAAMpb8RtyIuCkijpZ0rqS/qLeP7cXFPS/9W7ZsGd2AAACgJZRZWjZLOqpquadYV1dE/IukN9ueXmfb0ojoi4i+7u7u5icFAAAtr8zSskrSbNu9tsdJWiRpRfUOtt9i28X88ZLGS9paYiYAAJCp0j49FBGDti+TtFJSl6RlEfGQ7UuL7ddIukDSJbZ3Sdoh6QNVN+YCAADs4dw6Ql9fX/T39zf/jSsnfPbKbFwAAMiR7fsioq+RfZPfiAsAANAISgsAAMgCpQUAAGSB0gIAALJAaQEAAFmgtAAAgCxQWgAAQBYoLQAAIAuUFgAAkAVKCwAAyAKlBQAAZIHSAgAAstBQabH9O7bHF/On2/6k7SnlRgMAANir0TMtyyW9avstkpZKOkrSd0pLBQAAUKPR0rI7IgYlnSfpf0TE5ZKOLC8WAADAcI2Wll22L5L0IUm3FOvGlhMJAADgtRotLX8i6WRJfxkRT9julfS/yosFAAAw3JhGdoqIhyV9UpJsT5U0OSK+XGYwAACAao1+eugO279l+whJ90v6pu2/LTcaAADAXo1eHjo8Il6QdL6kv4+IEyX9QXmxWsDOnakTAACAKo2WljG2j5T0fu29Ebe9UVoAAGgpjZaW/ypppaTHImKV7TdLWl9erBbw+OOpEwAAgCoNlZaI+G5EHBcRHy+WH4+IC8qNltjmzakTAACAKo3eiNtj+ybbTxfTcts9ZYdLan17n0gCACA3jV4eulbSCkn/pph+WKxrX7d0xq07AADkotHS0h0R10bEYDFdJ6m7xFzp/exnqRMAAIAqjZaWrbYvtt1VTBdL2lpmsOQGB1MnAAAAVRotLR9R5ePOT0r6taQLJX24pEwAAACv0einh34VEWdHRHdEvCEizpXU3p8eAgAALaXRMy31fLZpKQAAAF7HSEqLm5YCAADgdYyktETTUgAAALyOMfvbaPtF1S8nlnRoKYkAAADq2G9piYjJoxUEAABgf0ZyeQgAAGDUUFoAAEAWKC0AACALlBYAAJAFSgsAAMgCpQUAAGSB0gIAALJAaQEAAFmgtAAAgCxQWgAAQBYoLQAAIAuUlv3ZuTN1AgAAUKC07M8TT6ROAAAACpSW/Vm5MnUCAABQoLTsz1//deoEAACgUGppsT3f9jrbG2wvqbP9g7YfsP2g7Ttt/16ZeQ7YU0+lTgAAAAqllRbbXZKulrRA0hxJF9meU7PbE5L+XUS8TdJfSFpaVh4AAJC3Ms+0zJO0ISIej4hXJN0o6ZzqHSLizoh4rli8W1JPiXkAAEDGyiwtMyRtqloeKNbty0cl3VZiHgAAkLExqQNIku13q1JaTt3H9sWSFkvSzJkzRzEZAABoFWWeadks6aiq5Z5i3TC2j5P0d5LOiYit9d4oIpZGRF9E9HV3d5cSFgAAtLYyS8sqSbNt99oeJ2mRpBXVO9ieKen7kv59RDxaYhYAAJC50i4PRcSg7cskrZTUJWlZRDxk+9Ji+zWSvihpmqSv25akwYjoKysTAADIlyMidYYD0tfXF/39/c1/40ppeq3MxgcAgJzYvq/RExZ8Iy4AAMgCpeX17NqVOgEAABCl5fX96EepEwAAAFFaXt9556VOAAAARGkBAACZoLQAAIAsUFoAAEAWKC0AACALlBYAAJAFSksj+FZcAACSo7Q04m/+JnUCAAA6HqWlEZdfnjoBAAAdj9ICAACyQGkBAABZoLQAAIAsUFoaddddqRMAANDRKC2NOuWU1AkAAOholBYAAJAFSgsAAMgCpeVArFmTOgEAAB2L0nIg3va21AkAAOhYlBYAAJAFSsuB4uGJAAAkQWk5UIcwZAAApMC/wAAAIAuUFgAAkAVKy8Ho7U2dAACAjkNpORgbN6ZOAABAx6G0AACALFBaDpadOgEAAB2F0gIAALJAaRkJvmgOAIBRQ2kZCb5oDgCAUcO/ugAAIAuUlpF69tnUCQAA6AiUlpGaNi11AgAAOgKlBQAAZIHS0gznn586AQAAbY/S0gw33ZQ6AQAAbY/S0iy7d6dOAABAW6O0NEtXV+oEAAC0NUoLAADIAqWlmc48M3UCAADaFqWlmX7849QJAABoW5SWZnv++dQJAABoS5SWZps6NXUCAADaEqUFAABkgdJSBjt1AgAA2g6lBQAAZIHSUhbOtgAA0FSllhbb822vs73B9pI624+2fZftnbY/V2YWAACQt9JKi+0uSVdLWiBpjqSLbM+p2e1ZSZ+U9NWyciT1pS+lTgAAQNso80zLPEkbIuLxiHhF0o2SzqneISKejohVknaVmCOdP//z1AkAAGgbZZaWGZI2VS0PFOs6yy23pE4AAEBbyOJGXNuLbffb7t+yZUvqOAfmj/4odQIAANpCmaVls6SjqpZ7inUHLCKWRkRfRPR1d3c3Jdyouu221AkAAMhemaVllaTZtnttj5O0SNKKEn+91rVwYeoEAABkr7TSEhGDki6TtFLSI5L+MSIesn2p7UslyfabbA9I+qyk/2J7wPZvlZUpqa98JXUCAACy5ohIneGA9PX1RX9/f/PfeDS+DC6zsQYAoGy274uIvkb2zeJG3LbBt+QCAHDQKC0AACALlJbRxtkWAAAOCqUlhRdeSJ0AAIDsUFpSOPzw1AkAAMgOpSUVLhMBAHBAKC0pbd+eOgEAANmgtKQ0eXLqBAAAZIPSkhqXiQAAaAilpRVQXAAAeF2Ullbx4Q+nTgAAQEujtLSK66+XrrwydQoAAFoWpaWVfOYznHEBAGAfKC2t5vrruccFAIA6KC2tiuICAMAwlJZWZkt/9VepUwAA0BIoLa3uC1+olBcesggA6HCUllwcfnilvGzbljoJAABJUFpyM2VKpbx87WupkwAAMKooLbn6xCcq5cWWXn01dRoAAEo3JnUANMGYqt/GiHQ5AAAoEWda2s3Q2RebAgMAaCuUlnZ2yCF7C8yuXanTAAAwIpSWTjFu3PCzMEPTgw+mTgYAQEMoLZ3uuOPqlxlb2rEjdToAAPagtGDfJk6sX2aWL0+dDADQgfj0EA7chRfue9uuXcM/zQQAQJPwrwuaa+zYfW+j0AAARoDLQxg9Y8fu+/4ZW3r22dQJAQAtjNKC1jFt2v5LTfX01FOp0wIARhmlBXl605saLzj7mr71LWn37tRHAgBoEKUFnetjH5O6ukZefhqZjj9eWrmSkgQAI0BpAUbDL34hzZ8/eiWpkemjH5VWraJIAcgGpWXI+96XOgEwupYtk+bNa60idTBTd7f0wQ9K114rbdzIM7eANsbnT4e8+93Sd7+bOgWAA/XMM9J3vlOZ8Fonnii9613SaadJJ5+894Z3IEOUliHHH586AQA03z33VKavfjV1ktYwfrx05pnSGWdI73mPdPTRlYfLIguUliFveUvqBACAsu3cKf3wh5Wp3U2aVPkG8/PPrxS0iRNTJxox6uWQKVNSJwAAoHm2b5euu046+2zpsMNGfv/Y97+f+ogoLXt0daVOAABA67rggtQJKC0AACAPlBYAAJAFSgsAAMgCpQUAAGSB0gIAALJAaQEAAFmgtAAAgCxQWgAAQBYoLfsTsXe65ZbUaQAA6GiUlmpr1+5721lnVcrLk0+OXh4AALBHqaXF9nzb62xvsL2kznbbvqrY/oDttI9afutb987v3l1/nze+ce/ZFwAAMGpKKy22uyRdLWmBpDmSLrI9p2a3BZJmF9NiSd8oK0/DhgqJ3fi+O3aUnwsAgA43psT3nidpQ0Q8Lkm2b5R0jqSHq/Y5R9LfR0RIutv2FNtHRsSvS8zVfBMmDD/zMmmS9NJL6fIgT7Y0efLeadKkys+JEytPaJ08ufLf2qRJlXWHHlqZHz++sm3cuMp+48dXfo4bV9lvaP2YMZWfh3BVuG1FSNu2Sc89J23dKj37bP3puedeu+6VV1KnR6u7997UCUotLTMkbapaHpB0YgP7zJCUV2mptX378OUI6ZRTpLvvTpNnpObOlS65RHrf+6QZMxo7CwVg9NnSlCmVqbc3dRqg6cosLU1je7Eql480c+bMxGkOgi3ddVfqFAAAZK3M88SbJR1VtdxTrDvQfRQRSyOiLyL6uru7mx4UAAC0vjJLyypJs2332h4naZGkFTX7rJB0SfEpopMkbcvufhYAADAqSrs8FBGDti+TtFJSl6RlEfGQ7UuL7ddIulXSQkkbJP1G0p+UlQcAAOSt1HtaIuJWVYpJ9bprquZD0p+WmQEAALQHPvsIAACyQGkBAABZoLQAAIAsUFoAAEAWKC0AACALlBYAAJAFSgsAAMgCpQUAAGSB0gIAALLgypfS5sP2Fkm/Kuntp0t6pqT3zgVjwBgMYRwYA4kxkBiDIWWNw29HRENPQ86utJTJdn9E9KXOkRJjwBgMYRwYA4kxkBiDIa0wDlweAgAAWaC0AACALFBahluaOkALYAwYgyGMA2MgMQYSYzAk+ThwTwsAAMgCZ1oAAEAWKC2SbM+3vc72BttLUucZKdvLbD9te03VuiNs/9j2+uLn1Kptny+OfZ3tP6xa/w7bDxbbrrLtYv142/9QrL/H9qzRPL5G2D7K9j/bftj2Q7Y/VazvmHGwPcH2vbZ/WYzBl4r1HTMGQ2x32f6F7VuK5U4cg41F/tW2+4t1HTUOtqfY/p7ttbYfsX1yJ42B7bcWv/9D0wu2P53VGERER0+SuiQ9JunNksZJ+qWkOalzjfCYTpN0vKQ1Vev+m6QlxfwSSV8u5ucUxzxeUm8xFl3FtnslnSTJkm6TtKBY/x8lXVPML5L0D6mPuc4YHCnp+GJ+sqRHi2PtmHEo8k4q5sdKuqc4jo4Zg6qx+Kyk70i6pRP/PBTZNkqaXrOuo8ZB0vWSPlbMj5M0pdPGoGosuiQ9Kem3cxqD5AOXepJ0sqSVVcufl/T51LmacFyzNLy0rJN0ZDF/pKR19Y5X0spiTI6UtLZq/UWS/mf1PsX8GFW+bMipj/l1xuMHks7o1HGQNFHS/ZJO7LQxkNQj6SeSfl97S0tHjUGRbaNeW1o6ZhwkHS7pidpMnTQGNcd9pqSf5zYGXB6SZkjaVLU8UKxrN2+MiF8X809KemMxv6/jn1HM164f9pqIGJS0TdK0cmKPXHF68u2qnGnoqHEoLouslvS0pB9HRMeNgaQrJf2ZpN1V6zptDCQpJN1u+z7bi4t1nTQOvZK2SLq2uFT4d7YPU2eNQbVFkm4o5rMZA0pLB4pKBe6Ij43ZniRpuaRPR8QL1ds6YRwi4tWImKvK2YZ5to+t2d7WY2D7vZKejoj79rVPu49BlVOL/xYWSPpT26dVb+yAcRijymXzb0TE2yW9pMqlkD06YAwkSbbHSTpb0ndrt7X6GFBapM2Sjqpa7inWtZunbB8pScXPp4v1+zr+zcV87fphr7E9RpXTrltLS36QbI9VpbB8OyK+X6zuuHGQpIh4XtI/S5qvzhqDd0o62/ZGSTdK+n3b/1udNQaSpIjYXPx8WtJNkuaps8ZhQNJAcbZRkr6nSonppDEYskDS/RHxVLGczRhQWqRVkmbb7i3a5yJJKxJnKsMKSR8q5j+kyj0eQ+sXFXd890qaLene4lThC7ZPKu4Kv6TmNUPvdaGknxbtvGUUmb8l6ZGI+NuqTR0zDra7bU8p5g9V5Z6eteqgMYiIz0dET0TMUuXP9k8j4mJ10BhIku3DbE8emlflfoY16qBxiIgnJW2y/dZi1XskPawOGoMqF2nvpSEppzFIfTNQK0ySFqry6ZLHJH0hdZ4mHM8Nkn4taZcq/3fxUVWuKf5E0npJt0s6omr/LxTHvk7FHeDF+j5V/mJ7TNLXtPfLCCeoclpxgyp3kL859THXGYNTVTnF+YCk1cW0sJPGQdJxkn5RjMEaSV8s1nfMGNSMx+naeyNuR42BKp+O/GUxPTT091wHjsNcSf3Fn4mbJU3twDE4TJUzH4dXrctmDPhGXAAAkAUuDwEAgCxQWgAAQBYoLQAAIAuUFgAAkAVKCwAAyAKlBUBT2L6z+DnL9h83+b3/c71fC0Bn4SPPAJrK9umSPhcR7z2A14yJynNK9rV9e0RMakY+APniTAuAprC9vZi9QtK7bK+2/ZnioY1fsb3K9gO2/0Ox/+m2/9X2ClW+mVS2by4e6PfQ0EP9bF8h6dDi/b5d/Wu54iu219h+0PYHqt77Dtvfs73W9reLb+4EkLExqQMAaDtLVHWmpSgf2yLiBNvjJf3c9j8V+x4v6diIeKJY/khEPFs8dmCV7eURscT2ZVF52F+t81X5ltPfkzS9eM2/FNveLul3Jf0/ST9X5TlE/7f5hwtgtHCmBUDZzpR0ie3Vku5R5SvDZxfb7q0qLJL0Sdu/lHS3Kg9dm639O1XSDVF5mvVTkn4m6YSq9x6IiN2qPMZhVlOOBkAynGkBUDZL+kRErBy2snLvy0s1y38g6eSI+I3tO1R5jsnB2lk1/6r4+w7IHmdaADTbi5ImVy2vlPRx22Mlyfa/LZ40XOtwSc8VheVoSSdVbds19Poa/yrpA8V9M92STlPlIW0A2hD/5wGg2R6Q9Gpxmec6Sf9dlUsz9xc3w26RdG6d1/0fSZfafkSVJ8reXbVtqaQHbN8fER+sWn+TpJNVeXpxSPqziHiyKD0A2gwfeQYAAFng8hAAAMgCpQUAAGSB0gIAALJAaQEAAFmgtAAAgCxQWgAAQBYoLQAAIAuUFgAAkIX/D+MfKOk02NHQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f29216e5828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.variable_scope('rnn', reuse=None):\n",
    "    train_lstm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    "def prediction():\n",
    "                    \n",
    "        pred, _ = lstm(1)  # 预测时只输入[1,time_step,inputSize]的测试数据\n",
    "        saver = tf.train.Saver(tf.global_variables())\n",
    "        #预测季度\n",
    "        pre_quarter = 10\n",
    "        with tf.Session() as sess:\n",
    "            # 参数恢复\n",
    "            module_file = tf.train.latest_checkpoint(\"./checkpoints-lstm\")\n",
    "            saver.restore(sess, module_file)\n",
    "            # 取训练集最后一行为测试样本. shape=[1,time_step,inputSize]\n",
    "            prev_seq = train_x[-1]\n",
    "            predict = []\n",
    "            # 得到之后10个季度的预测结果\n",
    "            for i in range(pre_quarter):\n",
    "                next_seq = sess.run(pred,feed_dict={X:[prev_seq]})\n",
    "                predict.append(next_seq[-1])   \n",
    "                #每次得到最后一个时间步的预测结果，与之前的数据加在一起，形成新的测试样本\n",
    "                #np.vstack()表示垂直（按照行顺序）的把数组给堆叠起来。\n",
    "                prev_seq = np.vstack((prev_seq[1:],next_seq[-1]))\n",
    "            \n",
    "            #得到实际预测值\n",
    "            predictY = scaler.inverse_transform(predict)\n",
    "            \n",
    "            testY = scaler.inverse_transform(test)\n",
    "            print(\"预测值：\", predictY)\n",
    "            print(\"真实值：\",testY )\n",
    "            \n",
    "            # 计算均方根误差（RMSE）\n",
    "            rmse = math.sqrt(mean_squared_error(testY, predictY))\n",
    "            print('Test RMSE: %.3f' % rmse)\n",
    "            \n",
    "            #以折线图表示结果\n",
    "            plt.figure()\n",
    "            plt.title(\"lead index\")\n",
    "            plt.plot(list(range(len(testY))), testY, 'cx--', list(range(len(predict))), predictY, 'b--')\n",
    "            plt.xlabel(\"date-num\")\n",
    "            plt.ylabel(\"index\")\n",
    "            plt.legend(['train', 'pred'], loc='upper right')\n",
    "            plt.plot()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"rnn_2/rnn/Reshape:0\", shape=(?, 5, 5), dtype=float32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Variable rnn/rnn/basic_lstm_cell/kernel does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=None in VarScope?",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-fb239d25cc53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rnn'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-f76ef9518467>\u001b[0m in \u001b[0;36mprediction\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 预测时只输入[1,time_step,inputSize]的测试数据\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m#预测季度\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-d3f85ec7a34e>\u001b[0m in \u001b[0;36mlstm\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0minput_lstm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0minitial_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             dtype = tf.float32) \n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_rnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_unit\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#  作为输出层的输入\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TensorFlow/lib/python3.5/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36mdynamic_rnn\u001b[0;34m(cell, inputs, sequence_length, initial_state, dtype, parallel_iterations, swap_memory, time_major, scope)\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0mswap_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0msequence_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m         dtype=dtype)\n\u001b[0m\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[0;31m# Outputs of _dynamic_rnn_loop are always shaped [time, batch, depth].\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TensorFlow/lib/python3.5/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m_dynamic_rnn_loop\u001b[0;34m(cell, inputs, initial_state, parallel_iterations, swap_memory, sequence_length, dtype)\u001b[0m\n\u001b[1;32m    759\u001b[0m       \u001b[0mloop_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_ta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m       \u001b[0mparallel_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m       swap_memory=swap_memory)\n\u001b[0m\u001b[1;32m    762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m   \u001b[0;31m# Unpack final output if not using output tuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TensorFlow/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name)\u001b[0m\n\u001b[1;32m   2773\u001b[0m     \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWhileContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mback_prop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2774\u001b[0m     \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWHILE_CONTEXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2775\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBuildLoop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape_invariants\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2776\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TensorFlow/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mBuildLoop\u001b[0;34m(self, pred, body, loop_vars, shape_invariants)\u001b[0m\n\u001b[1;32m   2602\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEnter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2603\u001b[0m       original_body_result, exit_vars = self._BuildLoop(\n\u001b[0;32m-> 2604\u001b[0;31m           pred, body, original_loop_vars, loop_vars, shape_invariants)\n\u001b[0m\u001b[1;32m   2605\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2606\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TensorFlow/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m_BuildLoop\u001b[0;34m(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\u001b[0m\n\u001b[1;32m   2552\u001b[0m         \u001b[0mstructure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moriginal_loop_vars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2553\u001b[0m         flat_sequence=vars_for_body_with_tensor_arrays)\n\u001b[0;32m-> 2554\u001b[0;31m     \u001b[0mbody_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpacked_vars_for_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2555\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2556\u001b[0m       \u001b[0mbody_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TensorFlow/lib/python3.5/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m_time_step\u001b[0;34m(time, output_ta_t, state)\u001b[0m\n\u001b[1;32m    744\u001b[0m           skip_conditionals=True)\n\u001b[1;32m    745\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m       \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m     \u001b[0;31m# Pack state if using state tuples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TensorFlow/lib/python3.5/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[0minput_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_sequence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m     \u001b[0mcall_cell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msequence_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TensorFlow/lib/python3.5/site-packages/tensorflow/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, state, scope)\u001b[0m\n\u001b[1;32m    178\u001b[0m       with vs.variable_scope(vs.get_variable_scope(),\n\u001b[1;32m    179\u001b[0m                              custom_getter=self._rnn_get_variable):\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNNCell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_rnn_get_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TensorFlow/lib/python3.5/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0;31m# Apply activity regularization.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TensorFlow/lib/python3.5/site-packages/tensorflow/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, state)\u001b[0m\n\u001b[1;32m    399\u001b[0m       \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_or_size_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m     \u001b[0mconcat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_linear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[0;31m# i = input_gate, j = new_input, f = forget_gate, o = output_gate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TensorFlow/lib/python3.5/site-packages/tensorflow/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36m_linear\u001b[0;34m(args, output_size, bias, bias_initializer, kernel_initializer)\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[0m_WEIGHTS_VARIABLE_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtotal_arg_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m         initializer=kernel_initializer)\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TensorFlow/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)\u001b[0m\n\u001b[1;32m   1063\u001b[0m       \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1064\u001b[0m       \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1065\u001b[0;31m       use_resource=use_resource, custom_getter=custom_getter)\n\u001b[0m\u001b[1;32m   1066\u001b[0m get_variable_or_local_docstring = (\n\u001b[1;32m   1067\u001b[0m     \"\"\"%s\n",
      "\u001b[0;32m~/anaconda3/envs/TensorFlow/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)\u001b[0m\n\u001b[1;32m    960\u001b[0m           \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 962\u001b[0;31m           use_resource=use_resource, custom_getter=custom_getter)\n\u001b[0m\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m~/anaconda3/envs/TensorFlow/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)\u001b[0m\n\u001b[1;32m    358\u001b[0m           \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m           validate_shape=validate_shape, use_resource=use_resource)\n\u001b[0m\u001b[1;32m    361\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m       return _true_getter(\n",
      "\u001b[0;32m~/anaconda3/envs/TensorFlow/lib/python3.5/site-packages/tensorflow/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36m_rnn_get_variable\u001b[0;34m(self, getter, *args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_rnn_get_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m     \u001b[0mvariable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m     trainable = (variable in tf_variables.trainable_variables() or\n\u001b[1;32m    185\u001b[0m                  (isinstance(variable, tf_variables.PartitionedVariable) and\n",
      "\u001b[0;32m~/anaconda3/envs/TensorFlow/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource)\u001b[0m\n\u001b[1;32m    350\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m           use_resource=use_resource)\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcustom_getter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TensorFlow/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource)\u001b[0m\n\u001b[1;32m    680\u001b[0m       raise ValueError(\"Variable %s does not exist, or was not created with \"\n\u001b[1;32m    681\u001b[0m                        \u001b[0;34m\"tf.get_variable(). Did you mean to set reuse=None in \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m                        \"VarScope?\" % name)\n\u001b[0m\u001b[1;32m    683\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_fully_defined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minitializing_from_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m       raise ValueError(\"Shape of a new variable (%s) must be fully defined, \"\n",
      "\u001b[0;31mValueError\u001b[0m: Variable rnn/rnn/basic_lstm_cell/kernel does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=None in VarScope?"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "with tf.variable_scope('rnn', reuse=None):\n",
    "    prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TensorFlow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
