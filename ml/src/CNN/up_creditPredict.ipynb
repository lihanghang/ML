{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from utils.utilities import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline    \n",
    "\n",
    "#加载原始数据\n",
    "raw_data_train = pd.read_csv(r\"./dataSets/train.csv\", encoding='gbk')\n",
    "raw_data_test = pd.read_csv(r\"./dataSets/test.csv\", encoding='gbk')\n",
    "\n",
    "#缺失值处理\n",
    "train_data = raw_data_train.fillna(0)\n",
    "train_feature_data = (train_data.drop(['id','label1','label2'],axis=1))\n",
    "train_target = train_data.label2\n",
    "X_train = train_feature_data.values.astype(np.float32)\n",
    "\n",
    "test_data = raw_data_test.fillna(0)\n",
    "test_feature_data = (test_data.drop(['id','label1','label2'],axis=1))\n",
    "test_target = test_data.label2\n",
    "X_test = test_feature_data.values.astype(np.float32)\n",
    "\n",
    "X_train, _, y_train, _ = train_test_split(X_train, train_target, test_size=0.0, random_state=123)\n",
    "_, X_test, _, y_test = train_test_split(X_test, test_target, test_size=0.9999, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载原始数据\n",
    "#raw_data = pd.read_csv(r\"./creditGrade_train_data.csv\", encoding='gbk')\n",
    "#data = raw_data.fillna(0)\n",
    "#features_data = (data.drop(['id','label1','label2'],axis=1))\n",
    "#5-class\n",
    "#target = data.label2\n",
    "#X = features_data.values.astype(np.float32) # 转换数据类型\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, target, test_size=0.3, random_state=123) # 参数test_size设置训练集占比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.01437473e-01   0.00000000e+00   2.17514172e-01 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  4.90476266e-02   0.00000000e+00   1.65245622e-01 ...,   7.08895456e-03\n",
      "    1.36673189e-04   2.60942634e-02]\n",
      " [  1.11642247e-03   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  6.29723221e-02   0.00000000e+00   1.66234493e-01 ...,   8.97091231e-05\n",
      "    0.00000000e+00   1.16708950e-04]\n",
      " [  1.07931413e-01   0.00000000e+00   1.36101902e-01 ...,   2.62339599e-03\n",
      "    3.63099825e-05   2.48723361e-03]\n",
      " [  9.69535932e-02   0.00000000e+00   1.26169785e-03 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Normalization\n",
    "from sklearn import preprocessing\n",
    "# l2正则化\n",
    "X_train = preprocessing.normalize(X_train, norm='l2')\n",
    "X_test = preprocessing.normalize(X_test, norm='l2')\n",
    "print(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2600, 106)\n",
      "(100, 106)\n",
      "train num: 2600\n",
      "val num: 100\n"
     ]
    }
   ],
   "source": [
    "#对分类进行one-hot编码\n",
    "y_tr = one_hot(y_train.astype(np.int64),5)\n",
    "y_vld = one_hot(y_test.astype(np.int64),5)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(\"train num:\", len(y_tr))\n",
    "print(\"val num:\", len(y_vld))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow运行版本：1.10.0\n",
      "WARNING:tensorflow:From <ipython-input-5-fe20a8485281>:78: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "Tensor(\"cnn:0\", shape=(?,), dtype=int64)\n",
      "Epoch: 4/5000 Iteration: 5 Train loss: 86.459549 Train acc: 0.471154\n",
      "Epoch: 9/5000 Iteration: 10 Train loss: 84.468910 Train acc: 0.471154\n",
      "Epoch: 9/5000 Iteration: 10 Validation loss: 84.193436 Validation acc: 0.440000\n",
      "Epoch: 14/5000 Iteration: 15 Train loss: 82.504745 Train acc: 0.471154\n",
      "Epoch: 19/5000 Iteration: 20 Train loss: 80.615685 Train acc: 0.471154\n",
      "Epoch: 19/5000 Iteration: 20 Validation loss: 80.346695 Validation acc: 0.440000\n",
      "Epoch: 24/5000 Iteration: 25 Train loss: 78.751335 Train acc: 0.471154\n",
      "Epoch: 29/5000 Iteration: 30 Train loss: 76.938721 Train acc: 0.471154\n",
      "Epoch: 29/5000 Iteration: 30 Validation loss: 76.685333 Validation acc: 0.440000\n",
      "Epoch: 34/5000 Iteration: 35 Train loss: 75.169563 Train acc: 0.471154\n",
      "Epoch: 39/5000 Iteration: 40 Train loss: 73.439346 Train acc: 0.471154\n",
      "Epoch: 39/5000 Iteration: 40 Validation loss: 73.201851 Validation acc: 0.440000\n",
      "Epoch: 44/5000 Iteration: 45 Train loss: 71.751610 Train acc: 0.471154\n",
      "Epoch: 49/5000 Iteration: 50 Train loss: 70.103348 Train acc: 0.471154\n",
      "Epoch: 49/5000 Iteration: 50 Validation loss: 69.878471 Validation acc: 0.440000\n",
      "Epoch: 54/5000 Iteration: 55 Train loss: 68.494179 Train acc: 0.471154\n",
      "Epoch: 59/5000 Iteration: 60 Train loss: 66.923294 Train acc: 0.471154\n",
      "Epoch: 59/5000 Iteration: 60 Validation loss: 66.714180 Validation acc: 0.440000\n",
      "Epoch: 64/5000 Iteration: 65 Train loss: 65.392136 Train acc: 0.471154\n",
      "Epoch: 69/5000 Iteration: 70 Train loss: 63.893616 Train acc: 0.471154\n",
      "Epoch: 69/5000 Iteration: 70 Validation loss: 63.699615 Validation acc: 0.440000\n",
      "Epoch: 74/5000 Iteration: 75 Train loss: 62.435654 Train acc: 0.471154\n",
      "Epoch: 79/5000 Iteration: 80 Train loss: 61.005333 Train acc: 0.471154\n",
      "Epoch: 79/5000 Iteration: 80 Validation loss: 60.825035 Validation acc: 0.440000\n",
      "Epoch: 84/5000 Iteration: 85 Train loss: 59.615913 Train acc: 0.471154\n",
      "Epoch: 89/5000 Iteration: 90 Train loss: 58.253872 Train acc: 0.471154\n",
      "Epoch: 89/5000 Iteration: 90 Validation loss: 58.084499 Validation acc: 0.440000\n",
      "Epoch: 94/5000 Iteration: 95 Train loss: 56.923763 Train acc: 0.471154\n",
      "Epoch: 99/5000 Iteration: 100 Train loss: 55.626984 Train acc: 0.471154\n",
      "Epoch: 99/5000 Iteration: 100 Validation loss: 55.470093 Validation acc: 0.440000\n",
      "Epoch: 104/5000 Iteration: 105 Train loss: 54.364166 Train acc: 0.471154\n",
      "Epoch: 109/5000 Iteration: 110 Train loss: 53.125061 Train acc: 0.471154\n",
      "Epoch: 109/5000 Iteration: 110 Validation loss: 52.975750 Validation acc: 0.440000\n",
      "Epoch: 114/5000 Iteration: 115 Train loss: 51.916626 Train acc: 0.471154\n",
      "Epoch: 119/5000 Iteration: 120 Train loss: 50.736839 Train acc: 0.471154\n",
      "Epoch: 119/5000 Iteration: 120 Validation loss: 50.595699 Validation acc: 0.440000\n",
      "Epoch: 124/5000 Iteration: 125 Train loss: 49.580696 Train acc: 0.471154\n",
      "Epoch: 129/5000 Iteration: 130 Train loss: 48.453270 Train acc: 0.471154\n",
      "Epoch: 129/5000 Iteration: 130 Validation loss: 48.324100 Validation acc: 0.440000\n",
      "Epoch: 134/5000 Iteration: 135 Train loss: 47.354687 Train acc: 0.471154\n",
      "Epoch: 139/5000 Iteration: 140 Train loss: 46.277153 Train acc: 0.471154\n",
      "Epoch: 139/5000 Iteration: 140 Validation loss: 46.157486 Validation acc: 0.440000\n",
      "Epoch: 144/5000 Iteration: 145 Train loss: 45.226223 Train acc: 0.471154\n",
      "Epoch: 149/5000 Iteration: 150 Train loss: 44.200455 Train acc: 0.471154\n",
      "Epoch: 149/5000 Iteration: 150 Validation loss: 44.087688 Validation acc: 0.440000\n",
      "Epoch: 154/5000 Iteration: 155 Train loss: 43.195545 Train acc: 0.471154\n",
      "Epoch: 159/5000 Iteration: 160 Train loss: 42.217361 Train acc: 0.471154\n",
      "Epoch: 159/5000 Iteration: 160 Validation loss: 42.111118 Validation acc: 0.440000\n",
      "Epoch: 164/5000 Iteration: 165 Train loss: 41.256729 Train acc: 0.471154\n",
      "Epoch: 169/5000 Iteration: 170 Train loss: 40.323059 Train acc: 0.471154\n",
      "Epoch: 169/5000 Iteration: 170 Validation loss: 40.224251 Validation acc: 0.440000\n",
      "Epoch: 174/5000 Iteration: 175 Train loss: 39.408310 Train acc: 0.471154\n",
      "Epoch: 179/5000 Iteration: 180 Train loss: 38.510509 Train acc: 0.471154\n",
      "Epoch: 179/5000 Iteration: 180 Validation loss: 38.421833 Validation acc: 0.440000\n",
      "Epoch: 184/5000 Iteration: 185 Train loss: 37.639324 Train acc: 0.471154\n",
      "Epoch: 189/5000 Iteration: 190 Train loss: 36.783398 Train acc: 0.471154\n",
      "Epoch: 189/5000 Iteration: 190 Validation loss: 36.700760 Validation acc: 0.440000\n",
      "Epoch: 194/5000 Iteration: 195 Train loss: 35.950783 Train acc: 0.471154\n",
      "Epoch: 199/5000 Iteration: 200 Train loss: 35.131634 Train acc: 0.471154\n",
      "Epoch: 199/5000 Iteration: 200 Validation loss: 35.057140 Validation acc: 0.440000\n",
      "Epoch: 204/5000 Iteration: 205 Train loss: 34.338535 Train acc: 0.471154\n",
      "Epoch: 209/5000 Iteration: 210 Train loss: 33.554398 Train acc: 0.471154\n",
      "Epoch: 209/5000 Iteration: 210 Validation loss: 33.486099 Validation acc: 0.440000\n",
      "Epoch: 214/5000 Iteration: 215 Train loss: 32.794228 Train acc: 0.471154\n",
      "Epoch: 219/5000 Iteration: 220 Train loss: 32.050850 Train acc: 0.471154\n",
      "Epoch: 219/5000 Iteration: 220 Validation loss: 31.985470 Validation acc: 0.440000\n",
      "Epoch: 224/5000 Iteration: 225 Train loss: 31.322687 Train acc: 0.471154\n",
      "Epoch: 229/5000 Iteration: 230 Train loss: 30.610504 Train acc: 0.471154\n",
      "Epoch: 229/5000 Iteration: 230 Validation loss: 30.551805 Validation acc: 0.440000\n",
      "Epoch: 234/5000 Iteration: 235 Train loss: 29.916130 Train acc: 0.471154\n",
      "Epoch: 239/5000 Iteration: 240 Train loss: 29.238094 Train acc: 0.471154\n",
      "Epoch: 239/5000 Iteration: 240 Validation loss: 29.180748 Validation acc: 0.440000\n",
      "Epoch: 244/5000 Iteration: 245 Train loss: 28.570557 Train acc: 0.471154\n",
      "Epoch: 249/5000 Iteration: 250 Train loss: 27.922054 Train acc: 0.471154\n",
      "Epoch: 249/5000 Iteration: 250 Validation loss: 27.869165 Validation acc: 0.440000\n",
      "Epoch: 254/5000 Iteration: 255 Train loss: 27.287214 Train acc: 0.471154\n",
      "Epoch: 259/5000 Iteration: 260 Train loss: 26.665607 Train acc: 0.470769\n",
      "Epoch: 259/5000 Iteration: 260 Validation loss: 26.615316 Validation acc: 0.440000\n",
      "Epoch: 264/5000 Iteration: 265 Train loss: 26.056499 Train acc: 0.471154\n",
      "Epoch: 269/5000 Iteration: 270 Train loss: 25.462158 Train acc: 0.471538\n",
      "Epoch: 269/5000 Iteration: 270 Validation loss: 25.412848 Validation acc: 0.440000\n",
      "Epoch: 274/5000 Iteration: 275 Train loss: 24.876659 Train acc: 0.471538\n",
      "Epoch: 279/5000 Iteration: 280 Train loss: 24.306366 Train acc: 0.471923\n",
      "Epoch: 279/5000 Iteration: 280 Validation loss: 24.252928 Validation acc: 0.440000\n",
      "Epoch: 284/5000 Iteration: 285 Train loss: 23.737146 Train acc: 0.478077\n",
      "Epoch: 289/5000 Iteration: 290 Train loss: 23.192095 Train acc: 0.476923\n",
      "Epoch: 289/5000 Iteration: 290 Validation loss: 23.137987 Validation acc: 0.440000\n",
      "Epoch: 294/5000 Iteration: 295 Train loss: 22.652864 Train acc: 0.485385\n",
      "Epoch: 299/5000 Iteration: 300 Train loss: 22.124990 Train acc: 0.498077\n",
      "Epoch: 299/5000 Iteration: 300 Validation loss: 22.072845 Validation acc: 0.400000\n",
      "Epoch: 304/5000 Iteration: 305 Train loss: 21.602940 Train acc: 0.501538\n",
      "Epoch: 309/5000 Iteration: 310 Train loss: 21.092518 Train acc: 0.513462\n",
      "Epoch: 309/5000 Iteration: 310 Validation loss: 21.051390 Validation acc: 0.380000\n",
      "Epoch: 314/5000 Iteration: 315 Train loss: 20.597124 Train acc: 0.511923\n",
      "Epoch: 319/5000 Iteration: 320 Train loss: 20.111406 Train acc: 0.524615\n",
      "Epoch: 319/5000 Iteration: 320 Validation loss: 20.056416 Validation acc: 0.420000\n",
      "Epoch: 324/5000 Iteration: 325 Train loss: 19.639755 Train acc: 0.531923\n",
      "Epoch: 329/5000 Iteration: 330 Train loss: 19.181398 Train acc: 0.536154\n",
      "Epoch: 329/5000 Iteration: 330 Validation loss: 19.115135 Validation acc: 0.490000\n",
      "Epoch: 334/5000 Iteration: 335 Train loss: 18.724730 Train acc: 0.540000\n",
      "Epoch: 339/5000 Iteration: 340 Train loss: 18.296904 Train acc: 0.545385\n",
      "Epoch: 339/5000 Iteration: 340 Validation loss: 18.222830 Validation acc: 0.510000\n",
      "Epoch: 344/5000 Iteration: 345 Train loss: 17.874542 Train acc: 0.545769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 349/5000 Iteration: 350 Train loss: 17.450886 Train acc: 0.542308\n",
      "Epoch: 349/5000 Iteration: 350 Validation loss: 17.380833 Validation acc: 0.520000\n",
      "Epoch: 354/5000 Iteration: 355 Train loss: 17.039013 Train acc: 0.554615\n",
      "Epoch: 359/5000 Iteration: 360 Train loss: 16.638956 Train acc: 0.555769\n",
      "Epoch: 359/5000 Iteration: 360 Validation loss: 16.582994 Validation acc: 0.530000\n",
      "Epoch: 364/5000 Iteration: 365 Train loss: 16.249918 Train acc: 0.567692\n",
      "Epoch: 369/5000 Iteration: 370 Train loss: 15.884161 Train acc: 0.559615\n",
      "Epoch: 369/5000 Iteration: 370 Validation loss: 15.826724 Validation acc: 0.540000\n",
      "Epoch: 374/5000 Iteration: 375 Train loss: 15.506008 Train acc: 0.561923\n",
      "Epoch: 379/5000 Iteration: 380 Train loss: 15.145622 Train acc: 0.566538\n",
      "Epoch: 379/5000 Iteration: 380 Validation loss: 15.098258 Validation acc: 0.520000\n",
      "Epoch: 384/5000 Iteration: 385 Train loss: 14.796136 Train acc: 0.579231\n",
      "Epoch: 389/5000 Iteration: 390 Train loss: 14.447940 Train acc: 0.577308\n",
      "Epoch: 389/5000 Iteration: 390 Validation loss: 14.410831 Validation acc: 0.520000\n",
      "Epoch: 394/5000 Iteration: 395 Train loss: 14.118512 Train acc: 0.572692\n",
      "Epoch: 399/5000 Iteration: 400 Train loss: 13.781974 Train acc: 0.580000\n",
      "Epoch: 399/5000 Iteration: 400 Validation loss: 13.753601 Validation acc: 0.530000\n",
      "Epoch: 404/5000 Iteration: 405 Train loss: 13.464464 Train acc: 0.584615\n",
      "Epoch: 409/5000 Iteration: 410 Train loss: 13.151045 Train acc: 0.593077\n",
      "Epoch: 409/5000 Iteration: 410 Validation loss: 13.118044 Validation acc: 0.520000\n",
      "Epoch: 414/5000 Iteration: 415 Train loss: 12.843186 Train acc: 0.580769\n",
      "Epoch: 419/5000 Iteration: 420 Train loss: 12.534842 Train acc: 0.603462\n",
      "Epoch: 419/5000 Iteration: 420 Validation loss: 12.517051 Validation acc: 0.540000\n",
      "Epoch: 424/5000 Iteration: 425 Train loss: 12.252486 Train acc: 0.598077\n",
      "Epoch: 429/5000 Iteration: 430 Train loss: 11.958222 Train acc: 0.605769\n",
      "Epoch: 429/5000 Iteration: 430 Validation loss: 11.949993 Validation acc: 0.550000\n",
      "Epoch: 434/5000 Iteration: 435 Train loss: 11.677262 Train acc: 0.603846\n",
      "Epoch: 439/5000 Iteration: 440 Train loss: 11.405631 Train acc: 0.601923\n",
      "Epoch: 439/5000 Iteration: 440 Validation loss: 11.400591 Validation acc: 0.540000\n",
      "Epoch: 444/5000 Iteration: 445 Train loss: 11.135410 Train acc: 0.620769\n",
      "Epoch: 449/5000 Iteration: 450 Train loss: 10.869658 Train acc: 0.618462\n",
      "Epoch: 449/5000 Iteration: 450 Validation loss: 10.875475 Validation acc: 0.540000\n",
      "Epoch: 454/5000 Iteration: 455 Train loss: 10.629534 Train acc: 0.613846\n",
      "Epoch: 459/5000 Iteration: 460 Train loss: 10.368095 Train acc: 0.627308\n",
      "Epoch: 459/5000 Iteration: 460 Validation loss: 10.376128 Validation acc: 0.560000\n",
      "Epoch: 464/5000 Iteration: 465 Train loss: 10.123845 Train acc: 0.625385\n",
      "Epoch: 469/5000 Iteration: 470 Train loss: 9.885283 Train acc: 0.627692\n",
      "Epoch: 469/5000 Iteration: 470 Validation loss: 9.886931 Validation acc: 0.570000\n",
      "Epoch: 474/5000 Iteration: 475 Train loss: 9.651107 Train acc: 0.635385\n",
      "Epoch: 479/5000 Iteration: 480 Train loss: 9.426311 Train acc: 0.636154\n",
      "Epoch: 479/5000 Iteration: 480 Validation loss: 9.430010 Validation acc: 0.580000\n",
      "Epoch: 484/5000 Iteration: 485 Train loss: 9.191698 Train acc: 0.655385\n",
      "Epoch: 489/5000 Iteration: 490 Train loss: 8.973883 Train acc: 0.654615\n",
      "Epoch: 489/5000 Iteration: 490 Validation loss: 8.989440 Validation acc: 0.570000\n",
      "Epoch: 494/5000 Iteration: 495 Train loss: 8.759407 Train acc: 0.663462\n",
      "Epoch: 499/5000 Iteration: 500 Train loss: 8.552808 Train acc: 0.665385\n",
      "Epoch: 499/5000 Iteration: 500 Validation loss: 8.580382 Validation acc: 0.580000\n",
      "Epoch: 504/5000 Iteration: 505 Train loss: 8.349634 Train acc: 0.677308\n",
      "Epoch: 509/5000 Iteration: 510 Train loss: 8.147571 Train acc: 0.683846\n",
      "Epoch: 509/5000 Iteration: 510 Validation loss: 8.180254 Validation acc: 0.610000\n",
      "Epoch: 514/5000 Iteration: 515 Train loss: 7.946545 Train acc: 0.687692\n",
      "Epoch: 519/5000 Iteration: 520 Train loss: 7.763445 Train acc: 0.702308\n",
      "Epoch: 519/5000 Iteration: 520 Validation loss: 7.794786 Validation acc: 0.640000\n",
      "Epoch: 524/5000 Iteration: 525 Train loss: 7.580265 Train acc: 0.690000\n",
      "Epoch: 529/5000 Iteration: 530 Train loss: 7.385822 Train acc: 0.700769\n",
      "Epoch: 529/5000 Iteration: 530 Validation loss: 7.427462 Validation acc: 0.630000\n",
      "Epoch: 534/5000 Iteration: 535 Train loss: 7.205136 Train acc: 0.710385\n",
      "Epoch: 539/5000 Iteration: 540 Train loss: 7.029888 Train acc: 0.719615\n",
      "Epoch: 539/5000 Iteration: 540 Validation loss: 7.082239 Validation acc: 0.660000\n",
      "Epoch: 544/5000 Iteration: 545 Train loss: 6.852989 Train acc: 0.721923\n",
      "Epoch: 549/5000 Iteration: 550 Train loss: 6.685191 Train acc: 0.725769\n",
      "Epoch: 549/5000 Iteration: 550 Validation loss: 6.753018 Validation acc: 0.670000\n",
      "Epoch: 554/5000 Iteration: 555 Train loss: 6.532448 Train acc: 0.740769\n",
      "Epoch: 559/5000 Iteration: 560 Train loss: 6.366401 Train acc: 0.747692\n",
      "Epoch: 559/5000 Iteration: 560 Validation loss: 6.437872 Validation acc: 0.710000\n",
      "Epoch: 564/5000 Iteration: 565 Train loss: 6.205158 Train acc: 0.758462\n",
      "Epoch: 569/5000 Iteration: 570 Train loss: 6.058622 Train acc: 0.758077\n",
      "Epoch: 569/5000 Iteration: 570 Validation loss: 6.144494 Validation acc: 0.660000\n",
      "Epoch: 574/5000 Iteration: 575 Train loss: 5.913147 Train acc: 0.760385\n",
      "Epoch: 579/5000 Iteration: 580 Train loss: 5.752715 Train acc: 0.770385\n",
      "Epoch: 579/5000 Iteration: 580 Validation loss: 5.840098 Validation acc: 0.680000\n",
      "Epoch: 584/5000 Iteration: 585 Train loss: 5.614307 Train acc: 0.778846\n",
      "Epoch: 589/5000 Iteration: 590 Train loss: 5.486530 Train acc: 0.775769\n",
      "Epoch: 589/5000 Iteration: 590 Validation loss: 5.593326 Validation acc: 0.690000\n",
      "Epoch: 594/5000 Iteration: 595 Train loss: 5.345012 Train acc: 0.782308\n",
      "Epoch: 599/5000 Iteration: 600 Train loss: 5.206584 Train acc: 0.788077\n",
      "Epoch: 599/5000 Iteration: 600 Validation loss: 5.311433 Validation acc: 0.690000\n",
      "Epoch: 604/5000 Iteration: 605 Train loss: 5.070298 Train acc: 0.799231\n",
      "Epoch: 609/5000 Iteration: 610 Train loss: 4.949286 Train acc: 0.808077\n",
      "Epoch: 609/5000 Iteration: 610 Validation loss: 5.081527 Validation acc: 0.690000\n",
      "Epoch: 614/5000 Iteration: 615 Train loss: 4.825587 Train acc: 0.807308\n",
      "Epoch: 619/5000 Iteration: 620 Train loss: 4.707681 Train acc: 0.811154\n",
      "Epoch: 619/5000 Iteration: 620 Validation loss: 4.838276 Validation acc: 0.710000\n",
      "Epoch: 624/5000 Iteration: 625 Train loss: 4.583458 Train acc: 0.824231\n",
      "Epoch: 629/5000 Iteration: 630 Train loss: 4.460405 Train acc: 0.831538\n",
      "Epoch: 629/5000 Iteration: 630 Validation loss: 4.601090 Validation acc: 0.730000\n",
      "Epoch: 634/5000 Iteration: 635 Train loss: 4.360072 Train acc: 0.822308\n",
      "Epoch: 639/5000 Iteration: 640 Train loss: 4.242013 Train acc: 0.836538\n",
      "Epoch: 639/5000 Iteration: 640 Validation loss: 4.396862 Validation acc: 0.750000\n",
      "Epoch: 644/5000 Iteration: 645 Train loss: 4.152048 Train acc: 0.840769\n",
      "Epoch: 649/5000 Iteration: 650 Train loss: 4.027625 Train acc: 0.845769\n",
      "Epoch: 649/5000 Iteration: 650 Validation loss: 4.189246 Validation acc: 0.740000\n",
      "Epoch: 654/5000 Iteration: 655 Train loss: 3.931198 Train acc: 0.848077\n",
      "Epoch: 659/5000 Iteration: 660 Train loss: 3.821748 Train acc: 0.862692\n",
      "Epoch: 659/5000 Iteration: 660 Validation loss: 4.000654 Validation acc: 0.730000\n",
      "Epoch: 664/5000 Iteration: 665 Train loss: 3.726138 Train acc: 0.861538\n",
      "Epoch: 669/5000 Iteration: 670 Train loss: 3.634727 Train acc: 0.860769\n",
      "Epoch: 669/5000 Iteration: 670 Validation loss: 3.815096 Validation acc: 0.750000\n",
      "Epoch: 674/5000 Iteration: 675 Train loss: 3.540114 Train acc: 0.873462\n",
      "Epoch: 679/5000 Iteration: 680 Train loss: 3.448927 Train acc: 0.867692\n",
      "Epoch: 679/5000 Iteration: 680 Validation loss: 3.625405 Validation acc: 0.800000\n",
      "Epoch: 684/5000 Iteration: 685 Train loss: 3.359524 Train acc: 0.877692\n",
      "Epoch: 689/5000 Iteration: 690 Train loss: 3.261627 Train acc: 0.888462\n",
      "Epoch: 689/5000 Iteration: 690 Validation loss: 3.477597 Validation acc: 0.750000\n",
      "Epoch: 694/5000 Iteration: 695 Train loss: 3.196558 Train acc: 0.877692\n",
      "Epoch: 699/5000 Iteration: 700 Train loss: 3.110152 Train acc: 0.882692\n",
      "Epoch: 699/5000 Iteration: 700 Validation loss: 3.310220 Validation acc: 0.780000\n",
      "Epoch: 704/5000 Iteration: 705 Train loss: 3.036012 Train acc: 0.888462\n",
      "Epoch: 709/5000 Iteration: 710 Train loss: 2.950803 Train acc: 0.891538\n",
      "Epoch: 709/5000 Iteration: 710 Validation loss: 3.168775 Validation acc: 0.800000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 714/5000 Iteration: 715 Train loss: 2.864194 Train acc: 0.901538\n",
      "Epoch: 719/5000 Iteration: 720 Train loss: 2.805364 Train acc: 0.901538\n",
      "Epoch: 719/5000 Iteration: 720 Validation loss: 3.031674 Validation acc: 0.780000\n",
      "Epoch: 724/5000 Iteration: 725 Train loss: 2.732373 Train acc: 0.906538\n",
      "Epoch: 729/5000 Iteration: 730 Train loss: 2.655185 Train acc: 0.909231\n",
      "Epoch: 729/5000 Iteration: 730 Validation loss: 2.879061 Validation acc: 0.740000\n",
      "Epoch: 734/5000 Iteration: 735 Train loss: 2.598379 Train acc: 0.901923\n",
      "Epoch: 739/5000 Iteration: 740 Train loss: 2.532416 Train acc: 0.912692\n",
      "Epoch: 739/5000 Iteration: 740 Validation loss: 2.759552 Validation acc: 0.790000\n",
      "Epoch: 744/5000 Iteration: 745 Train loss: 2.452259 Train acc: 0.921923\n",
      "Epoch: 749/5000 Iteration: 750 Train loss: 2.399244 Train acc: 0.914231\n",
      "Epoch: 749/5000 Iteration: 750 Validation loss: 2.645758 Validation acc: 0.760000\n",
      "Epoch: 754/5000 Iteration: 755 Train loss: 2.345198 Train acc: 0.913077\n",
      "Epoch: 759/5000 Iteration: 760 Train loss: 2.275708 Train acc: 0.926923\n",
      "Epoch: 759/5000 Iteration: 760 Validation loss: 2.527920 Validation acc: 0.820000\n",
      "Epoch: 764/5000 Iteration: 765 Train loss: 2.223046 Train acc: 0.924615\n",
      "Epoch: 769/5000 Iteration: 770 Train loss: 2.157926 Train acc: 0.932692\n",
      "Epoch: 769/5000 Iteration: 770 Validation loss: 2.415745 Validation acc: 0.760000\n",
      "Epoch: 774/5000 Iteration: 775 Train loss: 2.109387 Train acc: 0.928846\n",
      "Epoch: 779/5000 Iteration: 780 Train loss: 2.047613 Train acc: 0.939615\n",
      "Epoch: 779/5000 Iteration: 780 Validation loss: 2.301363 Validation acc: 0.830000\n",
      "Epoch: 784/5000 Iteration: 785 Train loss: 2.006698 Train acc: 0.929615\n",
      "Epoch: 789/5000 Iteration: 790 Train loss: 1.956470 Train acc: 0.927308\n",
      "Epoch: 789/5000 Iteration: 790 Validation loss: 2.195238 Validation acc: 0.800000\n",
      "Epoch: 794/5000 Iteration: 795 Train loss: 1.905195 Train acc: 0.935385\n",
      "Epoch: 799/5000 Iteration: 800 Train loss: 1.860535 Train acc: 0.935000\n",
      "Epoch: 799/5000 Iteration: 800 Validation loss: 2.108477 Validation acc: 0.830000\n",
      "Epoch: 804/5000 Iteration: 805 Train loss: 1.816709 Train acc: 0.934615\n",
      "Epoch: 809/5000 Iteration: 810 Train loss: 1.764959 Train acc: 0.936923\n",
      "Epoch: 809/5000 Iteration: 810 Validation loss: 2.033810 Validation acc: 0.780000\n",
      "Epoch: 814/5000 Iteration: 815 Train loss: 1.721030 Train acc: 0.939231\n",
      "Epoch: 819/5000 Iteration: 820 Train loss: 1.680528 Train acc: 0.939615\n",
      "Epoch: 819/5000 Iteration: 820 Validation loss: 1.960150 Validation acc: 0.790000\n",
      "Epoch: 824/5000 Iteration: 825 Train loss: 1.639173 Train acc: 0.939231\n",
      "Epoch: 829/5000 Iteration: 830 Train loss: 1.598564 Train acc: 0.943077\n",
      "Epoch: 829/5000 Iteration: 830 Validation loss: 1.862167 Validation acc: 0.830000\n",
      "Epoch: 834/5000 Iteration: 835 Train loss: 1.560916 Train acc: 0.946538\n",
      "Epoch: 839/5000 Iteration: 840 Train loss: 1.520815 Train acc: 0.948077\n",
      "Epoch: 839/5000 Iteration: 840 Validation loss: 1.799668 Validation acc: 0.810000\n",
      "Epoch: 844/5000 Iteration: 845 Train loss: 1.481701 Train acc: 0.948077\n",
      "Epoch: 849/5000 Iteration: 850 Train loss: 1.446639 Train acc: 0.948462\n",
      "Epoch: 849/5000 Iteration: 850 Validation loss: 1.732207 Validation acc: 0.840000\n",
      "Epoch: 854/5000 Iteration: 855 Train loss: 1.417154 Train acc: 0.940000\n",
      "Epoch: 859/5000 Iteration: 860 Train loss: 1.381407 Train acc: 0.950385\n",
      "Epoch: 859/5000 Iteration: 860 Validation loss: 1.654186 Validation acc: 0.800000\n",
      "Epoch: 864/5000 Iteration: 865 Train loss: 1.356681 Train acc: 0.946923\n",
      "Epoch: 869/5000 Iteration: 870 Train loss: 1.313466 Train acc: 0.951538\n",
      "Epoch: 869/5000 Iteration: 870 Validation loss: 1.595863 Validation acc: 0.750000\n",
      "Epoch: 874/5000 Iteration: 875 Train loss: 1.279474 Train acc: 0.950000\n",
      "Epoch: 879/5000 Iteration: 880 Train loss: 1.237910 Train acc: 0.961538\n",
      "Epoch: 879/5000 Iteration: 880 Validation loss: 1.546114 Validation acc: 0.780000\n",
      "Epoch: 884/5000 Iteration: 885 Train loss: 1.216753 Train acc: 0.955000\n",
      "Epoch: 889/5000 Iteration: 890 Train loss: 1.189092 Train acc: 0.955769\n",
      "Epoch: 889/5000 Iteration: 890 Validation loss: 1.481630 Validation acc: 0.780000\n",
      "Epoch: 894/5000 Iteration: 895 Train loss: 1.159926 Train acc: 0.955769\n",
      "Epoch: 899/5000 Iteration: 900 Train loss: 1.143823 Train acc: 0.950769\n",
      "Epoch: 899/5000 Iteration: 900 Validation loss: 1.421540 Validation acc: 0.820000\n",
      "Epoch: 904/5000 Iteration: 905 Train loss: 1.110957 Train acc: 0.954231\n",
      "Epoch: 909/5000 Iteration: 910 Train loss: 1.075929 Train acc: 0.955000\n",
      "Epoch: 909/5000 Iteration: 910 Validation loss: 1.375445 Validation acc: 0.760000\n",
      "Epoch: 914/5000 Iteration: 915 Train loss: 1.055623 Train acc: 0.954231\n",
      "Epoch: 919/5000 Iteration: 920 Train loss: 1.033423 Train acc: 0.960769\n",
      "Epoch: 919/5000 Iteration: 920 Validation loss: 1.337059 Validation acc: 0.810000\n",
      "Epoch: 924/5000 Iteration: 925 Train loss: 1.007244 Train acc: 0.956154\n",
      "Epoch: 929/5000 Iteration: 930 Train loss: 0.976530 Train acc: 0.962692\n",
      "Epoch: 929/5000 Iteration: 930 Validation loss: 1.294708 Validation acc: 0.830000\n",
      "Epoch: 934/5000 Iteration: 935 Train loss: 0.954704 Train acc: 0.962692\n",
      "Epoch: 939/5000 Iteration: 940 Train loss: 0.937147 Train acc: 0.960385\n",
      "Epoch: 939/5000 Iteration: 940 Validation loss: 1.277807 Validation acc: 0.760000\n",
      "Epoch: 944/5000 Iteration: 945 Train loss: 0.916610 Train acc: 0.961154\n",
      "Epoch: 949/5000 Iteration: 950 Train loss: 0.899750 Train acc: 0.961538\n",
      "Epoch: 949/5000 Iteration: 950 Validation loss: 1.210457 Validation acc: 0.830000\n",
      "Epoch: 954/5000 Iteration: 955 Train loss: 0.868130 Train acc: 0.965000\n",
      "Epoch: 959/5000 Iteration: 960 Train loss: 0.861889 Train acc: 0.962692\n",
      "Epoch: 959/5000 Iteration: 960 Validation loss: 1.170345 Validation acc: 0.780000\n",
      "Epoch: 964/5000 Iteration: 965 Train loss: 0.845122 Train acc: 0.961538\n",
      "Epoch: 969/5000 Iteration: 970 Train loss: 0.817152 Train acc: 0.966154\n",
      "Epoch: 969/5000 Iteration: 970 Validation loss: 1.163178 Validation acc: 0.800000\n",
      "Epoch: 974/5000 Iteration: 975 Train loss: 0.804231 Train acc: 0.965000\n",
      "Epoch: 979/5000 Iteration: 980 Train loss: 0.784645 Train acc: 0.963846\n",
      "Epoch: 979/5000 Iteration: 980 Validation loss: 1.100465 Validation acc: 0.860000\n",
      "Epoch: 984/5000 Iteration: 985 Train loss: 0.762458 Train acc: 0.966538\n",
      "Epoch: 989/5000 Iteration: 990 Train loss: 0.754143 Train acc: 0.964615\n",
      "Epoch: 989/5000 Iteration: 990 Validation loss: 1.079168 Validation acc: 0.850000\n",
      "Epoch: 994/5000 Iteration: 995 Train loss: 0.737824 Train acc: 0.963846\n",
      "Epoch: 999/5000 Iteration: 1000 Train loss: 0.719422 Train acc: 0.966923\n",
      "Epoch: 999/5000 Iteration: 1000 Validation loss: 1.041975 Validation acc: 0.780000\n",
      "Epoch: 1004/5000 Iteration: 1005 Train loss: 0.709046 Train acc: 0.961923\n",
      "Epoch: 1009/5000 Iteration: 1010 Train loss: 0.689225 Train acc: 0.965385\n",
      "Epoch: 1009/5000 Iteration: 1010 Validation loss: 1.010514 Validation acc: 0.770000\n",
      "Epoch: 1014/5000 Iteration: 1015 Train loss: 0.673775 Train acc: 0.965769\n",
      "Epoch: 1019/5000 Iteration: 1020 Train loss: 0.656299 Train acc: 0.968462\n",
      "Epoch: 1019/5000 Iteration: 1020 Validation loss: 0.994068 Validation acc: 0.770000\n",
      "Epoch: 1024/5000 Iteration: 1025 Train loss: 0.650184 Train acc: 0.968462\n",
      "Epoch: 1029/5000 Iteration: 1030 Train loss: 0.635689 Train acc: 0.968077\n",
      "Epoch: 1029/5000 Iteration: 1030 Validation loss: 0.966764 Validation acc: 0.830000\n",
      "Epoch: 1034/5000 Iteration: 1035 Train loss: 0.615202 Train acc: 0.972692\n",
      "Epoch: 1039/5000 Iteration: 1040 Train loss: 0.611138 Train acc: 0.970769\n",
      "Epoch: 1039/5000 Iteration: 1040 Validation loss: 0.953604 Validation acc: 0.780000\n",
      "Epoch: 1044/5000 Iteration: 1045 Train loss: 0.592217 Train acc: 0.971923\n",
      "Epoch: 1049/5000 Iteration: 1050 Train loss: 0.581272 Train acc: 0.973077\n",
      "Epoch: 1049/5000 Iteration: 1050 Validation loss: 0.920286 Validation acc: 0.830000\n",
      "Epoch: 1054/5000 Iteration: 1055 Train loss: 0.572291 Train acc: 0.965385\n",
      "Epoch: 1059/5000 Iteration: 1060 Train loss: 0.569348 Train acc: 0.965385\n",
      "Epoch: 1059/5000 Iteration: 1060 Validation loss: 0.908901 Validation acc: 0.770000\n",
      "Epoch: 1064/5000 Iteration: 1065 Train loss: 0.556479 Train acc: 0.970769\n",
      "Epoch: 1069/5000 Iteration: 1070 Train loss: 0.543683 Train acc: 0.969615\n",
      "Epoch: 1069/5000 Iteration: 1070 Validation loss: 0.875671 Validation acc: 0.770000\n",
      "Epoch: 1074/5000 Iteration: 1075 Train loss: 0.524535 Train acc: 0.971538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1079/5000 Iteration: 1080 Train loss: 0.521102 Train acc: 0.969615\n",
      "Epoch: 1079/5000 Iteration: 1080 Validation loss: 0.865307 Validation acc: 0.820000\n",
      "Epoch: 1084/5000 Iteration: 1085 Train loss: 0.513003 Train acc: 0.972692\n",
      "Epoch: 1089/5000 Iteration: 1090 Train loss: 0.510369 Train acc: 0.965385\n",
      "Epoch: 1089/5000 Iteration: 1090 Validation loss: 0.845408 Validation acc: 0.770000\n",
      "Epoch: 1094/5000 Iteration: 1095 Train loss: 0.491967 Train acc: 0.971538\n",
      "Epoch: 1099/5000 Iteration: 1100 Train loss: 0.481612 Train acc: 0.973462\n",
      "Epoch: 1099/5000 Iteration: 1100 Validation loss: 0.851536 Validation acc: 0.770000\n",
      "Epoch: 1104/5000 Iteration: 1105 Train loss: 0.474906 Train acc: 0.971154\n",
      "Epoch: 1109/5000 Iteration: 1110 Train loss: 0.470096 Train acc: 0.973462\n",
      "Epoch: 1109/5000 Iteration: 1110 Validation loss: 0.805744 Validation acc: 0.850000\n",
      "Epoch: 1114/5000 Iteration: 1115 Train loss: 0.459699 Train acc: 0.973846\n",
      "Epoch: 1119/5000 Iteration: 1120 Train loss: 0.450275 Train acc: 0.970769\n",
      "Epoch: 1119/5000 Iteration: 1120 Validation loss: 0.819072 Validation acc: 0.770000\n",
      "Epoch: 1124/5000 Iteration: 1125 Train loss: 0.442203 Train acc: 0.976923\n",
      "Epoch: 1129/5000 Iteration: 1130 Train loss: 0.438933 Train acc: 0.969231\n",
      "Epoch: 1129/5000 Iteration: 1130 Validation loss: 0.778430 Validation acc: 0.780000\n",
      "Epoch: 1134/5000 Iteration: 1135 Train loss: 0.429814 Train acc: 0.974615\n",
      "Epoch: 1139/5000 Iteration: 1140 Train loss: 0.419135 Train acc: 0.972692\n",
      "Epoch: 1139/5000 Iteration: 1140 Validation loss: 0.790162 Validation acc: 0.800000\n",
      "Epoch: 1144/5000 Iteration: 1145 Train loss: 0.417990 Train acc: 0.976538\n",
      "Epoch: 1149/5000 Iteration: 1150 Train loss: 0.407739 Train acc: 0.973846\n",
      "Epoch: 1149/5000 Iteration: 1150 Validation loss: 0.760328 Validation acc: 0.840000\n",
      "Epoch: 1154/5000 Iteration: 1155 Train loss: 0.396688 Train acc: 0.978462\n",
      "Epoch: 1159/5000 Iteration: 1160 Train loss: 0.397436 Train acc: 0.975000\n",
      "Epoch: 1159/5000 Iteration: 1160 Validation loss: 0.754947 Validation acc: 0.840000\n",
      "Epoch: 1164/5000 Iteration: 1165 Train loss: 0.387802 Train acc: 0.972692\n",
      "Epoch: 1169/5000 Iteration: 1170 Train loss: 0.381495 Train acc: 0.975000\n",
      "Epoch: 1169/5000 Iteration: 1170 Validation loss: 0.738058 Validation acc: 0.850000\n",
      "Epoch: 1174/5000 Iteration: 1175 Train loss: 0.380979 Train acc: 0.972692\n",
      "Epoch: 1179/5000 Iteration: 1180 Train loss: 0.372701 Train acc: 0.972692\n",
      "Epoch: 1179/5000 Iteration: 1180 Validation loss: 0.722306 Validation acc: 0.840000\n",
      "Epoch: 1184/5000 Iteration: 1185 Train loss: 0.371276 Train acc: 0.973846\n",
      "Epoch: 1189/5000 Iteration: 1190 Train loss: 0.360329 Train acc: 0.979231\n",
      "Epoch: 1189/5000 Iteration: 1190 Validation loss: 0.716849 Validation acc: 0.790000\n",
      "Epoch: 1194/5000 Iteration: 1195 Train loss: 0.358113 Train acc: 0.977308\n",
      "Epoch: 1199/5000 Iteration: 1200 Train loss: 0.349698 Train acc: 0.978846\n",
      "Epoch: 1199/5000 Iteration: 1200 Validation loss: 0.703379 Validation acc: 0.840000\n",
      "Epoch: 1204/5000 Iteration: 1205 Train loss: 0.344651 Train acc: 0.976923\n",
      "Epoch: 1209/5000 Iteration: 1210 Train loss: 0.345529 Train acc: 0.972692\n",
      "Epoch: 1209/5000 Iteration: 1210 Validation loss: 0.682600 Validation acc: 0.850000\n",
      "Epoch: 1214/5000 Iteration: 1215 Train loss: 0.336802 Train acc: 0.977692\n",
      "Epoch: 1219/5000 Iteration: 1220 Train loss: 0.326290 Train acc: 0.979231\n",
      "Epoch: 1219/5000 Iteration: 1220 Validation loss: 0.694179 Validation acc: 0.800000\n",
      "Epoch: 1224/5000 Iteration: 1225 Train loss: 0.331823 Train acc: 0.978462\n",
      "Epoch: 1229/5000 Iteration: 1230 Train loss: 0.329738 Train acc: 0.975385\n",
      "Epoch: 1229/5000 Iteration: 1230 Validation loss: 0.686776 Validation acc: 0.790000\n",
      "Epoch: 1234/5000 Iteration: 1235 Train loss: 0.317154 Train acc: 0.980000\n",
      "Epoch: 1239/5000 Iteration: 1240 Train loss: 0.323445 Train acc: 0.973462\n",
      "Epoch: 1239/5000 Iteration: 1240 Validation loss: 0.670741 Validation acc: 0.850000\n",
      "Epoch: 1244/5000 Iteration: 1245 Train loss: 0.318876 Train acc: 0.975000\n",
      "Epoch: 1249/5000 Iteration: 1250 Train loss: 0.319881 Train acc: 0.972308\n",
      "Epoch: 1249/5000 Iteration: 1250 Validation loss: 0.678047 Validation acc: 0.790000\n",
      "Epoch: 1254/5000 Iteration: 1255 Train loss: 0.310942 Train acc: 0.976538\n",
      "Epoch: 1259/5000 Iteration: 1260 Train loss: 0.303981 Train acc: 0.978846\n",
      "Epoch: 1259/5000 Iteration: 1260 Validation loss: 0.666866 Validation acc: 0.850000\n",
      "Epoch: 1264/5000 Iteration: 1265 Train loss: 0.307018 Train acc: 0.973077\n",
      "Epoch: 1269/5000 Iteration: 1270 Train loss: 0.299962 Train acc: 0.978846\n",
      "Epoch: 1269/5000 Iteration: 1270 Validation loss: 0.638323 Validation acc: 0.840000\n",
      "Epoch: 1274/5000 Iteration: 1275 Train loss: 0.292725 Train acc: 0.975385\n",
      "Epoch: 1279/5000 Iteration: 1280 Train loss: 0.287159 Train acc: 0.978846\n",
      "Epoch: 1279/5000 Iteration: 1280 Validation loss: 0.653425 Validation acc: 0.790000\n",
      "Epoch: 1284/5000 Iteration: 1285 Train loss: 0.296110 Train acc: 0.974231\n",
      "Epoch: 1289/5000 Iteration: 1290 Train loss: 0.283072 Train acc: 0.978846\n",
      "Epoch: 1289/5000 Iteration: 1290 Validation loss: 0.648354 Validation acc: 0.840000\n",
      "Epoch: 1294/5000 Iteration: 1295 Train loss: 0.283842 Train acc: 0.979231\n",
      "Epoch: 1299/5000 Iteration: 1300 Train loss: 0.277673 Train acc: 0.976154\n",
      "Epoch: 1299/5000 Iteration: 1300 Validation loss: 0.611004 Validation acc: 0.800000\n",
      "Epoch: 1304/5000 Iteration: 1305 Train loss: 0.272516 Train acc: 0.980000\n",
      "Epoch: 1309/5000 Iteration: 1310 Train loss: 0.274074 Train acc: 0.977692\n",
      "Epoch: 1309/5000 Iteration: 1310 Validation loss: 0.636154 Validation acc: 0.800000\n",
      "Epoch: 1314/5000 Iteration: 1315 Train loss: 0.273691 Train acc: 0.978462\n",
      "Epoch: 1319/5000 Iteration: 1320 Train loss: 0.270935 Train acc: 0.978077\n",
      "Epoch: 1319/5000 Iteration: 1320 Validation loss: 0.632021 Validation acc: 0.780000\n",
      "Epoch: 1324/5000 Iteration: 1325 Train loss: 0.266320 Train acc: 0.983077\n",
      "Epoch: 1329/5000 Iteration: 1330 Train loss: 0.260618 Train acc: 0.982308\n",
      "Epoch: 1329/5000 Iteration: 1330 Validation loss: 0.635298 Validation acc: 0.790000\n",
      "Epoch: 1334/5000 Iteration: 1335 Train loss: 0.255656 Train acc: 0.981154\n",
      "Epoch: 1339/5000 Iteration: 1340 Train loss: 0.262066 Train acc: 0.978077\n",
      "Epoch: 1339/5000 Iteration: 1340 Validation loss: 0.627404 Validation acc: 0.830000\n",
      "Epoch: 1344/5000 Iteration: 1345 Train loss: 0.259862 Train acc: 0.976923\n",
      "Epoch: 1349/5000 Iteration: 1350 Train loss: 0.257688 Train acc: 0.976923\n",
      "Epoch: 1349/5000 Iteration: 1350 Validation loss: 0.630367 Validation acc: 0.790000\n",
      "Epoch: 1354/5000 Iteration: 1355 Train loss: 0.251919 Train acc: 0.980385\n",
      "Epoch: 1359/5000 Iteration: 1360 Train loss: 0.247461 Train acc: 0.981538\n",
      "Epoch: 1359/5000 Iteration: 1360 Validation loss: 0.618928 Validation acc: 0.830000\n",
      "Epoch: 1364/5000 Iteration: 1365 Train loss: 0.250619 Train acc: 0.982308\n",
      "Epoch: 1369/5000 Iteration: 1370 Train loss: 0.245077 Train acc: 0.981154\n",
      "Epoch: 1369/5000 Iteration: 1370 Validation loss: 0.605046 Validation acc: 0.840000\n",
      "Epoch: 1374/5000 Iteration: 1375 Train loss: 0.242589 Train acc: 0.981923\n",
      "Epoch: 1379/5000 Iteration: 1380 Train loss: 0.245387 Train acc: 0.978077\n",
      "Epoch: 1379/5000 Iteration: 1380 Validation loss: 0.612318 Validation acc: 0.800000\n",
      "Epoch: 1384/5000 Iteration: 1385 Train loss: 0.237643 Train acc: 0.983462\n",
      "Epoch: 1389/5000 Iteration: 1390 Train loss: 0.244031 Train acc: 0.980385\n",
      "Epoch: 1389/5000 Iteration: 1390 Validation loss: 0.606551 Validation acc: 0.770000\n",
      "Epoch: 1394/5000 Iteration: 1395 Train loss: 0.239682 Train acc: 0.981154\n",
      "Epoch: 1399/5000 Iteration: 1400 Train loss: 0.237845 Train acc: 0.979615\n",
      "Epoch: 1399/5000 Iteration: 1400 Validation loss: 0.587299 Validation acc: 0.830000\n",
      "Epoch: 1404/5000 Iteration: 1405 Train loss: 0.231841 Train acc: 0.981154\n",
      "Epoch: 1409/5000 Iteration: 1410 Train loss: 0.238511 Train acc: 0.980385\n",
      "Epoch: 1409/5000 Iteration: 1410 Validation loss: 0.617073 Validation acc: 0.790000\n",
      "Epoch: 1414/5000 Iteration: 1415 Train loss: 0.236342 Train acc: 0.978462\n",
      "Epoch: 1419/5000 Iteration: 1420 Train loss: 0.228886 Train acc: 0.982692\n",
      "Epoch: 1419/5000 Iteration: 1420 Validation loss: 0.605582 Validation acc: 0.780000\n",
      "Epoch: 1424/5000 Iteration: 1425 Train loss: 0.226169 Train acc: 0.981538\n",
      "Epoch: 1429/5000 Iteration: 1430 Train loss: 0.231446 Train acc: 0.980385\n",
      "Epoch: 1429/5000 Iteration: 1430 Validation loss: 0.595098 Validation acc: 0.800000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1434/5000 Iteration: 1435 Train loss: 0.225252 Train acc: 0.983462\n",
      "Epoch: 1439/5000 Iteration: 1440 Train loss: 0.225427 Train acc: 0.981923\n",
      "Epoch: 1439/5000 Iteration: 1440 Validation loss: 0.598629 Validation acc: 0.820000\n",
      "Epoch: 1444/5000 Iteration: 1445 Train loss: 0.227140 Train acc: 0.977692\n",
      "Epoch: 1449/5000 Iteration: 1450 Train loss: 0.223719 Train acc: 0.985000\n",
      "Epoch: 1449/5000 Iteration: 1450 Validation loss: 0.596476 Validation acc: 0.790000\n",
      "Epoch: 1454/5000 Iteration: 1455 Train loss: 0.224513 Train acc: 0.979231\n",
      "Epoch: 1459/5000 Iteration: 1460 Train loss: 0.222681 Train acc: 0.982308\n",
      "Epoch: 1459/5000 Iteration: 1460 Validation loss: 0.595693 Validation acc: 0.820000\n",
      "Epoch: 1464/5000 Iteration: 1465 Train loss: 0.221115 Train acc: 0.980769\n",
      "Epoch: 1469/5000 Iteration: 1470 Train loss: 0.221769 Train acc: 0.979615\n",
      "Epoch: 1469/5000 Iteration: 1470 Validation loss: 0.594872 Validation acc: 0.780000\n",
      "Epoch: 1474/5000 Iteration: 1475 Train loss: 0.226796 Train acc: 0.977692\n",
      "Epoch: 1479/5000 Iteration: 1480 Train loss: 0.226988 Train acc: 0.978077\n",
      "Epoch: 1479/5000 Iteration: 1480 Validation loss: 0.573076 Validation acc: 0.840000\n",
      "Epoch: 1484/5000 Iteration: 1485 Train loss: 0.222363 Train acc: 0.980769\n",
      "Epoch: 1489/5000 Iteration: 1490 Train loss: 0.217714 Train acc: 0.980000\n",
      "Epoch: 1489/5000 Iteration: 1490 Validation loss: 0.578569 Validation acc: 0.800000\n",
      "Epoch: 1494/5000 Iteration: 1495 Train loss: 0.213075 Train acc: 0.983462\n",
      "Epoch: 1499/5000 Iteration: 1500 Train loss: 0.216118 Train acc: 0.980000\n",
      "Epoch: 1499/5000 Iteration: 1500 Validation loss: 0.576068 Validation acc: 0.780000\n",
      "Epoch: 1504/5000 Iteration: 1505 Train loss: 0.214637 Train acc: 0.980769\n",
      "Epoch: 1509/5000 Iteration: 1510 Train loss: 0.214963 Train acc: 0.980385\n",
      "Epoch: 1509/5000 Iteration: 1510 Validation loss: 0.585258 Validation acc: 0.820000\n",
      "Epoch: 1514/5000 Iteration: 1515 Train loss: 0.207668 Train acc: 0.980385\n",
      "Epoch: 1519/5000 Iteration: 1520 Train loss: 0.207379 Train acc: 0.983077\n",
      "Epoch: 1519/5000 Iteration: 1520 Validation loss: 0.600477 Validation acc: 0.780000\n",
      "Epoch: 1524/5000 Iteration: 1525 Train loss: 0.211265 Train acc: 0.980385\n",
      "Epoch: 1529/5000 Iteration: 1530 Train loss: 0.213561 Train acc: 0.981154\n",
      "Epoch: 1529/5000 Iteration: 1530 Validation loss: 0.585958 Validation acc: 0.830000\n",
      "Epoch: 1534/5000 Iteration: 1535 Train loss: 0.205851 Train acc: 0.982308\n",
      "Epoch: 1539/5000 Iteration: 1540 Train loss: 0.207362 Train acc: 0.983462\n",
      "Epoch: 1539/5000 Iteration: 1540 Validation loss: 0.588996 Validation acc: 0.790000\n",
      "Epoch: 1544/5000 Iteration: 1545 Train loss: 0.214947 Train acc: 0.978846\n",
      "Epoch: 1549/5000 Iteration: 1550 Train loss: 0.203193 Train acc: 0.981538\n",
      "Epoch: 1549/5000 Iteration: 1550 Validation loss: 0.558429 Validation acc: 0.800000\n",
      "Epoch: 1554/5000 Iteration: 1555 Train loss: 0.202233 Train acc: 0.985000\n",
      "Epoch: 1559/5000 Iteration: 1560 Train loss: 0.207237 Train acc: 0.981154\n",
      "Epoch: 1559/5000 Iteration: 1560 Validation loss: 0.572053 Validation acc: 0.790000\n",
      "Epoch: 1564/5000 Iteration: 1565 Train loss: 0.198353 Train acc: 0.986154\n",
      "Epoch: 1569/5000 Iteration: 1570 Train loss: 0.203893 Train acc: 0.983077\n",
      "Epoch: 1569/5000 Iteration: 1570 Validation loss: 0.602213 Validation acc: 0.770000\n",
      "Epoch: 1574/5000 Iteration: 1575 Train loss: 0.198335 Train acc: 0.986923\n",
      "Epoch: 1579/5000 Iteration: 1580 Train loss: 0.197635 Train acc: 0.983462\n",
      "Epoch: 1579/5000 Iteration: 1580 Validation loss: 0.578526 Validation acc: 0.780000\n",
      "Epoch: 1584/5000 Iteration: 1585 Train loss: 0.203379 Train acc: 0.981923\n",
      "Epoch: 1589/5000 Iteration: 1590 Train loss: 0.208076 Train acc: 0.980000\n",
      "Epoch: 1589/5000 Iteration: 1590 Validation loss: 0.561914 Validation acc: 0.780000\n",
      "Epoch: 1594/5000 Iteration: 1595 Train loss: 0.199561 Train acc: 0.983462\n",
      "Epoch: 1599/5000 Iteration: 1600 Train loss: 0.204109 Train acc: 0.982308\n",
      "Epoch: 1599/5000 Iteration: 1600 Validation loss: 0.576578 Validation acc: 0.800000\n",
      "Epoch: 1604/5000 Iteration: 1605 Train loss: 0.210185 Train acc: 0.976538\n",
      "Epoch: 1609/5000 Iteration: 1610 Train loss: 0.197834 Train acc: 0.983462\n",
      "Epoch: 1609/5000 Iteration: 1610 Validation loss: 0.588817 Validation acc: 0.770000\n",
      "Epoch: 1614/5000 Iteration: 1615 Train loss: 0.202397 Train acc: 0.981538\n",
      "Epoch: 1619/5000 Iteration: 1620 Train loss: 0.199260 Train acc: 0.982308\n",
      "Epoch: 1619/5000 Iteration: 1620 Validation loss: 0.569688 Validation acc: 0.810000\n",
      "Epoch: 1624/5000 Iteration: 1625 Train loss: 0.195137 Train acc: 0.986154\n",
      "Epoch: 1629/5000 Iteration: 1630 Train loss: 0.200344 Train acc: 0.982692\n",
      "Epoch: 1629/5000 Iteration: 1630 Validation loss: 0.572872 Validation acc: 0.780000\n",
      "Epoch: 1634/5000 Iteration: 1635 Train loss: 0.195059 Train acc: 0.981923\n",
      "Epoch: 1639/5000 Iteration: 1640 Train loss: 0.196108 Train acc: 0.984615\n",
      "Epoch: 1639/5000 Iteration: 1640 Validation loss: 0.552862 Validation acc: 0.820000\n",
      "Epoch: 1644/5000 Iteration: 1645 Train loss: 0.202495 Train acc: 0.978846\n",
      "Epoch: 1649/5000 Iteration: 1650 Train loss: 0.194622 Train acc: 0.981154\n",
      "Epoch: 1649/5000 Iteration: 1650 Validation loss: 0.597640 Validation acc: 0.790000\n",
      "Epoch: 1654/5000 Iteration: 1655 Train loss: 0.192916 Train acc: 0.985385\n",
      "Epoch: 1659/5000 Iteration: 1660 Train loss: 0.192404 Train acc: 0.985769\n",
      "Epoch: 1659/5000 Iteration: 1660 Validation loss: 0.561870 Validation acc: 0.820000\n",
      "Epoch: 1664/5000 Iteration: 1665 Train loss: 0.195608 Train acc: 0.983077\n",
      "Epoch: 1669/5000 Iteration: 1670 Train loss: 0.191419 Train acc: 0.984231\n",
      "Epoch: 1669/5000 Iteration: 1670 Validation loss: 0.579327 Validation acc: 0.820000\n",
      "Epoch: 1674/5000 Iteration: 1675 Train loss: 0.193480 Train acc: 0.981538\n",
      "Epoch: 1679/5000 Iteration: 1680 Train loss: 0.192216 Train acc: 0.982308\n",
      "Epoch: 1679/5000 Iteration: 1680 Validation loss: 0.586859 Validation acc: 0.820000\n",
      "Epoch: 1684/5000 Iteration: 1685 Train loss: 0.192173 Train acc: 0.984231\n",
      "Epoch: 1689/5000 Iteration: 1690 Train loss: 0.192566 Train acc: 0.982308\n",
      "Epoch: 1689/5000 Iteration: 1690 Validation loss: 0.587707 Validation acc: 0.800000\n",
      "Epoch: 1694/5000 Iteration: 1695 Train loss: 0.190749 Train acc: 0.985385\n",
      "Epoch: 1699/5000 Iteration: 1700 Train loss: 0.194374 Train acc: 0.981154\n",
      "Epoch: 1699/5000 Iteration: 1700 Validation loss: 0.587052 Validation acc: 0.790000\n",
      "Epoch: 1704/5000 Iteration: 1705 Train loss: 0.185804 Train acc: 0.986923\n",
      "Epoch: 1709/5000 Iteration: 1710 Train loss: 0.186663 Train acc: 0.983077\n",
      "Epoch: 1709/5000 Iteration: 1710 Validation loss: 0.581019 Validation acc: 0.810000\n",
      "Epoch: 1714/5000 Iteration: 1715 Train loss: 0.183525 Train acc: 0.985385\n",
      "Epoch: 1719/5000 Iteration: 1720 Train loss: 0.180781 Train acc: 0.986538\n",
      "Epoch: 1719/5000 Iteration: 1720 Validation loss: 0.576301 Validation acc: 0.780000\n",
      "Epoch: 1724/5000 Iteration: 1725 Train loss: 0.183183 Train acc: 0.985769\n",
      "Epoch: 1729/5000 Iteration: 1730 Train loss: 0.190029 Train acc: 0.983462\n",
      "Epoch: 1729/5000 Iteration: 1730 Validation loss: 0.567941 Validation acc: 0.780000\n",
      "Epoch: 1734/5000 Iteration: 1735 Train loss: 0.183397 Train acc: 0.985000\n",
      "Epoch: 1739/5000 Iteration: 1740 Train loss: 0.181499 Train acc: 0.986154\n",
      "Epoch: 1739/5000 Iteration: 1740 Validation loss: 0.580230 Validation acc: 0.780000\n",
      "Epoch: 1744/5000 Iteration: 1745 Train loss: 0.188846 Train acc: 0.983077\n",
      "Epoch: 1749/5000 Iteration: 1750 Train loss: 0.183985 Train acc: 0.985769\n",
      "Epoch: 1749/5000 Iteration: 1750 Validation loss: 0.589706 Validation acc: 0.780000\n",
      "Epoch: 1754/5000 Iteration: 1755 Train loss: 0.182757 Train acc: 0.985385\n",
      "Epoch: 1759/5000 Iteration: 1760 Train loss: 0.188807 Train acc: 0.984231\n",
      "Epoch: 1759/5000 Iteration: 1760 Validation loss: 0.564272 Validation acc: 0.850000\n",
      "Epoch: 1764/5000 Iteration: 1765 Train loss: 0.181182 Train acc: 0.984615\n",
      "Epoch: 1769/5000 Iteration: 1770 Train loss: 0.184629 Train acc: 0.983462\n",
      "Epoch: 1769/5000 Iteration: 1770 Validation loss: 0.568703 Validation acc: 0.790000\n",
      "Epoch: 1774/5000 Iteration: 1775 Train loss: 0.181212 Train acc: 0.985769\n",
      "Epoch: 1779/5000 Iteration: 1780 Train loss: 0.186555 Train acc: 0.984231\n",
      "Epoch: 1779/5000 Iteration: 1780 Validation loss: 0.571784 Validation acc: 0.850000\n",
      "Epoch: 1784/5000 Iteration: 1785 Train loss: 0.182372 Train acc: 0.985385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1789/5000 Iteration: 1790 Train loss: 0.180225 Train acc: 0.985769\n",
      "Epoch: 1789/5000 Iteration: 1790 Validation loss: 0.589894 Validation acc: 0.790000\n",
      "Epoch: 1794/5000 Iteration: 1795 Train loss: 0.181288 Train acc: 0.985000\n",
      "Epoch: 1799/5000 Iteration: 1800 Train loss: 0.182427 Train acc: 0.985385\n",
      "Epoch: 1799/5000 Iteration: 1800 Validation loss: 0.567924 Validation acc: 0.840000\n",
      "Epoch: 1804/5000 Iteration: 1805 Train loss: 0.179081 Train acc: 0.986538\n",
      "Epoch: 1809/5000 Iteration: 1810 Train loss: 0.179874 Train acc: 0.985000\n",
      "Epoch: 1809/5000 Iteration: 1810 Validation loss: 0.570712 Validation acc: 0.770000\n",
      "Epoch: 1814/5000 Iteration: 1815 Train loss: 0.176064 Train acc: 0.986154\n",
      "Epoch: 1819/5000 Iteration: 1820 Train loss: 0.178121 Train acc: 0.985000\n",
      "Epoch: 1819/5000 Iteration: 1820 Validation loss: 0.584180 Validation acc: 0.800000\n",
      "Epoch: 1824/5000 Iteration: 1825 Train loss: 0.182225 Train acc: 0.982692\n",
      "Epoch: 1829/5000 Iteration: 1830 Train loss: 0.182529 Train acc: 0.981154\n",
      "Epoch: 1829/5000 Iteration: 1830 Validation loss: 0.556705 Validation acc: 0.820000\n",
      "Epoch: 1834/5000 Iteration: 1835 Train loss: 0.180814 Train acc: 0.984231\n",
      "Epoch: 1839/5000 Iteration: 1840 Train loss: 0.178542 Train acc: 0.984231\n",
      "Epoch: 1839/5000 Iteration: 1840 Validation loss: 0.574550 Validation acc: 0.790000\n",
      "Epoch: 1844/5000 Iteration: 1845 Train loss: 0.175020 Train acc: 0.986154\n",
      "Epoch: 1849/5000 Iteration: 1850 Train loss: 0.174728 Train acc: 0.985000\n",
      "Epoch: 1849/5000 Iteration: 1850 Validation loss: 0.576525 Validation acc: 0.820000\n",
      "Epoch: 1854/5000 Iteration: 1855 Train loss: 0.176491 Train acc: 0.985769\n",
      "Epoch: 1859/5000 Iteration: 1860 Train loss: 0.177091 Train acc: 0.988077\n",
      "Epoch: 1859/5000 Iteration: 1860 Validation loss: 0.576332 Validation acc: 0.780000\n",
      "Epoch: 1864/5000 Iteration: 1865 Train loss: 0.172098 Train acc: 0.990769\n",
      "Epoch: 1869/5000 Iteration: 1870 Train loss: 0.184196 Train acc: 0.984231\n",
      "Epoch: 1869/5000 Iteration: 1870 Validation loss: 0.563661 Validation acc: 0.820000\n",
      "Epoch: 1874/5000 Iteration: 1875 Train loss: 0.175644 Train acc: 0.985385\n",
      "Epoch: 1879/5000 Iteration: 1880 Train loss: 0.178970 Train acc: 0.985000\n",
      "Epoch: 1879/5000 Iteration: 1880 Validation loss: 0.563839 Validation acc: 0.780000\n",
      "Epoch: 1884/5000 Iteration: 1885 Train loss: 0.173995 Train acc: 0.986923\n",
      "Epoch: 1889/5000 Iteration: 1890 Train loss: 0.175277 Train acc: 0.986538\n",
      "Epoch: 1889/5000 Iteration: 1890 Validation loss: 0.571160 Validation acc: 0.780000\n",
      "Epoch: 1894/5000 Iteration: 1895 Train loss: 0.176610 Train acc: 0.986538\n",
      "Epoch: 1899/5000 Iteration: 1900 Train loss: 0.175284 Train acc: 0.985769\n",
      "Epoch: 1899/5000 Iteration: 1900 Validation loss: 0.571766 Validation acc: 0.850000\n",
      "Epoch: 1904/5000 Iteration: 1905 Train loss: 0.174822 Train acc: 0.987308\n",
      "Epoch: 1909/5000 Iteration: 1910 Train loss: 0.173666 Train acc: 0.985769\n",
      "Epoch: 1909/5000 Iteration: 1910 Validation loss: 0.571768 Validation acc: 0.780000\n",
      "Epoch: 1914/5000 Iteration: 1915 Train loss: 0.174775 Train acc: 0.985000\n",
      "Epoch: 1919/5000 Iteration: 1920 Train loss: 0.174449 Train acc: 0.986923\n",
      "Epoch: 1919/5000 Iteration: 1920 Validation loss: 0.585541 Validation acc: 0.770000\n",
      "Epoch: 1924/5000 Iteration: 1925 Train loss: 0.177205 Train acc: 0.983846\n",
      "Epoch: 1929/5000 Iteration: 1930 Train loss: 0.171891 Train acc: 0.986154\n",
      "Epoch: 1929/5000 Iteration: 1930 Validation loss: 0.567590 Validation acc: 0.800000\n",
      "Epoch: 1934/5000 Iteration: 1935 Train loss: 0.172768 Train acc: 0.986154\n",
      "Epoch: 1939/5000 Iteration: 1940 Train loss: 0.172297 Train acc: 0.985769\n",
      "Epoch: 1939/5000 Iteration: 1940 Validation loss: 0.579257 Validation acc: 0.810000\n",
      "Epoch: 1944/5000 Iteration: 1945 Train loss: 0.169055 Train acc: 0.987692\n",
      "Epoch: 1949/5000 Iteration: 1950 Train loss: 0.170787 Train acc: 0.988462\n",
      "Epoch: 1949/5000 Iteration: 1950 Validation loss: 0.585170 Validation acc: 0.780000\n",
      "Epoch: 1954/5000 Iteration: 1955 Train loss: 0.174992 Train acc: 0.981923\n",
      "Epoch: 1959/5000 Iteration: 1960 Train loss: 0.170158 Train acc: 0.985385\n",
      "Epoch: 1959/5000 Iteration: 1960 Validation loss: 0.551727 Validation acc: 0.790000\n",
      "Epoch: 1964/5000 Iteration: 1965 Train loss: 0.171161 Train acc: 0.986538\n",
      "Epoch: 1969/5000 Iteration: 1970 Train loss: 0.175720 Train acc: 0.986538\n",
      "Epoch: 1969/5000 Iteration: 1970 Validation loss: 0.569137 Validation acc: 0.820000\n",
      "Epoch: 1974/5000 Iteration: 1975 Train loss: 0.176818 Train acc: 0.983846\n",
      "Epoch: 1979/5000 Iteration: 1980 Train loss: 0.172293 Train acc: 0.985769\n",
      "Epoch: 1979/5000 Iteration: 1980 Validation loss: 0.590421 Validation acc: 0.810000\n",
      "Epoch: 1984/5000 Iteration: 1985 Train loss: 0.171209 Train acc: 0.983846\n",
      "Epoch: 1989/5000 Iteration: 1990 Train loss: 0.167987 Train acc: 0.987308\n",
      "Epoch: 1989/5000 Iteration: 1990 Validation loss: 0.547972 Validation acc: 0.780000\n",
      "Epoch: 1994/5000 Iteration: 1995 Train loss: 0.171258 Train acc: 0.985000\n",
      "Epoch: 1999/5000 Iteration: 2000 Train loss: 0.172061 Train acc: 0.986538\n",
      "Epoch: 1999/5000 Iteration: 2000 Validation loss: 0.566345 Validation acc: 0.800000\n",
      "Epoch: 2004/5000 Iteration: 2005 Train loss: 0.169167 Train acc: 0.989231\n",
      "Epoch: 2009/5000 Iteration: 2010 Train loss: 0.171405 Train acc: 0.986154\n",
      "Epoch: 2009/5000 Iteration: 2010 Validation loss: 0.542536 Validation acc: 0.870000\n",
      "Epoch: 2014/5000 Iteration: 2015 Train loss: 0.169003 Train acc: 0.985769\n",
      "Epoch: 2019/5000 Iteration: 2020 Train loss: 0.165443 Train acc: 0.987692\n",
      "Epoch: 2019/5000 Iteration: 2020 Validation loss: 0.551511 Validation acc: 0.790000\n",
      "Epoch: 2024/5000 Iteration: 2025 Train loss: 0.171908 Train acc: 0.984615\n",
      "Epoch: 2029/5000 Iteration: 2030 Train loss: 0.174036 Train acc: 0.985385\n",
      "Epoch: 2029/5000 Iteration: 2030 Validation loss: 0.564502 Validation acc: 0.840000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "print(\"tensorflow运行版本：\" + tf.__version__)\n",
    "#设置相关参数\n",
    "batch_size = 2600  # Batch size\n",
    "features_num = 106        # Number of steps\n",
    "learning_rate = 0.00025\n",
    "epochs = 5000\n",
    "n_classes = 5\n",
    "lambda1 = 0.003\n",
    "log_dir = r'./logs'    # 输出日志保存的路径\n",
    "\n",
    "graph = tf.Graph()\n",
    "# Construct placeholders\n",
    "with graph.as_default():\n",
    "    in_units = 106\n",
    "    h1_units = 900\n",
    "    h2_units = 1024\n",
    "    #第一层全连接层参数\n",
    "    W1 = tf.Variable(tf.truncated_normal([in_units, h1_units], stddev=0.1))\n",
    "    tf.add_to_collection('losses', tf.contrib.layers.l2_regularizer(lambda1)(W1))\n",
    "    b1 = tf.Variable(tf.zeros([h1_units]))\n",
    "    \n",
    "    #第二层卷积层参数\n",
    "    Wconv1 = tf.Variable(tf.truncated_normal([3, 3, 1, 32], stddev=0.1))\n",
    "    #tf.add_to_collection('losses', tf.contrib.layers.l2_regularizer(lambda1)(Wconv1))\n",
    "    bconv1 = tf.Variable(tf.constant(0.1, shape=[32]))\n",
    "    \n",
    "    #第三层卷积层参数\n",
    "    Wconv2 = tf.Variable(tf.truncated_normal([3, 3, 32, 32], stddev=0.1))\n",
    "    tf.add_to_collection('losses', tf.contrib.layers.l2_regularizer(lambda1)(Wconv2))\n",
    "    bconv2 = tf.Variable(tf.constant(0.1, shape=[32]))\n",
    "    \n",
    "    #第四层全连接层参数\n",
    "    W2 = tf.Variable(tf.truncated_normal([15*15*32, h2_units], stddev=0.1))\n",
    "    tf.add_to_collection('losses', tf.contrib.layers.l2_regularizer(lambda1)(W2))\n",
    "    b2 = tf.Variable(tf.zeros([h2_units]))\n",
    "    \n",
    "    #第五层全连接层参数\n",
    "    W3 = tf.Variable(tf.zeros([h2_units, 5]))\n",
    "    tf.add_to_collection('losses', tf.contrib.layers.l2_regularizer(lambda1)(W3))\n",
    "    b3 = tf.Variable(tf.zeros([5]))    \n",
    "    \n",
    "    #构造网络\n",
    "    inputs_ = tf.placeholder(tf.float32, [None, 106], name = 'inputs')\n",
    "    labels_ = tf.placeholder(tf.float32, [None, 5], name = 'labels')\n",
    "    keep_prob_ = tf.placeholder(tf.float32, name = 'prob')\n",
    "    learning_rate_ = tf.placeholder(tf.float32, name = 'learning_rate')\n",
    "\n",
    "    inputs_ = tf.nn.dropout(inputs_, keep_prob_)\n",
    "    #第一层全连接层，将维度拓展到784\n",
    "    hidden1 = tf.nn.relu(tf.matmul(inputs_, W1) + b1)\n",
    "    hidden1_drop = tf.nn.dropout(hidden1, keep_prob_)\n",
    "    \n",
    "    #将数据转换为2维，送入第二层卷积层\n",
    "    hidden1_drop = tf.reshape(hidden1_drop, [-1, 30, 30, 1])\n",
    "    h_conv1 = tf.nn.relu(tf.nn.conv2d(hidden1_drop, Wconv1, strides=[1, 1, 1, 1], padding='SAME') + bconv1)\n",
    "    h_pool1 = tf.nn.max_pool(h_conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    h_pool1 = tf.nn.dropout(h_pool1, keep_prob_)\n",
    "    \n",
    "    #第三层卷积层\n",
    "    h_conv2 = tf.nn.relu(tf.nn.conv2d(h_pool1, Wconv2, strides=[1, 1, 1, 1], padding='SAME') + bconv2)\n",
    "    #h_pool2 = tf.nn.max_pool(h_conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')    \n",
    "    #h_pool2 = tf.reshape(h_pool2, [-1, 5*5*64])  #将数据转换为1维\n",
    "    h_pool2 = tf.nn.dropout(h_conv2, keep_prob_)\n",
    "    \n",
    "    h_pool2 = tf.reshape(h_pool2, [-1, 15*15*32])  #将数据转换为1维\n",
    "    #第四层全连接层，将维度转换为500\n",
    "    hidden2 = tf.nn.relu(tf.matmul(h_pool2, W2) + b2)\n",
    "    hidden2_drop = tf.nn.dropout(hidden2, keep_prob_)\n",
    "    \n",
    "    #第五层全连接层，维度转换为5，进行5分类\n",
    "    output_ = tf.matmul(hidden2_drop, W3) + b3\n",
    "    # Cost function and optimizer\n",
    "    #二次代价函数，计算预测值与真实值之间的误差代价值-loss，其中第一个参数logits为最后一层输出，第二个为训练目标值即分类值\n",
    "    #先通过Softmax函数，输出X对应输出每一类的概率大小，其次和真实值进行“交叉熵”，最终，对向量求均值，得到代价loss\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=output_, labels=labels_))\n",
    "    tf.add_to_collection('losses', loss)\n",
    "    cost = tf.add_n(tf.get_collection('losses'))\n",
    "    #cost = loss\n",
    "    \n",
    "    #梯度下降法，数据量选择AdamOptimizer\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate_).minimize(cost)\n",
    "    \n",
    "    # Accuracy\n",
    "    #correct_pred 返回一个布尔型数组，通过转化为0-1值后来计算准确率\n",
    "    correct_pred = tf.equal(tf.argmax(output_, 1), tf.argmax(labels_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "    #预测值\n",
    "    pred = tf.argmax(output_, 1, name='cnn')\n",
    "    print(pred)\n",
    "    #正确值\n",
    "    label = tf.argmax(labels_, 1)\n",
    "\n",
    "tf.summary.scalar(\"accuracy\", accuracy)\n",
    "tf.summary.scalar('loss_function', cost)\n",
    "\n",
    "if (os.path.exists(r'./checkpoints') == False):\n",
    "    !mkdir checkpoints\n",
    "\n",
    "validation_acc = []\n",
    "validation_loss = []\n",
    "\n",
    "train_acc = []\n",
    "train_loss = []\n",
    "\n",
    "with graph.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    iteration = 1\n",
    "    # summaries合并\n",
    "    merged = tf.summary.merge_all()    \n",
    "    # 写到指定的磁盘路径中\n",
    "    train_writer = tf.summary.FileWriter(log_dir + '/train', sess.graph)\n",
    "    test_writer = tf.summary.FileWriter(log_dir + '/test')\n",
    "    # Loop over epochs\n",
    "    for e in range(epochs):\n",
    "        \n",
    "        # Loop over batches\n",
    "        for x,y in get_batches(X_train, y_tr, batch_size):\n",
    "            x = x.reshape((batch_size,features_num))\n",
    "            # Feed dictionary\n",
    "            feed = {inputs_ : x, labels_ : y,keep_prob_ : 0.45, learning_rate_ : learning_rate}\n",
    "             # Loss\n",
    "            summary_str, loss, _ , acc = sess.run([merged, cost, optimizer, accuracy], feed_dict = feed)\n",
    "         \n",
    "            train_acc.append(acc)\n",
    "            train_loss.append(loss)\n",
    "            # Print at each 5 iters\n",
    "            if (iteration % 5 == 0):\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {:d}\".format(iteration),\n",
    "                      \"Train loss: {:6f}\".format(loss),\n",
    "                      \"Train acc: {:.6f}\".format(acc))\n",
    "                train_writer.add_summary(summary_str, e);\n",
    "            # Compute validation loss at every 10 iterations\n",
    "            if (iteration%10 == 0):                \n",
    "                val_acc_ = []\n",
    "                val_loss_ = []\n",
    "                \n",
    "                x_v = X_test.reshape(-1, features_num)\n",
    "                y_v = y_vld\n",
    "                feed = {inputs_ : x_v, labels_ : y_v, keep_prob_ : 1.0} \n",
    "                summary, loss_v, acc_v, pred_labels = sess.run([merged, cost, accuracy, pred], feed_dict = feed)                    \n",
    "                val_acc_.append(acc_v)\n",
    "                val_loss_.append(loss_v)\n",
    "                \n",
    "                #for x_v, y_v in get_batches(X_test, y_vld, batch_size):\n",
    "                    #x_v = x_v.reshape(batch_size, features_num)\n",
    "                    # Feed\n",
    "                    #feed = {inputs_ : x_v, labels_ : y_v, keep_prob_ : 1.0}                      \n",
    "                    # Loss\n",
    "                    #summary, loss_v, acc_v, pred_labels = sess.run([merged, cost, accuracy, pred], feed_dict = feed)                    \n",
    "                    #val_acc_.append(acc_v)\n",
    "                    #val_loss_.append(loss_v)\n",
    "                    \n",
    "                # Print info\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {:d}\".format(iteration),\n",
    "                      \"Validation loss: {:6f}\".format(np.mean(val_loss_)),\n",
    "                      \"Validation acc: {:.6f}\".format(np.mean(val_acc_)))\n",
    "                test_writer.add_summary(summary, e);\n",
    "                # Store\n",
    "                validation_acc.append(np.mean(val_acc_))\n",
    "                validation_loss.append(np.mean(val_loss_))\n",
    "            # Iterate \n",
    "            iteration += 1    \n",
    "            \n",
    "        \n",
    "#     # 保存二进制模型\n",
    "#     output_graph_def = tf.graph_util.convert_variables_to_constants(sess, sess.graph_def, output_node_names=['labels'])\n",
    "#     with tf.gfile.FastGFile(r'D:\\py_projects\\ML\\ML_Demo\\financial\\creditGrade.pb', mode='wb') as f:\n",
    "#         f.write(output_graph_def.SerializeToString())\n",
    "\n",
    "    saver.save(sess,\"checkpoints-cnn/creditGrade.ckpt\")\n",
    "\n",
    "    # 保存二进制模型\n",
    "    output_graph_def = tf.graph_util.convert_variables_to_constants(sess, sess.graph_def, output_node_names=['cnn'])\n",
    "    with tf.gfile.FastGFile(r'cnn.pb', mode='wb') as f:\n",
    "        f.write(output_graph_def.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "t = np.arange(iteration-1)\n",
    "#print(np.array(train_loss))\n",
    "plt.figure(figsize = (9,6))\n",
    "plt.plot(t, np.array(train_loss), 'r-', t[t % 10 == 0], np.array(validation_loss), 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot Accuracies\n",
    "plt.figure(figsize = (9,6))\n",
    "\n",
    "plt.plot(t, np.array(train_acc), 'r-', t[t % 10 == 0], validation_acc, 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Accuray\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_acc = []\n",
    "pred_labels = []\n",
    "label = []\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    # Restore\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints-cnn'))\n",
    "    \n",
    "    x_v = X_test.reshape(-1, features_num)\n",
    "    y_v = y_vld\n",
    "    feed = {inputs_ : x_v, labels_ : y_v, keep_prob_ : 1.0} \n",
    "    batch_acc = sess.run(accuracy, feed_dict=feed)\n",
    "    preds = sess.run(pred, feed_dict=feed)\n",
    "    labels = sess.run(label, feed_dict=feed)\n",
    "    #max_index = np.argmax(prediction)\n",
    "    #print(max_index)\n",
    "    test_acc.append(batch_acc)\n",
    "    pred_labels.append(preds)\n",
    "    label.append(labels)\n",
    "    \n",
    "    #for x_t, y_t in get_batches(X_test, y_vld, batch_size):\n",
    "        #x_t = x_t.reshape((batch_size, features_num))\n",
    "        #feed = {inputs_: x_t,\n",
    "        #        labels_: y_t,\n",
    "        #        keep_prob_: 1}\n",
    "       \n",
    "        #batch_acc = sess.run(accuracy, feed_dict=feed)\n",
    "        #preds = sess.run(pred, feed_dict=feed)\n",
    "        #labels = sess.run(label, feed_dict=feed)\n",
    "        #test_acc.append(batch_acc)\n",
    "        #pred_labels.append(preds)\n",
    "        #label.append(labels)\n",
    "    print(\"Test accuracy: {:.6f}\".format(np.mean(test_acc)))\n",
    "    print(\"pred value\", pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TensorFlow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
