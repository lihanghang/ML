{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-3-1e601ed4db92>, line 173)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-1e601ed4db92>\"\u001b[0;36m, line \u001b[0;32m173\u001b[0m\n\u001b[0;31m    from sklearn.metrics import mean_squared_error\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdate\n",
    "%matplotlib inline \n",
    "\n",
    "# 加载数据\n",
    "path = \"./房地产投资潜力指数-北京.xlsx\"\n",
    "# skipfooter=3\n",
    "\n",
    "Matrix_pre = np.zeros(shape=(4,1))\n",
    "\n",
    "#print (Matrix_pre)\n",
    "\n",
    "for i in range(1,6):\n",
    "    \n",
    "    print('**************************************************************************\\n')\n",
    "    print('**************************当前是第'+str(i)+'列数据,共5列**************************\\n')\n",
    "    print('**************************************************************************\\n')\n",
    "\n",
    "    dataset = pd.read_excel(path, sheet_name = 'train', usecols= [i],  nrows = 16)\n",
    "    dataset = np.array(dataset)\n",
    "\n",
    "    print(dataset)\n",
    "\n",
    "    plt.plot(dataset)\n",
    "    plt.show()\n",
    "\n",
    "    # normalize the dataset\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    dataSet = scaler.fit_transform(dataset)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # split into train and test sets; 80% 是训练数据，其余是测试数据\n",
    "    train_size = int(len(dataSet) * 0.8)\n",
    "    test_size = len(dataSet) - train_size\n",
    "    train, test = dataSet[0:train_size], dataSet[train_size:len(dataSet)]\n",
    "\n",
    "    # 数据格式转化(t,t+1)\n",
    "    def convert_data(data, time_step=1):\n",
    "        data_X,data_Y = [],[]  \n",
    "        for i in range(len(data) - time_step - 1):\n",
    "            x = data[i: (i + time_step)]  \n",
    "            y = data[i+1:i + time_step+1]      \n",
    "            data_X.append(x.tolist())\n",
    "            data_Y.append(y.tolist()) \n",
    "        return data_X, data_Y\n",
    "\n",
    "    # fix random seed for reproducibility\n",
    "    np.random.seed(7)\n",
    "\n",
    "    # use this function to prepare the train and test datasets for modeling\n",
    "    #time_step=5\n",
    "    time_step = 5      #时间步\n",
    "    train_x, train_y = convert_data(train, time_step)\n",
    "    test_x, test_y = convert_data(test, time_step)\n",
    "\n",
    "    #———————————————————形成训练集—————————————————————\n",
    "    #设置常量\n",
    "    hidden_unit = 10       #hidden layer units 记忆和储存过去状态的节点个数\n",
    "    batch_size = 5    #每一批次训练多少个样例\n",
    "    input_size = 1      #输入层维度\n",
    "    output_size = 1     #输出层维度\n",
    "    lr = 0.0001       #学习率\n",
    "\n",
    "    import tensorflow as tf\n",
    "\n",
    "\n",
    "    # LSTM 的 X 需要有这样的结构： [samples, time steps, features]，所以做一下变换\n",
    "    X = tf.placeholder(tf.float32, [None,time_step,input_size] ,name = 'inputs')    #每批次输入网络的tensor\n",
    "    Y = tf.placeholder(tf.float32, [None,time_step,output_size] ,name = 'outputs')   #每批次tensor对应的标签\n",
    "    # 输入层、输出层权重、偏置\n",
    "    with tf.name_scope('layer'):\n",
    "            with tf.name_scope('weights'):\n",
    "                weights={\n",
    "                         'in':tf.Variable(tf.random_normal([input_size,hidden_unit])),\n",
    "                         'out':tf.Variable(tf.random_normal([hidden_unit,1]))\n",
    "                         }\n",
    "            with tf.name_scope('biases'):\n",
    "                biases={\n",
    "                        'in':tf.Variable(tf.constant(0.1,shape=[hidden_unit,])),\n",
    "                        'out':tf.Variable(tf.constant(0.1,shape=[1,]))\n",
    "                        }\n",
    "\n",
    "    def lstm(batch):  #参数：输入网络批次数目\n",
    "\n",
    "        w_in = weights['in']\n",
    "        b_in = biases['in']\n",
    "        input = tf.reshape(X,[-1,input_size])  #需要将tensor转成2维进行计算，计算后的结果作为隐藏层的输入\n",
    "        lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(hidden_unit) #10个节点\n",
    "        input_lstm = tf.matmul(input, w_in) + b_in\n",
    "        input_lstm = tf.reshape(input_lstm, [-1, time_step, hidden_unit])  #将tensor转成3维，作为lstm cell的输入      \n",
    "        print(input_lstm)\n",
    "        init_state = lstm_cell.zero_state(batch,dtype = tf.float32)\n",
    "        # output_rnn是记录lstm每个隐状态输出节点的结果，final_states是最后一个cell的结果，数据格式为tuple\n",
    "        output_rnn, final_states = tf.nn.dynamic_rnn(\n",
    "            lstm_cell, \n",
    "            input_lstm, \n",
    "            initial_state = init_state, \n",
    "            dtype = tf.float32) \n",
    "\n",
    "        output = tf.reshape(output_rnn, [-1, hidden_unit]) #  作为输出层的输入\n",
    "        w_out = weights['out']\n",
    "        b_out = biases['out']\n",
    "        # 预测数据\n",
    "        multi = tf.matmul(output, w_out)\n",
    "        pred = tf.add(multi, b_out, name='preds')  \n",
    "        return pred, final_states\n",
    "\n",
    "    train_loss = []\n",
    "    def train_lstm():   \n",
    "        global batch_size\n",
    "        iteration = 1\n",
    "        epochs = 1000\n",
    "    #     with tf.variable_scope(\"sec_lstm\"):\n",
    "        pred, _ = lstm(batch_size)\n",
    "        # 损失函数\n",
    "        loss = tf.reduce_mean(tf.square(tf.reshape(pred,[-1])-tf.reshape(Y, [-1])))\n",
    "        #tf.summary.scalar('loss_function', loss)\n",
    "        train_op = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "        saver = tf.train.Saver(tf.global_variables())\n",
    "        with tf.Session() as sess:\n",
    "            keep_prob = tf.placeholder(tf.float32)\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            # summaries合并\n",
    "            #merged = tf.summary.merge_all()    \n",
    "            # 写到指定的磁盘路径中\n",
    "            #train_writer = tf.summary.FileWriter(log_dir + '/train', sess.graph)\n",
    "            # 重复训练5000次\n",
    "            for e in range(epochs):\n",
    "                step=0\n",
    "                start = 0\n",
    "                end = start + batch_size\n",
    "                while(end < len(train_x)):\n",
    "                    x = train_x[start:end]\n",
    "                    y = train_y[start:end]\n",
    "                    _,loss_ = sess.run([train_op, loss], feed_dict = {X: x, Y:y, keep_prob : 0.3})\n",
    "                    start += batch_size\n",
    "                    end = start + batch_size\n",
    "                    # 每10步保存一次参数\n",
    "                    if step% 10 == 0:                    \n",
    "                        print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                        \"Iteration: {:d}\".format(iteration),\n",
    "                        \"Train loss: {:6f}\".format(loss_))\n",
    "                        #train_writer.add_summary(summary, e);\n",
    "\n",
    "                    train_loss.append(loss_)\n",
    "                    iteration += 1  \n",
    "                    step += 1\n",
    "            saver.save(sess, \"./lstm/predict.ckpt\")\n",
    "             # 保存二进制模型\n",
    "            builder = tf.saved_model.builder.SavedModelBuilder(\"./model/model_\"+ str(i))\n",
    "            builder.add_meta_graph_and_variables(sess, ['mytag'])\n",
    "            builder.save()\n",
    "            #绘训练过程指标图\n",
    "            t = np.arange(iteration - 1)\n",
    "            plt.figure(figsize = (9,6))\n",
    "            plt.plot(t, np.array(train_loss),  'r-')\n",
    "            plt.xlabel(\"iteration\")\n",
    "            plt.ylabel(\"Loss\")\n",
    "            plt.legend(['train'], loc='upper right')\n",
    "            plt.show()        \n",
    "\n",
    "    #with tf.variable_scope('rnn', reuse=tf.AUTO_REUSE):\n",
    "        #train_lstm()\n",
    "\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    import math\n",
    "\n",
    "    def prediction():\n",
    "\n",
    "            pred, _ = lstm(1)  # 预测时只输入[1,time_step,inputSize]的测试数据\n",
    "            saver = tf.train.Saver(tf.global_variables())\n",
    "            #预测季度\n",
    "            pre_quarter = 4\n",
    "            with tf.Session() as sess:\n",
    "                # 参数恢复\n",
    "                module_file = tf.train.latest_checkpoint(\"./lstm/\")\n",
    "                saver.restore(sess, module_file)\n",
    "                # 取训练集最后一行为测试样本. shape=[1,time_step,inputSize]\n",
    "                prev_seq = train_x[-1]\n",
    "                predict = []\n",
    "                print(prev_seq)\n",
    "                # 得到之后10个季度的预测结果\n",
    "                for i in range(pre_quarter):\n",
    "                    next_seq = sess.run(pred,feed_dict={X:[prev_seq]})\n",
    "                    predict.append(next_seq[-1])   \n",
    "                    #每次得到最后一个时间步的预测结果，与之前的数据加在一起，形成新的测试样本\n",
    "                    #np.vstack()表示垂直（按照行顺序）的把数组给堆叠起来。\n",
    "                    prev_seq = np.vstack((prev_seq[1:],next_seq[-1]))\n",
    "\n",
    "                #得到实际预测值\n",
    "                predictY = scaler.inverse_transform(predict)\n",
    "\n",
    "                testY = scaler.inverse_transform(test)\n",
    "                print(\"预测值：\", predictY)\n",
    "                print(\"真实值：\",testY )\n",
    "\n",
    "\n",
    "                #Matrix_pre[0] = predictY\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                #print (C)\n",
    "\n",
    "                global Matrix_pre\n",
    "                Matrix_pre = (np.hstack((Matrix_pre,predictY)))\n",
    "\n",
    "\n",
    "                #以折线图表示结果\n",
    "                plt.figure()\n",
    "                plt.title(\"lead index\")\n",
    "                plt.plot(list(range(len(testY))), testY, 'cx--', list(range(len(predict))), predictY, 'b--')\n",
    "                plt.xlabel(\"date-num\")\n",
    "                plt.ylabel(\"index\")\n",
    "                plt.legend(['train', 'pred'], loc='upper right')\n",
    "                plt.plot()\n",
    "                plt.show()\n",
    "\n",
    "    with tf.variable_scope('rnn', reuse = tf.AUTO_REUSE):\n",
    "        prediction() \n",
    "\n",
    "#存进excel文件\n",
    "Matrix_input = pd.DataFrame(Matrix_pre)\n",
    "writer = pd.ExcelWriter('./经济因子预测数据.xlsx')\n",
    "Matrix_input.to_excel(writer, float_format='%.2f', header = False, index = False,) # float_format 控制精度\n",
    "writer.save()\n",
    "\n",
    "print('**************************************************************************\\n')\n",
    "print('*********************************迭代结束*********************************\\n')\n",
    "print('**************************************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TensorFlow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
